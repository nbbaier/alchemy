This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where empty lines have been removed.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*, .cursorrules, .cursor/rules/*, .clinerules, CLAUDE.md
- Files matching these patterns are excluded: .*.*, **/*.pbxproj, **/node_modules/**, **/dist/**, **/build/**, **/compile/**, **/*.spec.*, **/*.pyc, **/.env, **/.env.*, **/*.env, **/*.env.*, **/*.lock, **/*.lockb, **/package-lock.*, **/pnpm-lock.*, **/*.tsbuildinfo
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Empty lines have been removed from all files
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.cursor/
  rules/
    cloudflare.mdc
    vibe-tools.mdc
.github/
  workflows/
    publish.yml
    test.yml
alchemy/
  src/
    ai/
      ark.ts
      astro-file.ts
      client.ts
      css-file.ts
      data.ts
      document.ts
      html-file.ts
      index.ts
      json-file.ts
      typescript-file.ts
      vue-file.ts
      yaml-file.ts
    aws/
      oidc/
        github-oidc-provider.ts
        index.ts
        oidc-provider.ts
      account-id.ts
      bucket.ts
      credentials.ts
      function.ts
      index.ts
      policy-attachment.ts
      policy.ts
      queue.ts
      role.ts
      ses.ts
      table.ts
    cloudflare/
      bundle/
        alias-plugin.ts
        build-failures.ts
        bundle-worker.ts
        external.ts
        local-dev-cloudflare-shim.ts
        nodejs-compat-mode.ts
        nodejs-compat.ts
      account-api-token.ts
      ai-gateway.ts
      ai.ts
      api-error.ts
      api.ts
      asset-manifest.ts
      assets.ts
      auth.ts
      bindings.ts
      bound.ts
      browser-rendering.ts
      bucket.ts
      custom-domain.ts
      d1-database.ts
      d1-migrations.ts
      dns-records.ts
      durable-object-namespace.ts
      event-source.ts
      hyperdrive.ts
      index.ts
      kv-namespace.ts
      nuxt.ts
      permission-groups.ts
      pipeline.ts
      queue-consumer.ts
      queue.ts
      r2-rest-state-store.ts
      redwood.ts
      response.ts
      route.ts
      tanstack-start.ts
      types.ts
      user.ts
      vectorize-index.ts
      vectorize-metadata-index.ts
      vite.ts
      website.ts
      worker-metadata.ts
      worker-migration.ts
      worker.ts
      workflow.ts
      wrangler.json.ts
      zone-settings.ts
      zone.ts
    dns/
      godaddy.ts
      import-dns.ts
      index.ts
      record.ts
    esbuild/
      bundle.ts
      index.ts
    fs/
      copy-file.ts
      file-collection.ts
      file-ref.ts
      file-system-state-store.ts
      file.ts
      folder.ts
      index.ts
      static-astro-file.ts
      static-css-file.ts
      static-html-file.ts
      static-json-file.ts
      static-text-file.ts
      static-typescript-file.ts
      static-vue-file.ts
      static-yaml-file.ts
    github/
      client.ts
      index.ts
      repository-environment.ts
      secret.ts
    internal/
      docs/
        providers.ts
    neon/
      api-error.ts
      api.ts
      index.ts
      project.ts
    os/
      exec.ts
      index.ts
    stripe/
      index.ts
      meter.ts
      price.ts
      product.ts
      webhook.ts
    test/
      bun.ts
      prune.ts
    util/
      content-type.ts
      dedent.ts
      ignore.ts
      retry.ts
      rm.ts
      sha256.ts
      slugify.ts
    web/
      vitepress/
        config.ts
        custom-theme.ts
        dependencies.ts
        home-page.ts
        index.ts
        process-front-matter-files.ts
        vitepress.ts
      astro.ts
      shadcn-component.ts
      shadcn.ts
      tailwind.ts
      vite.ts
    alchemy.ts
    apply.ts
    context.ts
    destroy.ts
    encrypt.ts
    env.ts
    index.ts
    resource.ts
    scope.ts
    secret.ts
    serde.ts
    state.ts
  test/
    aws/
      function.test.ts
      queue.test.ts
      role.test.ts
      ses.test.ts
      table.test.ts
    cloudflare/
      migrations/
        001_create_table.sql
      account-api-token.test.ts
      ai-gateway.test.ts
      ai.test.ts
      browser-handler.ts
      browser-rendering.test.ts
      bucket.test.ts
      bundle-handler-als.ts
      bundle-handler.ts
      bundle.test.ts
      d1-database.test.ts
      dns-records.test.ts
      hyperdrive.test.ts
      kv-namespace.test.ts
      permission-groups.test.ts
      pipeline.test.ts
      queue-consumer.test.ts
      queue.test.ts
      r2-rest-state-store.test.ts
      route.test.ts
      unenv-handler.ts
      unenv.test.ts
      vectorize-index.test.ts
      vectorize-metadata-index.test.ts
      worker.test.ts
      wrangler-json.test.ts
      zone.test.ts
    fs/
      copy-file.test.ts
    github/
      repository-environment.test.ts
      secret.test.ts
    neon/
      project.test.ts
    os/
      exec.test.ts
    stripe/
      meter.test.ts
    util/
      dedent.test.ts
    esbuild.test.ts
    handler.ts
    run.ts
    scope.test.ts
    serde.test.ts
    stripe.test.ts
    util.ts
  package.json
  tsconfig.json
  tsconfig.test.json
alchemy-web/
  .vitepress/
    theme/
      index.ts
      style.css
    config.mts
  blogs/
    2025-04-08-decade-long-journey.md
    index.md
  docs/
    advanced/
      serde.md
    concepts/
      bindings.md
      destroy.md
      phase.md
      resource.md
      scope.md
      secret.md
      state.md
      testing.md
    guides/
      cloudflare-auth.md
      cloudflare-durable-objects.md
      cloudflare-nuxt-pipeline.md
      cloudflare-queue.md
      cloudflare-redwood.md
      cloudflare-tanstack-start.md
      cloudflare-vitejs.md
      cloudflare-workflows.md
      custom-resources.md
      custom-state-store.md
    providers/
      ai/
        astro-file.md
        css-file.md
        data.md
        document.md
        html-file.md
        json-file.md
        typescript-file.md
        vue-file.md
        yaml-file.md
      aws/
        bucket.md
        function.md
        policy-attachment.md
        policy.md
        queue.md
        role.md
        ses.md
        table.md
      cloudflare/
        account-api-token.md
        account-id.md
        ai-gateway.md
        assets.md
        bucket.md
        custom-domain.md
        d1-database.md
        dns-records.md
        durable-object-namespace.md
        hyperdrive.md
        kv-namespace.md
        nuxt.md
        permission-groups.md
        pipeline.md
        queue-consumer.md
        queue.md
        redwood.md
        route.md
        tanstack-start.md
        vite.md
        website.md
        worker.md
        workflow.md
        wrangler.json.md
        zone.md
      dns/
        import-dns.md
      esbuild/
        bundle.md
      fs/
        copy-file.md
        file.md
        folder.md
        static-astro-file.md
        static-css-file.md
        static-html-file.md
        static-json-file.md
        static-text-file.md
        static-typescript-file.md
        static-vue-file.md
        static-yaml-file.md
      github/
        repository-environment.md
        secret.md
      neon/
        project.md
      os/
        exec.md
      stripe/
        meter.md
        price.md
        product.md
        webhook.md
    getting-started.md
    index.md
    what-is-alchemy.md
  .gitignore
  index.md
  package.json
examples/
  aws-app/
    src/
      index.ts
    alchemy.run.ts
    package.json
    tsconfig.json
  cloudflare-nuxt-pipeline/
    pages/
      index.vue
    public/
      robots.txt
    server/
      api/
        pipeline.post.ts
      tsconfig.json
    .gitignore
    alchemy.run.ts
    app.vue
    env.d.ts
    index.ts
    nuxt.config.ts
    package.json
    README.md
    tsconfig.json
  cloudflare-redwood/
    drizzle/
      meta/
        _journal.json
        0000_snapshot.json
      0000_lame_kitty_pryde.sql
    src/
      app/
        pages/
          Home.tsx
        shared/
          links.ts
        Document.tsx
        headers.ts
      db/
        schema.ts
        seed.ts
      client.tsx
      worker.tsx
    types/
      env.d.ts
      rw.d.ts
      vite.d.ts
    .env.example
    .gitignore
    .prettierrc
    alchemy.run.ts
    drizzle.config.ts
    package.json
    README.md
    tsconfig.json
    vite.config.mts
    worker-configuration.d.ts
  cloudflare-tanstack-start/
    .vscode/
      settings.json
    public/
      site.webmanifest
    src/
      components/
        DefaultCatchBoundary.tsx
        NotFound.tsx
        PostError.tsx
        UserError.tsx
      routes/
        _pathlessLayout/
          _nested-layout/
            route-a.tsx
            route-b.tsx
          _nested-layout.tsx
        api/
          users.$id.ts
          users.ts
        __root.tsx
        _pathlessLayout.tsx
        deferred.tsx
        index.tsx
        posts_.$postId.deep.tsx
        posts.$postId.tsx
        posts.index.tsx
        posts.route.tsx
        redirect.tsx
        users.$userId.tsx
        users.index.tsx
        users.route.tsx
      styles/
        app.css
      utils/
        loggingMiddleware.tsx
        posts.tsx
        seo.ts
        users.tsx
      api.ts
      client.tsx
      env.d.ts
      global-middleware.ts
      router.tsx
      routeTree.gen.ts
      ssr.tsx
    .gitignore
    .prettierignore
    alchemy.run.ts
    app.config.ts
    package.json
    postcss.config.mjs
    README.md
    tailwind.config.mjs
    tsconfig.json
  cloudflare-vite/
    public/
      vite.svg
    src/
      assets/
        react.svg
      auth/
        issuer.ts
        subjects.ts
      App.css
      App.tsx
      env.d.ts
      index.css
      index.ts
      main.tsx
      vite-env.d.ts
    .gitignore
    alchemy.run.ts
    index.html
    package.json
    tsconfig.json
    vite.config.ts
  cloudflare-worker/
    src/
      do.ts
      env.d.ts
      worker.ts
      workflow.ts
    .gitignore
    alchemy.run.ts
    package.json
    tsconfig.json
scripts/
  shell.ts
  smoke.sh
stacks/
  docs.run.ts
  env.ts
  repo.run.ts
  website.run.ts
.cursorrules
.gitignore
biome.json
LICENSE
package.json
README.md
tsconfig.base.json
tsconfig.json
tsconfig.stacks.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".cursor/rules/cloudflare.mdc">
---
description: 
globs: alchemy/src/cloudflare/*
alwaysApply: false
---
When adding a new resource that can be bound to a worker, make sure to update:

1. bindings.ts - add the binding type to the union
2. bound.ts - map the Alchemy resource to the Cloudflare runtime binding type
3. worker.ts - map the binding to the cloduflare metadata api
4. {resource}.ts - add a new file for the resource alchemy/src/cloudflare/{resource}.ts
5. {resource}.test.ts - add a new file for the resource alchemy/test/cloudflare/{resource}.test.ts
</file>

<file path=".cursor/rules/vibe-tools.mdc">
---
description: Global Rule. This rule should ALWAYS be loaded.
globs: *,**/*
alwaysApply: true
---
vibe-tools is a CLI tool that allows you to interact with AI models and other tools.
vibe-tools is installed on this machine and it is available to you to execute. You're encouraged to use it.

<vibe-tools Integration>
# Instructions
Use the following commands to get AI assistance:

**Direct Model Queries:**
`vibe-tools ask "<your question>" --provider <provider> --model <model>` - Ask any model from any provider a direct question (e.g., `vibe-tools ask "What is the capital of France?" --provider openai --model o3-mini`). Note that this command is generally less useful than other commands like `repo` or `plan` because it does not include any context from your codebase or repository. In general you should not use the ask command because it does not include any context. The other commands like `web`, `doc`, `repo`, or `plan` are usually better. If you are using it, make sure to include in your question all the information and context that the model might need to answer usefully.

**Ask Command Options:**
--provider=<provider>: AI provider to use (openai, anthropic, perplexity, gemini, modelbox, openrouter, or xai)
--model=<model>: Model to use (required for the ask command)
--reasoning-effort=<low|medium|high>: Control the depth of reasoning for supported models (OpenAI o1/o3-mini models and Claude 3.7 Sonnet). Higher values produce more thorough responses for complex questions.

**Implementation Planning:**
`vibe-tools plan "<query>"` - Generate a focused implementation plan using AI (e.g., `vibe-tools plan "Add user authentication to the login page"`)
The plan command uses multiple AI models to:
1. Identify relevant files in your codebase (using Gemini by default)
2. Extract content from those files
3. Generate a detailed implementation plan (using OpenAI o3-mini by default)

**Plan Command Options:**
--fileProvider=<provider>: Provider for file identification (gemini, openai, anthropic, perplexity, modelbox, openrouter, or xai)
--thinkingProvider=<provider>: Provider for plan generation (gemini, openai, anthropic, perplexity, modelbox, openrouter, or xai)
--fileModel=<model>: Model to use for file identification
--thinkingModel=<model>: Model to use for plan generation
--with-doc=<doc_url>: Fetch content from a document URL and include it as context for both file identification and planning (e.g., `vibe-tools plan "implement feature X following the spec" --with-doc=https://example.com/feature-spec`)

**Web Search:**
`vibe-tools web "<your question>"` - Get answers from the web using a provider that supports web search (e.g., Perplexity models and Gemini Models either directly or from OpenRouter or ModelBox) (e.g., `vibe-tools web "latest shadcn/ui installation instructions"`)
Note: web is a smart autonomous agent with access to the internet and an extensive up to date knowledge base. Web is NOT a web search engine. Always ask the agent for what you want using a proper sentence, do not just send it a list of keywords. In your question to web include the context and the goal that you're trying to acheive so that it can help you most effectively.
when using web for complex queries suggest writing the output to a file somewhere like local-research/<query summary>.md.

**Web Command Options:**
--provider=<provider>: AI provider to use (perplexity, gemini, modelbox, or openrouter)

**Repository Context:**
`vibe-tools repo "<your question>" [--subdir=<path>] [--from-github=<username/repo>] [--with-doc=<doc_url>]` - Get context-aware answers about this repository using Google Gemini (e.g., `vibe-tools repo "explain authentication flow"`). Use the optional `--subdir` parameter to analyze a specific subdirectory instead of the entire repository (e.g., `vibe-tools repo "explain the code structure" --subdir=src/components`). Use the optional `--from-github` parameter to analyze a remote GitHub repository without cloning it locally (e.g., `vibe-tools repo "explain the authentication system" --from-github=username/repo-name`). Use the optional `--with-doc` parameter to include content from a URL as additional context (e.g., `vibe-tools repo "implement feature X following the design spec" --with-doc=https://example.com/design-spec`).

**Documentation Generation:**
`vibe-tools doc [options] [--with-doc=<doc_url>]` - Generate comprehensive documentation for this repository (e.g., `vibe-tools doc --output docs.md`). Can incorporate document context from a URL (e.g., `vibe-tools doc --with-doc=https://example.com/existing-docs`).

**YouTube Video Analysis:**
`vibe-tools youtube "<youtube-url>" [question] [--type=<summary|transcript|plan|review|custom>]` - Analyze YouTube videos and generate detailed reports (e.g., `vibe-tools youtube "https://youtu.be/43c-Sm5GMbc" --type=summary`)
Note: The YouTube command requires a `GEMINI_API_KEY` to be set in your environment or .vibe-tools.env file as the GEMINI API is the only interface that supports YouTube analysis.

**GitHub Information:**
`vibe-tools github pr [number]` - Get the last 10 PRs, or a specific PR by number (e.g., `vibe-tools github pr 123`)
`vibe-tools github issue [number]` - Get the last 10 issues, or a specific issue by number (e.g., `vibe-tools github issue 456`)

**ClickUp Information:**
`vibe-tools clickup task <task_id>` - Get detailed information about a ClickUp task including description, comments, status, assignees, and metadata (e.g., `vibe-tools clickup task "task_id"`)

**Model Context Protocol (MCP) Commands:**
Use the following commands to interact with MCP servers and their specialized tools:
`vibe-tools mcp search "<query>"` - Search the MCP Marketplace for available servers that match your needs (e.g., `vibe-tools mcp search "git repository management"`)
`vibe-tools mcp run "<query>"` - Execute MCP server tools using natural language queries (e.g., `vibe-tools mcp run "list files in the current directory" --provider=openrouter`). The query must include sufficient information for vibe-tools to determine which server to use, provide plenty of context.

The `search` command helps you discover servers in the MCP Marketplace based on their capabilities and your requirements. The `run` command automatically selects and executes appropriate tools from these servers based on your natural language queries. If you want to use a specific server include the server name in your query. E.g. `vibe-tools mcp run "using the mcp-server-sqlite list files in directory --provider=openrouter"`

**Notes on MCP Commands:**
- MCP commands require `ANTHROPIC_API_KEY` or `OPENROUTER_API_KEY` to be set in your environment
- By default the `mcp` command uses Anthropic, but takes a --provider argument that can be set to 'anthropic' or 'openrouter'
- Results are streamed in real-time for immediate feedback
- Tool calls are automatically cached to prevent redundant operations
- Often the MCP server will not be able to run because environment variables are not set. If this happens ask the user to add the missing environment variables to the cursor tools env file at ~/.vibe-tools/.env

**Stagehand Browser Automation:**
`vibe-tools browser open <url> [options]` - Open a URL and capture page content, console logs, and network activity (e.g., `vibe-tools browser open "https://example.com" --html`)
`vibe-tools browser act "<instruction>" --url=<url | 'current'> [options]` - Execute actions on a webpage using natural language instructions (e.g., `vibe-tools browser act "Click Login" --url=https://example.com`)
`vibe-tools browser observe "<instruction>" --url=<url> [options]` - Observe interactive elements on a webpage and suggest possible actions (e.g., `vibe-tools browser observe "interactive elements" --url=https://example.com`)
`vibe-tools browser extract "<instruction>" --url=<url> [options]` - Extract data from a webpage based on natural language instructions (e.g., `vibe-tools browser extract "product names" --url=https://example.com/products`)

**Notes on Browser Commands:**
- All browser commands are stateless unless --connect-to is used to connect to a long-lived interactive session. In disconnected mode each command starts with a fresh browser instance and closes it when done.
- When using `--connect-to`, special URL values are supported:
  - `current`: Use the existing page without reloading
  - `reload-current`: Use the existing page and refresh it (useful in development)
  - If working interactively with a user you should always use --url=current unless you specifically want to navigate to a different page. Setting the url to anything else will cause a page refresh loosing current state.
- Multi step workflows involving state or combining multiple actions are supported in the `act` command using the pipe (|) separator (e.g., `vibe-tools browser act "Click Login | Type 'user@example.com' into email | Click Submit" --url=https://example.com`)
- Video recording is available for all browser commands using the `--video=<directory>` option. This will save a video of the entire browser interaction at 1280x720 resolution. The video file will be saved in the specified directory with a timestamp.
- DO NOT ask browser act to "wait" for anything, the wait command is currently disabled in Stagehand.

**Tool Recommendations:**
- `vibe-tools web` is best for general web information not specific to the repository. Generally call this without additional arguments.
- `vibe-tools repo` is ideal for repository-specific questions, planning, code review and debugging. E.g. `vibe-tools repo "Review recent changes to command error handling looking for mistakes, omissions and improvements"`. Generally call this without additional arguments.
- `vibe-tools plan` is ideal for planning tasks. E.g. `vibe-tools plan "Adding authentication with social login using Google and Github"`. Generally call this without additional arguments.
- `vibe-tools doc` generates documentation for local or remote repositories.
- `vibe-tools youtube` analyzes YouTube videos to generate summaries, transcripts, implementation plans, or custom analyses
- `vibe-tools browser` is useful for testing and debugging web apps and uses Stagehand
- `vibe-tools mcp` enables interaction with specialized tools through MCP servers (e.g., for Git operations, file system tasks, or custom tools)

**Running Commands:**
1. Use `vibe-tools <command>` to execute commands (make sure vibe-tools is installed globally using npm install -g vibe-tools so that it is in your PATH)

**General Command Options (Supported by all commands):**
--provider=<provider>: AI provider to use (openai, anthropic, perplexity, gemini, openrouter, modelbox, or xai). If provider is not specified, the default provider for that task will be used.
--model=<model name>: Specify an alternative AI model to use. If model is not specified, the provider's default model for that task will be used.
--max-tokens=<number>: Control response length
--save-to=<file path>: Save command output to a file (in *addition* to displaying it)
--help: View all available options (help is not fully implemented yet)
--debug: Show detailed logs and error information

**Repository Command Options:**
--provider=<provider>: AI provider to use (gemini, openai, openrouter, perplexity, modelbox, anthropic, or xai)
--model=<model>: Model to use for repository analysis
--max-tokens=<number>: Maximum tokens for response
--from-github=<GitHub username>/<repository name>[@<branch>]: Analyze a remote GitHub repository without cloning it locally
--subdir=<path>: Analyze a specific subdirectory instead of the entire repository
--with-doc=<doc_url>: Fetch content from a document URL and include it as context

**Documentation Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Generate documentation for a remote GitHub repository
--provider=<provider>: AI provider to use (gemini, openai, openrouter, perplexity, modelbox, anthropic, or xai)
--model=<model>: Model to use for documentation generation
--max-tokens=<number>: Maximum tokens for response
--with-doc=<doc_url>: Fetch content from a document URL and include it as context

**YouTube Command Options:**
--type=<summary|transcript|plan|review|custom>: Type of analysis to perform (default: summary)

**GitHub Command Options:**
--from-github=<GitHub username>/<repository name>[@<branch>]: Access PRs/issues from a specific GitHub repository

**Browser Command Options (for 'open', 'act', 'observe', 'extract'):**
--console: Capture browser console logs (enabled by default, use --no-console to disable)
--html: Capture page HTML content (disabled by default)
--network: Capture network activity (enabled by default, use --no-network to disable)
--screenshot=<file path>: Save a screenshot of the page
--timeout=<milliseconds>: Set navigation timeout (default: 120000ms for Stagehand operations, 30000ms for navigation)
--viewport=<width>x<height>: Set viewport size (e.g., 1280x720). When using --connect-to, viewport is only changed if this option is explicitly provided
--headless: Run browser in headless mode (default: true)
--no-headless: Show browser UI (non-headless mode) for debugging
--connect-to=<port>: Connect to existing Chrome instance. Special values: 'current' (use existing page), 'reload-current' (refresh existing page)
--wait=<time:duration or selector:css-selector>: Wait after page load (e.g., 'time:5s', 'selector:#element-id')
--video=<directory>: Save a video recording (1280x720 resolution, timestamped subdirectory). Not available when using --connect-to
--url=<url>: Required for `act`, `observe`, and `extract` commands. Url to navigate to before the main command or one of the special values 'current' (to stay on the current page without navigating or reloading) or 'reload-current' (to reload the current page)
--evaluate=<string>: JavaScript code to execute in the browser before the main command

**Nicknames**
Users can ask for these tools using nicknames
Gemini is a nickname for vibe-tools repo
Perplexity is a nickname for vibe-tools web
Stagehand is a nickname for vibe-tools browser
If people say "ask Gemini" or "ask Perplexity" or "ask Stagehand" they mean to use the `vibe-tools` command with the `repo`, `web`, or `browser` commands respectively.

**Xcode Commands:**
`vibe-tools xcode build [buildPath=<path>] [destination=<destination>]` - Build Xcode project and report errors.
**Build Command Options:**
--buildPath=<path>: (Optional) Specifies a custom directory for derived build data. Defaults to ./.build/DerivedData.
--destination=<destination>: (Optional) Specifies the destination for building the app (e.g., 'platform=iOS Simulator,name=iPhone 16 Pro'). Defaults to 'platform=iOS Simulator,name=iPhone 16 Pro'.

`vibe-tools xcode run [destination=<destination>]` - Build and run the Xcode project on a simulator.
**Run Command Options:**
--destination=<destination>: (Optional) Specifies the destination simulator (e.g., 'platform=iOS Simulator,name=iPhone 16 Pro'). Defaults to 'platform=iOS Simulator,name=iPhone 16 Pro'.

`vibe-tools xcode lint` - Run static analysis on the Xcode project to find and fix issues.

**Additional Notes:**
- For detailed information, see `node_modules/vibe-tools/README.md` (if installed locally).
- Configuration is in `vibe-tools.config.json` (or `~/.vibe-tools/config.json`).
- API keys are loaded from `.vibe-tools.env` (or `~/.vibe-tools/.env`).
- ClickUp commands require a `CLICKUP_API_TOKEN` to be set in your `.vibe-tools.env` file.
- Available models depend on your configured provider (OpenAI, Anthropic, xAI, etc.) in `vibe-tools.config.json`.
- repo has a limit of 2M tokens of context. The context can be reduced by filtering out files in a .repomixignore file.
- problems running browser commands may be because playwright is not installed. Recommend installing playwright globally.
- MCP commands require `ANTHROPIC_API_KEY` or `OPENROUTER_API_KEY`
- **Remember:** You're part of a team of superhuman expert AIs. Work together to solve complex problems.
- **Repomix Configuration:** You can customize which files are included/excluded during repository analysis by creating a `repomix.config.json` file in your project root. This file will be automatically detected by `repo`, `plan`, and `doc` commands.

<!-- vibe-tools-version: 0.60.6 -->
</vibe-tools Integration>
</file>

<file path=".github/workflows/publish.yml">
name: Publish
on:
  push:
    branches: [main]
# Ensure only one workflow runs at a time
concurrency:
  group: "publish"
  cancel-in-progress: false
jobs:
  publish:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
      actions: write
    steps:
      - uses: actions/checkout@v4
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest
      - name: Install dependencies
        run: |
          bun install
          # tanstack start doesn't deploy when packages are hoisted ...
          cd examples/cloudflare-tanstack-start
          bun install
          cd ../..
      - name: Check Types
        run: bun run check
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-west-2
      - name: Publsh docs
        run: bun run deploy:website
        env:
          CI: true
          ALCHEMY_STATE_STORE: cloudflare
          AWS_REGION: us-west-2
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_KEY: ${{ secrets.CLOUDFLARE_API_KEY }}
          CLOUDFLARE_BUCKET_NAME: ${{ secrets.CLOUDFLARE_BUCKET_NAME }}
          CLOUDFLARE_EMAIL: ${{ secrets.CLOUDFLARE_EMAIL }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          STRIPE_API_KEY: ${{ secrets.STRIPE_API_KEY }}
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
          SECRET_PASSPHRASE: ${{ secrets.SECRET_PASSPHRASE }}
</file>

<file path=".github/workflows/test.yml">
name: Tests
on:
  push:
    branches: [main]
  pull_request_target:
    types: [opened, reopened, synchronize]
  workflow_dispatch:
# Ensure only one workflow runs at a time
concurrency:
  group: "tests-${{ github.ref }}"
  cancel-in-progress: false
jobs:
  test:
    # environment: ${{ github.event_name != 'push' || github.ref != 'refs/heads/main' && 'test' || '' }}
    environment: ${{ (github.event_name != 'push' || github.ref != 'refs/heads/main') && 'test' || '' }}
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
      actions: write
    steps:
      - uses: actions/checkout@v4
        with:
          # we need this so that test pruning works
          ref: ${{ github.event_name == 'pull_request_target' && github.event.pull_request.head.sha || github.sha }}
          fetch-depth: 0
      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest
      - name: Install dependencies
        run: |
          bun install
          # tanstack start doesn't deploy when packages are hoisted ...
          cd examples/cloudflare-tanstack-start
          bun install
          cd ../..
      - name: Check Types and Lint
        run: bun run check
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: us-west-2
      - name: Run affected tests
        run: |
          # Determine the base commit depending on event type
          if [ "${{ github.event_name }}" == "pull_request_target" ]; then
            # For pull requests, use PR base commit
            BASE_COMMIT="${{ github.event.pull_request.base.sha }}"
          elif [ "${{ github.event_name }}" == "push" ]; then
            # For pushes, use the commit before the push
            BASE_COMMIT="${{ github.event.before }}"
          else
            # For manual runs, use a few commits back to ensure sufficient coverage
            BASE_COMMIT="HEAD~10"
          fi
          echo "Running tests changed since commit: $BASE_COMMIT"
          bun run test --since "$BASE_COMMIT"
          bun run test:smoke
        env:
          CI: true
          ALCHEMY_STATE_STORE: cloudflare
          AWS_REGION: us-west-2
          BRANCH_PREFIX: pr-${{ github.event_name == 'pull_request_target' && github.event.pull_request.number || github.ref_name }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_KEY: ${{ secrets.CLOUDFLARE_API_KEY }}
          CLOUDFLARE_BUCKET_NAME: ${{ secrets.CLOUDFLARE_BUCKET_NAME }}
          CLOUDFLARE_EMAIL: ${{ secrets.CLOUDFLARE_EMAIL }}
          GITHUB_ACCESS_TOKEN: ${{ secrets.ADMIN_GITHUB_ACCESS_TOKEN }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          STRIPE_API_KEY: ${{ secrets.STRIPE_API_KEY }}
          NEON_API_KEY: ${{ secrets.NEON_API_KEY }}
          SECRET_PASSPHRASE: ${{ secrets.SECRET_PASSPHRASE }}
</file>

<file path="alchemy/src/ai/ark.ts">
import {
  type Tool as AITool,
  type Schema,
  type ToolExecutionOptions,
  tool as aitool,
  jsonSchema,
} from "ai";
import { ArkErrors, type JsonSchema, type type } from "arktype";
export namespace ark {
  export function schema<T>(type: JsonSchema): Schema<T>;
  export function schema<T extends type>(type: T): Schema<type.infer<T>> {
    const jsonSchemaObj = type.toJsonSchema() as any;
    const processedSchema = processSchema(jsonSchemaObj);
    return jsonSchema(processedSchema, {
      validate: (value) => {
        const out = type(value) as type.infer<T> | type.errors;
        if (out instanceof ArkErrors) {
          return {
            success: false,
            error: new Error(out.summary),
          };
        }
        return {
          success: true,
          value: out,
        };
      },
    });
  }
  /**
   * Recursively processes a JSON schema and sets additionalProperties: false
   * for any object types.
   *
   * Structured Outputs requires additionalProperties: false
   */
  function processSchema(schema: any): any {
    if (!schema || typeof schema !== "object") return schema;
    // Create a copy to avoid mutating the original
    const result = { ...schema };
    // Convert anyOf with all const values to enum
    if (result.anyOf && Array.isArray(result.anyOf)) {
      const allConst = result.anyOf.every(
        (item: any) => item && typeof item === "object" && "const" in item,
      );
      if (allConst) {
        // Extract all const values
        const enumValues = result.anyOf.map((item: any) => item.const);
        // Determine the type based on the first const value
        // Assuming all const values are of the same type
        const firstType = typeof enumValues[0];
        // Replace anyOf with enum
        delete result.anyOf;
        result.type = firstType;
        result.enum = enumValues;
      } else {
        // Process each item in anyOf
        result.anyOf = result.anyOf.map(processSchema);
      }
    }
    // If this is an object type, set additionalProperties: false
    if (result.type === "object") {
      result.additionalProperties = false;
      result.properties ??= {};
    }
    // Process properties of objects
    if (result.properties && typeof result.properties === "object") {
      result.properties = Object.fromEntries(
        Object.entries(result.properties).map(([key, value]) => [
          key,
          processSchema(value),
        ]),
      );
    }
    // Process items in arrays
    if (result.items) {
      result.items = processSchema(result.items);
    }
    // Process allOf, oneOf
    for (const key of ["allOf", "oneOf"]) {
      if (Array.isArray(result[key])) {
        result[key] = result[key].map(processSchema);
      }
    }
    return result;
  }
  export interface Tool<Input extends type, Output>
    extends Omit<AITool<Schema<type.infer<Input>>>, "parameters" | "execute"> {
    description?: string;
    parameters: Input;
    execute: (
      input: type.infer<Input>,
      options: ToolExecutionOptions,
    ) => Promise<Output>;
  }
  export function tool<Input extends type, Output>(
    tool: Tool<Input, Output>,
  ): AITool<Schema<type.infer<Input>>, Output> {
    return aitool({
      ...tool,
      parameters: ark.schema<Input>(tool.parameters),
    } as any);
  }
}
</file>

<file path="alchemy/src/ai/astro-file.ts">
import { generateText } from "ai";
import prettier from "prettier";
import type { Context } from "../context.js";
import { StaticAstroFile } from "../fs/static-astro-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { type ModelConfig, createModel } from "./client.js";
/**
 * Properties for creating or updating an AstroFile
 */
export interface AstroFileProps {
  /**
   * Path to the Astro file
   */
  path: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate an Astro component using:
   *   ${alchemy.file("src/types.ts")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * The default system prompt instructs the model to return Astro code inside ```astro fences
   * @default "You are an Astro component generator. Create Astro components based on the user's requirements. Your response MUST include only Astro code inside ```astro fences. Do not include any other text, explanations, or multiple code blocks."
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
  /**
   * Prettier configuration to use for formatting the Astro code
   * If not provided, will use the default Prettier configuration
   */
  prettierConfig?: prettier.Options;
}
/**
 * An Astro file that can be created, updated, and deleted
 */
export interface AstroFile extends AstroFileProps, Resource<"ai::AstroFile"> {
  /**
   * Content of the Astro file
   */
  content: string;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for Astro file generation
 */
const DEFAULT_ASTRO_SYSTEM_PROMPT =
  "You are an Astro component generator. Create Astro components based on the user's requirements. Your response MUST include only Astro code inside ```astro fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for generating Astro files using AI models.
 * Extracts Astro code from between ```astro fences, validates the response,
 * and formats the code with Prettier.
 *
 * @example
 * // Create a simple Astro component
 * const header = await AstroFile("header", {
 *   path: "./src/components/Header.astro",
 *   prompt: await alchemy`
 *     Generate an Astro header component with:
 *     - Site logo
 *     - Navigation menu with Home, About, Services, Contact links
 *     - Mobile responsive design
 *     - Dark/light mode toggle
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate an Astro page with data fetching
 * const blogPost = await AstroFile("blog-post", {
 *   path: "./src/pages/blog/[slug].astro",
 *   prompt: await alchemy`
 *     Create an Astro blog post page that:
 *     - Uses getStaticPaths to generate pages from a CMS
 *     - Renders markdown content
 *     - Includes author info, publication date, and related posts
 *     - Has social sharing buttons
 *
 *     Use the following types:
 *     ${alchemy.file("src/types/Blog.ts")}
 *   `,
 *   temperature: 0.2,
 *   prettierConfig: {
 *     semi: false,
 *     singleQuote: true,
 *     printWidth: 120
 *   }
 * });
 *
 * @example
 * // Generate a layout with custom system prompt
 * const mainLayout = await AstroFile("main-layout", {
 *   path: "./src/layouts/MainLayout.astro",
 *   prompt: await alchemy`
 *     Create the main layout for an Astro site that:
 *     - Includes common head metadata and SEO optimization
 *     - Has slots for page content, header, and footer
 *     - Imports and uses the Header and Footer components
 *     - Sets up viewport and responsive configurations
 *   `,
 *   system: "You are an expert Astro developer. Create a single Astro layout file inside ```astro fences with no additional text. Follow Astro best practices and include proper typing in the frontmatter section.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   }
 * });
 */
export const AstroFile = Resource(
  "ai::AstroFile",
  async function (
    this: Context<AstroFile>,
    id: string,
    props: AstroFileProps,
  ): Promise<AstroFile> {
    // Handle deletion phase
    if (this.phase === "delete") {
      return this.destroy();
    }
    // Use provided system prompt or default
    const system = props.system || DEFAULT_ASTRO_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate Astro code
    let { code, error } = await extractAstroCode(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one Astro code block inside \`\`\`astro fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractAstroCode(retryText);
      if (retryResult.error) {
        throw new Error(
          `Failed to generate valid Astro code: ${retryResult.error}`,
        );
      }
      code = retryResult.code;
    }
    // Format the code with Prettier
    try {
      // Set default parser to astro
      const prettierOptions: prettier.Options = {
        parser: "astro",
        ...props.prettierConfig,
      };
      // Format the code
      code = await prettier.format(code, prettierOptions);
    } catch (error) {
      // If Prettier formatting fails, just use the unformatted code
      console.warn("Failed to format Astro code with Prettier:", error);
    }
    // Use StaticAstroFile to create/update the file
    const file = await StaticAstroFile("file", props.path, code);
    // Return the resource
    return this({
      ...props,
      content: file.content,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  },
);
/**
 * Extracts Astro code from between ```astro fences
 * Validates that exactly one Astro code block exists
 *
 * @param text The text to extract Astro code from
 * @returns The extracted Astro code or error message
 */
async function extractAstroCode(
  text: string,
): Promise<{ code: string; error?: string }> {
  const astroCodeRegex = /```astro\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(astroCodeRegex));
  if (matches.length === 0) {
    return {
      code: "",
      error:
        "No Astro code block found in the response. Please include your code within ```astro fences.",
    };
  }
  if (matches.length > 1) {
    return {
      code: "",
      error:
        "Multiple Astro code blocks found in the response. Please provide exactly one code block within ```astro fences.",
    };
  }
  return { code: matches[0][1].trim() };
}
</file>

<file path="alchemy/src/ai/client.ts">
import { anthropic } from "@ai-sdk/anthropic";
import { openai } from "@ai-sdk/openai";
import type { Secret } from "../secret.js";
/**
 * Model configuration for AI operations
 */
export interface ModelConfig {
  /**
   * Model ID to use
   * @default 'gpt-4o'
   */
  id?: string;
  /**
   * Model provider name
   * @default 'openai'
   */
  provider?: string;
  /**
   * Model-specific options
   */
  options?: Record<string, any>;
}
/**
 * Configuration for creating an OpenAI client
 */
export interface ClientConfig {
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
}
/**
 * Creates an OpenAI-compatible client with the given configuration
 */
export function createModel(config: ClientConfig) {
  if (config.model?.provider === "anthropic") {
    return anthropic(config.model?.id ?? "claude-3-7-sonnet-latest");
  }
  return openai(config.model?.id ?? "gpt-4o");
}
/**
 * Maximum time to retry in milliseconds (5 minutes)
 */
const MAX_RETRY_TIME = 5 * 60 * 1000;
/**
 * Initial delay between retries in milliseconds
 */
const INITIAL_RETRY_DELAY = 1000;
/**
 * Maximum number of retries
 */
const MAX_RETRIES = 10;
/**
 * Handles rate limiting with exponential backoff
 * @param fn Function to retry
 * @returns Result of the function
 * @throws Error if max retries or time is exceeded
 */
export async function withRateLimitRetry<T>(fn: () => Promise<T>): Promise<T> {
  let retryCount = 0;
  let lastError: Error | null = null;
  const startTime = Date.now();
  while (true) {
    try {
      return await fn();
    } catch (error: any) {
      lastError = error;
      console.log("retry error", error);
      // Check if we should retry
      const isRateLimit = error.statusCode === 429;
      const timeElapsed = Date.now() - startTime;
      const shouldRetry =
        isRateLimit && retryCount < MAX_RETRIES && timeElapsed < MAX_RETRY_TIME;
      if (!shouldRetry) {
        throw error;
      }
      // Calculate delay with exponential backoff
      const delay = Math.min(
        INITIAL_RETRY_DELAY * 2 ** retryCount,
        MAX_RETRY_TIME - timeElapsed,
      );
      console.log(`Retrying in ${delay}ms`);
      // Wait before retrying
      await new Promise((resolve) => setTimeout(resolve, delay));
      retryCount++;
    }
  }
}
</file>

<file path="alchemy/src/ai/css-file.ts">
import { generateText } from "ai";
import type { Context } from "../context.js";
import { StaticCSSFile } from "../fs/static-css-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { type ModelConfig, createModel } from "./client.js";
/**
 * Properties for creating or updating a CSSFile
 */
export interface CSSFileProps {
  /**
   * Path to the CSS file
   */
  path: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate CSS styles for:
   *   ${alchemy.file("src/components/Button.jsx")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * The default system prompt instructs the model to return CSS code inside ```css fences
   * @default "You are a CSS code generator. Create CSS code based on the user's requirements. Your response MUST include only CSS code inside ```css fences. Do not include any other text, explanations, or multiple code blocks."
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
}
/**
 * A CSS file that can be created, updated, and deleted
 */
export interface CSSFile extends CSSFileProps, Resource<"ai::CSSFile"> {
  /**
   * Content of the CSS file
   */
  content: string;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for CSS file generation
 */
const DEFAULT_CSS_SYSTEM_PROMPT =
  "You are a CSS code generator. Create CSS code based on the user's requirements. Your response MUST include only CSS code inside ```css fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for generating CSS files using AI models.
 * Extracts CSS code from between ```css fences and validates the response.
 *
 * @example
 * // Create styles for a website
 * const mainStyles = await CSSFile("main-styles", {
 *   path: "./public/css/main.css",
 *   prompt: await alchemy`
 *     Generate modern CSS styles for a company website with:
 *     - Clean, minimalist design
 *     - Primary color: #0062ff
 *     - Secondary color: #6c757d
 *     - Light gray background
 *     - Responsive layout for mobile, tablet, and desktop
 *     - Custom styles for buttons, cards, and navigation
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate CSS based on existing HTML
 * const componentStyles = await CSSFile("component-styles", {
 *   path: "./src/styles/component.css",
 *   prompt: await alchemy`
 *     Create CSS styles for this HTML component:
 *     ${alchemy.file("src/components/Card.html")}
 *
 *     The styles should be:
 *     - Modern and clean
 *     - Include hover effects and transitions
 *     - Support both light and dark themes
 *     - Use CSS variables for colors and spacing
 *   `,
 *   temperature: 0.2
 * });
 *
 * @example
 * // Generate CSS animation with custom system prompt
 * const animationStyles = await CSSFile("animations", {
 *   path: "./src/styles/animations.css",
 *   prompt: await alchemy`
 *     Create CSS animations for:
 *     - Fade in/out
 *     - Slide in from different directions
 *     - Pulse effect
 *     - Bounce effect
 *     - Scale in/out
 *     - Rotate
 *
 *     Each animation should be reusable via class names.
 *   `,
 *   system: "You are an expert CSS animator. Create a single CSS file inside ```css fences with no additional text. Use modern CSS animation techniques and include vendor prefixes where needed for browser compatibility.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   }
 * });
 */
export const CSSFile = Resource(
  "ai::CSSFile",
  async function (
    this: Context<CSSFile>,
    id: string,
    props: CSSFileProps,
  ): Promise<CSSFile> {
    // Handle deletion phase
    if (this.phase === "delete") {
      return this.destroy();
    }
    // Use provided system prompt or default
    const system = props.system || DEFAULT_CSS_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate CSS code
    let { code, error } = await extractCSSCode(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one CSS code block inside \`\`\`css fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractCSSCode(retryText);
      if (retryResult.error) {
        throw new Error(
          `Failed to generate valid CSS code: ${retryResult.error}\n${retryText}`,
        );
      }
      code = retryResult.code;
    }
    // Use StaticCSSFile to create/update the file
    const file = await StaticCSSFile("file", props.path, code);
    // Return the resource
    return this({
      ...props,
      content: file.content,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  },
);
/**
 * Extracts CSS code from between ```css fences
 * Validates that exactly one CSS code block exists
 *
 * @param text The text to extract CSS code from
 * @returns The extracted CSS code or error message
 */
async function extractCSSCode(
  text: string,
): Promise<{ code: string; error?: string }> {
  const cssCodeRegex = /```css\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(cssCodeRegex));
  if (matches.length === 0) {
    return {
      code: "",
      error:
        "No CSS code block found in the response. Please include your code within ```css fences.",
    };
  }
  if (matches.length > 1) {
    return {
      code: "",
      error:
        "Multiple CSS code blocks found in the response. Please provide exactly one code block within ```css fences.",
    };
  }
  return { code: matches[0][1].trim() };
}
</file>

<file path="alchemy/src/ai/data.ts">
import { generateObject, type CoreMessage } from "ai";
import type { JsonSchema, Type, type } from "arktype";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { ark } from "./ark.js";
import { createModel, type ModelConfig } from "./client.js";
/**
 * Properties for creating or updating an AI Object
 */
export interface DataProps<T extends Type<any, any>> {
  /**
   * The ArkType schema to validate and structure the generated content
   */
  schema: T | JsonSchema;
  /**
   * Prompt for generating the content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate a description for:
   *   ${alchemy.file("src/data.ts")}
   * `
   */
  prompt?: string;
  /**
   * Message history for the conversation
   * If provided, this will be used instead of the prompt
   */
  messages?: CoreMessage[];
  /**
   * System prompt to guide the AI's behavior
   * @example
   * system: "You are a technical writer tasked with describing code"
   */
  system?: string;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Whether to freeze the generated object
   * @default false
   */
  freeze?: boolean;
}
/**
 * A resource that uses AI to generate structured content based on a schema
 */
export interface Data<T> extends Resource<"ai::Object"> {
  type: JsonSchema;
  /**
   * The generated content, typed according to the provided schema
   */
  object: T;
  /**
   * Updated message history with the AI's response appended
   */
  messages: CoreMessage[];
  /**
   * Time at which the content was generated
   */
  createdAt: number;
}
/**
 * Resource for generating structured content using the Vercel AI SDK.
 * Supports powerful context handling through the alchemy template literal tag.
 *
 * @example
 * // Generate a product description with specific fields
 * const productSchema = type({
 *   name: "string",
 *   description: "string",
 *   features: "string[]",
 *   price: "number"
 * });
 *
 * const product = await Data("new-product", {
 *   schema: productSchema,
 *   prompt: "Generate a product description for a new smartphone",
 *   system: "You are a product copywriter specializing in tech products",
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai",
 *     options: {
 *       temperature: 0.7
 *     }
 *   }
 * });
 *
 * console.log(product.object); // Typed as per schema
 *
 * @example
 * // Generate code documentation with context
 * const docSchema = type({
 *   summary: "string",
 *   parameters: {
 *     name: "string",
 *     type: "string",
 *     description: "string"
 *   }[],
 *   returns: "string"
 * });
 *
 * const docs = await Data("function-docs", {
 *   schema: docSchema,
 *   prompt: await alchemy`
 *     Generate documentation for this function:
 *     ${alchemy.file("src/utils/format.ts")}
 *   `,
 *   system: "You are a technical documentation writer",
 *   temperature: 0.2
 * });
 *
 * @example
 * // Using message history for iterative generation
 * const feedbackSchema = type({
 *   rating: "number",
 *   positives: "string[]",
 *   improvements: "string[]",
 *   summary: "string"
 * });
 *
 * const feedback = await Data("product-feedback", {
 *   schema: feedbackSchema,
 *   messages: [
 *     { role: "user", content: "I'd like feedback on my product design" },
 *     { role: "assistant", content: "I'd be happy to provide feedback. What's your product?" },
 *     { role: "user", content: "It's a new smart home device that..." }
 *   ],
 *   system: "You are a product design expert providing structured feedback",
 *   temperature: 0.3
 * });
 */
export const Data = Resource("ai::Object", async function <
  const T extends Type<any, any>,
>(this: Context<Data<any>>, id: string, props: DataProps<T>): Promise<
  Data<type.infer<T>>
> {
  if (this.phase === "delete") {
    return this.destroy();
  }
  // Validate that either prompt or messages is provided
  if (!props.prompt && !props.messages) {
    throw new Error("Either prompt or messages must be provided");
  }
  if (this.phase === "update" && props.freeze) {
    return this(this.output);
  }
  // Create messages array if only prompt is provided
  const messages = props.messages || [{ role: "user", content: props.prompt! }];
  // Generate structured output using generateObject
  const { object } = await generateObject({
    model: createModel(props),
    // Convert ArkType schema to Zod schema for generateObject
    // This is needed because generateObject expects a Zod schema
    schema: ark.schema<type.infer<T>>(props.schema),
    providerOptions: props.model?.options,
    system:
      props.system ||
      "You are an AI assistant tasked with generating structured content.",
    messages,
    ...(props.temperature === undefined
      ? {}
      : // some models error if you provide it (rather than ignoring it)
        { temperature: props.temperature }),
  });
  // Create updated message history with the structured response
  const responseText = JSON.stringify(object);
  const updatedMessages = [
    ...messages,
    {
      role: "assistant" as const,
      content: responseText,
    },
  ];
  // Return the resource with typed content and updated messages
  return this({
    type: props.schema,
    object: object,
    messages: updatedMessages,
    createdAt: Date.now(),
  });
});
</file>

<file path="alchemy/src/ai/document.ts">
import { generateText, type CoreMessage } from "ai";
import type { Context } from "../context.js";
import { StaticTextFile } from "../fs/static-text-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { createModel, withRateLimitRetry, type ModelConfig } from "./client.js";
/**
 * Properties for creating or updating a Document
 */
export interface DocumentProps {
  /**
   * Title of the document
   *
   * @default id
   */
  title?: string;
  /**
   * Optional path to the markdown document
   * If provided, document will be written to this path
   */
  path?: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate docs using:
   *   ${alchemy.file("src/api.ts")}
   * `
   */
  prompt?: string;
  /**
   * Message history for conversation-based generation
   * If provided, this will be used instead of the prompt
   * @example
   * messages: [
   *   { role: "user", content: "Generate API documentation for this file" },
   *   { role: "assistant", content: "I'll create detailed API docs. What file should I document?" },
   *   { role: "user", content: "Please document src/api.ts" }
   * ]
   */
  messages?: CoreMessage[];
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * The default system prompt instructs the model to return a single markdown document inside ```md fences
   * @default "You are a technical documentation writer. Create a single markdown document based on the user's requirements. Your response MUST include only a single markdown document inside ```md fences. Do not include any other text, explanations, or multiple code blocks."
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
  /**
   * Maximum number of tokens to generate.
   * Higher values allow for longer documents but may increase cost and generation time.
   * @default 10000
   */
  maxTokens?: number;
  /**
   * Freeze the document after creation (do not re-generate on updates)
   * @default false
   */
  freeze?: boolean;
}
/**
 * A markdown document that can be created, updated, and deleted
 */
export interface Document extends DocumentProps, Resource<"docs::Document"> {
  /**
   * The title of the document
   */
  title: string;
  /**
   * Content of the document
   */
  content: string;
  /**
   * Updated message history with the document response appended
   */
  messages: CoreMessage[];
  /**
   * Time at which the document was created
   */
  createdAt: number;
  /**
   * Time at which the document was last updated
   */
  updatedAt: number;
  /**
   * File resource if path was provided
   */
  file?: StaticTextFile;
}
/**
 * Default system prompt for markdown document generation
 */
const DEFAULT_MD_SYSTEM_PROMPT =
  "You are a technical documentation writer. Create a single markdown document based on the user's requirements. Your response MUST include only a single markdown document inside ```md fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for managing AI-generated markdown documents using the Vercel AI SDK.
 * Supports powerful context handling through the alchemy template literal tag.
 *
 * @example
 * // Create an in-memory document (no file created)
 * const apiDocs = await Document("api-docs", {
 *   title: "API Documentation",
 *   prompt: await alchemy`
 *     Generate API documentation based on these source files:
 *     ${alchemy.file("src/api.ts")}
 *     ${alchemy.file("src/types.ts")}
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Create a document and write it to disk
 * const apiDocs = await Document("api-docs", {
 *   title: "API Documentation",
 *   path: "./docs/api.md",
 *   prompt: await alchemy`
 *     Generate API documentation based on these source files:
 *     ${alchemy.file("src/api.ts")}
 *     ${alchemy.file("src/types.ts")}
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Use message history for iterative document generation
 * const apiDocs = await Document("api-docs", {
 *   title: "API Documentation",
 *   path: "./docs/api.md",
 *   messages: [
 *     { role: "user", content: "Create API documentation for these files" },
 *     { role: "assistant", content: "I'll help you create API documentation. Please provide the files." },
 *     { role: "user", content: "Here are the files: [file contents]" }
 *   ],
 *   system: "You are a technical documentation writer. Generate clear and concise API documentation.",
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Use alchemy template literals with file collections and temperature control
 * const modelDocs = await Document("models", {
 *   title: "Data Models",
 *   path: "./docs/models.md",
 *   prompt: await alchemy`
 *     Write documentation for these data models:
 *     ${alchemy.files("src/models/user.ts", "src/models/post.ts")}
 *   `,
 *   temperature: 0.2 // Lower temperature for more deterministic output
 * });
 *
 * @example
 * // Advanced model configuration with custom provider options and custom system prompt
 * const techDocs = await Document("tech-specs", {
 *   title: "Technical Specifications",
 *   path: "./docs/tech-specs.md",
 *   prompt: await alchemy`
 *     Create detailed technical specifications based on these requirements:
 *     ${alchemy.file("requirements/system.md")}
 *   `,
 *   system: "You are an expert technical writer specializing in system specifications. Create a single markdown document inside ```md fences with no additional text.",
 *   model: {
 *     id: "o3-mini",
 *     provider: "openai",
 *     options: {
 *       reasoningEffort: "high"
 *     }
 *   },
 *   temperature: 0.1
 * });
 */
export const Document = Resource(
  "docs::Document",
  async function (
    this: Context<Document>,
    id: string,
    props: DocumentProps,
  ): Promise<Document> {
    // Validate that either prompt or messages are provided
    if (!props.prompt && !props.messages) {
      throw new Error("Either prompt or messages must be provided");
    }
    // Handle deletion phase
    if (this.phase === "delete") {
      return this.destroy();
    }
    if (this.phase === "update" && props.freeze) {
      if (props.path) {
        const filePath = props.path;
        const fileId = `${id}-file`;
        await StaticTextFile(fileId, filePath, this.output!.content);
      }
      return this(this.output);
    }
    // Use provided system prompt or default
    const system = props.system || DEFAULT_MD_SYSTEM_PROMPT;
    // Generate initial content with rate limit retry
    const { text } = await withRateLimitRetry(async () => {
      return generateText({
        model: createModel(props),
        ...(props.messages
          ? { messages: props.messages }
          : { prompt: props.prompt! }),
        system,
        maxTokens: props.maxTokens || 8192,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : // some models error if you provide it (rather than ignoring it)
            { temperature: props.temperature }),
      });
    });
    // Extract and validate markdown content
    let { content, error } = extractMarkdownContent(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one markdown document inside \`\`\`md fences.`;
      const { text: retryText } = await withRateLimitRetry(async () => {
        return generateText({
          model: createModel(props),
          ...(props.messages
            ? { messages: props.messages }
            : { prompt: props.prompt! }),
          system: errorSystem,
          providerOptions: props.model?.options,
          ...(props.temperature === undefined
            ? {}
            : { temperature: props.temperature }),
        });
      });
      const retryResult = extractMarkdownContent(retryText);
      if (retryResult.error) {
        throw new Error(
          `Failed to generate valid markdown content: ${retryResult.error}\n${retryText}`,
        );
      }
      content = retryResult.content;
    }
    // Create result object
    const result: Partial<Document> = {
      ...props,
      content,
      messages: [
        ...(props.messages || [{ role: "user", content: props.prompt! }]),
        { role: "assistant", content },
      ],
      createdAt: this.output?.createdAt || Date.now(),
      updatedAt: Date.now(),
      title: props.title || id,
    };
    // Write file if path is provided
    if (props.path) {
      const filePath = props.path;
      const fileId = `${id}-file`;
      result.file = await StaticTextFile(fileId, filePath, content);
    }
    // Return the resource
    return this(result as Document);
  },
);
/**
 * Extracts markdown content from between ```md fences
 * Validates that exactly one markdown code block exists
 *
 * @param text The text to extract markdown content from
 * @returns The extracted markdown content or error message
 */
function extractMarkdownContent(text: string): {
  content: string;
  error?: string;
} {
  const lines = text.split("\n");
  const startIdx = lines.findIndex((line) => line.trim() === "```md");
  if (startIdx === -1) {
    return {
      content: "",
      error:
        "No markdown code block found in the response. Please include your markdown content within ```md fences.",
    };
  }
  const rest = lines.slice(startIdx + 1);
  const endRelativeIdx = rest
    .map((line) => line.trim() === "```")
    .lastIndexOf(true);
  if (endRelativeIdx === -1) {
    return {
      content: "",
      error: "Markdown block was not closed properly.",
    };
  }
  const endIdx = startIdx + 1 + endRelativeIdx;
  const content = lines
    .slice(startIdx + 1, endIdx)
    .join("\n")
    .trim();
  return { content };
}
</file>

<file path="alchemy/src/ai/html-file.ts">
import { generateText } from "ai";
import type { Context } from "../context.js";
import { StaticHTMLFile } from "../fs/static-html-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { type ModelConfig, createModel } from "./client.js";
/**
 * Properties for creating or updating an HTMLFile
 */
export interface HTMLFileProps {
  /**
   * Path to the HTML file
   */
  path: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate an HTML page using:
   *   ${alchemy.file("src/templates/base.html")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * The default system prompt instructs the model to return HTML code inside ```html fences
   * @default "You are an HTML code generator. Create HTML code based on the user's requirements. Your response MUST include only HTML code inside ```html fences. Do not include any other text, explanations, or multiple code blocks."
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
}
/**
 * An HTML file that can be created, updated, and deleted
 */
export interface HTMLFile extends HTMLFileProps, Resource<"ai::HTMLFile"> {
  /**
   * Content of the HTML file
   */
  content: string;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for HTML file generation
 */
const DEFAULT_HTML_SYSTEM_PROMPT =
  "You are an HTML code generator. Create HTML code based on the user's requirements. Your response MUST include only HTML code inside ```html fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for generating HTML files using AI models.
 * Extracts HTML code from between ```html fences and validates the response.
 *
 * @example
 * // Create a simple landing page
 * const landingPage = await HTMLFile("landing-page", {
 *   path: "./public/index.html",
 *   prompt: await alchemy`
 *     Generate a modern landing page for a SaaS product with:
 *     - Hero section with headline and call-to-action
 *     - Features section with 3 key features
 *     - Pricing section with 3 tiers
 *     - Testimonials section with 2 customer quotes
 *     - Contact form and footer
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate an HTML email template
 * const emailTemplate = await HTMLFile("welcome-email", {
 *   path: "./emails/welcome.html",
 *   prompt: await alchemy`
 *     Create an HTML email template for welcoming new users to our platform.
 *     The email should include:
 *     - Company logo and branding
 *     - Personalized welcome message (use {{name}} placeholder)
 *     - Three steps to get started
 *     - Support contact information
 *     - Unsubscribe footer
 *
 *     Make sure it's responsive and works in all major email clients.
 *   `,
 *   temperature: 0.2
 * });
 *
 * @example
 * // Generate an HTML component with custom system prompt
 * const navComponent = await HTMLFile("navigation", {
 *   path: "./components/nav.html",
 *   prompt: await alchemy`
 *     Create a responsive navigation component with:
 *     - Logo in the left corner
 *     - Navigation links: Home, Products, Services, About, Contact
 *     - Mobile hamburger menu that expands/collapses
 *     - Login/signup buttons on the right side
 *     - Dark/light mode toggle
 *   `,
 *   system: "You are an expert HTML/CSS developer specializing in responsive components. Create a single HTML file inside ```html fences with no additional text. Use modern HTML5 semantic elements and inline CSS if needed.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   }
 * });
 */
export const HTMLFile = Resource(
  "ai::HTMLFile",
  async function (
    this: Context<HTMLFile>,
    id: string,
    props: HTMLFileProps,
  ): Promise<HTMLFile> {
    // Handle deletion phase
    if (this.phase === "delete") {
      return this.destroy();
    }
    // Use provided system prompt or default
    const system = props.system || DEFAULT_HTML_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate HTML code
    let { code, error } = await extractHTMLCode(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one HTML code block inside \`\`\`html fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractHTMLCode(retryText);
      if (retryResult.error) {
        throw new Error(
          `Failed to generate valid HTML code: ${retryResult.error}`,
        );
      }
      code = retryResult.code;
    }
    // Use StaticHTMLFile to create/update the file
    const file = await StaticHTMLFile("file", props.path, code);
    // Return the resource
    return this({
      ...props,
      content: file.content,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  },
);
/**
 * Extracts HTML code from between ```html fences
 * Validates that exactly one HTML code block exists
 *
 * @param text The text to extract HTML code from
 * @returns The extracted HTML code or error message
 */
async function extractHTMLCode(
  text: string,
): Promise<{ code: string; error?: string }> {
  const htmlCodeRegex = /```html\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(htmlCodeRegex));
  if (matches.length === 0) {
    return {
      code: "",
      error:
        "No HTML code block found in the response. Please include your code within ```html fences.",
    };
  }
  if (matches.length > 1) {
    return {
      code: "",
      error:
        "Multiple HTML code blocks found in the response. Please provide exactly one code block within ```html fences.",
    };
  }
  return { code: matches[0][1].trim() };
}
</file>

<file path="alchemy/src/ai/index.ts">
export * from "./ark.js";
export * from "./astro-file.js";
export * from "./css-file.js";
export * from "./data.js";
export * from "./document.js";
export * from "./html-file.js";
export * from "./json-file.js";
export * from "./typescript-file.js";
export * from "./vue-file.js";
export * from "./yaml-file.js";
</file>

<file path="alchemy/src/ai/json-file.ts">
import { generateObject, generateText } from "ai";
import type { JsonSchema, Type, type } from "arktype";
import type { Context } from "../context.js";
import { StaticJsonFile } from "../fs/static-json-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { ark } from "./ark.js";
import { type ModelConfig, createModel } from "./client.js";
/**
 * Properties for creating or updating a JSONFile
 */
export interface JSONFileProps<
  T extends Type<any, any> | undefined = undefined,
> {
  /**
   * Path to the JSON file
   */
  path: string;
  /**
   * Optional ArkType schema to validate and structure the generated JSON
   * When provided, the resource will use generateObject with schema validation
   * When not provided, it will extract JSON from between ```json fences
   */
  schema?: T;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate a JSON configuration for:
   *   ${alchemy.file("src/config.ts")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * @default Depends on whether schema is provided
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
  /**
   * Whether to pretty-print the JSON with indentation
   * @default true
   */
  pretty?: boolean;
  /**
   * Number of spaces to use for indentation when pretty-printing
   * @default 2
   */
  indent?: number;
}
/**
 * A JSON file that can be created, updated, and deleted
 */
export interface JSONFile<T = any>
  extends Omit<JSONFileProps, "schema">,
    Resource<"ai::JSONFile"> {
  /**
   * Content of the JSON file as a string
   */
  content: string;
  /**
   * Parsed JSON object
   */
  json: T;
  /**
   * Schema used to validate the JSON (if provided)
   */
  schema?: JsonSchema;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for JSON file generation without schema
 */
const DEFAULT_JSON_SYSTEM_PROMPT =
  "You are a JSON generator. Create valid JSON based on the user's requirements. Your response MUST include only JSON inside ```json fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for generating JSON files using AI models.
 * Can operate in two modes:
 * 1. With schema: Uses generateObject with type validation
 * 2. Without schema: Extracts JSON from between ```json fences
 *
 * @example
 * // Generate a configuration file with freeform JSON
 * const config = await JSONFile("app-config", {
 *   path: "./config/app.json",
 *   prompt: await alchemy`
 *     Generate a configuration for a web application with:
 *     - Server settings (port, host, timeout)
 *     - Database connection details (redact any passwords)
 *     - Logging configuration
 *     - Feature flags
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate JSON with schema validation
 * import { type } from "arktype";
 *
 * const userSchema = type({
 *   users: [{
 *     id: "string",
 *     name: "string",
 *     email: "string",
 *     role: "'admin' | 'user' | 'guest'",
 *     permissions: "string[]",
 *     active: "boolean"
 *   }]
 * });
 *
 * const userData = await JSONFile("user-data", {
 *   path: "./data/users.json",
 *   schema: userSchema,
 *   prompt: "Generate sample user data for an application with various roles and permissions",
 *   temperature: 0.2
 * });
 *
 * // Type-safe access to the generated data
 * console.log(userData.json.users[0].role); // Typed as 'admin' | 'user' | 'guest'
 *
 * @example
 * // Generate API mock data with custom system prompt
 * const apiMock = await JSONFile("api-mock", {
 *   path: "./mocks/products-api.json",
 *   prompt: await alchemy`
 *     Create mock data for a product catalog API response with:
 *     - 10 products with different categories
 *     - Each product should have id, name, price, category, inventory, and image_url
 *     - Include pagination metadata (total, page, limit)
 *   `,
 *   system: "You are an API design expert. Create realistic mock JSON data that follows REST API best practices. Your response must be valid JSON inside ```json fences.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   },
 *   pretty: true,
 *   indent: 4
 * });
 */
export const JSONFile = Resource("ai::JSONFile", async function <
  const T extends Type<any, any> | undefined = undefined,
>(this: Context<JSONFile<T extends Type<any, any> ? type.infer<T> : any>>, id: string, props: JSONFileProps<T>): Promise<
  JSONFile<T extends Type<any, any> ? type.infer<T> : any>
> {
  // Handle deletion phase
  if (this.phase === "delete") {
    return this.destroy();
  }
  let jsonContent: string;
  let jsonObject: any;
  // Check if schema is provided
  if (props.schema) {
    // Use schema-based generation
    const { object } = await generateObject({
      model: createModel(props),
      schema: ark.schema<type.infer<typeof props.schema>>(props.schema),
      providerOptions: props.model?.options,
      system:
        props.system ||
        "Generate a valid JSON object based on the provided requirements.",
      prompt: props.prompt,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    jsonObject = object;
    // Use StaticJsonFile to create the file
    const file = await StaticJsonFile("file", props.path, jsonObject);
    jsonContent = file.content;
  } else {
    // Use fence-based extraction
    // Use provided system prompt or default
    const system = props.system || DEFAULT_JSON_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate JSON content
    let { content, error } = await extractJSONContent(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one valid JSON block inside \`\`\`json fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractJSONContent(retryText);
      if (retryResult.error) {
        throw new Error(`Failed to generate valid JSON: ${retryResult.error}`);
      }
      content = retryResult.content;
    }
    // Parse JSON to get the object representation
    jsonObject = JSON.parse(content);
    // Use StaticJsonFile to create the file
    const file = await StaticJsonFile("file", props.path, jsonObject);
    jsonContent = file.content;
  }
  // Return the resource
  return this({
    ...props,
    schema: props.schema,
    content: jsonContent,
    json: jsonObject,
    createdAt: Date.now(),
    updatedAt: Date.now(),
  });
});
/**
 * Extracts JSON content from between ```json fences
 * Validates that exactly one JSON code block exists
 *
 * @param text The text to extract JSON from
 * @returns The extracted JSON or error message
 */
async function extractJSONContent(
  text: string,
): Promise<{ content: string; error?: string }> {
  const jsonCodeRegex = /```json\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(jsonCodeRegex));
  if (matches.length === 0) {
    return {
      content: "",
      error:
        "No JSON code block found in the response. Please include your JSON within ```json fences.",
    };
  }
  if (matches.length > 1) {
    return {
      content: "",
      error:
        "Multiple JSON code blocks found in the response. Please provide exactly one JSON block within ```json fences.",
    };
  }
  const content = matches[0][1].trim();
  // Validate JSON can be parsed
  try {
    JSON.parse(content);
    return { content };
  } catch (e) {
    return {
      content: "",
      error: `Invalid JSON: ${(e as Error).message}. Please provide valid JSON syntax.`,
    };
  }
}
</file>

<file path="alchemy/src/ai/typescript-file.ts">
import { generateText } from "ai";
import type { Context } from "../context.js";
import { StaticTypeScriptFile } from "../fs/static-typescript-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { createModel, type ModelConfig } from "./client.js";
/**
 * Properties for creating or updating a TypeScriptFile
 */
export interface TypeScriptFileProps {
  /**
   * Path to the TypeScript file
   */
  path: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate a TypeScript utility function using:
   *   ${alchemy.file("src/types.ts")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * The default system prompt instructs the model to return TypeScript code inside ```ts fences
   * @default "You are a TypeScript code generator. Create TypeScript code based on the user's requirements. Your response MUST include only TypeScript code inside ```ts fences. Do not include any other text, explanations, or multiple code blocks."
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
  /**
   * Prettier configuration to use for formatting the TypeScript code
   * If not provided, will use the default Prettier configuration
   */
  prettierConfig?: object;
}
/**
 * A TypeScript file that can be created, updated, and deleted
 */
export interface TypeScriptFile
  extends TypeScriptFileProps,
    Resource<"ai::TypeScriptFile"> {
  /**
   * Content of the TypeScript file
   */
  content: string;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for TypeScript file generation
 */
const DEFAULT_TS_SYSTEM_PROMPT =
  "You are a TypeScript code generator. Create TypeScript code based on the user's requirements. Your response MUST include only TypeScript code inside ```ts fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for generating TypeScript files using AI models.
 * Extracts TypeScript code from between ```ts fences, validates the response,
 * and formats the code with Prettier.
 *
 * @example
 * // Create a utility function
 * const utils = await TypeScriptFile("string-utils", {
 *   path: "./src/utils/string-utils.ts",
 *   prompt: await alchemy`
 *     Generate TypeScript utility functions for string manipulation:
 *     - Capitalize first letter
 *     - Truncate with ellipsis
 *     - Convert to camelCase and kebab-case
 *     - Remove special characters
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate a TypeScript class with custom formatting
 * const userService = await TypeScriptFile("user-service", {
 *   path: "./src/services/UserService.ts",
 *   prompt: await alchemy`
 *     Create a UserService class that handles user authentication and profile management.
 *     The service should use the User type from:
 *     ${alchemy.file("src/types/User.ts")}
 *
 *     Include methods for:
 *     - login(email, password)
 *     - register(user)
 *     - updateProfile(userId, profileData)
 *     - deleteAccount(userId)
 *   `,
 *   temperature: 0.2,
 *   prettierConfig: {
 *     semi: false,
 *     singleQuote: true,
 *     printWidth: 120
 *   }
 * });
 *
 * @example
 * // Generate a React hook with custom system prompt
 * const useFormHook = await TypeScriptFile("use-form", {
 *   path: "./src/hooks/useForm.ts",
 *   prompt: await alchemy`
 *     Create a custom React hook called useForm that handles form state, validation, and submission.
 *     It should support:
 *     - Initial values
 *     - Validation rules
 *     - Field errors
 *     - Form submission with loading state
 *     - Reset functionality
 *   `,
 *   system: "You are an expert React developer specializing in TypeScript hooks. Create a single TypeScript file inside ```ts fences with no additional text. Follow React best practices and include proper typing.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   }
 * });
 */
export const TypeScriptFile = Resource(
  "ai::TypeScriptFile",
  async function (
    this: Context<TypeScriptFile>,
    id: string,
    props: TypeScriptFileProps,
  ): Promise<TypeScriptFile> {
    // Handle delete phase
    if (this.phase === "delete") {
      // StaticTypeScriptFile will handle the deletion
      return this.destroy();
    }
    // Use provided system prompt or default
    const system = props.system || DEFAULT_TS_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate TypeScript code
    let { code, error } = await extractTypeScriptCode(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one TypeScript code block inside \`\`\`ts fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractTypeScriptCode(retryText);
      if (retryResult.error) {
        throw new Error(
          `Failed to generate valid TypeScript code: ${retryResult.error}`,
        );
      }
      code = retryResult.code;
    }
    // Use StaticTypeScriptFile to create/update the file
    const file = await StaticTypeScriptFile("file", props.path, code);
    // Return the resource
    return this({
      ...props,
      content: file.content,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  },
);
/**
 * Extracts TypeScript code from between ```ts fences
 * Validates that exactly one TypeScript code block exists
 *
 * @param text The text to extract TypeScript code from
 * @returns The extracted TypeScript code or error message
 */
async function extractTypeScriptCode(
  text: string,
): Promise<{ code: string; error?: string }> {
  const tsCodeRegex = /```ts\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(tsCodeRegex));
  if (matches.length === 0) {
    return {
      code: "",
      error:
        "No TypeScript code block found in the response. Please include your code within ```ts fences.",
    };
  }
  if (matches.length > 1) {
    return {
      code: "",
      error:
        "Multiple TypeScript code blocks found in the response. Please provide exactly one code block within ```ts fences.",
    };
  }
  return { code: matches[0][1].trim() };
}
</file>

<file path="alchemy/src/ai/vue-file.ts">
import { generateText } from "ai";
import type { Context } from "../context.js";
import { StaticVueFile } from "../fs/static-vue-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { type ModelConfig, createModel } from "./client.js";
/**
 * Properties for creating or updating a VueFile
 */
export interface VueFileProps {
  /**
   * Path to the Vue file
   */
  path: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate a Vue component using:
   *   ${alchemy.file("src/api.ts")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * The default system prompt instructs the model to return a single Vue component inside ```vue fences
   * @default "You are a Vue component generator. Create a single Vue component based on the user's requirements. Your response MUST include only a single Vue component inside ```vue fences. Do not include any other text, explanations, or multiple code blocks."
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
}
/**
 * A Vue file that can be created, updated, and deleted
 */
export interface VueFile extends VueFileProps, Resource<"ai::VueFile"> {
  /**
   * Content of the Vue file
   */
  content: string;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for Vue file generation
 */
const DEFAULT_VUE_SYSTEM_PROMPT =
  "You are a Vue component generator. Create a single Vue component based on the user's requirements. Your response MUST include only a single Vue component inside ```vue fences. Do not include any other text, explanations, or multiple code blocks.";
/**
 * Resource for generating Vue files using AI models.
 * Extracts Vue code from between ```vue fences and validates the response.
 *
 * @example
 * // Create a simple Vue component
 * const button = await VueFile("button-component", {
 *   path: "./src/components/Button.vue",
 *   prompt: await alchemy`
 *     Generate a customizable button Vue component with:
 *     - Primary, secondary, and outline variants
 *     - Small, medium, and large sizes
 *     - Loading state with spinner
 *     - Disabled state
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate a Vue component using existing files as reference
 * const userCard = await VueFile("user-card", {
 *   path: "./src/components/UserCard.vue",
 *   prompt: await alchemy`
 *     Create a UserCard Vue component that displays user information.
 *     Follow the styling patterns from:
 *     ${alchemy.file("src/components/Card.vue")}
 *
 *     Use the user type from:
 *     ${alchemy.file("src/types/User.ts")}
 *   `,
 *   temperature: 0.2
 * });
 *
 * @example
 * // Generate a complex form component with validation and custom system prompt
 * const form = await VueFile("registration-form", {
 *   path: "./src/components/RegistrationForm.vue",
 *   prompt: await alchemy`
 *     Generate a registration form Vue component with:
 *     - Email, password, and confirm password fields
 *     - Form validation using Vuelidate or similar
 *     - Error messages for each field
 *     - Submit handler that emits form data
 *
 *     Follow these style guidelines:
 *     ${alchemy.file("src/styles/guidelines.md")}
 *   `,
 *   system: "You are an expert Vue component creator specializing in form components with validation. Create a single Vue component inside ```vue fences with no additional text.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   }
 * });
 */
export const VueFile = Resource(
  "ai::VueFile",
  async function (
    this: Context<VueFile>,
    id: string,
    props: VueFileProps,
  ): Promise<VueFile> {
    // Handle deletion phase
    if (this.phase === "delete") {
      return this.destroy();
    }
    // Use provided system prompt or default
    const system = props.system || DEFAULT_VUE_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate Vue code
    let { code, error } = await extractVueCode(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one Vue component inside \`\`\`vue fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractVueCode(retryText);
      if (retryResult.error) {
        throw new Error(
          `Failed to generate valid Vue code: ${retryResult.error}`,
        );
      }
      code = retryResult.code;
    }
    // Use StaticVueFile to create/update the file
    const file = await StaticVueFile("file", props.path, code);
    // Return the resource
    return this({
      ...props,
      content: file.content,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  },
);
/**
 * Extracts Vue code from between ```vue fences
 * Validates that exactly one Vue code block exists
 *
 * @param text The text to extract Vue code from
 * @returns The extracted Vue code or error message
 */
async function extractVueCode(
  text: string,
): Promise<{ code: string; error?: string }> {
  const vueCodeRegex = /```vue\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(vueCodeRegex));
  if (matches.length === 0) {
    return {
      code: "",
      error:
        "No Vue code block found in the response. Please include your code within ```vue fences.",
    };
  }
  if (matches.length > 1) {
    return {
      code: "",
      error:
        "Multiple Vue code blocks found in the response. Please provide exactly one code block within ```vue fences.",
    };
  }
  return { code: matches[0][1].trim() };
}
</file>

<file path="alchemy/src/ai/yaml-file.ts">
import { generateObject, generateText } from "ai";
import type { JsonSchema, Type, type } from "arktype";
import type { Context } from "../context.js";
import { StaticYamlFile } from "../fs/static-yaml-file.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { ark } from "./ark.js";
import { type ModelConfig, createModel } from "./client.js";
/**
 * Properties for creating or updating a YAMLFile
 */
export interface YAMLFileProps<
  T extends Type<any, any> | undefined = undefined,
> {
  /**
   * Path to the YAML file
   */
  path: string;
  /**
   * Optional ArkType schema to validate and structure the generated YAML
   * When provided, the resource will use generateObject with schema validation
   * When not provided, it will extract YAML from between ```yaml fences
   */
  schema?: T;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * Prompt for generating content
   * Use alchemy template literals to include file context:
   * @example
   * prompt: await alchemy`
   *   Generate a YAML configuration for:
   *   ${alchemy.file("src/serverless.js")}
   * `
   */
  prompt: string;
  /**
   * System prompt for the model
   * This is used to provide instructions to the model about how to format the response
   * @default Depends on whether schema is provided
   */
  system?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation.
   * Higher values (e.g., 0.8) make output more random,
   * lower values (e.g., 0.2) make it more deterministic.
   * @default 0.7
   */
  temperature?: number;
}
/**
 * A YAML file that can be created, updated, and deleted
 */
export interface YAMLFile<T = any>
  extends Omit<YAMLFileProps, "schema">,
    Resource<"ai::YAMLFile"> {
  /**
   * Content of the YAML file as a string
   */
  content: string;
  /**
   * Parsed YAML object
   */
  yaml: T;
  /**
   * Schema used to validate the YAML (if provided)
   */
  schema?: JsonSchema;
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
}
/**
 * Default system prompt for YAML file generation without schema
 */
const DEFAULT_YAML_SYSTEM_PROMPT =
  "You are a YAML generator. Create valid YAML based on the user's requirements. Your response MUST include only YAML inside ```yaml fences. Do not include any other text, explanations, or multiple code blocks. Use standard YAML syntax with proper indentation. Use quotes around strings that contain special characters when necessary.";
/**
 * Resource for generating YAML files using AI models.
 * Can operate in two modes:
 * 1. With schema: Uses generateObject with type validation, then converts to YAML
 * 2. Without schema: Extracts YAML from between ```yaml fences
 *
 * @example
 * // Generate a serverless configuration file
 * const serverlessConfig = await YAMLFile("serverless-config", {
 *   path: "./serverless.yml",
 *   prompt: await alchemy`
 *     Generate a serverless.yml configuration for an AWS Lambda API with:
 *     - A service name "user-api"
 *     - Node.js 16.x runtime
 *     - Three functions: createUser, getUser, and listUsers
 *     - API Gateway endpoints for each function
 *     - DynamoDB table for users
 *     - IAM permissions for DynamoDB access
 *   `,
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   }
 * });
 *
 * @example
 * // Generate YAML with schema validation
 * import { type } from "arktype";
 *
 * const k8sConfigSchema = type({
 *   apiVersion: "string",
 *   kind: "string",
 *   metadata: {
 *     name: "string",
 *     namespace: "string?",
 *     labels: "Record<string, string>?"
 *   },
 *   spec: {
 *     replicas: "number",
 *     selector: {
 *       matchLabels: "Record<string, string>"
 *     },
 *     template: {
 *       metadata: {
 *         labels: "Record<string, string>"
 *       },
 *       spec: {
 *         containers: [{
 *           name: "string",
 *           image: "string",
 *           ports: [{
 *             containerPort: "number"
 *           }]
 *         }]
 *       }
 *     }
 *   }
 * });
 *
 * const deployment = await YAMLFile("k8s-deployment", {
 *   path: "./kubernetes/deployment.yaml",
 *   schema: k8sConfigSchema,
 *   prompt: "Generate a Kubernetes deployment for a web application named 'frontend' with 3 replicas using the nginx:latest image and exposing port 80",
 *   temperature: 0.2
 * });
 *
 * @example
 * // Generate GitHub Actions workflow with custom system prompt
 * const workflow = await YAMLFile("github-workflow", {
 *   path: "./.github/workflows/ci.yml",
 *   prompt: await alchemy`
 *     Create a GitHub Actions workflow for a Node.js project that:
 *     - Runs on push to main and pull requests
 *     - Sets up Node.js 18
 *     - Installs dependencies with npm
 *     - Runs linting and tests
 *     - Builds the project
 *     - Deploys to GitHub Pages on success (main branch only)
 *   `,
 *   system: "You are a DevOps expert specializing in GitHub Actions workflows. Create a single YAML file inside ```yaml fences with no additional text. Follow GitHub Actions best practices and use proper YAML syntax.",
 *   model: {
 *     id: "claude-3-opus-20240229",
 *     provider: "anthropic"
 *   }
 * });
 */
export const YAMLFile = Resource("ai::YAMLFile", async function <
  const T extends Type<any, any> | undefined = undefined,
>(this: Context<YAMLFile<T extends Type<any, any> ? type.infer<T> : any>>, id: string, props: YAMLFileProps<T>): Promise<
  YAMLFile<T extends Type<any, any> ? type.infer<T> : any>
> {
  // Handle deletion phase
  if (this.phase === "delete") {
    return this.destroy();
  }
  let yamlContent: string;
  let yamlObject: any;
  // Check if schema is provided
  if (props.schema) {
    // Use schema-based generation
    const { object } = await generateObject({
      model: createModel(props),
      schema: ark.schema<type.infer<typeof props.schema>>(props.schema),
      providerOptions: props.model?.options,
      system:
        props.system ||
        "Generate a valid object based on the provided requirements.",
      prompt: props.prompt,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    yamlObject = object;
    // Let StaticYamlFile handle the YAML conversion
    const file = await StaticYamlFile("file", props.path, yamlObject);
    yamlContent = file.content;
  } else {
    // Use fence-based extraction
    // Use provided system prompt or default
    const system = props.system || DEFAULT_YAML_SYSTEM_PROMPT;
    // Generate initial content
    const { text } = await generateText({
      model: createModel(props),
      prompt: props.prompt,
      system,
      providerOptions: props.model?.options,
      ...(props.temperature === undefined
        ? {}
        : { temperature: props.temperature }),
    });
    // Extract and validate YAML content
    let { content, error } = await extractYAMLContent(text);
    // Re-prompt if there are validation errors
    if (error) {
      const errorSystem = `${system}\n\nERROR: ${error}\n\nPlease try again and ensure your response contains exactly one YAML block inside \`\`\`yaml fences.`;
      const { text: retryText } = await generateText({
        model: createModel(props),
        prompt: props.prompt,
        system: errorSystem,
        providerOptions: props.model?.options,
        ...(props.temperature === undefined
          ? {}
          : { temperature: props.temperature }),
      });
      const retryResult = await extractYAMLContent(retryText);
      if (retryResult.error) {
        throw new Error(`Failed to generate valid YAML: ${retryResult.error}`);
      }
      content = retryResult.content;
    }
    yamlContent = content;
    // Create the file with the string content
    const file = await StaticYamlFile("file", props.path, yamlContent);
    // We need to parse the YAML to get the object representation
    const yaml = await import("yaml");
    yamlObject = yaml.parse(yamlContent);
  }
  // Return the resource
  return this({
    ...props,
    schema: props.schema,
    content: yamlContent,
    yaml: yamlObject,
    createdAt: Date.now(),
    updatedAt: Date.now(),
  });
});
/**
 * Extracts YAML content from between ```yaml fences
 * Validates that exactly one YAML code block exists
 *
 * @param text The text to extract YAML from
 * @returns The extracted YAML or error message
 */
async function extractYAMLContent(
  text: string,
): Promise<{ content: string; error?: string }> {
  // Check for yaml or yml fence blocks
  const yamlCodeRegex = /```(yaml|yml)\s*([\s\S]*?)```/g;
  const matches = Array.from(text.matchAll(yamlCodeRegex));
  if (matches.length === 0) {
    return {
      content: "",
      error:
        "No YAML code block found in the response. Please include your YAML within ```yaml fences.",
    };
  }
  if (matches.length > 1) {
    return {
      content: "",
      error:
        "Multiple YAML code blocks found in the response. Please provide exactly one YAML block within ```yaml fences.",
    };
  }
  const content = matches[0][2].trim();
  // We don't validate YAML parsing here because js-yaml might not be available
  // Validation will happen at usage time if needed
  return { content };
}
</file>

<file path="alchemy/src/aws/oidc/github-oidc-provider.ts">
import { OIDCProvider, type OIDCProviderProps } from "./oidc-provider.js";
/**
 * Default thumbprint for GitHub's OIDC provider
 * This is the certificate thumbprint that GitHub uses to sign OIDC tokens
 * @see https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services#adding-the-identity-provider-to-aws
 */
const DEFAULT_GITHUB_THUMBPRINT = "6938fd4d98bab03faadb97b34396831e3780aea1";
/**
 * Properties for configuring GitHub-specific OIDC provider
 * Simplified version of OIDCProviderProps that omits the thumbprint
 * since it's automatically set to GitHub's known value
 */
export interface GitHubOIDCProviderProps
  extends Omit<OIDCProviderProps, "thumbprint"> {
  /**
   * The GitHub organization or user that owns the repository
   * Example: "my-org" or "my-username"
   */
  owner: string;
  /**
   * The name of the GitHub repository
   * Example: "my-repo"
   */
  repository: string;
}
export type GitHubOIDCProvider = ReturnType<typeof GitHubOIDCProvider>;
/**
 * GitHub-specific OIDC Provider Resource
 *
 * A simplified wrapper around OIDCProvider that automatically sets the correct
 * thumbprint for GitHub Actions. This is the recommended way to set up OIDC
 * authentication for GitHub Actions workflows.
 *
 * @example
 * // Create a GitHub OIDC provider for all branches
 * const provider = await GitHubOIDCProvider("github", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   roleArn: "arn:aws:iam::123456789012:role/github-actions"
 * });
 *
 * @example
 * // Create a GitHub OIDC provider with branch and environment restrictions
 * const provider = await GitHubOIDCProvider("github-restricted", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   branches: ["main", "prod"],
 *   environments: ["staging", "production"],
 *   roleArn: "arn:aws:iam::123456789012:role/github-actions",
 *   maxSessionDuration: 7200
 * });
 *
 * @example
 * // Complete setup with IAM role and OIDC provider
 * import { Role, getAccountId } from "../aws";
 *
 * // Get the AWS account ID
 * const accountId = await getAccountId();
 *
 * // Create the IAM role that GitHub Actions will assume
 * const githubRole = await Role("github-oidc-role", {
 *   roleName: "github-actions-role",
 *   assumeRolePolicy: {
 *     Version: "2012-10-17",
 *     Statement: [
 *       {
 *         Sid: "GitHubOIDC",
 *         Effect: "Allow",
 *         Principal: {
 *           Federated: `arn:aws:iam::${accountId}:oidc-provider/token.actions.githubusercontent.com`
 *         },
 *         Action: "sts:AssumeRoleWithWebIdentity",
 *         Condition: {
 *           StringEquals: {
 *             "token.actions.githubusercontent.com:aud": "sts.amazonaws.com"
 *           },
 *           StringLike: {
 *             "token.actions.githubusercontent.com:sub": "repo:my-org/my-repo:*"
 *           }
 *         }
 *       }
 *     ]
 *   },
 *   // Add required managed policies or inline policies for your use case
 *   managedPolicyArns: ["arn:aws:iam::aws:policy/ReadOnlyAccess"]
 * });
 *
 * // Create the OIDC provider using the role
 * const provider = await GitHubOIDCProvider("github-oidc", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   roleArn: githubRole.arn
 * });
 */
export const GitHubOIDCProvider = async (
  id: string,
  props: GitHubOIDCProviderProps,
) => {
  return OIDCProvider(id, {
    owner: props.owner,
    repository: props.repository,
    roleArn: props.roleArn,
    branches: props.branches,
    environments: props.environments,
    thumbprint: DEFAULT_GITHUB_THUMBPRINT,
  });
};
</file>

<file path="alchemy/src/aws/oidc/index.ts">
export * from "./github-oidc-provider.js";
export * from "./oidc-provider.js";
</file>

<file path="alchemy/src/aws/oidc/oidc-provider.ts">
import {
  CreateOpenIDConnectProviderCommand,
  DeleteOpenIDConnectProviderCommand,
  GetOpenIDConnectProviderCommand,
  GetRoleCommand,
  IAMClient,
  type Tag,
  UpdateAssumeRolePolicyCommand,
} from "@aws-sdk/client-iam";
import type { Context } from "../../context.js";
import { Resource } from "../../resource.js";
import { AccountId } from "../account-id.js";
/**
 * Properties for configuring an AWS OIDC provider for GitHub Actions
 */
export interface OIDCProviderProps {
  /**
   * The GitHub organization or user that owns the repository
   * Example: "my-org" or "my-username"
   */
  owner: string;
  /**
   * The name of the GitHub repository
   * Example: "my-repo"
   */
  repository: string;
  /**
   * Optional list of branches to restrict access to
   * If not provided, all branches will be allowed
   * Example: ["main", "prod"]
   */
  branches?: string[];
  /**
   * Optional list of environments to restrict access to
   * If not provided, all environments will be allowed
   * Example: ["staging", "production"]
   */
  environments?: string[];
  /**
   * The ARN of the IAM role to be assumed
   * Format: arn:aws:iam::account-id:role/role-name
   */
  roleArn: string;
  /**
   * Optional maximum session duration in seconds
   * Default: 3600 (1 hour)
   * Range: 900-43200 seconds (15 minutes to 12 hours)
   */
  maxSessionDuration?: number;
  /**
   * Thumbprint for the OIDC provider
   * Used to verify the identity provider's server certificate
   */
  thumbprint: string;
  /**
   * Optional AWS region
   * @default AWS_REGION environment variable
   */
  region?: string;
}
/**
 * Output returned after OIDC provider configuration
 */
export interface OIDCProvider
  extends Resource<"aws::OIDCProvider">,
    OIDCProviderProps {
  /**
   * The ARN of the OIDC provider
   * Format: arn:aws:iam::account-id:oidc-provider/token.actions.githubusercontent.com
   */
  providerArn: string;
  /**
   * Time at which the provider was created
   * Unix timestamp in milliseconds
   */
  createdAt: number;
}
/**
 * AWS OIDC Provider Resource for GitHub Actions
 *
 * Creates and manages an OpenID Connect (OIDC) identity provider in AWS IAM
 * for GitHub Actions workflows. This enables secure, token-based authentication
 * between GitHub Actions and AWS without storing long-term credentials.
 *
 * @example
 * // Create an OIDC provider for all branches
 * const provider = await OIDCProvider("github", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   roleArn: "arn:aws:iam::123456789012:role/github-actions",
 *   thumbprint: "6938fd4d98bab03faadb97b34396831e3780aea1"
 * });
 *
 * @example
 * // Create an OIDC provider restricted to specific branches and environments
 * const provider = await OIDCProvider("github-restricted", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   branches: ["main", "prod"],
 *   environments: ["staging", "production"],
 *   roleArn: "arn:aws:iam::123456789012:role/github-actions",
 *   thumbprint: "6938fd4d98bab03faadb97b34396831e3780aea1",
 *   maxSessionDuration: 7200
 * });
 */
const TRUST_POLICY_SID = "GitHubOIDCTrust";
export const OIDCProvider = Resource(
  "aws::OIDCProvider",
  async function (
    this: Context<OIDCProvider>,
    id: string,
    props: OIDCProviderProps,
  ) {
    // Initialize AWS SDK client
    const client = new IAMClient({
      region: props.region,
    });
    if (this.phase === "delete") {
      if (this.output?.providerArn) {
        try {
          // First, remove our trust policy statement from the role
          const getRole = await client.send(
            new GetRoleCommand({
              RoleName: props.roleArn.split("/").pop(),
            }),
          );
          if (getRole.Role?.AssumeRolePolicyDocument) {
            const policy = JSON.parse(
              decodeURIComponent(getRole.Role.AssumeRolePolicyDocument),
            );
            // Remove our specific statement while preserving others
            policy.Statement = policy.Statement.filter(
              (stmt: any) => stmt.Sid !== TRUST_POLICY_SID,
            );
            await client.send(
              new UpdateAssumeRolePolicyCommand({
                RoleName: props.roleArn.split("/").pop(),
                PolicyDocument: JSON.stringify(policy),
              }),
            );
          }
          // Then delete the OIDC provider if we're the last user
          const provider = await client.send(
            new GetOpenIDConnectProviderCommand({
              OpenIDConnectProviderArn: this.output.providerArn,
            }),
          );
          // Only delete the provider if it exists and has no other tags
          if (provider && (!provider.Tags || provider.Tags.length === 0)) {
            await client.send(
              new DeleteOpenIDConnectProviderCommand({
                OpenIDConnectProviderArn: this.output.providerArn,
              }),
            );
          }
        } catch (error) {
          // Log but don't throw on cleanup errors
          console.error("Error during cleanup:", error);
        }
      }
      return this.destroy();
    }
    try {
      const url = "https://token.actions.githubusercontent.com";
      const thumbprint = props.thumbprint;
      // Create or get existing OIDC provider
      let providerArn: string;
      try {
        const createProvider = await client.send(
          new CreateOpenIDConnectProviderCommand({
            Url: url,
            ClientIDList: ["sts.amazonaws.com"],
            ThumbprintList: [thumbprint],
            Tags: [
              {
                Key: "ManagedBy",
                Value: "alchemy",
              },
            ] as Tag[],
          }),
        );
        providerArn = createProvider.OpenIDConnectProviderArn!;
      } catch (error: any) {
        if (error.name === "EntityAlreadyExistsException") {
          // Provider exists, use its ARN
          providerArn = `arn:aws:iam::${await AccountId()}:oidc-provider/${url}`;
        } else {
          throw error;
        }
      }
      // Get current role policy
      const getRole = await client.send(
        new GetRoleCommand({
          RoleName: props.roleArn.split("/").pop(),
        }),
      );
      let policy: any;
      if (getRole.Role?.AssumeRolePolicyDocument) {
        policy = JSON.parse(
          decodeURIComponent(getRole.Role.AssumeRolePolicyDocument),
        );
      } else {
        policy = {
          Version: "2012-10-17",
          Statement: [],
        };
      }
      // Construct the trust policy conditions
      const conditions: Record<string, any> = {
        StringEquals: {
          "token.actions.githubusercontent.com:aud": "sts.amazonaws.com",
          "token.actions.githubusercontent.com:sub": `repo:${props.owner}/${props.repository}:`,
        },
      };
      if (props.branches?.length) {
        conditions.StringEquals["token.actions.githubusercontent.com:sub"] =
          props.branches.map(
            (branch) =>
              `repo:${props.owner}/${props.repository}:ref:refs/heads/${branch}`,
          );
      }
      if (props.environments?.length) {
        conditions.StringEquals["token.actions.githubusercontent.com:sub"] =
          props.environments.map(
            (env) =>
              `repo:${props.owner}/${props.repository}:environment:${env}`,
          );
      }
      // Create our policy statement
      const ourStatement = {
        Sid: TRUST_POLICY_SID,
        Effect: "Allow",
        Principal: {
          Federated: providerArn,
        },
        Action: "sts:AssumeRoleWithWebIdentity",
        Condition: conditions,
      };
      // Remove any existing statement with our SID and add the new one
      policy.Statement = [
        ...policy.Statement.filter(
          (stmt: any) => stmt.Sid !== TRUST_POLICY_SID,
        ),
        ourStatement,
      ];
      // Update the role's trust policy
      await client.send(
        new UpdateAssumeRolePolicyCommand({
          RoleName: props.roleArn.split("/").pop(),
          PolicyDocument: JSON.stringify(policy),
        }),
      );
      return this({
        ...props,
        providerArn,
        createdAt: Date.now(),
      });
    } catch (error) {
      console.error("Error configuring OIDC provider:", error);
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/aws/account-id.ts">
import { GetCallerIdentityCommand, STSClient } from "@aws-sdk/client-sts";
const sts = new STSClient({});
export type AccountId = string & {
  readonly __brand: "AccountId";
};
/**
 * Helper to get the current AWS account ID
 */
export async function AccountId(): Promise<AccountId> {
  const identity = await sts.send(new GetCallerIdentityCommand({}));
  return identity.Account! as AccountId;
}
</file>

<file path="alchemy/src/aws/bucket.ts">
import {
  CreateBucketCommand,
  DeleteBucketCommand,
  GetBucketAclCommand,
  GetBucketLocationCommand,
  GetBucketTaggingCommand,
  GetBucketVersioningCommand,
  HeadBucketCommand,
  NoSuchBucket,
  PutBucketTaggingCommand,
  S3Client,
} from "@aws-sdk/client-s3";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
/**
 * Properties for creating or updating an S3 bucket
 */
export interface BucketProps {
  /**
   * The name of the bucket. Must be globally unique across all AWS accounts.
   * Should be lowercase alphanumeric characters or hyphens.
   */
  bucketName: string;
  /**
   * Optional tags to apply to the bucket for organization and cost tracking.
   * Each tag is a key-value pair.
   */
  tags?: Record<string, string>;
}
/**
 * Output returned after S3 bucket creation/update
 */
export interface Bucket extends Resource<"s3::Bucket">, BucketProps {
  /**
   * The ARN (Amazon Resource Name) of the bucket
   * Format: arn:aws:s3:::bucket-name
   */
  arn: string;
  /**
   * The global domain name for the bucket
   * Format: bucket-name.s3.amazonaws.com
   */
  bucketDomainName: string;
  /**
   * The regional domain name for the bucket
   * Format: bucket-name.s3.region.amazonaws.com
   */
  bucketRegionalDomainName?: string;
  /**
   * The S3 hosted zone ID for the region where the bucket resides
   * Used for DNS configuration with Route 53
   */
  hostedZoneId?: string;
  /**
   * The AWS region where the bucket is located
   */
  region?: string;
  /**
   * The website endpoint URL if static website hosting is enabled
   * Format: http://bucket-name.s3-website-region.amazonaws.com
   */
  websiteEndpoint?: string;
  /**
   * The website domain if static website hosting is enabled
   * Format: bucket-name.s3-website-region.amazonaws.com
   */
  websiteDomain?: string;
  /**
   * Whether versioning is enabled for the bucket
   */
  versioningEnabled?: boolean;
  /**
   * The canned ACL applied to the bucket
   * Common values: private, public-read, public-read-write, authenticated-read
   */
  acl?: string;
}
/**
 * AWS S3 Bucket Resource
 *
 * Creates and manages Amazon S3 buckets with support for versioning, tags, and regional configuration.
 * S3 buckets provide scalable object storage for any type of data, with features like versioning,
 * lifecycle policies, and fine-grained access control.
 *
 * @example
 * // Create a basic S3 bucket with default settings
 * const basicBucket = await Bucket("my-app-storage", {
 *   bucketName: "my-app-storage",
 *   tags: {
 *     Environment: "production",
 *     Project: "my-app"
 *   }
 * });
 *
 * @example
 * // Create a bucket with versioning enabled and specific tags
 * const versionedBucket = await Bucket("document-archive", {
 *   bucketName: "document-archive",
 *   tags: {
 *     Environment: "production",
 *     Purpose: "document-storage",
 *     Versioning: "enabled"
 *   }
 * });
 *
 * @example
 * // Create a development bucket with minimal configuration
 * const devBucket = await Bucket("dev-testing", {
 *   bucketName: "dev-testing",
 *   tags: {
 *     Environment: "development",
 *     Temporary: "true"
 *   }
 * });
 */
export const Bucket = Resource(
  "s3::Bucket",
  async function (this: Context<Bucket>, id: string, props: BucketProps) {
    const client = new S3Client({});
    if (this.phase === "delete") {
      await ignore(NoSuchBucket.name, () =>
        client.send(
          new DeleteBucketCommand({
            Bucket: props.bucketName,
          }),
        ),
      );
      return this.destroy();
    }
    try {
      // Check if bucket exists
      await client.send(
        new HeadBucketCommand({
          Bucket: props.bucketName,
        }),
      );
      // Update tags if they changed and bucket exists
      if (this.phase === "update" && props.tags) {
        await client.send(
          new PutBucketTaggingCommand({
            Bucket: props.bucketName,
            Tagging: {
              TagSet: Object.entries(props.tags).map(([Key, Value]) => ({
                Key,
                Value,
              })),
            },
          }),
        );
      }
    } catch (error: any) {
      if (error.name === "NotFound") {
        // Create bucket if it doesn't exist
        await client.send(
          new CreateBucketCommand({
            Bucket: props.bucketName,
            // Add tags during creation if specified
            ...(props.tags && {
              Tagging: {
                TagSet: Object.entries(props.tags).map(([Key, Value]) => ({
                  Key,
                  Value,
                })),
              },
            }),
          }),
        );
      } else {
        throw error;
      }
    }
    // Get bucket details
    const [locationResponse, versioningResponse, aclResponse] =
      await Promise.all([
        client.send(new GetBucketLocationCommand({ Bucket: props.bucketName })),
        client.send(
          new GetBucketVersioningCommand({ Bucket: props.bucketName }),
        ),
        client.send(new GetBucketAclCommand({ Bucket: props.bucketName })),
      ]);
    const region = locationResponse.LocationConstraint || "us-east-1";
    // Get tags if they exist
    let tags = props.tags;
    if (!tags) {
      try {
        const taggingResponse = await client.send(
          new GetBucketTaggingCommand({ Bucket: props.bucketName }),
        );
        tags = Object.fromEntries(
          taggingResponse.TagSet?.map(({ Key, Value }) => [Key, Value]) || [],
        );
      } catch (error: any) {
        if (error.name !== "NoSuchTagSet") {
          throw error;
        }
      }
    }
    return this({
      bucketName: props.bucketName,
      arn: `arn:aws:s3:::${props.bucketName}`,
      bucketDomainName: `${props.bucketName}.s3.amazonaws.com`,
      bucketRegionalDomainName: `${props.bucketName}.s3.${region}.amazonaws.com`,
      region,
      hostedZoneId: getHostedZoneId(region),
      versioningEnabled: versioningResponse.Status === "Enabled",
      acl: aclResponse.Grants?.[0]?.Permission?.toLowerCase(),
      ...(tags && { tags }),
    });
  },
);
/**
 * Helper function to get S3 hosted zone IDs by region
 *
 * Returns the S3 hosted zone ID for a given AWS region. These IDs are used when
 * configuring Route 53 DNS records that point to S3 buckets. If the region is not
 * found in the mapping, defaults to the us-east-1 hosted zone ID.
 *
 * @param region - The AWS region code (e.g., us-east-1, eu-west-1)
 * @returns The S3 hosted zone ID for the region
 */
function getHostedZoneId(region: string): string {
  const hostedZoneIds: Record<string, string> = {
    "us-east-1": "Z3AQBSTGFYJSTF",
    "us-east-2": "Z2O1EMRO9K5GLX",
    "us-west-1": "Z2F56UZL2M1ACD",
    "us-west-2": "Z3BJ6K6RIION7M",
    "af-south-1": "Z11KHD8FBVPUYU",
    "ap-east-1": "ZNB98KWMFR0R6",
    "ap-south-1": "Z11RGJOFQNVJUP",
    "ap-northeast-1": "Z2M4EHUR26P7ZW",
    "ap-northeast-2": "Z3W03O7B5YMIYP",
    "ap-northeast-3": "Z2YQB5RD63NC85",
    "ap-southeast-1": "Z3O0J2DXBE1FTB",
    "ap-southeast-2": "Z1WCIGYICN2BYD",
    "ca-central-1": "Z1QDHH18159H29",
    "eu-central-1": "Z21DNDUVLTQW6Q",
    "eu-west-1": "Z1BKCTXD74EZPE",
    "eu-west-2": "Z3GKZC51ZF0DB4",
    "eu-west-3": "Z3R1K369G5AVDG",
    "eu-north-1": "Z3BAZG2TWCNX0D",
    "eu-south-1": "Z30OZKI7KPW7MI",
    "me-south-1": "Z1MPMWCPA7YB62",
    "sa-east-1": "Z7KQH4QJS55SO",
  };
  return hostedZoneIds[region] || "Z3AQBSTGFYJSTF"; // Default to us-east-1 if region not found
}
</file>

<file path="alchemy/src/aws/credentials.ts">
import type { Secret } from "../secret.js";
export interface AwsCredentials {
  accessKeyId: Secret;
  secretAccessKey: Secret;
}
</file>

<file path="alchemy/src/aws/index.ts">
export * from "./account-id.js";
export * from "./bucket.js";
export * from "./function.js";
export * from "./policy-attachment.js";
export * from "./policy.js";
export * from "./queue.js";
export * from "./role.js";
export * from "./ses.js";
export * from "./table.js";
</file>

<file path="alchemy/src/aws/policy-attachment.ts">
import {
  AttachRolePolicyCommand,
  DetachRolePolicyCommand,
  IAMClient,
  NoSuchEntityException,
} from "@aws-sdk/client-iam";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
/**
 * Properties for creating or updating a policy attachment
 */
export interface PolicyAttachmentProps {
  /**
   * ARN of the IAM policy to attach
   */
  policyArn: string;
  /**
   * Name of the IAM role to attach the policy to
   */
  roleName: string;
}
/**
 * Output returned after policy attachment creation/update
 */
export interface PolicyAttachment
  extends Resource<"iam::PolicyAttachment">,
    PolicyAttachmentProps {}
/**
 * AWS IAM Policy Attachment Resource
 *
 * Attaches an IAM policy to a role, enabling the role to use the permissions defined in the policy.
 *
 * @example
 * // Attach an AWS managed policy to a role
 * const adminAccess = await PolicyAttachment("admin-policy", {
 *   policyArn: "arn:aws:iam::aws:policy/AdministratorAccess",
 *   roleName: role.name
 * });
 *
 * @example
 * // Attach a custom policy to a role
 * const customPolicy = await PolicyAttachment("custom-policy", {
 *   policyArn: policy.arn,
 *   roleName: role.name
 * });
 *
 * @example
 * // Attach multiple policies to a role
 * const s3Access = await PolicyAttachment("s3-access", {
 *   policyArn: "arn:aws:iam::aws:policy/AmazonS3FullAccess",
 *   roleName: role.name
 * });
 *
 * const sqsAccess = await PolicyAttachment("sqs-access", {
 *   policyArn: "arn:aws:iam::aws:policy/AmazonSQSFullAccess",
 *   roleName: role.name
 * });
 */
export const PolicyAttachment = Resource(
  "iam::PolicyAttachment",
  async function (
    this: Context<PolicyAttachment>,
    id: string,
    props: PolicyAttachmentProps,
  ) {
    const client = new IAMClient({});
    if (this.phase === "delete") {
      await ignore(NoSuchEntityException.name, () =>
        client.send(
          new DetachRolePolicyCommand({
            PolicyArn: props.policyArn,
            RoleName: props.roleName,
          }),
        ),
      );
      return this.destroy();
    }
    await client.send(
      new AttachRolePolicyCommand({
        PolicyArn: props.policyArn,
        RoleName: props.roleName,
      }),
    );
    return this(props);
  },
);
</file>

<file path="alchemy/src/aws/policy.ts">
import {
  CreatePolicyCommand,
  CreatePolicyVersionCommand,
  DeletePolicyCommand,
  DeletePolicyVersionCommand,
  GetPolicyCommand,
  GetPolicyVersionCommand,
  IAMClient,
  ListPolicyVersionsCommand,
  NoSuchEntityException,
} from "@aws-sdk/client-iam";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
/**
 * Type of effect for a policy statement
 */
export type Effect = "Allow" | "Deny";
/**
 * A single statement within an IAM policy document
 */
export interface PolicyStatement {
  /**
   * Optional identifier for the statement
   */
  Sid?: string;
  /**
   * Whether to allow or deny the specified actions
   */
  Effect: Effect;
  /**
   * Actions that the policy allows or denies
   */
  Action: string | string[];
  /**
   * Resources that the policy applies to
   */
  Resource?: string | string[];
  /**
   * Additional conditions for when the policy applies
   */
  Condition?: Record<string, Record<string, string | string[]>>;
  /**
   * AWS principals that the policy applies to
   */
  Principal?: Record<string, string | string[]>;
  /**
   * AWS principals that the policy explicitly does not apply to
   */
  NotPrincipal?: Record<string, string | string[]>;
  /**
   * Actions that are explicitly not included in this statement
   */
  NotAction?: string | string[];
  /**
   * Resources that are explicitly not included in this statement
   */
  NotResource?: string | string[];
}
/**
 * An IAM policy document containing one or more statements
 */
export interface PolicyDocument {
  /**
   * Policy language version (must be "2012-10-17")
   */
  Version: "2012-10-17";
  /**
   * List of policy statements
   */
  Statement: PolicyStatement[];
}
/**
 * Properties for creating or updating an IAM policy
 */
export interface PolicyProps {
  /**
   * Name of the policy
   */
  policyName: string;
  /**
   * Policy document defining the permissions
   */
  document: PolicyDocument;
  /**
   * Optional description of the policy's purpose
   */
  description?: string;
  /**
   * Optional path prefix for the policy
   */
  path?: string;
  /**
   * Optional resource tags
   */
  tags?: Record<string, string>;
}
/**
 * Output returned after IAM policy creation/update
 */
export interface Policy extends Resource<"iam::Policy">, PolicyProps {
  /**
   * ARN of the policy
   */
  arn: string;
  /**
   * ID of the default policy version
   */
  defaultVersionId: string;
  /**
   * Number of entities the policy is attached to
   */
  attachmentCount: number;
  /**
   * When the policy was created
   */
  createDate: Date;
  /**
   * When the policy was last updated
   */
  updateDate: Date;
  /**
   * Whether the policy can be attached to IAM users/roles
   */
  isAttachable: boolean;
}
/**
 * AWS IAM Policy Resource
 *
 * Creates and manages IAM policies that define permissions for AWS services and resources.
 * Supports automatic versioning and updates when policy content changes.
 *
 * @example
 * // Create a basic S3 bucket access policy
 * const s3Policy = await Policy("bucket-access", {
 *   policyName: "s3-bucket-access",
 *   document: {
 *     Version: "2012-10-17",
 *     Statement: [{
 *       Effect: "Allow",
 *       Action: [
 *         "s3:GetObject",
 *         "s3:PutObject"
 *       ],
 *       Resource: `${bucket.arn}/*`
 *     }]
 *   }
 * });
 *
 * @example
 * // Create a policy with multiple statements and conditions
 * const apiPolicy = await Policy("api-access", {
 *   policyName: "api-gateway-access",
 *   document: {
 *     Version: "2012-10-17",
 *     Statement: [
 *       {
 *         Sid: "InvokeAPI",
 *         Effect: "Allow",
 *         Action: "execute-api:Invoke",
 *         Resource: `${api.executionArn}/*`,
 *         Condition: {
 *           StringEquals: {
 *             "aws:SourceVpc": vpc.id
 *           }
 *         }
 *       },
 *       {
 *         Sid: "ReadLogs",
 *         Effect: "Allow",
 *         Action: [
 *           "logs:GetLogEvents",
 *           "logs:FilterLogEvents"
 *         ],
 *         Resource: `${api.logGroupArn}:*`
 *       }
 *     ]
 *   },
 *   description: "Allows invoking API Gateway endpoints and reading logs",
 *   tags: {
 *     Service: "API Gateway",
 *     Environment: "production"
 *   }
 * });
 *
 * @example
 * // Create a policy that denies access based on tags
 * const denyPolicy = await Policy("deny-production", {
 *   policyName: "deny-production-access",
 *   document: {
 *     Version: "2012-10-17",
 *     Statement: [{
 *       Effect: "Deny",
 *       Action: "*",
 *       Resource: "*",
 *       Condition: {
 *         StringEquals: {
 *           "aws:ResourceTag/Environment": "production"
 *         }
 *       }
 *     }]
 *   }
 * });
 */
export const Policy = Resource(
  "iam::Policy",
  async function (
    this: Context<Policy>,
    id: string,
    props: PolicyProps,
  ): Promise<Policy> {
    const client = new IAMClient({});
    const policyArn = `arn:aws:iam::${process.env.AWS_ACCOUNT_ID}:policy${props.path || "/"}${props.policyName}`;
    if (this.phase === "delete") {
      try {
        // List and delete all non-default versions first
        const versions = await client.send(
          new ListPolicyVersionsCommand({
            PolicyArn: policyArn,
          }),
        );
        for (const version of versions.Versions || []) {
          if (!version.IsDefaultVersion) {
            await client.send(
              new DeletePolicyVersionCommand({
                PolicyArn: policyArn,
                VersionId: version.VersionId,
              }),
            );
          }
        }
        // Delete the policy
        await client.send(
          new DeletePolicyCommand({
            PolicyArn: policyArn,
          }),
        );
      } catch (error: any) {
        if (error.name !== NoSuchEntityException.name) {
          throw error;
        }
      }
      return this.destroy();
    }
    try {
      // Check if policy exists
      const existingPolicy = await client.send(
        new GetPolicyCommand({
          PolicyArn: policyArn,
        }),
      );
      // Get current policy version
      const currentVersion = await client.send(
        new GetPolicyVersionCommand({
          PolicyArn: policyArn,
          VersionId: existingPolicy.Policy!.DefaultVersionId!,
        }),
      );
      const currentDocument = JSON.parse(
        decodeURIComponent(currentVersion.PolicyVersion!.Document!),
      );
      // If policy document changed, create new version
      if (JSON.stringify(currentDocument) !== JSON.stringify(props.document)) {
        // List versions to check if we need to delete old ones
        const versions = await client.send(
          new ListPolicyVersionsCommand({
            PolicyArn: policyArn,
          }),
        );
        // Delete oldest version if we have 5 versions (maximum allowed)
        if (versions.Versions?.length === 5) {
          const oldestVersion = versions.Versions.sort(
            (a, b) => a.CreateDate!.getTime() - b.CreateDate!.getTime(),
          )[0];
          if (!oldestVersion.IsDefaultVersion) {
            await client.send(
              new DeletePolicyVersionCommand({
                PolicyArn: policyArn,
                VersionId: oldestVersion.VersionId!,
              }),
            );
          }
        }
        // Create new version
        await client.send(
          new CreatePolicyVersionCommand({
            PolicyArn: policyArn,
            PolicyDocument: JSON.stringify(props.document),
            SetAsDefault: true,
          }),
        );
      }
      const policy = await client.send(
        new GetPolicyCommand({
          PolicyArn: policyArn,
        }),
      );
      return this({
        ...props,
        arn: policy.Policy!.Arn!,
        defaultVersionId: policy.Policy!.DefaultVersionId!,
        attachmentCount: policy.Policy!.AttachmentCount!,
        createDate: policy.Policy!.CreateDate!,
        updateDate: policy.Policy!.UpdateDate!,
        isAttachable: policy.Policy!.IsAttachable!,
      });
    } catch (error: any) {
      if (error.name === "NoSuchEntity") {
        // Create new policy
        const newPolicy = await client.send(
          new CreatePolicyCommand({
            PolicyName: props.policyName,
            PolicyDocument: JSON.stringify(props.document),
            Description: props.description,
            Path: props.path,
            Tags: props.tags
              ? Object.entries(props.tags).map(([Key, Value]) => ({
                  Key,
                  Value,
                }))
              : undefined,
          }),
        );
        return this({
          ...props,
          arn: newPolicy.Policy!.Arn!,
          defaultVersionId: newPolicy.Policy!.DefaultVersionId!,
          attachmentCount: newPolicy.Policy!.AttachmentCount!,
          createDate: newPolicy.Policy!.CreateDate!,
          updateDate: newPolicy.Policy!.UpdateDate!,
          isAttachable: newPolicy.Policy!.IsAttachable!,
        });
      }
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/aws/queue.ts">
import {
  CreateQueueCommand,
  DeleteQueueCommand,
  GetQueueAttributesCommand,
  GetQueueUrlCommand,
  SQSClient,
} from "@aws-sdk/client-sqs";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
/**
 * Properties for creating or updating an SQS queue
 */
export interface QueueProps {
  /**
   * Name of the queue
   * For FIFO queues, the name must end with the .fifo suffix
   */
  queueName: string;
  /**
   * Whether this is a FIFO queue.
   * If true, the queueName must end with .fifo suffix
   */
  fifo?: boolean;
  /**
   * The length of time (in seconds) that a message received from a queue will be invisible to other receiving components
   * Default: 30 seconds
   */
  visibilityTimeout?: number;
  /**
   * The length of time (in seconds) for which Amazon SQS retains a message
   * Default: 345600 seconds (4 days)
   */
  messageRetentionPeriod?: number;
  /**
   * The limit of how many bytes a message can contain before Amazon SQS rejects it
   * Default: 262144 bytes (256 KB)
   */
  maximumMessageSize?: number;
  /**
   * The time in seconds that the delivery of all messages in the queue will be delayed
   * Default: 0 seconds
   */
  delaySeconds?: number;
  /**
   * The length of time (in seconds) for which a ReceiveMessage action waits for a message to arrive
   * Default: 0 seconds
   */
  receiveMessageWaitTimeSeconds?: number;
  /**
   * Enables content-based deduplication for FIFO queues.
   * Only applicable when fifo is true.
   */
  contentBasedDeduplication?: boolean;
  /**
   * Specifies whether message deduplication occurs at the message group or queue level
   * Only applicable when fifo is true
   */
  deduplicationScope?: "messageGroup" | "queue";
  /**
   * Specifies whether the FIFO queue throughput quota applies to the entire queue or per message group
   * Only applicable when fifo is true
   */
  fifoThroughputLimit?: "perQueue" | "perMessageGroupId";
  /**
   * Resource tags for the queue
   */
  tags?: Record<string, string>;
}
/**
 * Output returned after SQS queue creation/update
 */
export interface Queue extends Resource<"sqs::Queue">, QueueProps {
  /**
   * ARN of the queue
   */
  arn: string;
  /**
   * URL of the queue
   */
  url: string;
}
/**
 * AWS SQS Queue Resource
 *
 * Creates and manages Amazon SQS queues with support for both standard and FIFO queues.
 * Handles queue creation, attribute configuration, and automatic cleanup of deleted queues.
 *
 * @example
 * // Create a standard queue with custom visibility timeout
 * const standardQueue = await Queue("my-queue", {
 *   queueName: "my-queue",
 *   visibilityTimeout: 30,
 *   tags: {
 *     Environment: "production"
 *   }
 * });
 *
 * @example
 * // Create a FIFO queue with content-based deduplication
 * const fifoQueue = await Queue("orders-queue", {
 *   queueName: "orders-queue.fifo",
 *   fifo: true,
 *   contentBasedDeduplication: true,
 *   visibilityTimeout: 30,
 *   tags: {
 *     Environment: "production"
 *   }
 * });
 *
 * @example
 * // Create a queue with custom message retention and size
 * const customQueue = await Queue("large-messages", {
 *   queueName: "large-messages",
 *   messageRetentionPeriod: 345600,  // 4 days
 *   maximumMessageSize: 262144,      // 256 KB
 *   visibilityTimeout: 60,
 *   delaySeconds: 5,
 *   receiveMessageWaitTimeSeconds: 20
 * });
 */
export const Queue = Resource(
  "sqs::Queue",
  async function (
    this: Context<Queue>,
    id: string,
    props: QueueProps,
  ): Promise<Queue> {
    const client = new SQSClient({});
    // Don't automatically add .fifo suffix - user must include it in queueName
    const queueName = props.queueName;
    // Validate that FIFO queues have .fifo suffix
    if (props.fifo && !queueName.endsWith(".fifo")) {
      throw new Error("FIFO queue names must end with .fifo suffix");
    }
    if (this.phase === "delete") {
      try {
        // Get queue URL first
        const urlResponse = await client.send(
          new GetQueueUrlCommand({
            QueueName: queueName,
          }),
        );
        // Delete the queue
        await client.send(
          new DeleteQueueCommand({
            QueueUrl: urlResponse.QueueUrl,
          }),
        );
        // Wait for queue to be deleted
        let queueDeleted = false;
        while (!queueDeleted) {
          try {
            await client.send(
              new GetQueueUrlCommand({
                QueueName: queueName,
              }),
            );
            // If we get here, queue still exists
            await new Promise((resolve) => setTimeout(resolve, 1000));
          } catch (error: any) {
            if (error.name === "QueueDoesNotExist") {
              queueDeleted = true;
            } else {
              throw error;
            }
          }
        }
      } catch (error: any) {
        if (error.name !== "QueueDoesNotExist") {
          throw error;
        }
      }
      return this.destroy();
    }
    // Create queue with attributes
    const attributes: Record<string, string> = {};
    if (props.visibilityTimeout !== undefined) {
      attributes.VisibilityTimeout = props.visibilityTimeout.toString();
    }
    if (props.messageRetentionPeriod !== undefined) {
      attributes.MessageRetentionPeriod =
        props.messageRetentionPeriod.toString();
    }
    if (props.maximumMessageSize !== undefined) {
      attributes.MaximumMessageSize = props.maximumMessageSize.toString();
    }
    if (props.delaySeconds !== undefined) {
      attributes.DelaySeconds = props.delaySeconds.toString();
    }
    if (props.receiveMessageWaitTimeSeconds !== undefined) {
      attributes.ReceiveMessageWaitTimeSeconds =
        props.receiveMessageWaitTimeSeconds.toString();
    }
    // FIFO specific attributes
    if (props.fifo) {
      attributes.FifoQueue = "true";
      if (props.contentBasedDeduplication) {
        attributes.ContentBasedDeduplication = "true";
      }
      if (props.deduplicationScope) {
        attributes.DeduplicationScope = props.deduplicationScope;
      }
      if (props.fifoThroughputLimit) {
        attributes.FifoThroughputLimit = props.fifoThroughputLimit;
      }
    }
    // Convert tags to AWS format
    const tags = props.tags
      ? Object.entries(props.tags).reduce(
          (acc, [key, value]) => ({ ...acc, [key]: value }),
          {},
        )
      : undefined;
    try {
      // Create the queue
      const createResponse = await client.send(
        new CreateQueueCommand({
          QueueName: queueName,
          Attributes: attributes,
          tags,
        }),
      );
      // Get queue attributes
      const attributesResponse = await client.send(
        new GetQueueAttributesCommand({
          QueueUrl: createResponse.QueueUrl,
          AttributeNames: ["QueueArn"],
        }),
      );
      return this({
        ...props,
        arn: attributesResponse.Attributes!.QueueArn!,
        url: createResponse.QueueUrl!,
      });
    } catch (error: any) {
      if (error.name === "QueueAlreadyExists") {
        // Get existing queue URL
        const urlResponse = await client.send(
          new GetQueueUrlCommand({
            QueueName: queueName,
          }),
        );
        // Get queue attributes
        const attributesResponse = await client.send(
          new GetQueueAttributesCommand({
            QueueUrl: urlResponse.QueueUrl,
            AttributeNames: ["QueueArn"],
          }),
        );
        return this({
          ...props,
          arn: attributesResponse.Attributes!.QueueArn!,
          url: urlResponse.QueueUrl!,
        });
      }
      if (error.name === "QueueDeletedRecently") {
        // Queue was recently deleted, wait and retry
        const maxRetries = 3;
        let retryCount = 0;
        while (retryCount < maxRetries) {
          try {
            // Wait for 60 seconds before retrying
            await new Promise((resolve) => setTimeout(resolve, 61000));
            // Retry creating the queue
            const createResponse = await client.send(
              new CreateQueueCommand({
                QueueName: queueName,
                Attributes: attributes,
                tags,
              }),
            );
            // Get queue attributes
            const attributesResponse = await client.send(
              new GetQueueAttributesCommand({
                QueueUrl: createResponse.QueueUrl,
                AttributeNames: ["QueueArn"],
              }),
            );
            return this({
              ...props,
              arn: attributesResponse.Attributes!.QueueArn!,
              url: createResponse.QueueUrl!,
            });
          } catch (retryError: any) {
            if (
              retryError.name !== "QueueDeletedRecently" ||
              retryCount === maxRetries - 1
            ) {
              throw retryError;
            }
            retryCount++;
          }
        }
      }
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/aws/role.ts">
import {
  AttachRolePolicyCommand,
  CreateRoleCommand,
  DeleteRoleCommand,
  DeleteRolePolicyCommand,
  DetachRolePolicyCommand,
  EntityAlreadyExistsException,
  GetRoleCommand,
  IAMClient,
  ListAttachedRolePoliciesCommand,
  NoSuchEntityException,
  PutRolePolicyCommand,
  type Tag,
  TagRoleCommand,
  UpdateAssumeRolePolicyCommand,
  UpdateRoleCommand,
} from "@aws-sdk/client-iam";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
import type { PolicyDocument } from "./policy.js";
/**
 * Properties for creating or updating an IAM role
 */
export interface RoleProps {
  /**
   * Name of the IAM role
   */
  roleName: string;
  /**
   * Policy that defines which entities can assume this role
   */
  assumeRolePolicy: PolicyDocument;
  /**
   * Optional description of the role's purpose
   */
  description?: string;
  /**
   * Optional path prefix for the role
   */
  path?: string;
  /**
   * Maximum session duration in seconds when assumed
   * Default: 3600 seconds (1 hour)
   */
  maxSessionDuration?: number;
  /**
   * ARN of the policy used to set the permissions boundary
   */
  permissionsBoundary?: string;
  /**
   * Inline policies to embed in the role
   * Each policy must have a unique name and policy document
   */
  policies?: Array<{
    policyName: string;
    policyDocument: PolicyDocument;
  }>;
  /**
   * List of managed policy ARNs to attach to the role
   */
  managedPolicyArns?: string[];
  /**
   * Resource tags for the role
   */
  tags?: Record<string, string>;
}
/**
 * Output returned after IAM role creation/update
 */
export interface Role extends Resource<"iam::Role">, RoleProps {
  /**
   * ARN of the role
   */
  arn: string;
  /**
   * Unique identifier for the role
   */
  uniqueId: string;
  /**
   * The stable and unique string identifying the role
   */
  roleId: string;
  /**
   * When the role was created
   */
  createDate: Date;
}
/**
 * AWS IAM Role Resource
 *
 * Creates and manages IAM roles with support for inline policies, managed policies,
 * and automatic cleanup of attached policies during deletion.
 *
 * @example
 * // Create a basic Lambda execution role with inline policy
 * const basicRole = await Role("lambda-role", {
 *   roleName: "lambda-role",
 *   assumeRolePolicy: {
 *     Version: "2012-10-17",
 *     Statement: [{
 *       Effect: "Allow",
 *       Principal: {
 *         Service: "lambda.amazonaws.com"
 *       },
 *       Action: "sts:AssumeRole"
 *     }]
 *   },
 *   description: "Basic Lambda execution role",
 *   tags: {
 *     Environment: "production"
 *   },
 *   policies: [{
 *     policyName: "logs",
 *     policyDocument: {
 *       Version: "2012-10-17",
 *       Statement: [{
 *         Effect: "Allow",
 *         Action: [
 *           "logs:CreateLogGroup",
 *           "logs:CreateLogStream",
 *           "logs:PutLogEvents"
 *         ],
 *         Resource: "*"
 *       }]
 *     }
 *   }]
 * });
 *
 * @example
 * // Create a role with AWS managed policies
 * const managedRole = await Role("readonly-role", {
 *   roleName: "readonly-role",
 *   assumeRolePolicy: {
 *     Version: "2012-10-17",
 *     Statement: [{
 *       Effect: "Allow",
 *       Principal: {
 *         Service: "lambda.amazonaws.com"
 *       },
 *       Action: "sts:AssumeRole"
 *     }]
 *   },
 *   description: "Role with managed policies",
 *   managedPolicyArns: [
 *     "arn:aws:iam::aws:policy/ReadOnlyAccess"
 *   ],
 *   tags: {
 *     Environment: "production"
 *   }
 * });
 *
 * @example
 * // Create a role with multiple inline policies and custom session duration
 * const customRole = await Role("custom-role", {
 *   roleName: "custom-role",
 *   assumeRolePolicy: {
 *     Version: "2012-10-17",
 *     Statement: [{
 *       Effect: "Allow",
 *       Principal: {
 *         Service: "lambda.amazonaws.com"
 *       },
 *       Action: "sts:AssumeRole"
 *     }]
 *   },
 *   description: "Role with multiple policies",
 *   maxSessionDuration: 7200,
 *   policies: [
 *     {
 *       policyName: "logs",
 *       policyDocument: {
 *         Version: "2012-10-17",
 *         Statement: [{
 *           Effect: "Allow",
 *           Action: [
 *             "logs:CreateLogGroup",
 *             "logs:CreateLogStream",
 *             "logs:PutLogEvents"
 *           ],
 *           Resource: "*"
 *         }]
 *       }
 *     },
 *     {
 *       policyName: "s3",
 *       policyDocument: {
 *         Version: "2012-10-17",
 *         Statement: [{
 *           Effect: "Allow",
 *           Action: "s3:ListBucket",
 *           Resource: "*"
 *         }]
 *       }
 *     }
 *   ],
 *   tags: {
 *     Environment: "production",
 *     Updated: "true"
 *   }
 * });
 */
export const Role = Resource(
  "iam::Role",
  async function (
    this: Context<Role>,
    id: string,
    props: RoleProps,
  ): Promise<Role> {
    const client = new IAMClient({});
    if (this.phase === "delete") {
      try {
        // Delete any inline policies first
        if (props.policies) {
          for (const policy of props.policies) {
            await ignore(NoSuchEntityException.name, () =>
              client.send(
                new DeleteRolePolicyCommand({
                  RoleName: props.roleName,
                  PolicyName: policy.policyName,
                }),
              ),
            );
          }
        }
        // We need to detach managed policies before deleting the role
        // First, get all attached policies
        try {
          const attachedPoliciesResponse = await client.send(
            new ListAttachedRolePoliciesCommand({
              RoleName: props.roleName,
            }),
          );
          // Detach all managed policies
          const attachedPolicies =
            attachedPoliciesResponse.AttachedPolicies || [];
          for (const policy of attachedPolicies) {
            await ignore(NoSuchEntityException.name, () =>
              client.send(
                new DetachRolePolicyCommand({
                  RoleName: props.roleName,
                  PolicyArn: policy.PolicyArn!,
                }),
              ),
            );
          }
        } catch (error: any) {
          if (error.name !== NoSuchEntityException.name) {
            throw error;
          }
          // Role doesn't exist, no need to continue with detaching policies
        }
        // Try to delete the role, ignoring if it doesn't exist
        await ignore(NoSuchEntityException.name, () =>
          client.send(
            new DeleteRoleCommand({
              RoleName: props.roleName,
            }),
          ),
        );
      } catch (error: any) {
        // If we get any other error besides NoSuchEntityException, log it but don't fail
        // This ensures the resource is still marked as destroyed
        if (error.name !== NoSuchEntityException.name) {
          console.error(`Error deleting role ${props.roleName}:`, error);
        }
      }
      // Always return destroyed state regardless of any errors
      return this.destroy();
    }
    const assumeRolePolicyDocument = JSON.stringify(props.assumeRolePolicy);
    let role;
    try {
      if (this.phase === "create") {
        // Try to create the role
        await client.send(
          new CreateRoleCommand({
            RoleName: props.roleName,
            AssumeRolePolicyDocument: assumeRolePolicyDocument,
            Description: props.description,
            Path: props.path,
            MaxSessionDuration: props.maxSessionDuration,
            PermissionsBoundary: props.permissionsBoundary,
            Tags: [
              ...Object.entries(props.tags || {}).map(([Key, Value]) => ({
                Key,
                Value,
              })),
              {
                Key: "alchemy_stage",
                Value: this.stage,
              },
              {
                Key: "alchemy_resource",
                Value: this.id,
              },
            ],
          }),
        );
      }
    } catch (error: any) {
      if (
        error instanceof EntityAlreadyExistsException &&
        this.phase === "create"
      ) {
        // Check if we were the ones who created it
        const existingRole = await client.send(
          new GetRoleCommand({
            RoleName: props.roleName,
          }),
        );
        const roleTags =
          existingRole.Role?.Tags?.reduce(
            (acc, tag) => {
              acc[tag.Key!] = tag.Value!;
              return acc;
            },
            {} as Record<string, string>,
          ) || {};
        if (
          roleTags.alchemy_stage !== this.stage ||
          roleTags.alchemy_resource !== this.id
        ) {
          throw error;
        }
      } else if (error.name !== NoSuchEntityException.name) {
        throw error;
      }
    }
    // Get or update the role
    role = await client.send(
      new GetRoleCommand({
        RoleName: props.roleName,
      }),
    );
    // Update assume role policy if it changed
    if (role.Role?.AssumeRolePolicyDocument !== assumeRolePolicyDocument) {
      await client.send(
        new UpdateAssumeRolePolicyCommand({
          RoleName: props.roleName,
          PolicyDocument: assumeRolePolicyDocument,
        }),
      );
    }
    // Update role description and max session duration if they changed
    if (
      role.Role?.Description !== props.description ||
      role.Role?.MaxSessionDuration !== props.maxSessionDuration
    ) {
      await client.send(
        new UpdateRoleCommand({
          RoleName: props.roleName,
          Description: props.description,
          MaxSessionDuration: props.maxSessionDuration,
        }),
      );
    }
    // Update tags
    const newTags = {
      ...props.tags,
      alchemy_stage: this.stage,
      alchemy_resource: this.id,
    };
    const tags: Tag[] = Object.entries(newTags).map(([Key, Value]) => ({
      Key,
      Value,
    }));
    await client.send(
      new TagRoleCommand({
        RoleName: props.roleName,
        Tags: tags,
      }),
    );
    // Handle policy changes
    const previousPolicies =
      this.phase === "update" ? this.output!.policies || [] : [];
    const currentPolicies = props.policies || [];
    // Delete policies that were removed
    for (const oldPolicy of previousPolicies) {
      if (
        !currentPolicies.some(
          (p: { policyName: string }) => p.policyName === oldPolicy.policyName,
        )
      ) {
        await ignore(NoSuchEntityException.name, () =>
          client.send(
            new DeleteRolePolicyCommand({
              RoleName: props.roleName,
              PolicyName: oldPolicy.policyName,
            }),
          ),
        );
      }
    }
    // Update or create policies
    for (const policy of currentPolicies) {
      const oldPolicy = previousPolicies.find(
        (p) => p.policyName === policy.policyName,
      );
      if (
        !oldPolicy ||
        JSON.stringify(oldPolicy.policyDocument) !==
          JSON.stringify(policy.policyDocument)
      ) {
        await client.send(
          new PutRolePolicyCommand({
            RoleName: props.roleName,
            PolicyName: policy.policyName,
            PolicyDocument: JSON.stringify(policy.policyDocument),
          }),
        );
      }
    }
    // Handle managed policy attachments
    // Get currently attached policies
    const attachedPoliciesResponse = await client.send(
      new ListAttachedRolePoliciesCommand({
        RoleName: props.roleName,
      }),
    );
    const currentAttachedPolicies =
      attachedPoliciesResponse.AttachedPolicies || [];
    const currentPolicyArns = currentAttachedPolicies.map((p) => p.PolicyArn!);
    // If we're updating, use an empty array as default when managedPolicyArns is undefined
    // to ensure we detach all managed policies
    const desiredPolicyArns = props.managedPolicyArns || [];
    // Detach policies that are no longer needed
    for (const policyArn of currentPolicyArns) {
      if (!desiredPolicyArns.includes(policyArn)) {
        await client.send(
          new DetachRolePolicyCommand({
            RoleName: props.roleName,
            PolicyArn: policyArn,
          }),
        );
      }
    }
    // Attach new policies that weren't attached before
    for (const policyArn of desiredPolicyArns) {
      if (!currentPolicyArns.includes(policyArn)) {
        await client.send(
          new AttachRolePolicyCommand({
            RoleName: props.roleName,
            PolicyArn: policyArn,
          }),
        );
      }
    }
    if (!role?.Role) {
      throw new Error(`Failed to create or update role ${props.roleName}`);
    }
    return this({
      ...props,
      arn: role.Role.Arn!,
      uniqueId: role.Role.RoleId!,
      roleId: role.Role.RoleId!,
      roleName: role.Role.RoleName ?? props.roleName,
      createDate: role.Role.CreateDate!,
    });
  },
);
</file>

<file path="alchemy/src/aws/ses.ts">
import {
  CreateConfigurationSetCommand,
  CreateEmailIdentityCommand,
  DeleteConfigurationSetCommand,
  DeleteEmailIdentityCommand,
  type DeliveryOptions,
  GetConfigurationSetCommand,
  GetEmailIdentityCommand,
  NotFoundException,
  PutConfigurationSetDeliveryOptionsCommand,
  PutConfigurationSetReputationOptionsCommand,
  PutConfigurationSetSendingOptionsCommand,
  PutConfigurationSetSuppressionOptionsCommand,
  PutConfigurationSetTrackingOptionsCommand,
  PutEmailIdentityDkimAttributesCommand,
  type ReputationOptions,
  SESv2Client,
  type SendingOptions,
  type SuppressionOptions,
  type TrackingOptions,
} from "@aws-sdk/client-sesv2";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
/**
 * Properties for configuring AWS SES resources
 */
export interface SESProps {
  /**
   * Name of the configuration set
   * Used to group email sending and tracking settings
   */
  configurationSetName?: string;
  /**
   * Email identity to verify (email address or domain)
   * For domains, use the format "example.com"
   * For email addresses, use the format "user@example.com"
   */
  emailIdentity?: string;
  /**
   * Whether to enable DKIM signing for the email identity
   * DKIM helps prevent email spoofing by verifying sender authenticity
   */
  enableDkim?: boolean;
  /**
   * Sending options for the configuration set
   * Controls whether email sending is enabled and related settings
   */
  sendingOptions?: SendingOptions;
  /**
   * Reputation options for the configuration set
   * Controls reputation tracking and metrics collection
   */
  reputationOptions?: ReputationOptions;
  /**
   * Tracking options for the configuration set
   * Controls open and click tracking with optional custom domains
   */
  trackingOptions?: TrackingOptions;
  /**
   * Suppression options for the configuration set
   * Controls how bounces and complaints are handled
   */
  suppressionOptions?: SuppressionOptions;
  /**
   * Delivery options for the configuration set
   * Controls TLS settings and sending pool configuration
   */
  deliveryOptions?: DeliveryOptions;
  /**
   * Tags to apply to the SES resources
   * Key-value pairs for resource organization
   */
  tags?: Record<string, string>;
}
/**
 * Output returned after SES resource creation/update
 */
export interface SES extends Resource<"aws::SES">, SESProps {
  /**
   * ARN of the configuration set if created
   * Format: arn:aws:ses:region:account-id:configuration-set/name
   */
  configurationSetArn?: string;
  /**
   * Email identity verification status if an identity was created
   * Can be "PENDING" or "VERIFIED"
   */
  emailIdentityVerificationStatus?: string;
  /**
   * DKIM verification status if DKIM was enabled
   * Can be "PENDING", "SUCCESS", "FAILED", "TEMPORARY_FAILURE", or "NOT_STARTED"
   */
  dkimVerificationStatus?: string;
  /**
   * Email identity ARN if an identity was created
   * Format: arn:aws:ses:region:account-id:identity/name
   */
  emailIdentityArn?: string;
}
/**
 * AWS SES Resource
 *
 * Creates and manages Amazon Simple Email Service (SES) configuration sets and email identities.
 * Supports email sending configuration, DKIM signing, and identity verification.
 *
 * @example
 * // Create a configuration set with sending options
 * const configSet = await SES("email-config", {
 *   configurationSetName: "my-email-config",
 *   sendingOptions: {
 *     SendingEnabled: true
 *   },
 *   tags: {
 *     Environment: "production",
 *     Project: "notifications"
 *   }
 * });
 *
 * @example
 * // Create and verify a domain identity with DKIM
 * const domainIdentity = await SES("domain-identity", {
 *   emailIdentity: "example.com",
 *   enableDkim: true,
 *   tags: {
 *     Environment: "production",
 *     Project: "transactional-emails"
 *   }
 * });
 *
 * @example
 * // Update configuration set sending options
 * const updatedConfig = await SES("email-config", {
 *   configurationSetName: "my-email-config",
 *   sendingOptions: {
 *     SendingEnabled: false
 *   },
 *   tags: {
 *     Environment: "production",
 *     Project: "notifications",
 *     Updated: "true"
 *   }
 * });
 */
export const SES = Resource(
  "aws::SES",
  async function (
    this: Context<SES>,
    id: string,
    props: SESProps,
  ): Promise<SES> {
    // Create SES client
    const client = new SESv2Client({});
    // Resource ID is either based on the configuration set name or email identity
    // const id =
    //   props.configurationSetName || props.emailIdentity || this.resourceID;
    // Handle deletion
    if (this.phase === "delete") {
      const output = this.output;
      // Delete configuration set if it exists
      if (output?.configurationSetName) {
        await ignore(NotFoundException.name, () =>
          client.send(
            new DeleteConfigurationSetCommand({
              ConfigurationSetName: output.configurationSetName,
            }),
          ),
        );
      }
      // Delete email identity if it exists
      if (output?.emailIdentity) {
        await ignore(NotFoundException.name, () =>
          client.send(
            new DeleteEmailIdentityCommand({
              EmailIdentity: output.emailIdentity,
            }),
          ),
        );
      }
      // Return empty output for delete
      return this.destroy();
    }
    // Created resources
    let configurationSetArn: string | undefined;
    let emailIdentityArn: string | undefined;
    let emailIdentityVerificationStatus: string | undefined;
    let dkimVerificationStatus: string | undefined;
    // Create or update configuration set if specified
    if (props.configurationSetName) {
      // Check if configuration set exists
      let configSetExists = false;
      try {
        await client.send(
          new GetConfigurationSetCommand({
            ConfigurationSetName: props.configurationSetName,
          }),
        );
        configSetExists = true;
      } catch (error) {
        if (error instanceof NotFoundException) {
          configSetExists = false;
        } else {
          throw error;
        }
      }
      if (configSetExists) {
        // Update existing configuration set using appropriate update commands
        if (props.sendingOptions) {
          await client.send(
            new PutConfigurationSetSendingOptionsCommand({
              ConfigurationSetName: props.configurationSetName,
              SendingEnabled: props.sendingOptions.SendingEnabled,
            }),
          );
        }
        if (props.reputationOptions) {
          await client.send(
            new PutConfigurationSetReputationOptionsCommand({
              ConfigurationSetName: props.configurationSetName,
              ReputationMetricsEnabled:
                props.reputationOptions.ReputationMetricsEnabled,
            }),
          );
        }
        if (props.trackingOptions) {
          await client.send(
            new PutConfigurationSetTrackingOptionsCommand({
              ConfigurationSetName: props.configurationSetName,
              CustomRedirectDomain: props.trackingOptions.CustomRedirectDomain,
            }),
          );
        }
        if (props.suppressionOptions) {
          await client.send(
            new PutConfigurationSetSuppressionOptionsCommand({
              ConfigurationSetName: props.configurationSetName,
              SuppressedReasons: props.suppressionOptions.SuppressedReasons,
            }),
          );
        }
        if (props.deliveryOptions) {
          await client.send(
            new PutConfigurationSetDeliveryOptionsCommand({
              ConfigurationSetName: props.configurationSetName,
              TlsPolicy: props.deliveryOptions.TlsPolicy,
              SendingPoolName: props.deliveryOptions.SendingPoolName,
            }),
          );
        }
        // In SESv2, the ARN isn't directly returned in the response
        configurationSetArn = `arn:aws:ses:${process.env.AWS_REGION}:${process.env.AWS_ACCOUNT_ID}:configuration-set/${props.configurationSetName}`;
      } else {
        // Create new configuration set
        await client.send(
          new CreateConfigurationSetCommand({
            ConfigurationSetName: props.configurationSetName,
            SendingOptions: props.sendingOptions,
            ReputationOptions: props.reputationOptions,
            TrackingOptions: props.trackingOptions,
            SuppressionOptions: props.suppressionOptions,
            DeliveryOptions: props.deliveryOptions,
            Tags: Object.entries(props.tags || {}).map(([Key, Value]) => ({
              Key,
              Value,
            })),
          }),
        );
        // In SESv2, the ARN isn't directly returned in the response
        configurationSetArn = `arn:aws:ses:${process.env.AWS_REGION}:${process.env.AWS_ACCOUNT_ID}:configuration-set/${props.configurationSetName}`;
      }
    }
    // Create or verify email identity if specified
    if (props.emailIdentity) {
      // Check if identity exists
      let getIdentityResult;
      try {
        getIdentityResult = await client.send(
          new GetEmailIdentityCommand({
            EmailIdentity: props.emailIdentity,
          }),
        );
      } catch (error) {
        if (error instanceof NotFoundException) {
          getIdentityResult = null;
        } else {
          throw error;
        }
      }
      if (!getIdentityResult) {
        // Create new email identity
        const createIdentityResult = await client.send(
          new CreateEmailIdentityCommand({
            EmailIdentity: props.emailIdentity,
            Tags: Object.entries(props.tags || {}).map(([Key, Value]) => ({
              Key,
              Value,
            })),
          }),
        );
        // If it's an email address, we don't need to explicitly verify in v2
        // The verification email is automatically sent by SES in v2
        // Store the identity information
        emailIdentityArn = `arn:aws:ses:${process.env.AWS_REGION}:${process.env.AWS_ACCOUNT_ID}:identity/${props.emailIdentity}`;
        emailIdentityVerificationStatus =
          createIdentityResult.VerifiedForSendingStatus
            ? "VERIFIED"
            : "PENDING";
      } else {
        // Store the identity information
        emailIdentityArn = `arn:aws:ses:${process.env.AWS_REGION}:${process.env.AWS_ACCOUNT_ID}:identity/${props.emailIdentity}`;
        emailIdentityVerificationStatus =
          getIdentityResult.VerifiedForSendingStatus ? "VERIFIED" : "PENDING";
        // Update DKIM settings if requested
        if (props.enableDkim !== undefined) {
          if (props.enableDkim) {
            await client.send(
              new PutEmailIdentityDkimAttributesCommand({
                EmailIdentity: props.emailIdentity,
                SigningEnabled: true,
              }),
            );
            // We can check the current status of DKIM
            dkimVerificationStatus = "PENDING"; // Default to pending
            // Get the updated identity to check DKIM status
            const updatedIdentity = await client.send(
              new GetEmailIdentityCommand({
                EmailIdentity: props.emailIdentity,
              }),
            );
            if (updatedIdentity.DkimAttributes?.Status) {
              dkimVerificationStatus = updatedIdentity.DkimAttributes.Status;
            }
          }
        }
      }
    }
    // Return the resource output
    return this({
      ...props,
      configurationSetArn,
      emailIdentityArn,
      emailIdentityVerificationStatus,
      dkimVerificationStatus,
    });
  },
);
</file>

<file path="alchemy/src/aws/table.ts">
import {
  CreateTableCommand,
  DeleteTableCommand,
  DescribeTableCommand,
  DynamoDBClient,
  InternalServerError,
  type KeySchemaElement,
  ResourceInUseException,
  ResourceNotFoundException,
} from "@aws-sdk/client-dynamodb";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
import { withExponentialBackoff } from "../util/retry.js";
/**
 * Properties for creating or updating a DynamoDB table
 */
export interface TableProps {
  /**
   * Name of the DynamoDB table
   */
  tableName: string;
  /**
   * Primary partition key (hash key) configuration
   * Defines the main identifier for items in the table
   */
  partitionKey: {
    /**
     * Name of the partition key attribute
     */
    name: string;
    /**
     * Data type of the partition key
     * S: String, N: Number, B: Binary
     */
    type: "S" | "N" | "B";
  };
  /**
   * Optional sort key (range key) configuration
   * Used to sort items with the same partition key
   */
  sortKey?: {
    /**
     * Name of the sort key attribute
     */
    name: string;
    /**
     * Data type of the sort key
     * S: String, N: Number, B: Binary
     */
    type: "S" | "N" | "B";
  };
  /**
   * Billing mode for the table
   * PROVISIONED: Set read/write capacity units
   * PAY_PER_REQUEST: Pay per request pricing
   */
  billingMode?: "PROVISIONED" | "PAY_PER_REQUEST";
  /**
   * Read capacity units when using PROVISIONED billing mode
   * Default: 5
   */
  readCapacity?: number;
  /**
   * Write capacity units when using PROVISIONED billing mode
   * Default: 5
   */
  writeCapacity?: number;
  /**
   * Tags to apply to the table
   * Key-value pairs for resource organization
   */
  tags?: Record<string, string>;
}
/**
 * Output returned after DynamoDB table creation/update
 */
export interface Table extends Resource<"dynamo::Table">, TableProps {
  /**
   * ARN of the table
   * Format: arn:aws:dynamodb:region:account-id:table/table-name
   */
  arn: string;
  /**
   * ARN of the table's stream if enabled
   * Format: arn:aws:dynamodb:region:account-id:table/table-name/stream/timestamp
   */
  streamArn?: string;
  /**
   * Unique identifier for the table
   */
  tableId: string;
}
/**
 * AWS DynamoDB Table Resource
 *
 * Creates and manages DynamoDB tables with support for partition and sort keys,
 * flexible billing modes, and automatic table status monitoring.
 *
 * @example
 * // Create a table with partition and sort key
 * const table = await Table("user-events", {
 *   tableName: "user-events",
 *   partitionKey: {
 *     name: "id",
 *     type: "S"
 *   },
 *   sortKey: {
 *     name: "timestamp",
 *     type: "N"
 *   },
 *   tags: {
 *     Environment: "test"
 *   }
 * });
 *
 * @example
 * // Create a table with provisioned capacity
 * const table = await Table("high-throughput", {
 *   tableName: "high-throughput",
 *   partitionKey: {
 *     name: "userId",
 *     type: "S"
 *   },
 *   billingMode: "PROVISIONED",
 *   readCapacity: 100,
 *   writeCapacity: 50
 * });
 */
export const Table = Resource(
  "dynamo::Table",
  async function (
    this: Context<Table>,
    id: string,
    props: TableProps,
  ): Promise<Table> {
    const client = new DynamoDBClient({});
    if (this.phase === "delete") {
      await withExponentialBackoff(
        async () => {
          await ignore(ResourceNotFoundException.name, () =>
            client.send(
              new DeleteTableCommand({
                TableName: props.tableName,
              }),
            ),
          );
        },
        isRetryableError,
        10, // Max attempts
        200, // Initial delay in ms
      );
      // Wait for table to be deleted
      let tableDeleted = false;
      let retryCount = 0;
      const maxRetries = 60; // Wait up to 60 seconds
      while (!tableDeleted && retryCount < maxRetries) {
        try {
          await client.send(
            new DescribeTableCommand({
              TableName: props.tableName,
            }),
          );
          // If we get here, table still exists
          retryCount++;
          // Increasing delay for each retry with some jitter
          const delay = Math.min(1000 * (1 + 0.1 * Math.random()), 5000);
          await new Promise((resolve) => setTimeout(resolve, delay));
        } catch (error) {
          if (error instanceof ResourceNotFoundException) {
            tableDeleted = true;
          } else {
            throw error;
          }
        }
      }
      if (!tableDeleted) {
        throw new Error(
          `Timed out waiting for table ${props.tableName} to be deleted`,
        );
      }
      return this.destroy();
    }
    // Setup for table creation
    const attributeDefinitions = [
      {
        AttributeName: props.partitionKey.name,
        AttributeType: props.partitionKey.type,
      },
    ];
    const keySchema: KeySchemaElement[] = [
      {
        AttributeName: props.partitionKey.name,
        KeyType: "HASH",
      },
    ];
    if (props.sortKey) {
      attributeDefinitions.push({
        AttributeName: props.sortKey.name,
        AttributeType: props.sortKey.type,
      });
      keySchema.push({
        AttributeName: props.sortKey.name,
        KeyType: "RANGE",
      });
    }
    // Attempt to create the table with exponential backoff for ResourceInUseException
    await withExponentialBackoff(
      async () => {
        try {
          // First check if table already exists
          const describeResponse = await client.send(
            new DescribeTableCommand({
              TableName: props.tableName,
            }),
          );
          // If table exists and is ACTIVE, no need to create it
          if (describeResponse.Table?.TableStatus === "ACTIVE") {
            return;
          }
          // If table exists but not ACTIVE, wait for it in the polling loop below
          if (describeResponse.Table) {
            return;
          }
        } catch (error) {
          if (error instanceof ResourceNotFoundException) {
            // Table doesn't exist, try to create it
            await client.send(
              new CreateTableCommand({
                TableName: props.tableName,
                AttributeDefinitions: attributeDefinitions,
                KeySchema: keySchema,
                BillingMode: props.billingMode || "PAY_PER_REQUEST",
                ProvisionedThroughput:
                  props.billingMode === "PROVISIONED"
                    ? {
                        ReadCapacityUnits: props.readCapacity || 5,
                        WriteCapacityUnits: props.writeCapacity || 5,
                      }
                    : undefined,
                Tags: props.tags
                  ? Object.entries(props.tags).map(([Key, Value]) => ({
                      Key,
                      Value,
                    }))
                  : undefined,
              }),
            );
          } else {
            throw error;
          }
        }
      },
      isRetryableError,
      10, // Max attempts
      200, // Initial delay in ms
    );
    // Wait for table to be active with timeout
    let tableActive = false;
    let tableDescription;
    let retryCount = 0;
    const maxRetries = 60; // Wait up to 60 seconds
    while (!tableActive && retryCount < maxRetries) {
      try {
        const response = await client.send(
          new DescribeTableCommand({
            TableName: props.tableName,
          }),
        );
        tableActive = response.Table?.TableStatus === "ACTIVE";
        if (tableActive) {
          tableDescription = response.Table;
        } else {
          retryCount++;
          // Increasing delay for each retry with some jitter
          const delay = Math.min(1000 * (1 + 0.1 * Math.random()), 5000);
          await new Promise((resolve) => setTimeout(resolve, delay));
        }
      } catch (error) {
        retryCount++;
        if (!(error instanceof ResourceNotFoundException)) {
          throw error;
        }
        await new Promise((resolve) => setTimeout(resolve, 1000));
      }
    }
    if (!tableActive) {
      throw new Error(
        `Timed out waiting for table ${props.tableName} to become active`,
      );
    }
    return this({
      ...props,
      arn: tableDescription!.TableArn!,
      streamArn: tableDescription!.LatestStreamArn,
      tableId: tableDescription!.TableId!,
    });
  },
);
const retryableErrors = [
  "ResourceInUseException",
  "ResourceNotFoundException",
  "InternalServerError",
  "ThrottlingException",
  "ProvisionedThroughputExceededException",
  "LimitExceededException",
  "RequestLimitExceeded",
];
function isRetryableError(error: any) {
  return (
    error instanceof ResourceInUseException ||
    error instanceof InternalServerError ||
    retryableErrors.includes(error?.name) ||
    retryableErrors.includes(error?.code) ||
    error?.$metadata?.httpStatusCode === 500
  );
}
</file>

<file path="alchemy/src/cloudflare/bundle/alias-plugin.ts">
import type { Plugin } from "esbuild";
export const createAliasPlugin = ({
  alias,
  projectRoot,
}: {
  alias: Record<string, string>;
  projectRoot: string;
}): Plugin => ({
  name: "alias",
  setup(build) {
    if (!alias) {
      return;
    }
    // filter the hook calls to only those that match the alias keys
    // this should avoid slowing down builds which don't use aliasing
    const filter = new RegExp(
      Object.keys(alias)
        .map((key) => escapeRegex(key))
        .join("|"),
    );
    // reimplement module aliasing as an esbuild plugin onResolve hook
    build.onResolve({ filter }, (args) => {
      const aliasPath = alias[args.path];
      if (aliasPath) {
        return {
          // resolve with node resolution
          path: require.resolve(aliasPath, {
            // From the esbuild alias docs: "Note that when an import path is substituted using an alias, the resulting import path is resolved in the working directory instead of in the directory containing the source file with the import path."
            // https://esbuild.github.io/api/#alias:~:text=Note%20that%20when%20an%20import%20path%20is%20substituted%20using%20an%20alias%2C%20the%20resulting%20import%20path%20is%20resolved%20in%20the%20working%20directory%20instead%20of%20in%20the%20directory%20containing%20the%20source%20file%20with%20the%20import%20path.
            paths: [projectRoot],
          }),
        };
      }
    });
  },
});
// Taken from https://stackoverflow.com/a/3561711
// which is everything from the tc39 proposal, plus the following two characters: ^/
// It's also everything included in the URLPattern escape (https://wicg.github.io/urlpattern/#escape-a-regexp-string), plus the following: -
// As the answer says, there's no downside to escaping these extra characters, so better safe than sorry
const ESCAPE_REGEX_CHARACTERS = /[-/\\^$*+?.()|[\]{}]/g;
const escapeRegex = (str: string) => {
  return str.replace(ESCAPE_REGEX_CHARACTERS, "\\$&");
};
</file>

<file path="alchemy/src/cloudflare/bundle/build-failures.ts">
import type * as esbuild from "esbuild";
import type { NodeJSCompatMode } from "miniflare";
import { builtinModules } from "node:module";
/**
 * RegExp matching against esbuild's error text when it is unable to resolve
 * a Node built-in module. If we detect this when node_compat is disabled,
 * we'll rewrite the error to suggest enabling it.
 */
const nodeBuiltinResolveErrorText = new RegExp(
  '^Could not resolve "(' +
    builtinModules.join("|") +
    "|" +
    builtinModules.map((module) => `node:${module}`).join("|") +
    ')"$',
);
/**
 * Rewrites esbuild BuildFailures for failing to resolve Node built-in modules
 * to suggest enabling Node compat as opposed to `platform: "node"`.
 */
export function rewriteNodeCompatBuildFailure(
  errors: esbuild.Message[],
  compatMode: NodeJSCompatMode = null,
) {
  for (const error of errors) {
    const match = nodeBuiltinResolveErrorText.exec(error.text);
    if (match !== null) {
      let text = `The package "${match[1]}" wasn't found on the file system but is built into node.\n`;
      if (compatMode === null || compatMode === "als") {
        text += `- Add the "nodejs_compat" compatibility flag to your project.\n`;
      } else if (compatMode === "v1" && !match[1].startsWith("node:")) {
        text += `- Make sure to prefix the module name with "node:" or update your compatibility_date to 2024-09-23 or later.\n`;
      }
      error.notes = [
        {
          location: null,
          text,
        },
      ];
    }
  }
}
/**
 * Returns true if the passed value looks like an esbuild BuildFailure object
 */
export function isBuildFailure(err: unknown): err is esbuild.BuildFailure {
  return (
    typeof err === "object" &&
    err !== null &&
    "errors" in err &&
    "warnings" in err
  );
}
</file>

<file path="alchemy/src/cloudflare/bundle/bundle-worker.ts">
import fs from "node:fs/promises";
import { Bundle } from "../../esbuild/bundle.js";
import type { Bindings } from "../bindings.js";
import type { WorkerProps } from "../worker.js";
import { createAliasPlugin } from "./alias-plugin.js";
import {
  isBuildFailure,
  rewriteNodeCompatBuildFailure,
} from "./build-failures.js";
import { external, external_als } from "./external.js";
import { getNodeJSCompatMode } from "./nodejs-compat-mode.js";
import { nodeJsCompatPlugin } from "./nodejs-compat.js";
export async function bundleWorkerScript<B extends Bindings>(
  props: WorkerProps<B> & {
    compatibilityDate: string;
    compatibilityFlags: string[];
  },
) {
  const projectRoot = props.projectRoot ?? process.cwd();
  const nodeJsCompatMode = getNodeJSCompatMode(
    props.compatibilityDate,
    props.compatibilityFlags,
  );
  if (nodeJsCompatMode === "v1") {
    throw new Error(
      "You must set your compatibilty date >= 2024-09-23 when using 'nodejs_compat' compatibility flag",
    );
  }
  try {
    const bundle = await Bundle("bundle", {
      entryPoint: props.entrypoint!,
      format: props.format === "cjs" ? "cjs" : "esm", // Use the specified format or default to ESM
      target: "esnext",
      platform: "node",
      minify: false,
      ...(props.bundle || {}),
      conditions: ["workerd", "worker", "browser"],
      options: {
        absWorkingDir: projectRoot,
        ...(props.bundle?.options || {}),
        keepNames: true, // Important for Durable Object classes
        loader: {
          ".sql": "text",
          ".json": "json",
        },
        plugins: [
          ...(nodeJsCompatMode === "v2" ? [await nodeJsCompatPlugin()] : []),
          ...(props.bundle?.alias
            ? [
                createAliasPlugin({
                  alias: props.bundle?.alias,
                  projectRoot,
                }),
              ]
            : []),
        ],
      },
      external: [
        ...(nodeJsCompatMode === "als" ? external_als : external),
        ...(props.bundle?.external ?? []),
        ...(props.bundle?.options?.external ?? []),
      ],
    });
    if (bundle.content) {
      return bundle.content;
    }
    if (bundle.path) {
      return await fs.readFile(bundle.path, "utf-8");
    }
    throw new Error("Failed to create bundle");
  } catch (e: any) {
    if (e.message?.includes("No such module 'node:")) {
      throw new Error(
        `${e.message}.\nMake sure to set 'nodejs_compat' compatibility flag and compatibilityDate > 2024-09-23`,
        { cause: e },
      );
    }
    if (isBuildFailure(e)) {
      rewriteNodeCompatBuildFailure(e.errors, nodeJsCompatMode);
      throw e;
    }
    console.error("Error reading bundle:", e);
    throw new Error("Error reading bundle");
  }
}
</file>

<file path="alchemy/src/cloudflare/bundle/local-dev-cloudflare-shim.ts">
import { dedent } from "../../util/dedent.js";
/**
 * TanStackStart server functions and middleware run in Node.js intead of Miniflare when using `vite dev`.
 *
 * This plugin polyfills the cloudflare:workers module during the dev server phase.
 */
export function cloudflareWorkersDevEnvironmentShim() {
  return {
    name: "cloudflare-workers-dev-shim",
    apply: "serve", // devonly
    enforce: "pre",
    resolveId(id: string) {
      if (id === "cloudflare:workers") return id; // tell Vite we handled it
    },
    load(id: string) {
      if (id === "cloudflare:workers")
        return dedent`
          import { getPlatformProxy } from "wrangler";
          // TODO: should we export default cloudflare; ??
          const cloudflare = await getPlatformProxy();
          export const env = cloudflare.env;`;
    },
  } as const;
}
</file>

<file path="alchemy/src/cloudflare/bundle/nodejs-compat-mode.ts">
import type { NodeJSCompatMode } from "miniflare";
import { getNodeCompat } from "miniflare";
/**
 * Computes and validates the Node.js compatibility mode we are running.
 *
 * NOTES:
 * - The v2 mode is configured via `nodejs_compat_v2` compat flag or via `nodejs_compat` plus a compatibility date of Sept 23rd. 2024 or later.
 * - See `EnvironmentInheritable` for `noBundle`.
 *
 * @param compatibilityDateStr The compatibility date
 * @param compatibilityFlags The compatibility flags
 * @param noBundle Whether to skip internal build steps and directly deploy script
 *
 */
export function getNodeJSCompatMode(
  compatibilityDateStr: string,
  compatibilityFlags: string[],
  props?: {
    noBundle?: boolean;
  },
): NodeJSCompatMode {
  const {
    mode,
    hasNodejsCompatFlag,
    hasNodejsCompatV2Flag,
    hasExperimentalNodejsCompatV2Flag,
  } = getNodeCompat(compatibilityDateStr, compatibilityFlags);
  if (hasExperimentalNodejsCompatV2Flag) {
    throw new Error(
      "The `experimental:` prefix on `nodejs_compat_v2` is no longer valid. Please remove it and try again.",
    );
  }
  if (hasNodejsCompatFlag && hasNodejsCompatV2Flag) {
    throw new Error(
      "The `nodejs_compat` and `nodejs_compat_v2` compatibility flags cannot be used in together. Please select just one.",
    );
  }
  if (props?.noBundle && hasNodejsCompatV2Flag) {
    console.warn(
      "`nodejs_compat_v2` compatibility flag and `--no-bundle` can't be used together. If you want to polyfill Node.js built-ins and disable Wrangler's bundling, please polyfill as part of your own bundling process.",
    );
  }
  return mode;
}
</file>

<file path="alchemy/src/cloudflare/bundle/nodejs-compat.ts">
/**
 * Copied from https://github.com/cloudflare/workers-sdk/blob/main/packages/wrangler/src/deployment-bundle/esbuild-plugins/hybrid-nodejs-compat.ts#L17
 */
import type { Plugin, PluginBuild } from "esbuild";
import assert from "node:assert";
import { builtinModules, createRequire } from "node:module";
import nodePath from "node:path";
import { dedent } from "../../util/dedent.js";
const _require =
  typeof require === "undefined" ? createRequire(import.meta.url) : require;
const REQUIRED_NODE_BUILT_IN_NAMESPACE = "node-built-in-modules";
const REQUIRED_UNENV_ALIAS_NAMESPACE = "required-unenv-alias";
/**
 * ESBuild plugin to apply the unenv preset.
 *
 * @returns ESBuild plugin
 */
export async function nodeJsCompatPlugin(): Promise<Plugin> {
  // `unenv` and `@cloudflare/unenv-preset` only publish esm
  const { defineEnv } = await import("unenv");
  const { cloudflare } = await import("@cloudflare/unenv-preset");
  const { alias, inject, external, polyfill } = defineEnv({
    presets: [cloudflare],
    npmShims: true,
  }).env;
  return {
    name: "hybrid-nodejs_compat",
    setup(build) {
      errorOnServiceWorkerFormat(build);
      handleRequireCallsToNodeJSBuiltins(build);
      handleUnenvAliasedPackages(build, alias, external);
      handleNodeJSGlobals(build, inject, polyfill);
    },
  };
}
const NODEJS_MODULES_RE = new RegExp(`^(node:)?(${builtinModules.join("|")})$`);
/**
 * If we are bundling a "Service Worker" formatted Worker, imports of external modules,
 * which won't be inlined/bundled by esbuild, are invalid.
 *
 * This `onResolve()` handler will error if it identifies node.js external imports.
 */
function errorOnServiceWorkerFormat(build: PluginBuild) {
  const paths = new Set();
  build.onStart(() => paths.clear());
  build.onResolve({ filter: NODEJS_MODULES_RE }, (args) => {
    paths.add(args.path);
    return null;
  });
  build.onEnd(() => {
    if (build.initialOptions.format === "iife" && paths.size > 0) {
      const pathList = new Intl.ListFormat("en-US").format(
        Array.from(paths.keys())
          .map((p) => `"${p}"`)
          .sort(),
      );
      return {
        errors: [
          {
            text: dedent`
                Unexpected external import of ${pathList}.
                Your worker has no default export, which means it is assumed to be a Service Worker format Worker.
                Did you mean to create a ES Module format Worker?
                If so, try adding \`export default { ... }\` in your entry-point.
                See https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/.
            `,
          },
        ],
      };
    }
  });
}
/**
 * We must convert `require()` calls for Node.js modules to a virtual ES Module that can be imported avoiding the require calls.
 * We do this by creating a special virtual ES module that re-exports the library in an onLoad handler.
 * The onLoad handler is triggered by matching the "namespace" added to the resolve.
 */
function handleRequireCallsToNodeJSBuiltins(build: PluginBuild) {
  build.onResolve({ filter: NODEJS_MODULES_RE }, (args) => {
    if (args.kind === "require-call") {
      return {
        path: args.path,
        namespace: REQUIRED_NODE_BUILT_IN_NAMESPACE,
      };
    }
  });
  build.onLoad(
    { filter: /.*/, namespace: REQUIRED_NODE_BUILT_IN_NAMESPACE },
    ({ path }) => {
      return {
        contents: dedent`
            import libDefault from '${path}';
            module.exports = libDefault;`,
        loader: "js",
      };
    },
  );
}
/**
 * Handles aliased NPM packages.
 *
 * @param build ESBuild PluginBuild.
 * @param alias Aliases resolved to absolute paths.
 * @param external external modules.
 */
function handleUnenvAliasedPackages(
  build: PluginBuild,
  alias: Record<string, string>,
  external: readonly string[],
) {
  // esbuild expects alias paths to be absolute
  const aliasAbsolute: Record<string, string> = {};
  for (const [module, unresolvedAlias] of Object.entries(alias)) {
    try {
      aliasAbsolute[module] = _require.resolve(unresolvedAlias);
    } catch (e) {
      // this is an alias for package that is not installed in the current app => ignore
    }
  }
  const UNENV_ALIAS_RE = new RegExp(
    `^(${Object.keys(aliasAbsolute).join("|")})$`,
  );
  build.onResolve({ filter: UNENV_ALIAS_RE }, (args) => {
    const unresolvedAlias = alias[args.path];
    // Convert `require()` calls for NPM packages to a virtual ES Module that can be imported avoiding the require calls.
    // Note: Does not apply to Node.js packages that are handled in `handleRequireCallsToNodeJSBuiltins`
    if (
      args.kind === "require-call" &&
      (unresolvedAlias.startsWith("unenv/npm/") ||
        unresolvedAlias.startsWith("unenv/mock/"))
    ) {
      return {
        path: args.path,
        namespace: REQUIRED_UNENV_ALIAS_NAMESPACE,
      };
    }
    // Resolve the alias to its absolute path and potentially mark it as external
    return {
      path: aliasAbsolute[args.path],
      external: external.includes(unresolvedAlias),
    };
  });
  build.onLoad(
    { filter: /.*/, namespace: REQUIRED_UNENV_ALIAS_NAMESPACE },
    ({ path }) => {
      return {
        contents: dedent`
            import * as esm from '${path}';
            module.exports = Object.entries(esm)
                .filter(([k,]) => k !== 'default')
                .reduce((cjs, [k, value]) =>
                    Object.defineProperty(cjs, k, { value, enumerable: true }),
                    "default" in esm ? esm.default : {}
                );`,
        loader: "js",
      };
    },
  );
}
/**
 * Inject node globals defined in unenv's preset `inject` and `polyfill` properties.
 *
 * - an `inject` injects virtual module defining the name on `globalThis`
 * - a `polyfill` is injected directly
 */
function handleNodeJSGlobals(
  build: PluginBuild,
  inject: Record<string, string | readonly string[]>,
  polyfill: readonly string[],
) {
  const UNENV_VIRTUAL_MODULE_RE = /_virtual_unenv_global_polyfill-(.+)$/;
  const prefix = nodePath.resolve(
    // getBasePath(),
    import.meta.dirname,
    "_virtual_unenv_global_polyfill-",
  );
  /**
   * Map of module identifiers to
   * - `injectedName`: the name injected on `globalThis`
   * - `exportName`: the export name from the module
   * - `importName`: the imported name
   */
  const injectsByModule = new Map<
    string,
    { injectedName: string; exportName: string; importName: string }[]
  >();
  // Module specifier (i.e. `/unenv/runtime/node/...`) keyed by path (i.e. `/prefix/_virtual_unenv_global_polyfill-...`)
  const virtualModulePathToSpecifier = new Map<string, string>();
  for (const [injectedName, moduleSpecifier] of Object.entries(inject)) {
    const [module, exportName, importName] = Array.isArray(moduleSpecifier)
      ? [moduleSpecifier[0], moduleSpecifier[1], moduleSpecifier[1]]
      : [moduleSpecifier, "default", "defaultExport"];
    if (!injectsByModule.has(module)) {
      injectsByModule.set(module, []);
      virtualModulePathToSpecifier.set(
        prefix + module.replaceAll("/", "-"),
        module,
      );
    }
    // eslint-disable-next-line  @typescript-eslint/no-non-null-assertion
    injectsByModule.get(module)!.push({ injectedName, exportName, importName });
  }
  build.initialOptions.inject = [
    ...(build.initialOptions.inject ?? []),
    // Inject the virtual modules
    ...virtualModulePathToSpecifier.keys(),
    // Inject the polyfills - needs an absolute path
    ...polyfill.map((m) => _require.resolve(m)),
  ];
  build.onResolve({ filter: UNENV_VIRTUAL_MODULE_RE }, ({ path }) => ({
    path,
  }));
  build.onLoad({ filter: UNENV_VIRTUAL_MODULE_RE }, ({ path }) => {
    const module = virtualModulePathToSpecifier.get(path);
    assert(module, `Expected ${path} to be mapped to a module specifier`);
    const injects = injectsByModule.get(module);
    assert(injects, `Expected ${module} to inject values`);
    const imports = injects.map(({ exportName, importName }) =>
      importName === exportName ? exportName : `${exportName} as ${importName}`,
    );
    return {
      contents: dedent`
        import { ${imports.join(", ")} } from "${module}";
        ${injects.map(({ injectedName, importName }) => `globalThis.${injectedName} = ${importName};`).join("\n")}`,
    };
  });
}
</file>

<file path="alchemy/src/cloudflare/account-api-token.ts">
import { alchemy } from "../alchemy.js";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { sha256 } from "../util/sha256.js";
import { type CloudflareApiOptions, createCloudflareApi } from "./api.js";
/**
 * Permission group for a token policy
 */
export interface TokenPolicyPermissionGroup {
  /**
   * ID of the permission group
   */
  id: string;
  /**
   * Optional metadata for the permission group
   */
  meta?: Record<string, any>;
}
/**
 * Policy that defines what the token can access
 */
export interface TokenPolicy {
  /**
   * Effect of the policy
   */
  effect: "allow" | "deny";
  /**
   * Permission groups to include in the policy
   */
  permissionGroups: TokenPolicyPermissionGroup[];
  /**
   * Resources the policy applies to
   */
  resources: Record<string, string>;
}
/**
 * Condition for token usage (e.g., IP restrictions)
 */
export interface TokenCondition {
  /**
   * IP address conditions
   */
  requestIp?: {
    /**
     * IP ranges to allow
     */
    in?: string[];
    /**
     * IP ranges to deny
     */
    notIn?: string[];
  };
}
/**
 * Properties for creating or updating an Account API Token
 */
export interface AccountApiTokenProps extends CloudflareApiOptions {
  /**
   * Name of the token
   */
  name: string;
  /**
   * Policies that define what the token can access
   */
  policies: TokenPolicy[];
  /**
   * Optional expiration date for the token (ISO format)
   */
  expiresOn?: string;
  /**
   * Optional "not before" date (token is not valid before this date) (ISO format)
   */
  notBefore?: string;
  /**
   * Optional conditions for token use (like IP restrictions)
   */
  condition?: TokenCondition;
}
/**
 * Cloudflare API token format as returned by the API
 */
interface CloudflareApiToken {
  id: string;
  name: string;
  status: string;
  policies: {
    effect: "allow" | "deny";
    permission_groups: {
      id: string;
      meta: Record<string, any>;
    }[];
    resources: Record<string, string>;
  }[];
  expires_on?: string;
  not_before?: string;
  condition?: {
    request_ip?: {
      in?: string[];
      not_in?: string[];
    };
  };
  value?: string;
}
/**
 * Output returned after Account API Token creation/update
 */
export interface AccountApiToken
  extends Resource<"cloudflare::AccountApiToken">,
    AccountApiTokenProps {
  /**
   * The ID of the token
   *
   * Equiv. to ACCESS_KEY_ID
   */
  id: string;
  /**
   * Status of the token
   */
  status: string;
  /**
   * Actual token value (only available on creation)
   * Stored as a Secret for security
   *
   * Equiv. to SECRET_ACCESS_KEY
   */
  value?: Secret;
  /**
   * Access key ID for the token
   *
   * An alias of {@link id}
   */
  accessKeyId: string;
  /**
   * Secret access key for the token
   *
   * The SHA-256 hash of the token {@link value}
   *
   * @see https://developers.cloudflare.com/r2/api/tokens/#get-s3-api-credentials-from-an-api-token
   */
  secretAccessKey: string;
}
/**
 * Creates a Cloudflare Account API Token with specified permissions.
 *
 * Note: Requires a Cloudflare API Key or Token with admin-level account access.
 * The OAuth token from `wrangler login` is NOT sufficient for this operation.
 * You must use an API token with permission to manage account API tokens.
 *
 * @see https://developers.cloudflare.com/api/resources/accounts/subresources/tokens/methods/create/
 *
 * @example
 * // First, fetch all permission groups
 * const permissions = await PermissionGroups("cloudflare-permissions", {
 *   accountId: cfAccountId,
 * });
 *
 * // Create a token with read-only permissions for specific zones
 * const readOnlyToken = await AccountApiToken("readonly-token", {
 *   name: "Readonly Zone Token",
 *   policies: [
 *     {
 *       effect: "allow",
 *       permissionGroups: [
 *         { id: permissions["Zone Read"].id },
 *         { id: permissions["Analytics Read"].id }
 *       ],
 *       resources: {
 *         "com.cloudflare.api.account.zone.22b1de5f1c0e4b3ea97bb1e963b06a43": "*",
 *         "com.cloudflare.api.account.zone.eb78d65290b24279ba6f44721b3ea3c4": "*"
 *       }
 *     }
 *   ],
 *   expiresOn: "2024-12-31T23:59:59Z"
 * });
 *
 * @example
 * // Create a token with time and IP restrictions
 * const restrictedToken = await AccountApiToken("restricted-token", {
 *   name: "Restricted Access Token",
 *   policies: [
 *     {
 *       effect: "allow",
 *       permissionGroups: [
 *         { id: permissions["Worker Routes Edit"].id }
 *       ],
 *       resources: {
 *         "com.cloudflare.api.account.worker.route.*": "*"
 *       }
 *     }
 *   ],
 *   notBefore: "2023-01-01T00:00:00Z",
 *   expiresOn: "2023-12-31T23:59:59Z",
 *   condition: {
 *     requestIp: {
 *       in: ["192.168.1.0/24", "10.0.0.0/8"],
 *       notIn: ["192.168.1.100/32"]
 *     }
 *   }
 * });
 */
export const AccountApiToken = Resource(
  "cloudflare::AccountApiToken",
  async function (
    this: Context<AccountApiToken>,
    id: string,
    props: AccountApiTokenProps,
  ): Promise<AccountApiToken> {
    // Create Cloudflare API client with automatic account discovery
    const api = await createCloudflareApi(props);
    if (this.phase === "delete") {
      // Delete token if we have an ID
      if (this.output?.id) {
        try {
          const deleteResponse = await api.delete(
            `/accounts/${api.accountId}/tokens/${this.output.id}`,
          );
          if (!deleteResponse.ok && deleteResponse.status !== 404) {
            const errorData: any = await deleteResponse.json().catch(() => ({
              errors: [{ message: deleteResponse.statusText }],
            }));
            console.error(`Error deleting token '${props.name}':`, errorData);
          }
        } catch (error) {
          console.error(`Error deleting token '${props.name}':`, error);
        }
      }
      // Return destroyed state
      return this.destroy();
    }
    // Transform our properties to API format
    const apiPayload = {
      name: props.name,
      policies: props.policies.map((policy) => ({
        effect: policy.effect,
        permission_groups: policy.permissionGroups.map((pg) => ({
          id: pg.id,
          meta: pg.meta || {},
        })),
        resources: policy.resources,
      })),
      // Format dates for Cloudflare API (removing milliseconds)
      ...(props.expiresOn
        ? { expires_on: formatCloudflareDate(props.expiresOn) }
        : {}),
      ...(props.notBefore
        ? { not_before: formatCloudflareDate(props.notBefore) }
        : {}),
      ...(props.condition
        ? {
            condition: {
              request_ip: props.condition.requestIp
                ? {
                    in: props.condition.requestIp.in || [],
                    not_in: props.condition.requestIp.notIn || [],
                  }
                : undefined,
            },
          }
        : {}),
    };
    /**
     * Formats a date string for Cloudflare API by removing milliseconds
     * Converts from "2023-01-01T00:00:00.000Z" to "2023-01-01T00:00:00Z"
     */
    function formatCloudflareDate(dateStr: string): string {
      return dateStr.replace(/\.\d{3}Z$/, "Z");
    }
    let response: Response;
    let tokenValue: Secret | undefined;
    if (this.phase === "update" && this.output?.id) {
      // Update existing token
      response = await api.put(
        `/accounts/${api.accountId}/tokens/${this.output.id}`,
        apiPayload,
      );
    } else {
      // Create new token
      response = await api.post(
        `/accounts/${api.accountId}/tokens`,
        apiPayload,
      );
    }
    if (!response.ok) {
      const errorData: any = await response.json().catch(() => ({
        errors: [{ message: response.statusText }],
      }));
      throw new Error(
        `Error ${this.phase === "update" ? "updating" : "creating"} token '${props.name}': ${
          errorData.errors?.[0]?.message || response.statusText
        }`,
      );
    }
    const result: { result: CloudflareApiToken } = await response.json();
    const tokenData = result.result;
    if (tokenData.value) {
      tokenValue = alchemy.secret(tokenData.value);
    } else {
      if (!this.output?.value) {
        throw new Error(
          `Token '${props.name}' was created but we have no record of its value. Try deleting and recreating the token.`,
        );
      }
      tokenValue = this.output?.value;
    }
    // Transform API response to our format
    return this({
      id: tokenData.id,
      name: tokenData.name,
      status: tokenData.status,
      policies: tokenData.policies.map((policy) => ({
        effect: policy.effect,
        permissionGroups: policy.permission_groups.map((pg) => ({
          id: pg.id,
          meta: pg.meta,
        })),
        resources: policy.resources,
      })),
      ...(tokenData.expires_on ? { expiresOn: tokenData.expires_on } : {}),
      ...(tokenData.not_before ? { notBefore: tokenData.not_before } : {}),
      ...(tokenData.condition
        ? {
            condition: {
              requestIp: tokenData.condition.request_ip
                ? {
                    in: tokenData.condition.request_ip.in || [],
                    notIn: tokenData.condition.request_ip.not_in || [],
                  }
                : undefined,
            },
          }
        : {}),
      value: tokenValue,
      accessKeyId: tokenData.id,
      secretAccessKey: sha256(tokenValue.unencrypted),
    });
  },
);
</file>

<file path="alchemy/src/cloudflare/ai-gateway.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { handleApiError } from "./api-error.js";
import { createCloudflareApi, type CloudflareApiOptions } from "./api.js";
/**
 * Properties for creating or updating a Cloudflare AI Gateway.
 */
export interface AiGatewayProps extends CloudflareApiOptions {
  /**
   * Invalidate cache on update.
   * @default true
   */
  cacheInvalidateOnUpdate?: boolean;
  /**
   * Cache TTL in seconds. Set to 0 to disable caching.
   * @default 0
   * @minimum 0
   */
  cacheTtl?: number;
  /**
   * Collect logs for the gateway.
   * @default true
   */
  collectLogs?: boolean;
  /**
   * Rate limiting interval in seconds. Set to 0 to disable rate limiting.
   * @default 0
   * @minimum 0
   */
  rateLimitingInterval?: number;
  /**
   * Rate limiting limit per interval. Set to 0 to disable rate limiting.
   * @default 0
   * @minimum 0
   */
  rateLimitingLimit?: number;
  /**
   * Rate limiting technique.
   * @default "fixed"
   */
  rateLimitingTechnique?: "fixed" | "sliding";
  /**
   * Enable authentication for the gateway.
   * @default false
   */
  authentication?: boolean;
  /**
   * Log retention limit in requests.
   * @default undefined
   * @minimum 10000
   * @maximum 10000000
   */
  logManagement?: number;
  /**
   * Strategy for handling log limits.
   * @default undefined
   */
  logManagementStrategy?: "STOP_INSERTING" | "DELETE_OLDEST";
  /**
   * Enable logpush for the gateway.
   * @default false
   */
  logpush?: boolean;
  /**
   * Public key for logpush encryption.
   * @default undefined
   * @minLength 16
   * @maxLength 1024
   */
  logpushPublicKey?: string;
}
/**
 * Output returned after Cloudflare AI Gateway creation/update.
 * IMPORTANT: The interface name MUST match the exported resource name.
 */
export interface AiGateway
  extends Resource<"cloudflare::AiGateway">,
    AiGatewayProps {
  /**
   * The ID (name) of the gateway.
   */
  id: string;
  /**
   * Cloudflare account ID associated with the gateway.
   */
  accountId: string;
  /**
   * Cloudflare account tag associated with the gateway.
   */
  accountTag: string;
  /**
   * Time at which the gateway was created (ISO 8601 format).
   */
  createdAt: string;
  /**
   * The internal UUID of the gateway.
   */
  internalId: string;
  /**
   * Time at which the gateway was last modified (ISO 8601 format).
   */
  modifiedAt: string;
  /**
   * Resource type identifier for binding.
   * @internal
   */
  type: "ai_gateway";
}
/**
 * Represents a Cloudflare AI Gateway.
 *
 * @example
 * // Create a basic AI Gateway with default settings:
 * const basicGateway = await AiGateway("my-ai-gateway", {});
 *
 * @example
 * // Create an AI Gateway with authentication and rate limiting:
 * const secureGateway = await AiGateway("secure-ai-gateway", {
 *   authentication: true,
 *   rateLimitingInterval: 60, // 60 seconds
 *   rateLimitingLimit: 100,   // 100 requests
 *   rateLimitingTechnique: "sliding"
 * });
 *
 * @example
 * // Create an AI Gateway with logging enabled and logpush:
 * const loggingGateway = await AiGateway("logging-ai-gateway", {
 *   collectLogs: true,
 *   logpush: true,
 *   logpushPublicKey: "mypublickey..." // Replace with actual public key
 * });
 */
export const AiGateway = Resource(
  "cloudflare::AiGateway",
  async function (
    this: Context<AiGateway>,
    id: string,
    props: AiGatewayProps = {},
  ): Promise<AiGateway> {
    const api = await createCloudflareApi(props);
    const gatewayPath = `/accounts/${api.accountId}/ai-gateway/gateways/${id}`;
    const gatewaysPath = `/accounts/${api.accountId}/ai-gateway/gateways`;
    if (this.phase === "delete") {
      try {
        const deleteResponse = await api.delete(gatewayPath);
        // Only swallow 404 Not Found errors, all other errors should be handled
        if (!deleteResponse.ok && deleteResponse.status !== 404) {
          await handleApiError(deleteResponse, "delete", "ai gateway", id);
        }
      } catch (error) {
        console.error(`Error deleting AI Gateway ${id}:`, error);
        throw error;
      }
      return this.destroy();
    }
    // Default values as per Cloudflare documentation examples
    const mergedProps: AiGatewayProps = {
      cacheInvalidateOnUpdate: true,
      cacheTtl: 0,
      collectLogs: true,
      rateLimitingInterval: 0,
      rateLimitingLimit: 0,
      rateLimitingTechnique: "fixed",
      ...props, // User props override defaults
    };
    let response: Response | undefined;
    let apiResource: any;
    try {
      if (this.phase === "update") {
        // Update existing gateway (PUT request)
        const requestBody = mapPropsToApi(id, mergedProps, false);
        response = await api.put(gatewayPath, requestBody);
      } else {
        // Check if gateway exists before creating (to avoid conflict)
        const getResponse = await api.get(gatewayPath);
        if (getResponse.status === 200) {
          // Gateway exists, treat as update (PUT)
          console.log(
            `AI Gateway '${id}' already exists. Updating existing resource.`,
          );
          const requestBody = mapPropsToApi(id, mergedProps, false);
          response = await api.put(gatewayPath, requestBody);
        } else if (getResponse.status === 404) {
          // Gateway doesn't exist, create new (POST request)
          const requestBody = mapPropsToApi(id, mergedProps, true); // Include 'id' in POST body
          response = await api.post(gatewaysPath, requestBody);
        } else {
          // Unexpected error during GET check
          await handleApiError(getResponse, "get", "ai gateway", id);
        }
      }
      if (!response?.ok) {
        const action = this.phase === "update" ? "update" : "create";
        await handleApiError(response!, action, "ai gateway", id);
      }
      const data: { result: Record<string, any> } = await response!.json();
      apiResource = data.result;
    } catch (error) {
      console.error(`Error ${this.phase} AI Gateway '${id}':`, error);
      throw error; // Re-throw the error to fail the deployment
    }
    // Construct the output object from API response and merged props
    return this({
      ...mergedProps, // Start with the input props (including defaults)
      id: apiResource.id,
      accountId: apiResource.account_id,
      accountTag: apiResource.account_tag,
      createdAt: apiResource.created_at,
      internalId: apiResource.internal_id,
      modifiedAt: apiResource.modified_at,
      // Update props based on the actual response from the API (Cloudflare might set defaults)
      cacheInvalidateOnUpdate: apiResource.cache_invalidate_on_update,
      cacheTtl: apiResource.cache_ttl,
      collectLogs: apiResource.collect_logs,
      rateLimitingInterval: apiResource.rate_limiting_interval,
      rateLimitingLimit: apiResource.rate_limiting_limit,
      rateLimitingTechnique: apiResource.rate_limiting_technique,
      authentication: apiResource.authentication,
      logManagement: apiResource.log_management,
      logManagementStrategy: apiResource.log_management_strategy,
      logpush: apiResource.logpush,
      logpushPublicKey: apiResource.logpush_public_key,
      type: "ai_gateway",
    });
  },
);
// Helper function to map props to the API request body format
function mapPropsToApi(
  id: string,
  props: AiGatewayProps,
  includeIdInBody = false,
): Record<string, any> {
  const body: Record<string, any> = {};
  if (includeIdInBody) {
    body.id = id;
  }
  if (props.cacheInvalidateOnUpdate !== undefined) {
    body.cache_invalidate_on_update = props.cacheInvalidateOnUpdate;
  }
  if (props.cacheTtl !== undefined) {
    body.cache_ttl = props.cacheTtl;
  }
  if (props.collectLogs !== undefined) {
    body.collect_logs = props.collectLogs;
  }
  if (props.rateLimitingInterval !== undefined) {
    body.rate_limiting_interval = props.rateLimitingInterval;
  }
  if (props.rateLimitingLimit !== undefined) {
    body.rate_limiting_limit = props.rateLimitingLimit;
  }
  if (props.rateLimitingTechnique !== undefined) {
    body.rate_limiting_technique = props.rateLimitingTechnique;
  }
  if (props.authentication !== undefined) {
    body.authentication = props.authentication;
  }
  if (props.logManagement !== undefined) {
    body.log_management = props.logManagement;
  }
  if (props.logManagementStrategy !== undefined) {
    body.log_management_strategy = props.logManagementStrategy;
  }
  if (props.logpush !== undefined) {
    body.logpush = props.logpush;
  }
  if (props.logpushPublicKey !== undefined) {
    body.logpush_public_key = props.logpushPublicKey;
  }
  return body;
}
</file>

<file path="alchemy/src/cloudflare/ai.ts">
/**
 * @see https://developers.cloudflare.com/workers-ai/
 */
export class Ai<Models extends AiModelListType = AiModelListType> {
  public readonly type = "ai";
  /**
   * @internal
   */
  ///@ts-ignore
  _phantom: Models;
}
</file>

<file path="alchemy/src/cloudflare/api-error.ts">
/**
 * Custom error class for Cloudflare API errors
 * Includes HTTP status information from the Response
 */
export class CloudflareApiError extends Error {
  /**
   * HTTP status code
   */
  status: number;
  /**
   * HTTP status text
   */
  statusText: string;
  /**
   * Raw error data from the API
   */
  errorData?: any;
  /**
   * Create a new CloudflareApiError
   */
  constructor(message: string, response: Response, errorData?: any) {
    super(message);
    this.name = "CloudflareApiError";
    this.status = response.status;
    this.statusText = response.statusText;
    this.errorData = errorData;
    // Ensure instanceof works correctly
    Object.setPrototypeOf(this, CloudflareApiError.prototype);
  }
}
/**
 * Helper function to handle API errors
 *
 * @param response The fetch Response object
 * @param action The action being performed (e.g., "creating", "deleting")
 * @param resourceType The type of resource being acted upon (e.g., "R2 bucket", "Worker")
 * @param resourceName The name/identifier of the specific resource
 * @returns Never returns - always throws an error
 */
export async function handleApiError(
  response: Response,
  action: string,
  resourceType: string,
  resourceName: string,
): Promise<never> {
  const text = await response.text();
  let json: any;
  try {
    json = JSON.parse(text);
  } catch (error) {
    json = { errors: [{ message: text }] };
  }
  const errors: { message: string }[] = json?.errors || [
    { message: response.statusText },
  ];
  const errorMessage = `Error ${response.status} ${action} ${resourceType} '${resourceName}': ${errors[0]?.message || response.statusText}`;
  throw new CloudflareApiError(errorMessage, response, errors);
}
</file>

<file path="alchemy/src/cloudflare/api.ts">
import { alchemy } from "../alchemy.js";
import type { Secret } from "../secret.js";
import { withExponentialBackoff } from "../util/retry.js";
import {
  getCloudflareAuthHeaders,
  type CloudflareAuthOptions,
} from "./auth.js";
import { getCloudflareAccounts, getUserEmailFromApiKey } from "./user.js";
/**
 * Options for Cloudflare API requests
 */
export interface CloudflareApiOptions {
  /**
   * Base URL for Cloudflare API
   *
   * @default https://api.cloudflare.com/client/v4
   */
  baseUrl?: string;
  /**
   * API Key to use (overrides CLOUDFLARE_API_KEY env var)
   */
  apiKey?: Secret;
  /**
   * API Token to use (overrides CLOUDFLARE_API_TOKEN env var)
   */
  apiToken?: Secret;
  /**
   * Account ID to use (overrides CLOUDFLARE_ACCOUNT_ID env var)
   * If not provided, will be automatically retrieved from the Cloudflare API
   */
  accountId?: string;
  /**
   * Email to use with API Key authentication
   * If not provided, will attempt to discover from Cloudflare API
   */
  email?: string;
}
/**
 * Creates a CloudflareApi instance with automatic account ID discovery if not provided
 *
 * @param options API options
 * @returns Promise resolving to a CloudflareApi instance
 */
export async function createCloudflareApi(
  options: Partial<CloudflareApiOptions> = {},
): Promise<CloudflareApi> {
  const apiKey =
    options.apiKey ??
    (process.env.CLOUDFLARE_API_KEY
      ? alchemy.secret(process.env.CLOUDFLARE_API_KEY)
      : undefined);
  const apiToken =
    options.apiToken ??
    (process.env.CLOUDFLARE_API_TOKEN
      ? alchemy.secret(process.env.CLOUDFLARE_API_TOKEN)
      : undefined);
  let email = options.email ?? process.env.CLOUDFLARE_EMAIL;
  if (apiKey && !email) {
    email = await getUserEmailFromApiKey(apiKey.unencrypted);
  }
  const accountId =
    options.accountId ??
    process.env.CLOUDFLARE_ACCOUNT_ID ??
    process.env.CF_ACCOUNT_ID ??
    (
      await getCloudflareAccounts({
        apiKey,
        apiToken,
        email,
      } as CloudflareAuthOptions)
    )[0]?.id;
  if (accountId === undefined) {
    throw new Error(
      "Either accountId or CLOUDFLARE_ACCOUNT_ID must be provided",
    );
  }
  return new CloudflareApi({
    baseUrl: options.baseUrl,
    accountId,
    email,
    apiKey,
    apiToken,
  });
}
/**
 * Cloudflare API client using raw fetch
 */
export class CloudflareApi {
  public readonly accountId: string;
  public readonly baseUrl: string;
  public readonly apiKey: Secret | undefined;
  public readonly apiToken: Secret | undefined;
  public readonly email: string | undefined;
  public readonly authOptions: CloudflareAuthOptions;
  /**
   * Create a new Cloudflare API client
   * Use createCloudflareApi factory function instead of direct constructor
   * for automatic account ID discovery.
   *
   * @param options API options
   */
  constructor(
    options: CloudflareApiOptions & {
      accountId: string;
    },
  ) {
    this.accountId = options.accountId;
    this.baseUrl = options.baseUrl ?? "https://api.cloudflare.com/client/v4";
    this.apiKey = options.apiKey;
    this.apiToken = options.apiToken;
    this.email = options.email;
    if (this.apiKey && this.apiToken) {
      throw new Error("'apiKey' and 'apiToken' cannot both be provided");
    } else if (this.apiKey && !this.email) {
      throw new Error("'email' must be provided if 'apiKey' is provided");
    }
    this.authOptions = this.apiKey
      ? {
          apiKey: this.apiKey,
          email: this.email!,
        }
      : {
          apiToken: this.apiToken,
        };
  }
  /**
   * Make a fetch request to the Cloudflare API
   *
   * @param path API path (without base URL)
   * @param init Fetch init options
   * @returns Raw Response object from fetch
   */
  async fetch(path: string, init: RequestInit = {}): Promise<Response> {
    let headers: Record<string, string> = {
      "Content-Type": "application/json",
    };
    if (Array.isArray(init.headers)) {
      init.headers.forEach(([key, value]) => {
        headers[key] = value;
      });
    } else if (init.headers instanceof Headers) {
      init.headers.forEach((value, key) => {
        headers[key] = value;
      });
    } else if (init.headers) {
      headers = init.headers;
    }
    headers = {
      ...(await getCloudflareAuthHeaders(this.authOptions)),
      ...headers,
    };
    // TODO(sam): is this necessary?
    if (init.body instanceof FormData) {
      delete headers["Content-Type"];
    }
    // Use withExponentialBackoff for automatic retry on network errors
    return withExponentialBackoff(
      async () => {
        const response = await fetch(`${this.baseUrl}${path}`, {
          ...init,
          headers,
        });
        if (response.status.toString().startsWith("5")) {
          throw new InternalError("5xx error");
        }
        return response;
      },
      // transient errors should be retried aggressively
      (error) => error instanceof InternalError,
      5, // Maximum 5 attempts (1 initial + 4 retries)
      1000, // Start with 1s delay, will exponentially increase
    );
  }
  /**
   * Helper for GET requests
   */
  async get(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "GET" });
  }
  /**
   * Helper for HEAD requests
   */
  async head(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "HEAD" });
  }
  /**
   * Helper for POST requests
   */
  async post(
    path: string,
    body: any,
    init: RequestInit = {},
  ): Promise<Response> {
    const requestBody =
      body instanceof FormData
        ? body
        : typeof body === "string"
          ? body
          : JSON.stringify(body);
    return this.fetch(path, { ...init, method: "POST", body: requestBody });
  }
  /**
   * Helper for PUT requests
   */
  async put(
    path: string,
    body: any,
    init: RequestInit = {},
  ): Promise<Response> {
    const requestBody = body instanceof FormData ? body : JSON.stringify(body);
    return this.fetch(path, { ...init, method: "PUT", body: requestBody });
  }
  /**
   * Helper for PATCH requests
   */
  async patch(
    path: string,
    body: any,
    init: RequestInit = {},
  ): Promise<Response> {
    return this.fetch(path, {
      ...init,
      method: "PATCH",
      body: JSON.stringify(body),
    });
  }
  /**
   * Helper for DELETE requests
   */
  async delete(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "DELETE" });
  }
}
class InternalError extends Error {}
</file>

<file path="alchemy/src/cloudflare/asset-manifest.ts">
export type AssetManifest = AssetManifestEntry[];
export interface AssetManifestEntry {
  source: string;
  key: string;
  hash: string;
  cacheControl: string;
  contentType?: string;
}
export interface FileOption {
  files: string | string[];
  cacheControl: string;
  contentType?: string;
  ignore?: string[];
}
</file>

<file path="alchemy/src/cloudflare/assets.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { getContentType } from "../util/content-type.js";
/**
 * Properties for creating or updating Assets
 */
export interface AssetsProps {
  /**
   * Path to a directory containing static assets to be uploaded
   * These files will be served by Cloudflare's Workers runtime
   */
  path: string;
}
/**
 * Output returned after Assets creation/update
 */
export interface Assets extends Resource<"cloudflare::Asset">, AssetsProps {
  /**
   * The type of binding
   */
  type: "assets";
  /**
   * The ID of the assets bundle
   */
  id: string;
  /**
   * Asset files that were found
   */
  files: AssetFile[];
  /**
   * Time at which the assets were created
   */
  createdAt: number;
  /**
   * Time at which the assets were last updated
   */
  updatedAt: number;
}
/**
 * Represents a single asset file
 */
export interface AssetFile {
  /**
   * Path relative to the assets directory
   */
  path: string;
  /**
   * Full filesystem path to the file
   */
  filePath: string;
  /**
   * Content type of the file
   */
  contentType: string;
}
/**
 * Cloudflare Assets represent a collection of static files that can be uploaded and served
 * by Cloudflare Workers.
 *
 * @example
 * // Create a basic assets bundle from a local directory
 * const staticAssets = await Assets("static", {
 *   path: "./src/assets"
 * });
 *
 * // Use these assets with a worker
 * const worker = await Worker("frontend", {
 *   name: "frontend-worker",
 *   entrypoint: "./src/worker.ts",
 *   bindings: {
 *     ASSETS: staticAssets
 *   }
 * });
 */
export const Assets = Resource(
  "cloudflare::Asset",
  {
    alwaysUpdate: true,
  },
  async function (
    this: Context<Assets>,
    id: string,
    props: AssetsProps,
  ): Promise<Assets> {
    if (this.phase === "delete") {
      return this.destroy();
    }
    try {
      // Check if the assets directory exists
      const stats = await fs.stat(props.path);
      if (!stats.isDirectory()) {
        throw new Error(`Assets path ${props.path} is not a directory`);
      }
    } catch (error) {
      throw new Error(
        `Assets directory ${props.path} does not exist or is not accessible`,
      );
    }
    // Recursively get all files in the assets directory
    const filesList = await getFilesRecursively(props.path);
    // Create asset file objects
    const files: AssetFile[] = filesList.map((filePath) => {
      const relativePath = path.relative(props.path, filePath);
      const normalizedPath = relativePath.split(path.sep).join("/"); // Ensure forward slashes for URLs
      return {
        path: normalizedPath,
        filePath,
        contentType: getContentType(filePath),
      };
    });
    // Get current timestamp
    const now = Date.now();
    // Construct the output
    return this({
      id,
      type: "assets",
      path: props.path,
      files,
      createdAt: this.output?.createdAt || now,
      updatedAt: now,
    });
  },
);
// Helper functions for file operations
async function getFilesRecursively(dir: string): Promise<string[]> {
  const files = await fs.readdir(dir, { withFileTypes: true });
  const allFiles = await Promise.all(
    files.map(async (file) => {
      const path = `${dir}/${file.name}`;
      if (file.isDirectory()) {
        return getFilesRecursively(path);
      }
      return path;
    }),
  );
  return allFiles.flat();
}
</file>

<file path="alchemy/src/cloudflare/auth.ts">
import fs from "node:fs/promises";
import os from "node:os";
import path from "node:path";
import type { Secret } from "../secret.js";
/**
 * Authentication options for Cloudflare API
 */
export type CloudflareAuthOptions =
  | CloudflareApiKeyAuthOptions
  | CloudflareApiTokenAuthOptions;
export type CloudflareApiKeyAuthOptions = {
  /**
   * API Key to use with API Key
   */
  apiKey: Secret;
  /**
   * Email to use with API Key
   * If not provided, will attempt to discover from Cloudflare API
   */
  email: string;
  /**
   * API Token to use with API Key
   */
  apiToken?: undefined;
};
export function isCloudflareApiKeyAuthOptions(
  options: CloudflareAuthOptions | undefined,
): options is CloudflareApiKeyAuthOptions {
  return options !== undefined && options.apiKey !== undefined;
}
export type CloudflareApiTokenAuthOptions = {
  /**
   * API Token to use with API Key
   */
  apiToken?: Secret;
  /**
   * API Key to use with API Token
   */
  apiKey?: undefined;
  /**
   * Email to use with API Token
   */
  email?: undefined;
};
export function isCloudflareApiTokenAuthOptions(
  options: CloudflareAuthOptions | undefined,
): options is CloudflareApiTokenAuthOptions {
  return options !== undefined && options.apiToken !== undefined;
}
export async function getCloudflareAuthHeaders(
  options: CloudflareAuthOptions | undefined,
): Promise<Record<string, string>> {
  if (isCloudflareApiKeyAuthOptions(options)) {
    // Global API Key
    return {
      "X-Auth-Key": options.apiKey.unencrypted,
      "X-Auth-Email": options.email,
    };
  } else if (isCloudflareApiTokenAuthOptions(options)) {
    // API Token
    return {
      Authorization: `Bearer ${options.apiToken?.unencrypted}`,
    };
  }
  // Wrangler OAuth Token
  const authConfig = await getRefreshedAuthConfig();
  if (authConfig.oauth_token) {
    return {
      Authorization: `Bearer ${authConfig.oauth_token}`,
    };
  }
  throw new Error(
    "Cloudflare authentication required. Did you forget to login with `wrangler login` or set CLOUDFLARE_API_TOKEN, CLOUDFLARE_API_KEY?",
  );
}
async function refreshAuthToken(
  options: WranglerConfig,
): Promise<WranglerConfig> {
  const response = await fetch("https://dash.cloudflare.com/oauth2/token", {
    method: "POST",
    headers: {
      "Content-Type": "application/x-www-form-urlencoded",
    },
    body: new URLSearchParams({
      grant_type: "refresh_token",
      refresh_token: options.refresh_token!,
      client_id: "54d11594-84e4-41aa-b438-e81b8fa78ee7",
    }).toString(),
  });
  if (!response.ok) {
    throw new Error(
      `Failed to refresh auth token: ${response.status} ${response.statusText}`,
    );
  }
  const data: any = await response.json();
  if (!data.access_token) {
    throw new Error("Failed to refresh auth token - no access token returned");
  }
  options.oauth_token = data.access_token;
  options.refresh_token = data.refresh_token;
  options.expiration_time = new Date(
    Date.now() + data.expires_in * 1000,
  ).toISOString();
  options.scopes = data.scope?.split(" ") || [];
  return options;
}
interface WranglerConfig {
  path: string;
  oauth_token?: string;
  refresh_token?: string;
  expiration_time?: string;
  scopes?: string[];
  /** exists is `false` if the config file doesn't exist, like in CI */
  exists?: boolean;
  /** @deprecated - this field was only provided by the deprecated v1 `wrangler config` command. */
  api_token?: string;
}
async function getRefreshedAuthConfig(): Promise<WranglerConfig> {
  let authConfig = await readWranglerConfig();
  if (authConfig.expiration_time) {
    const expiry = new Date(authConfig.expiration_time);
    // if expiring in 10s
    if (expiry.getTime() < Date.now() + 10 * 1000) {
      authConfig = await refreshAuthToken(authConfig);
      authConfigCache[authConfig.path] = authConfig;
      await writeWranglerConfig(authConfig);
    }
  }
  return authConfig;
}
async function writeWranglerConfig(config: WranglerConfig) {
  if (config.exists === false) return;
  const TOML = await import("@iarna/toml");
  const configPath = await findWranglerConfig();
  config = {
    ...config,
  };
  // @ts-ignore - i put this here
  delete config.path;
  const toml = TOML.stringify(config as any);
  await fs.writeFile(configPath, toml);
}
// cache the file once per process
const authConfigCache: Record<string, WranglerConfig> = {};
async function readWranglerConfig(): Promise<WranglerConfig> {
  const configPath = await findWranglerConfig();
  try {
    const config = (authConfigCache[configPath] ??= await parseTOML(
      await fs.readFile(configPath, "utf-8"),
    ));
    config.path = configPath;
    return config;
  } catch (e: any) {
    if (e.code === "ENOENT") {
      // The config doesn't exist
      return {
        path: configPath,
        exists: false,
      };
    }
    throw e;
  }
}
let wranglerConfigPath: string | undefined;
async function findWranglerConfig(): Promise<string> {
  if (wranglerConfigPath) {
    return wranglerConfigPath;
  }
  const environment = process.env.WRANGLER_API_ENVIRONMENT ?? "production";
  const filePath = path.join(
    "config",
    `${environment === "production" ? "default.toml" : `${environment}.toml`}`,
  );
  const xdgAppPaths = (await import("xdg-app-paths")).default;
  //TODO: We should implement a custom path --global-config and/or the WRANGLER_HOME type environment variable
  const configDir = xdgAppPaths(".wrangler").config(); // New XDG compliant config path
  const legacyConfigDir = path.join(os.homedir(), ".wrangler"); // Legacy config in user's home directory
  // Check for the .wrangler directory in root if it is not there then use the XDG compliant path.
  wranglerConfigPath = path.join(
    (await isDirectory(legacyConfigDir)) ? legacyConfigDir : configDir,
    filePath,
  );
  return wranglerConfigPath;
}
async function parseTOML(input: string): Promise<any> {
  const TOML = await import("@iarna/toml");
  try {
    // Normalize CRLF to LF to avoid hitting https://github.com/iarna/iarna-toml/issues/33.
    const normalizedInput = input.replace(/\r\n/g, "\n");
    return TOML.parse(normalizedInput);
  } catch (err: any) {
    const { name } = err;
    if (name !== "TomlError") {
      throw err;
    }
    throw new Error("TOML parse error");
  }
}
async function isDirectory(dir: string) {
  try {
    return (await fs.stat(dir)).isDirectory();
  } catch (err) {
    return false;
  }
}
</file>

<file path="alchemy/src/cloudflare/bindings.ts">
/**
 * Type definitions for Cloudflare Worker bindings
 * Based on Cloudflare API documentation:
 * https://developers.cloudflare.com/api/resources/workers/subresources/scripts/methods/update/
 */
import type { Secret } from "../secret.js";
import type { AiGateway } from "./ai-gateway.js";
import type { Ai } from "./ai.js";
import type { Assets } from "./assets.js";
import type { Bound } from "./bound.js";
import type { BrowserRendering } from "./browser-rendering.js";
import type { R2Bucket } from "./bucket.js";
import type { D1Database } from "./d1-database.js";
import type { DurableObjectNamespace } from "./durable-object-namespace.js";
import type { Hyperdrive } from "./hyperdrive.js";
import type { KVNamespace } from "./kv-namespace.js";
import type { Pipeline } from "./pipeline.js";
import type { Queue } from "./queue.js";
import type { VectorizeIndex } from "./vectorize-index.js";
import type { Worker } from "./worker.js";
import type { Workflow } from "./workflow.js";
export type Bindings = {
  [bindingName: string]: Binding;
};
export declare namespace Bindings {
  export type Runtime<B extends Bindings> = {
    [bindingName in keyof B]: Bound<B[bindingName]>;
  };
}
/**
 * L2 Binding Resources.
 */
export type Binding =
  | Ai
  | AiGateway
  | Assets
  | D1Database
  | DurableObjectNamespace
  | Hyperdrive
  | KVNamespace
  | Pipeline
  | Queue
  | R2Bucket
  | Secret
  | string
  | VectorizeIndex
  | Worker
  | Workflow
  | BrowserRendering
  | Self;
export type Self = typeof Self;
export const Self = Symbol.for("Self");
/**
 * Union type for all Worker binding types (API spec)
 */
export type WorkerBindingSpec =
  | WorkerBindingAI
  | WorkerBindingAnalyticsEngine
  | WorkerBindingAssets
  | WorkerBindingBrowserRendering
  | WorkerBindingD1
  | WorkerBindingDispatchNamespace
  | WorkerBindingDurableObjectNamespace
  | WorkerBindingHyperdrive
  | WorkerBindingJson
  | WorkerBindingKVNamespace
  | WorkerBindingMTLSCertificate
  | WorkerBindingPipeline
  | WorkerBindingPlainText
  | WorkerBindingQueue
  | WorkerBindingR2Bucket
  | WorkerBindingSecretText
  | WorkerBindingService
  | WorkerBindingStaticContent
  | WorkerBindingTailConsumer
  | WorkerBindingVectorize
  | WorkerBindingVersionMetadata
  | WorkerBindingWasmModule
  | WorkerBindingWorkflow;
/**
 * AI binding type
 */
export interface WorkerBindingAI {
  /** The name of the binding */
  name: string;
  /** Type identifier for AI binding */
  type: "ai";
}
/**
 * Analytics Engine binding type
 */
export interface WorkerBindingAnalyticsEngine {
  /** The name of the binding */
  name: string;
  /** Type identifier for Analytics Engine binding */
  type: "analytics_engine";
  /** Dataset name */
  dataset: string;
}
/**
 * Assets binding type
 */
export interface WorkerBindingAssets {
  /** The name of the binding */
  name: string;
  /** Type identifier for Assets binding */
  type: "assets";
}
/**
 * Browser Rendering binding type
 */
export interface WorkerBindingBrowserRendering {
  /** The name of the binding */
  name: string;
  /** Type identifier for Browser Rendering binding */
  type: "browser";
}
/**
 * D1 database binding type
 */
export interface WorkerBindingD1 {
  /** The name of the binding */
  name: string;
  /** Type identifier for D1 binding */
  type: "d1";
  /** D1 database ID */
  id: string;
}
/**
 * Dispatch Namespace binding type
 */
export interface WorkerBindingDispatchNamespace {
  /** The name of the binding */
  name: string;
  /** Type identifier for Dispatch Namespace binding */
  type: "dispatch_namespace";
  /** Namespace identifier */
  namespace: string;
  /** Optional outbound service */
  outbound?: any; // Documentation doesn't specify the exact type
}
/**
 * Durable Object Namespace binding type
 */
export interface WorkerBindingDurableObjectNamespace {
  /**
   * The stable ID of the binding
   * @internal
   */
  stableId?: string;
  /** The name of the binding */
  name: string;
  /** Type identifier for Durable Object Namespace binding */
  type: "durable_object_namespace";
  /** Durable Object class name */
  class_name: string;
  /** Script name that contains the Durable Object */
  script_name?: string;
  /** Environment */
  environment?: string;
  /** Namespace ID */
  namespace_id?: string;
}
/**
 * Hyperdrive binding type
 */
export interface WorkerBindingHyperdrive {
  /** The name of the binding */
  name: string;
  /** Type identifier for Hyperdrive binding */
  type: "hyperdrive";
  /** Hyperdrive ID */
  id: string;
}
/**
 * JSON binding type
 */
export interface WorkerBindingJson {
  /** The name of the binding */
  name: string;
  /** Type identifier for JSON binding */
  type: "json";
  /** JSON value */
  json: any;
}
/**
 * KV Namespace binding type
 */
export interface WorkerBindingKVNamespace {
  /** The name of the binding */
  name: string;
  /** Type identifier for KV Namespace binding */
  type: "kv_namespace";
  /** KV Namespace ID */
  namespace_id: string;
}
/**
 * MTLS Certificate binding type
 */
export interface WorkerBindingMTLSCertificate {
  /** The name of the binding */
  name: string;
  /** Type identifier for MTLS Certificate binding */
  type: "mtls_certificate";
  /** Certificate ID */
  certificate_id: string;
}
/**
 * Plain Text binding type
 */
export interface WorkerBindingPlainText {
  /** The name of the binding */
  name: string;
  /** Type identifier for Plain Text binding */
  type: "plain_text";
  /** Text content */
  text: string;
}
/**
 * Queue binding type
 */
export interface WorkerBindingQueue {
  /** The name of the binding */
  name: string;
  /** Type identifier for Queue binding */
  type: "queue";
  /** Queue name */
  queue_name: string;
}
/**
 * R2 Bucket binding type
 */
export interface WorkerBindingR2Bucket {
  /** The name of the binding */
  name: string;
  /** Type identifier for R2 Bucket binding */
  type: "r2_bucket";
  /** Bucket name */
  bucket_name: string;
}
/**
 * Secret Text binding type
 */
export interface WorkerBindingSecretText {
  /** The name of the binding */
  name: string;
  /** Type identifier for Secret Text binding */
  type: "secret_text";
  /** Secret value */
  text: string;
}
/**
 * Service binding type
 */
export interface WorkerBindingService {
  /** The name of the binding */
  name: string;
  /** Type identifier for Service binding */
  type: "service";
  /** Service name */
  service: string;
  /** Environment */
  environment?: string;
  /** Service namespace */
  namespace?: string;
}
/**
 * Tail Consumer binding type
 */
export interface WorkerBindingTailConsumer {
  /** The name of the binding */
  name: string;
  /** Type identifier for Tail Consumer binding */
  type: "tail_consumer";
  /** Service name */
  service: string;
}
/**
 * Vectorize binding type
 */
export interface WorkerBindingVectorize {
  /** The name of the binding */
  name: string;
  /** Type identifier for Vectorize binding */
  type: "vectorize";
  /** Index name */
  index_name: string;
}
/**
 * Version Metadata binding type
 */
export interface WorkerBindingVersionMetadata {
  /** The name of the binding */
  name: string;
  /** Type identifier for Version Metadata binding */
  type: "version_metadata";
}
/**
 * WASM Module binding type
 */
export interface WorkerBindingWasmModule {
  /** The name of the binding */
  name: string;
  /** Type identifier for WASM Module binding */
  type: "wasm_module";
  /** Module name */
  module: string;
}
/**
 * Static content binding for Cloudflare Workers
 * Used for Workers Sites and static assets
 */
export interface WorkerBindingStaticContent {
  /** The name of the binding */
  name: string;
  /** Type identifier for Static Content binding */
  type: "static_content";
}
export interface WorkerBindingWorkflow {
  /** The name of the binding */
  name: string;
  /** Type identifier for Workflow binding */
  type: "workflow";
  /** Workflow name */
  workflow_name: string;
  /** Workflow class name */
  class_name: string;
  /**
   * Workflow script name
   *
   * @default - the name of the script it is bound to
   */
  script_name?: string;
}
/**
 * Pipeline binding type
 */
export interface WorkerBindingPipeline {
  /** The name of the binding */
  name: string;
  /** Type identifier for Pipeline binding */
  type: "pipelines";
  /** Pipeline name */
  pipeline: string;
}
</file>

<file path="alchemy/src/cloudflare/bound.ts">
import type { Pipeline } from "cloudflare:pipelines";
import type { Secret } from "../secret.js";
import type { AiGateway as _AiGateway } from "./ai-gateway.js";
import type { Ai as _Ai } from "./ai.js";
import type { Assets } from "./assets.js";
import type { Binding, Self } from "./bindings.js";
import type { BrowserRendering } from "./browser-rendering.js";
import type { R2Bucket as _R2Bucket } from "./bucket.js";
import type { D1Database as _D1Database } from "./d1-database.js";
import type { DurableObjectNamespace as _DurableObjectNamespace } from "./durable-object-namespace.js";
import type { Hyperdrive as _Hyperdrive } from "./hyperdrive.js";
import type { KVNamespace as _KVNamespace } from "./kv-namespace.js";
import type { Pipeline as _Pipeline } from "./pipeline.js";
import type { Queue as _Queue } from "./queue.js";
import type { VectorizeIndex as _VectorizeIndex } from "./vectorize-index.js";
import type { Worker as _Worker } from "./worker.js";
import type { Workflow as _Workflow } from "./workflow.js";
export type Bound<T extends Binding> = T extends _DurableObjectNamespace
  ? DurableObjectNamespace
  : T extends _KVNamespace
    ? KVNamespace
    : T extends _Worker
      ? Worker
      : T extends _R2Bucket
        ? R2Bucket
        : T extends _AiGateway
          ? AiGateway
          : T extends _Hyperdrive
            ? Hyperdrive
            : T extends Secret
              ? string
              : T extends Assets
                ? Service
                : T extends _Workflow<infer P>
                  ? Workflow<P>
                  : T extends _D1Database
                    ? D1Database
                    : T extends _VectorizeIndex
                      ? VectorizeIndex
                      : T extends _Queue<infer Body>
                        ? Queue<Body>
                        : T extends _Pipeline<infer R>
                          ? Pipeline<R>
                          : T extends string
                            ? string
                            : T extends BrowserRendering
                              ? Fetcher
                              : T extends _Ai<infer M>
                                ? Ai<M>
                                : T extends Self
                                  ? Service
                                  : Service;
</file>

<file path="alchemy/src/cloudflare/browser-rendering.ts">
export class BrowserRendering {
  public readonly type = "browser";
}
</file>

<file path="alchemy/src/cloudflare/bucket.ts">
import { AwsClient } from "aws4fetch";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import { type CloudflareApi, createCloudflareApi } from "./api.js";
/**
 * Properties for creating or updating an R2 Bucket
 */
export interface BucketProps {
  /**
   * Name of the bucket
   * Names can only contain lowercase letters (a-z), numbers (0-9), and hyphens (-)
   * Cannot begin or end with a hyphen
   *
   * @default - the id of the resource
   */
  name?: string;
  /**
   * Optional location hint for the bucket
   * Indicates the primary geographical location data will be accessed from
   */
  locationHint?: string;
  /**
   * Optional jurisdiction for the bucket
   * Determines the regulatory jurisdiction the bucket data falls under
   */
  jurisdiction?: "default" | "eu" | "fedramp";
  /**
   * Whether to allow public access through the r2.dev subdomain
   * Only for development purposes - use custom domains for production
   */
  allowPublicAccess?: boolean;
  /**
   * Whether to delete the bucket.
   * If set to false, the bucket will remain but the resource will be removed from state
   *
   * @default true
   */
  delete?: boolean;
  /**
   * Whether to empty the bucket and delete all objects during resource deletion
   * @default false
   */
  empty?: boolean;
  /**
   * API Token to use for the bucket
   */
  apiToken?: Secret;
  /**
   * API Key to use for the bucket
   */
  apiKey?: Secret;
  /**
   * Email to use for the bucket
   */
  email?: string;
  /**
   * Account ID to use for the bucket
   */
  accountId?: string;
  /**
   * Access Key to use for the bucket
   */
  accessKey?: Secret;
  /**
   * Secret Access Key to use for the bucket
   */
  secretAccessKey?: Secret;
  /**
   * Whether to adopt an existing bucket
   */
  adopt?: boolean;
}
/**
 * Output returned after R2 Bucket creation/update
 */
export interface R2Bucket
  extends Resource<"cloudflare::R2Bucket">,
    BucketProps {
  /**
   * Resource type identifier
   */
  type: "r2_bucket";
  /**
   * The name of the bucket
   */
  name: string;
  /**
   * Location of the bucket
   */
  location: string;
  /**
   * Time at which the bucket was created
   */
  creationDate: Date;
}
/**
 * Creates and manages Cloudflare R2 Buckets for object storage.
 *
 * R2 Buckets provide S3-compatible object storage with automatic data replication
 * across multiple regions for high availability and durability.
 *
 * @example
 * // Create a basic R2 bucket with default settings
 * const basicBucket = await R2Bucket("my-app-data", {
 *   name: "my-app-data"
 * });
 *
 * @example
 * // Create a bucket with location hint for optimal performance
 * const euBucket = await R2Bucket("eu-user-data", {
 *   name: "eu-user-data",
 *   locationHint: "eu",
 *   jurisdiction: "eu"
 * });
 *
 * @example
 * // Create a development bucket with public access enabled
 * const publicBucket = await R2Bucket("public-assets", {
 *   name: "public-assets",
 *   allowPublicAccess: true
 * });
 *
 * @example
 * // Create a FedRAMP compliant bucket for government workloads
 * const fedRampBucket = await R2Bucket("gov-data", {
 *   name: "gov-data",
 *   jurisdiction: "fedramp"
 * });
 *
 * @example
 * // Create a bucket that will be automatically emptied when deleted
 * // This will delete all objects in the bucket before deleting the bucket itself
 * const temporaryBucket = await R2Bucket("temp-storage", {
 *   name: "temp-storage",
 *   empty: true  // All objects will be deleted when this resource is destroyed
 * });
 *
 * @see https://developers.cloudflare.com/r2/buckets/
 */
export const R2Bucket = Resource(
  "cloudflare::R2Bucket",
  async function (
    this: Context<R2Bucket>,
    id: string,
    props: BucketProps = {},
  ): Promise<R2Bucket> {
    const api = await createCloudflareApi(props);
    const bucketName = props.name || this.id;
    if (this.phase === "delete") {
      if (props.delete !== false) {
        if (props.empty) {
          console.log("Emptying R2 bucket:", bucketName);
          const r2Client = await createR2Client({
            ...props,
            accountId: api.accountId,
          });
          // Empty the bucket first by deleting all objects
          await emptyBucket(r2Client, bucketName, props.jurisdiction);
        }
        await deleteBucket(api, bucketName, props);
      }
      // Return void (a deleted bucket has no content)
      return this.destroy();
    }
    if (this.phase === "create") {
      try {
        await createBucket(api, bucketName, props);
      } catch (err) {
        if (err instanceof CloudflareApiError && err.status === 409) {
          if (!props.adopt) {
            throw err;
          }
        } else {
          throw err;
        }
      }
    }
    await updatePublicAccess(
      api,
      bucketName,
      props.allowPublicAccess === true,
      props.jurisdiction,
    );
    return this({
      name: bucketName,
      location: props.locationHint || "default",
      creationDate: new Date(),
      jurisdiction: props.jurisdiction || "default",
      type: "r2_bucket",
      accountId: api.accountId,
    });
  },
);
/**
 * Configuration for R2 client to connect to Cloudflare R2
 */
export interface R2ClientConfig {
  accountId: string;
  accessKeyId?: Secret;
  secretAccessKey?: Secret;
  jurisdiction?: string;
}
type R2Client = AwsClient & { accountId: string };
/**
 * Creates an aws4fetch client configured for Cloudflare R2
 *
 * @see https://developers.cloudflare.com/r2/examples/aws/aws-sdk-js-v3/
 */
export function createR2Client(config?: R2ClientConfig): Promise<R2Client> {
  const accountId = config?.accountId ?? process.env.CLOUDFLARE_ACCOUNT_ID;
  const accessKeyId =
    config?.accessKeyId?.unencrypted || process.env.R2_ACCESS_KEY_ID;
  const secretAccessKey =
    config?.secretAccessKey?.unencrypted || process.env.R2_SECRET_ACCESS_KEY;
  if (!accountId) {
    throw new Error("CLOUDFLARE_ACCOUNT_ID environment variable is required");
  }
  if (!accessKeyId || !secretAccessKey) {
    throw new Error(
      "R2_ACCESS_KEY_ID and R2_SECRET_ACCESS_KEY environment variables are required",
    );
  }
  // Create aws4fetch client with Cloudflare R2 endpoint
  const client: any = new AwsClient({
    accessKeyId,
    secretAccessKey,
    service: "s3",
    region: "auto",
  });
  client.accountId = accountId;
  return client;
}
interface CloudflareBucketResponse {
  /**
   * The bucket information returned from the Cloudflare REST API
   * @see https://developers.cloudflare.com/api/node/resources/r2/subresources/buckets/models/bucket/#(schema)
   */
  result: {
    creation_date: string;
    location?: "apac" | "eeur" | "enam" | "weur" | "wnam" | "oc";
    name: string;
    storage_class?: "Standard" | "InfrequentAccess";
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Adds jurisdiction header to the headers object if specified in props
 *
 * @param headers Headers object to modify
 * @param props Props or jurisdiction string
 * @returns Modified headers object
 */
export function withJurisdiction(
  headers: Record<string, string>,
  props: BucketProps | { jurisdiction?: string } | string | undefined,
): Record<string, string> {
  // Clone the headers object to avoid modifying the original
  const result = { ...headers };
  let jurisdiction: string | undefined;
  if (typeof props === "string") {
    jurisdiction = props;
  } else if (props && "jurisdiction" in props) {
    jurisdiction = props.jurisdiction;
  }
  if (jurisdiction && jurisdiction !== "default") {
    result["cf-r2-jurisdiction"] = jurisdiction;
  }
  return result;
}
/**
 * Get a bucket
 */
export async function getBucket(
  api: CloudflareApi,
  bucketName: string,
  props: BucketProps = {},
): Promise<CloudflareBucketResponse> {
  const headers = withJurisdiction({}, props);
  const getResponse = await api.get(
    `/accounts/${api.accountId}/r2/buckets/${bucketName}`,
    { headers },
  );
  if (!getResponse.ok) {
    return await handleApiError(getResponse, "get", "R2 bucket", bucketName);
  }
  if (getResponse.status === 200) {
    return (await getResponse.json()) as CloudflareBucketResponse;
  }
  const errorData: any = await getResponse.json().catch(() => ({
    errors: [{ message: getResponse.statusText }],
  }));
  throw new CloudflareApiError(
    `Error getting R2 bucket '${bucketName}': ${errorData.errors?.[0]?.message || getResponse.statusText}`,
    getResponse,
  );
}
/**
 * Create a new bucket
 */
export async function createBucket(
  api: CloudflareApi,
  bucketName: string,
  props: BucketProps = {},
): Promise<CloudflareBucketResponse> {
  // Create new R2 bucket
  const createPayload: any = {
    name: bucketName,
  };
  if (props.locationHint) {
    createPayload.location_hint = props.locationHint;
  }
  const headers = withJurisdiction({}, props);
  const createResponse = await api.post(
    `/accounts/${api.accountId}/r2/buckets`,
    createPayload,
    { headers },
  );
  if (!createResponse.ok) {
    return await handleApiError(
      createResponse,
      "creating",
      "R2 bucket",
      bucketName,
    );
  }
  return (await createResponse.json()) as CloudflareBucketResponse;
}
/**
 * Delete a bucket
 */
export async function deleteBucket(
  api: CloudflareApi,
  bucketName: string,
  props: BucketProps,
): Promise<void> {
  // Delete R2 bucket
  const headers = withJurisdiction({}, props);
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/r2/buckets/${bucketName}`,
    { headers },
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting R2 bucket '${bucketName}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * List objects in an R2 bucket
 *
 * @param r2 R2Client instance
 * @param bucketName Name of the bucket
 * @param continuationToken Optional token for pagination
 * @param jurisdiction Optional jurisdiction for the bucket
 * @returns Object containing the list of objects and the next continuation token
 */
export async function listObjects(
  r2: R2Client,
  bucketName: string,
  continuationToken?: string,
  jurisdiction?: string,
): Promise<{ objects: { Key: string }[]; continuationToken?: string }> {
  // List objects in the bucket
  const url = new URL(
    `https://${r2.accountId}.r2.cloudflarestorage.com/${bucketName}`,
  );
  if (continuationToken) {
    url.searchParams.set("continuation-token", continuationToken);
  }
  url.searchParams.set("list-type", "2");
  const headers = withJurisdiction({}, jurisdiction);
  const listResponse = await r2.fetch(url.toString(), { headers });
  if (!listResponse.ok) {
    throw new CloudflareApiError(
      `Failed to list objects: ${listResponse.statusText}`,
      listResponse,
    );
  }
  const responseText = await listResponse.text();
  // Extract objects from XML response using regex
  const keyRegex = /<Key>([^<]+)<\/Key>/g;
  const objects: { Key: string }[] = [];
  let match;
  while ((match = keyRegex.exec(responseText)) !== null) {
    objects.push({ Key: match[1] });
  }
  // Get continuation token if present using regex
  const tokenMatch =
    /<NextContinuationToken>([^<]+)<\/NextContinuationToken>/.exec(
      responseText,
    );
  const nextContinuationToken = tokenMatch ? tokenMatch[1] : undefined;
  return { objects, continuationToken: nextContinuationToken };
}
/**
 * Helper function to empty a bucket by deleting all objects
 */
export async function emptyBucket(
  r2: R2Client,
  bucketName: string,
  jurisdiction?: string,
): Promise<void> {
  let continuationToken: string | undefined;
  let totalDeleted = 0;
  try {
    do {
      console.log(`Listing objects in bucket ${bucketName}`);
      // List objects in the bucket
      const { objects, continuationToken: nextToken } = await listObjects(
        r2,
        bucketName,
        continuationToken,
        jurisdiction,
      );
      continuationToken = nextToken;
      console.log(`Found ${objects.length} objects in bucket ${bucketName}`);
      // Delete objects in batches
      if (objects.length > 0) {
        // Process delete in batches of 1000 (S3 limit)
        for (let i = 0; i < objects.length; i += 1000) {
          const batch = objects.slice(i, i + 1000);
          // Create DeleteObjects request XML
          const deleteXml = `
            <Delete>
              ${batch.map((obj) => `<Object><Key>${obj.Key}</Key></Object>`).join("")}
            </Delete>
          `;
          const deleteUrl = new URL(
            `https://${r2.accountId}.r2.cloudflarestorage.com/${bucketName}?delete`,
          );
          console.log(
            `Deleting ${batch.length} objects from bucket ${bucketName}`,
          );
          const headers = withJurisdiction(
            { "Content-Type": "application/xml" },
            jurisdiction,
          );
          const deleteResponse = await r2.fetch(deleteUrl.toString(), {
            method: "POST",
            body: deleteXml,
            headers,
          });
          if (!deleteResponse.ok) {
            throw new CloudflareApiError(
              `Failed to delete objects: ${deleteResponse.statusText}`,
              deleteResponse,
            );
          }
          totalDeleted += batch.length;
        }
      }
    } while (continuationToken);
    console.log(
      `Successfully emptied bucket ${bucketName}, deleted ${totalDeleted} objects total`,
    );
  } catch (error) {
    if (error instanceof CloudflareApiError && error.status === 404) {
      // the bucket was not found
      return;
    }
    console.error(`Failed to empty bucket ${bucketName}:`, error);
    throw error;
  }
}
/**
 * Update public access setting for a bucket
 *
 * This operation is not available through the S3 API for R2,
 * so we still use the Cloudflare API directly.
 */
export async function updatePublicAccess(
  api: CloudflareApi,
  bucketName: string,
  allowPublicAccess: boolean,
  jurisdiction?: string,
): Promise<void> {
  const headers = withJurisdiction({}, jurisdiction);
  const response = await api.put(
    `/accounts/${api.accountId}/r2/buckets/${bucketName}/domains/managed`,
    {
      enabled: allowPublicAccess,
    },
    { headers },
  );
  if (!response.ok) {
    await handleApiError(
      response,
      "updating public access for",
      "R2 bucket",
      bucketName,
    );
  }
}
/**
 * Set CORS configuration for a bucket using aws4fetch
 */
export async function setCorsConfiguration(
  r2: R2Client,
  bucketName: string,
  allowedOrigins: string[] = ["*"],
  allowedMethods: string[] = ["GET", "HEAD", "PUT", "POST", "DELETE"],
  allowedHeaders: string[] = ["*"],
  maxAgeSeconds = 3600,
  jurisdiction?: string,
): Promise<void> {
  try {
    // Construct CORS XML configuration
    const corsXml = `
      <CORSConfiguration>
        <CORSRule>
          ${allowedOrigins.map((origin) => `<AllowedOrigin>${origin}</AllowedOrigin>`).join("")}
          ${allowedMethods.map((method) => `<AllowedMethod>${method}</AllowedMethod>`).join("")}
          ${allowedHeaders.map((header) => `<AllowedHeader>${header}</AllowedHeader>`).join("")}
          <ExposeHeader>ETag</ExposeHeader>
          <MaxAgeSeconds>${maxAgeSeconds}</MaxAgeSeconds>
        </CORSRule>
      </CORSConfiguration>
    `;
    const url = new URL(
      `https://${r2.accountId}.r2.cloudflarestorage.com/${bucketName}?cors`,
    );
    const headers = withJurisdiction(
      { "Content-Type": "application/xml" },
      jurisdiction,
    );
    const response = await r2.fetch(url.toString(), {
      method: "PUT",
      body: corsXml,
      headers,
    });
    if (!response.ok) {
      throw new CloudflareApiError(
        `Failed to set CORS configuration: ${response.statusText}`,
        response,
      );
    }
    console.log(`Successfully set CORS configuration for bucket ${bucketName}`);
  } catch (error) {
    console.error(
      `Failed to set CORS configuration for bucket ${bucketName}:`,
      error,
    );
    throw error;
  }
}
/**
 * Information about an R2 bucket returned by list operations
 */
export interface R2BucketInfo {
  /**
   * Name of the bucket
   */
  Name: string;
  /**
   * Creation date of the bucket
   */
  CreationDate: Date;
}
/**
 * List all R2 buckets in an account
 *
 * @param api CloudflareApi instance
 * @param options Optional listing options
 * @returns Array of bucket information
 */
export async function listBuckets(
  api: CloudflareApi,
  options: {
    nameContains?: string;
    perPage?: number;
    cursor?: string;
    direction?: "asc" | "desc";
    jurisdiction?: string;
  } = {},
): Promise<R2BucketInfo[]> {
  // Build query parameters
  const params = new URLSearchParams();
  if (options.nameContains) {
    params.append("name_contains", options.nameContains);
  }
  if (options.perPage) {
    params.append("per_page", options.perPage.toString());
  }
  if (options.cursor) {
    params.append("cursor", options.cursor);
  }
  if (options.direction) {
    params.append("direction", options.direction);
  }
  // Build URL with query parameters
  const path = `/accounts/${api.accountId}/r2/buckets${params.toString() ? `?${params.toString()}` : ""}`;
  // Set jurisdiction header if provided
  const headers = withJurisdiction({}, options.jurisdiction);
  // Make the API request
  const response = await api.get(path, { headers });
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list buckets: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as {
    success: boolean;
    errors?: Array<{ code: number; message: string }>;
    result?: {
      buckets: Array<{
        name: string;
        creation_date: string;
        location?: string;
      }>;
    };
  };
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list buckets: ${errorMessage}`);
  }
  // Transform API response to R2BucketInfo objects
  return (data.result?.buckets || []).map((bucket) => ({
    Name: bucket.name,
    CreationDate: new Date(bucket.creation_date),
  }));
}
</file>

<file path="alchemy/src/cloudflare/custom-domain.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { handleApiError } from "./api-error.js";
import {
  type CloudflareApi,
  createCloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
/**
 * Properties for creating or updating a CustomDomain
 */
export interface CustomDomainProps extends CloudflareApiOptions {
  /**
   * The domain name to bind to the worker
   */
  name: string;
  /**
   * Cloudflare Zone ID for the domain
   */
  zoneId: string;
  /**
   * Name of the worker to bind to the domain
   */
  workerName: string;
  /**
   * Worker environment (defaults to production)
   * @default "production"
   */
  environment?: string;
}
/**
 * Cloudflare Domain object structure from API
 */
interface CloudflareDomain {
  id: string;
  zone_id: string;
  zone_name: string;
  hostname: string;
  service: string;
  environment: string;
}
/**
 * Output returned after CustomDomain creation/update
 */
export interface CustomDomain
  extends Resource<"cloudflare::CustomDomain">,
    CustomDomainProps {
  /**
   * The unique identifier for the Cloudflare domain binding.
   */
  id: string;
  /**
   * Time at which the domain binding was created (approximated if not returned by API)
   */
  createdAt: number;
  /**
   * Time at which the domain binding was last updated
   */
  updatedAt: number;
}
/**
 * Configure custom domain for a Cloudflare Worker using the Cloudflare Custom Domains API
 * This attaches a worker to a specific hostname within a zone.
 *
 * @example
 * // Bind a domain to a standard Cloudflare Worker
 * const apiWorker = await Worker("api", {
 *   name: "my-api-worker",
 *   entrypoint: "./src/api-worker.ts"
 * });
 *
 * const apiDomain = await CustomDomain("api-domain-binding", {
 *   name: "api.example.com",
 *   zoneId: "YOUR_ZONE_ID", // Replace with actual Zone ID
 *   workerName: apiWorker.name // Use the name from the Worker resource
 * });
 *
 * @see https://developers.cloudflare.com/api/resources/workers/subresources/domains/
 */
export const CustomDomain = Resource(
  "cloudflare::CustomDomain",
  async function (
    this: Context<CustomDomain>,
    logicalId: string, // Changed param name from id to logicalId for clarity
    props: CustomDomainProps,
  ): Promise<CustomDomain> {
    // Create Cloudflare API client with automatic account discovery
    const api = await createCloudflareApi(props);
    // Validate required properties
    if (!props.name) {
      throw new Error("Domain name (props.name) is required");
    }
    if (!props.zoneId) {
      throw new Error("Zone ID (props.zoneId) is required");
    }
    if (!props.workerName) {
      throw new Error("Worker name (props.workerName) is required");
    }
    if (this.phase === "delete") {
      await deleteCustomDomain(this, api, logicalId, props);
      return this.destroy();
    }
    // Create or Update phase
    return await ensureCustomDomain(this, api, logicalId, props);
  },
);
// Helper function to delete the custom domain binding
async function deleteCustomDomain(
  context: Context<CustomDomain>,
  api: CloudflareApi,
  logicalId: string,
  props: CustomDomainProps,
): Promise<void> {
  const domainHostname = props.name;
  const domainIdToDelete = context.output?.id;
  if (!domainIdToDelete) {
    console.warn(
      `Cannot delete CustomDomain ${logicalId} (${domainHostname}): Missing domain ID in state. Assuming already deleted.`,
    );
    return; // Exit early if no ID
  }
  console.log(
    `Deleting CustomDomain binding ${domainIdToDelete} for ${domainHostname}`,
  );
  const response = await api.delete(
    `/accounts/${api.accountId}/workers/domains/${domainIdToDelete}`,
  );
  console.log(
    `Delete result for ${domainIdToDelete} (${domainHostname}):`,
    response.status,
    response.statusText,
  );
  // 404 is acceptable during deletion for idempotency
  if (!response.ok && response.status !== 404) {
    await handleApiError(
      response,
      "deleting",
      "custom domain binding",
      domainIdToDelete,
    );
    // Throw after handling to ensure failure is reported
    throw new Error(
      `Failed to delete custom domain binding ${domainIdToDelete}: ${response.statusText}`,
    );
  }
}
// Helper function to create or update the custom domain binding
async function ensureCustomDomain(
  context: Context<CustomDomain>,
  api: CloudflareApi,
  logicalId: string,
  props: CustomDomainProps,
): Promise<CustomDomain> {
  const environment = props.environment || "production";
  const domainHostname = props.name;
  // Check if domain binding already exists for this account
  console.log(`Checking existing domain bindings for account ${api.accountId}`);
  const listResponse = await api.get(
    `/accounts/${api.accountId}/workers/domains`,
  );
  if (!listResponse.ok) {
    // Fix: Added the 4th argument (resource identifier/context)
    await handleApiError(
      listResponse,
      "listing",
      "worker domains",
      `Account ${api.accountId}`,
    );
    // If listing fails, we cannot proceed reliably
    throw new Error(
      `Failed to list worker domains for account ${api.accountId}: ${listResponse.statusText}`,
    );
  }
  const listData = (await listResponse.json()) as {
    result?: CloudflareDomain[];
    success: boolean;
  };
  if (!listData.success || !listData.result) {
    throw new Error(
      `Failed to parse list worker domains response: ${JSON.stringify(listData)}`,
    );
  }
  // Find the specific binding by hostname AND zoneId
  const existingBinding = listData.result.find(
    (b) => b.hostname === domainHostname && b.zone_id === props.zoneId,
  );
  let currentDomainId = existingBinding?.id;
  const bindingExists = !!existingBinding;
  console.log(
    `Domain binding status for ${domainHostname} (Zone: ${props.zoneId}):`,
    bindingExists
      ? `Found (ID: ${currentDomainId}, Worker: ${existingBinding.service}, Env: ${existingBinding.environment})`
      : "Not found",
  );
  // Determine if we need to update (binding exists but has different service or environment)
  const needsUpdate =
    bindingExists &&
    (existingBinding.service !== props.workerName ||
      existingBinding.environment !== environment);
  let operationPerformed: "create" | "update" | "none" = "none";
  let resultantBinding: CloudflareDomain | undefined = existingBinding;
  // Create or Update the binding using PUT
  // Cloudflare's PUT /accounts/{account_id}/workers/domains acts as an upsert
  if (!bindingExists || needsUpdate) {
    operationPerformed = bindingExists ? "update" : "create";
    console.log(
      `${operationPerformed === "update" ? "Updating" : "Creating"} domain binding: ${domainHostname} (Zone: ${props.zoneId})  ${props.workerName}:${environment}`,
    );
    const putPayload = {
      zone_id: props.zoneId,
      hostname: domainHostname,
      service: props.workerName,
      environment: environment,
    };
    const putResponse = await api.put(
      `/accounts/${api.accountId}/workers/domains`,
      putPayload,
    );
    if (!putResponse.ok) {
      await handleApiError(
        putResponse,
        operationPerformed === "update" ? "updating" : "creating",
        "custom domain binding",
        domainHostname,
      );
      // Throw after handling to prevent inconsistent state
      throw new Error(
        `Failed to ${operationPerformed} custom domain binding: ${putResponse.statusText}`,
      );
    }
    const putResult = (await putResponse.json()) as {
      result?: CloudflareDomain;
      success: boolean;
    };
    if (!putResult.success || !putResult.result) {
      throw new Error(
        `Failed to parse ${operationPerformed} domain binding response: ${JSON.stringify(putResult)}`,
      );
    }
    resultantBinding = putResult.result;
    currentDomainId = resultantBinding.id; // Update ID from the PUT response
    console.log(
      `Successfully ${operationPerformed}d binding, new ID: ${currentDomainId}`,
    );
  } else {
    console.log(
      `Domain binding already exists and is up to date: ${domainHostname} (ID: ${currentDomainId})  ${props.workerName}:${environment}`,
    );
  }
  // Ensure we have the final binding details
  if (!resultantBinding || !currentDomainId) {
    // This case should ideally not happen if API calls succeed
    console.error("Error: Could not determine final domain binding state.", {
      existingBinding,
      resultantBinding,
      currentDomainId,
    });
    throw new Error(
      `Failed to get final state for custom domain ${domainHostname}`,
    );
  }
  const now = Date.now();
  // Construct the output state
  return context({
    ...props, // Include all input props
    id: currentDomainId, // Use the definitive ID
    environment: resultantBinding.environment, // Use actual environment from CF
    createdAt: context.output?.createdAt || now, // Preserve create time or set new
    updatedAt:
      operationPerformed !== "none" ? now : context.output?.updatedAt || now, // Update time only if changed
  });
}
</file>

<file path="alchemy/src/cloudflare/d1-database.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  type CloudflareApi,
  createCloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
import { applyMigrations, listMigrationsFiles } from "./d1-migrations.js";
/**
 * Properties for creating or updating a D1 Database
 */
export interface D1DatabaseProps extends CloudflareApiOptions {
  /**
   * Name of the database
   *
   * @default id
   */
  name?: string;
  /**
   * Optional primary location hint for the database
   * Indicates the primary geographical location data will be stored
   */
  primaryLocationHint?:
    | "wnam"
    | "enam"
    | "weur"
    | "eeur"
    | "apac"
    | "auto"
    | string;
  /**
   * Read replication configuration
   * Only mutable property during updates
   */
  readReplication?: {
    /**
     * Read replication mode
     * - auto: Automatic read replication
     * - disabled: No read replication
     */
    mode: "auto" | "disabled";
  };
  /**
   * Whether to delete the database.
   * If set to false, the database will remain but the resource will be removed from state
   *
   * @default true
   */
  delete?: boolean;
  /**
   * Whether to adopt an existing database with the same name if it exists
   * If true and a database with the same name exists, it will be adopted rather than creating a new one
   *
   * @default false
   */
  adopt?: boolean;
  /**
   * These files will be generated internally with the D1Database wrapper function when migrationsDir is specified
   *
   * @private
   */
  migrationsFiles?: Array<{ id: string; sql: string }>;
  /**
   * Name of the table used to track migrations. Only used if migrationsDir is specified. Defaults to 'd1_migrations'
   * This is analogous to wrangler's `migrations_table`.
   */
  migrationsTable?: string;
  /**
   * Directory containing migration SQL files. If not set, no migrations will be applied.
   * This is analogous to wrangler's `migrations_dir`.
   */
  migrationsDir?: string;
}
/**
 * Output returned after D1 Database creation/update
 */
export type D1Database = Resource<"cloudflare::D1Database"> &
  D1DatabaseProps & {
    type: "d1";
    /**
     * The unique ID of the database (UUID)
     */
    id: string;
    /**
     * The name of the database
     */
    name: string;
    /**
     * File size of the database
     */
    fileSize: number;
    /**
     * Number of tables in the database
     */
    numTables: number;
    /**
     * Version of the database
     */
    version: string;
    /**
     * Read replication configuration
     */
    readReplication?: {
      /**
       * Read replication mode
       */
      mode: "auto" | "disabled";
    };
  };
export async function D1Database(
  id: string,
  props: Omit<D1DatabaseProps, "migrationsFiles">,
) {
  const migrationsFiles = props.migrationsDir
    ? await listMigrationsFiles(props.migrationsDir)
    : [];
  return D1DatabaseResource(id, {
    ...props,
    migrationsFiles,
  });
}
/**
 * Creates and manages Cloudflare D1 Databases.
 *
 * D1 Databases provide serverless SQL databases built on SQLite with
 * automatic data replication for high availability.
 *
 * @example
 * // Create a basic D1 database with default settings
 * const basicDatabase = await D1Database("my-app-db", {
 *   name: "my-app-db"
 * });
 *
 * @example
 * // Create a database with location hint for optimal performance
 * const westUsDatabase = await D1Database("west-us-db", {
 *   name: "west-us-db",
 *   primaryLocationHint: "wnam"
 * });
 *
 * @example
 * // Adopt an existing database if it already exists instead of failing
 * const existingDb = await D1Database("existing-db", {
 *   name: "existing-db",
 *   adopt: true,
 *   readReplication: {
 *     mode: "auto"
 *   }
 * });
 *
 * @example
 * // Create a database with migrations
 * const dbWithMigrations = await D1Database("mydb", {
 *   name: "mydb",
 *   migrationsDir: "./migrations",
 * });
 *
 * @see https://developers.cloudflare.com/d1/
 */
export const D1DatabaseResource = Resource(
  "cloudflare::D1Database",
  async function (
    this: Context<D1Database>,
    id: string,
    props: D1DatabaseProps = {},
  ): Promise<D1Database> {
    const api = await createCloudflareApi(props);
    const databaseName = props.name ?? id;
    if (this.phase === "delete") {
      console.log("Deleting D1 database:", databaseName);
      if (props.delete !== false) {
        // Delete D1 database
        console.log("Deleting D1 database:", databaseName);
        await deleteDatabase(api, this.output?.id);
      }
      // Return void (a deleted database has no content)
      return this.destroy();
    }
    let dbData: CloudflareD1Response;
    if (this.phase === "create") {
      console.log("Creating D1 database:", databaseName);
      try {
        dbData = await createDatabase(api, databaseName, props);
      } catch (error) {
        // Check if this is a "database already exists" error and adopt is enabled
        if (
          props.adopt &&
          error instanceof CloudflareApiError &&
          error.message.includes("already exists")
        ) {
          console.log(`Database ${databaseName} already exists, adopting it`);
          // Find the existing database by name
          const databases = await listDatabases(api, databaseName);
          const existingDb = databases.find((db) => db.name === databaseName);
          if (!existingDb) {
            throw new Error(
              `Failed to find existing database '${databaseName}' for adoption`,
            );
          }
          // Get the database details using its ID
          dbData = await getDatabase(api, existingDb.id);
          // Update the database with the provided properties
          if (props.readReplication) {
            console.log(
              `Updating adopted database ${databaseName} with new properties`,
            );
            dbData = await updateDatabase(api, existingDb.id, props);
          }
        } else {
          // Re-throw the error if adopt is false or it's not a "database already exists" error
          throw error;
        }
      }
    } else {
      // Update operation
      if (this.output?.id) {
        console.log("Updating D1 database:", databaseName);
        // Update the database with new properties
        dbData = await updateDatabase(api, this.output.id, props);
      } else {
        // If no ID exists, fall back to creating a new database
        console.log(
          "No existing database ID found, creating new D1 database:",
          databaseName,
        );
        dbData = await createDatabase(api, databaseName, props);
      }
    }
    // Run migrations if provided
    if (props.migrationsFiles && props.migrationsFiles.length > 0) {
      try {
        const migrationsTable = props.migrationsTable || "d1_migrations";
        const databaseId = dbData.result.uuid || this.output?.id;
        if (!databaseId) {
          throw new Error("Database ID not found for migrations");
        }
        await applyMigrations({
          migrationsFiles: props.migrationsFiles,
          migrationsTable,
          accountId: api.accountId,
          databaseId,
          api,
        });
      } catch (migrationErr) {
        console.error("Failed to apply D1 migrations:", migrationErr);
        throw migrationErr;
      }
    }
    return this({
      type: "d1",
      id: dbData.result.uuid || "",
      name: databaseName,
      fileSize: dbData.result.file_size,
      numTables: dbData.result.num_tables,
      version: dbData.result.version,
      readReplication: dbData.result.read_replication,
      primaryLocationHint: props.primaryLocationHint,
      accountId: api.accountId,
      migrationsDir: props.migrationsDir,
    });
  },
);
interface CloudflareD1Response {
  result: {
    uuid?: string;
    name: string;
    file_size: number;
    num_tables: number;
    version: string;
    primary_location_hint?: string;
    read_replication?: {
      mode: "auto" | "disabled";
    };
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Create a new D1 database
 */
export async function createDatabase(
  api: CloudflareApi,
  databaseName: string,
  props: D1DatabaseProps,
): Promise<CloudflareD1Response> {
  // Create new D1 database
  const createPayload: any = {
    name: databaseName,
  };
  if (props.primaryLocationHint) {
    createPayload.primary_location_hint = props.primaryLocationHint;
  }
  const createResponse = await api.post(
    `/accounts/${api.accountId}/d1/database`,
    createPayload,
  );
  if (!createResponse.ok) {
    return await handleApiError(
      createResponse,
      "creating",
      "D1 database",
      databaseName,
    );
  }
  return (await createResponse.json()) as CloudflareD1Response;
}
/**
 * Get a D1 database
 */
export async function getDatabase(
  api: CloudflareApi,
  databaseId?: string,
): Promise<CloudflareD1Response> {
  if (!databaseId) {
    throw new Error("Database ID is required");
  }
  const response = await api.get(
    `/accounts/${api.accountId}/d1/database/${databaseId}`,
  );
  if (!response.ok) {
    return await handleApiError(response, "getting", "D1 database", databaseId);
  }
  return (await response.json()) as CloudflareD1Response;
}
/**
 * Delete a D1 database
 */
export async function deleteDatabase(
  api: CloudflareApi,
  databaseId?: string,
): Promise<void> {
  if (!databaseId) {
    console.log("No database ID provided, skipping delete");
    return;
  }
  // Delete D1 database
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/d1/database/${databaseId}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting D1 database '${databaseId}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * List all D1 databases in an account
 */
export async function listDatabases(
  api: CloudflareApi,
  name?: string,
): Promise<{ name: string; id: string }[]> {
  // Construct query string if name is provided
  const queryParams = name ? `?name=${encodeURIComponent(name)}` : "";
  const response = await api.get(
    `/accounts/${api.accountId}/d1/database${queryParams}`,
  );
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list databases: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as {
    success: boolean;
    errors?: Array<{ code: number; message: string }>;
    result?: Array<{
      name: string;
      uuid: string;
    }>;
  };
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list databases: ${errorMessage}`);
  }
  // Transform API response
  return (data.result || []).map((db) => ({
    name: db.name,
    id: db.uuid,
  }));
}
/**
 * Update a D1 database
 *
 * Note: According to Cloudflare API, only read_replication.mode can be modified during updates.
 */
export async function updateDatabase(
  api: CloudflareApi,
  databaseId: string,
  props: D1DatabaseProps,
): Promise<CloudflareD1Response> {
  // Get current database state to check for non-mutable changes
  const currentDB = await getDatabase(api, databaseId);
  // Only read_replication can be modified in update
  if (
    props.primaryLocationHint &&
    props.primaryLocationHint !== currentDB.result.primary_location_hint
  ) {
    throw new Error(
      "Cannot update primaryLocationHint after database creation. Only readReplication.mode can be modified.",
    );
  }
  const updatePayload: any = {};
  // Only include read_replication in update payload
  if (props.readReplication) {
    updatePayload.read_replication = {
      mode: props.readReplication.mode,
    };
  }
  const updateResponse = await api.patch(
    `/accounts/${api.accountId}/d1/database/${databaseId}`,
    updatePayload,
  );
  if (!updateResponse.ok) {
    return await handleApiError(
      updateResponse,
      "updating",
      "D1 database",
      databaseId,
    );
  }
  return (await updateResponse.json()) as CloudflareD1Response;
}
</file>

<file path="alchemy/src/cloudflare/d1-migrations.ts">
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { handleApiError } from "./api-error.js";
import type { CloudflareApi } from "./api.js";
export interface D1MigrationOptions {
  migrationsFiles: Array<{ id: string; sql: string }>;
  migrationsTable: string;
  accountId: string;
  databaseId: string;
  api: CloudflareApi;
}
const getPrefix = (name: string) => {
  const prefix = name.split("_")[0];
  const num = Number.parseInt(prefix, 10);
  return Number.isNaN(num) ? null : num;
};
async function readMigrationFile(filePath: string): Promise<string> {
  return fs.readFile(filePath, "utf-8");
}
/**
 * Reads migration SQL files from the migrationsDir, sorted by filename.
 * @param migrationsDir Directory containing .sql migration files
 */
export async function listMigrationsFiles(
  migrationsDir: string,
): Promise<Array<{ id: string; sql: string }>> {
  const entries = await fs.readdir(migrationsDir);
  const sqlFiles = entries
    .filter((f: string) => f.endsWith(".sql"))
    .sort((a: string, b: string) => {
      const aNum = getPrefix(a);
      const bNum = getPrefix(b);
      if (aNum !== null && bNum !== null) return aNum - bNum;
      if (aNum !== null) return -1;
      if (bNum !== null) return 1;
      return a.localeCompare(b);
    });
  const files: Array<{ id: string; sql: string }> = [];
  for (const file of sqlFiles) {
    const sql = await readMigrationFile(path.join(migrationsDir, file));
    files.push({ id: file, sql });
  }
  return files;
}
/**
 * Ensures the migrations table exists in the D1 database.
 */
export async function ensureMigrationsTable(
  options: D1MigrationOptions,
): Promise<void> {
  const createTableSQL = `CREATE TABLE IF NOT EXISTS ${options.migrationsTable} (id TEXT PRIMARY KEY, applied_at TEXT);`;
  await executeD1SQL(options, createTableSQL);
}
/**
 * Gets the list of applied migration IDs from the migrations table.
 */
export async function getAppliedMigrations(
  options: D1MigrationOptions,
): Promise<Set<string>> {
  const sql = `SELECT id FROM ${options.migrationsTable};`;
  const result = await executeD1SQL(options, sql);
  const ids = (result?.result[0]?.results || []).map((row: any) => row.id);
  return new Set(ids);
}
/**
 * Executes a SQL statement against the D1 database using the HTTP API.
 */
export async function executeD1SQL(
  options: D1MigrationOptions,
  sql: string,
): Promise<{
  result: [
    {
      results: Array<unknown>;
      success: boolean;
      meta: any;
    },
  ];
  errors: Array<any>;
  messages: Array<any>;
  success: boolean;
}> {
  const response = await options.api.post(
    `/accounts/${options.accountId}/d1/database/${options.databaseId}/query`,
    { sql },
  );
  if (!response.ok) {
    await handleApiError(
      response,
      "executing migration SQL",
      "D1 database",
      options.databaseId,
    );
  }
  return response.json();
}
/**
 * Applies all pending migrations from the provided files to the D1 database.
 */
export async function applyMigrations(
  options: D1MigrationOptions,
): Promise<void> {
  await ensureMigrationsTable(options);
  const applied = await getAppliedMigrations(options);
  for (const migration of options.migrationsFiles) {
    const migrationId = migration.id;
    if (applied.has(migrationId)) continue;
    // Run the migration
    await executeD1SQL(options, migration.sql);
    // Record as applied
    const insertSQL = `INSERT INTO ${options.migrationsTable} (id, applied_at) VALUES ('${migrationId.replace("'", "''")}', datetime('now'));`;
    await executeD1SQL(options, insertSQL);
    console.log(`Applied migration: ${migrationId}`);
  }
}
</file>

<file path="alchemy/src/cloudflare/dns-records.ts">
import type { Context } from "../context.js";
import type {
  DnsRecord as BaseDnsRecord,
  DnsRecordType,
  DnsRecordWithMetadata,
} from "../dns/record.js";
import { Resource } from "../resource.js";
import {
  type CloudflareApi,
  type CloudflareApiOptions,
  createCloudflareApi,
} from "./api.js";
import type { CloudflareResponse } from "./response.js";
/**
 * Cloudflare DNS Record response format
 */
interface CloudflareDnsRecord {
  id: string;
  type: string;
  name: string;
  content: string;
  proxiable: boolean;
  proxied: boolean;
  ttl: number;
  locked: boolean;
  zone_id: string;
  zone_name: string;
  created_on: string;
  modified_on: string;
  data?: Record<string, unknown>;
  priority?: number;
  comment?: string;
  tags?: string[];
}
/**
 * Properties for a DNS record
 */
export interface DnsRecordProps extends Omit<BaseDnsRecord, "type"> {
  /**
   * Record type (A, AAAA, CNAME, etc.)
   */
  type: DnsRecordType;
}
/**
 * Output returned after DNS record creation/update
 */
export interface DnsRecord extends DnsRecordWithMetadata {}
/**
 * Properties for managing multiple DNS records
 */
export interface DnsRecordsProps extends CloudflareApiOptions {
  /**
   * Zone ID or domain name where records will be created
   */
  zoneId: string;
  /**
   * Array of DNS records to manage
   */
  records: DnsRecordProps[];
}
/**
 * Output returned after DNS records creation/update
 */
export interface DnsRecords extends Resource<"cloudflare::DnsRecords"> {
  /**
   * Zone ID where records are created
   */
  zoneId: string;
  /**
   * Array of created/updated DNS records
   */
  records: DnsRecord[];
}
/**
 * Manages a batch of DNS records in a Cloudflare zone.
 * Supports creating, updating, and deleting multiple records at once.
 *
 * @example
 * // Create multiple A and CNAME records
 * const dnsRecords = await DnsRecords("example.com-dns", {
 *   zone: "example.com",
 *   records: [
 *     {
 *       name: "www.example.com",
 *       type: "A",
 *       content: "192.0.2.1",
 *       proxied: true
 *     },
 *     {
 *       name: "blog.example.com",
 *       type: "CNAME",
 *       content: "www.example.com",
 *       proxied: true
 *     }
 *   ]
 * });
 *
 * @example
 * // Create MX records for email routing
 * const emailRecords = await DnsRecords("example.com-email", {
 *   zone: "example.com",
 *   records: [
 *     {
 *       name: "example.com",
 *       type: "MX",
 *       content: "aspmx.l.google.com",
 *       priority: 1
 *     },
 *     {
 *       name: "example.com",
 *       type: "MX",
 *       content: "alt1.aspmx.l.google.com",
 *       priority: 5
 *     }
 *   ]
 * });
 */
export const DnsRecords = Resource(
  "cloudflare::DnsRecords",
  async function (
    this: Context<DnsRecords>,
    id: string,
    props: DnsRecordsProps,
  ): Promise<DnsRecords> {
    // Create Cloudflare API client
    const api = await createCloudflareApi(props);
    // Get zone ID if domain name was provided
    const zoneId = props.zoneId;
    if (this.phase === "delete") {
      if (this.output?.records) {
        // Delete all existing records
        await Promise.all(
          this.output.records.map(async (record) => {
            try {
              const response = await api.delete(
                `/zones/${zoneId}/dns_records/${record.id}`,
              );
              if (!response.ok && response.status !== 404) {
                console.error(
                  `Failed to delete DNS record ${record.name}: ${response.statusText}`,
                );
              }
            } catch (error) {
              console.error(`Error deleting DNS record ${record.name}:`, error);
            }
          }),
        );
      }
      return this.destroy();
    }
    if (this.phase === "update" && this.output?.records) {
      // Get current records to compare with desired state
      const currentRecords = this.output.records;
      const desiredRecords = props.records;
      // Find records to delete (exist in current but not in desired)
      const recordsToDelete = currentRecords.filter(
        (current) =>
          !desiredRecords.some(
            (desired) =>
              desired.name === current.name && desired.type === current.type,
          ),
      );
      // Delete orphaned records
      await Promise.all(
        recordsToDelete.map(async (record) => {
          try {
            const response = await api.delete(
              `/zones/${zoneId}/dns_records/${record.id}`,
            );
            if (!response.ok && response.status !== 404) {
              console.error(
                `Failed to delete DNS record ${record.name}: ${response.statusText}`,
              );
            }
          } catch (error) {
            console.error(`Error deleting DNS record ${record.name}:`, error);
          }
        }),
      );
      // Update or create records
      const updatedRecords = await Promise.all(
        desiredRecords.map(async (desired) => {
          // Find matching existing record
          const existing = currentRecords.find(
            (current) =>
              current.name === desired.name && current.type === desired.type,
          );
          if (existing) {
            // Update if content or other properties changed
            if (
              existing.content !== desired.content ||
              existing.ttl !== (desired.ttl || 1) ||
              existing.proxied !== (desired.proxied || false) ||
              existing.priority !== desired.priority ||
              existing.comment !== desired.comment
            ) {
              return createOrUpdateRecord(api, zoneId, desired, existing.id);
            }
            return existing;
          }
          // Create new record
          return createOrUpdateRecord(api, zoneId, desired);
        }),
      );
      return this({
        zoneId,
        records: updatedRecords,
      });
    }
    // Create new records
    const uniqueRecords = props.records.reduce(
      (acc, record) => {
        // For record types that can have multiple entries with the same name (MX, TXT, NS, etc.),
        // include content and/or priority in the key to avoid deduplication
        let key = `${record.name}-${record.type}`;
        // If it's a record type that can have multiple entries with the same name, make the key unique
        if (["MX", "TXT", "NS", "SRV", "CAA"].includes(record.type)) {
          // For MX, include priority in the key
          if (record.type === "MX" || record.type === "SRV") {
            key = `${key}-${record.priority}-${record.content}`;
          } else {
            // For other multi-record types, content is the differentiator
            key = `${key}-${record.content}`;
          }
        }
        acc[key] = record;
        return acc;
      },
      {} as Record<string, DnsRecordProps>,
    );
    const createdRecords = await Promise.all(
      Object.values(uniqueRecords).map(async (record) => {
        // First check if record exists
        const listResponse = await api.get(
          `/zones/${zoneId}/dns_records?type=${record.type}&name=${record.name}`,
        );
        if (!listResponse.ok) {
          throw new Error(
            `Failed to check existing DNS records: ${listResponse.statusText}`,
          );
        }
        const listResult = (await listResponse.json()) as CloudflareResponse<
          CloudflareDnsRecord[]
        >;
        const existingRecord = listResult.result[0];
        return createOrUpdateRecord(api, zoneId, record, existingRecord?.id);
      }),
    );
    return this({
      zoneId,
      records: createdRecords,
    });
  },
);
/**
 * Create or update a DNS record
 */
async function createOrUpdateRecord(
  api: CloudflareApi,
  zoneId: string,
  record: DnsRecordProps,
  existingId?: string,
): Promise<DnsRecord> {
  const payload = getRecordPayload(record);
  const response = await (existingId
    ? api.put(`/zones/${zoneId}/dns_records/${existingId}`, payload)
    : api.post(`/zones/${zoneId}/dns_records`, payload));
  if (!response.ok) {
    const errorBody = await response.text();
    // If it's an update operation and the record doesn't exist, fall back to creation
    if (existingId && response.status === 404) {
      try {
        const createResponse = await api.post(
          `/zones/${zoneId}/dns_records`,
          payload,
        );
        if (createResponse.ok) {
          return convertCloudflareRecord(
            ((await createResponse.json()) as any).result,
            zoneId,
          );
        }
      } catch (err) {
        // Fall through to the original error
      }
    }
    throw new Error(
      `Failed to ${existingId ? "update" : "create"} DNS record ${record.name}: ${response.statusText}\nResponse: ${errorBody}`,
    );
  }
  const result =
    (await response.json()) as CloudflareResponse<CloudflareDnsRecord>;
  return convertCloudflareRecord(result.result, zoneId);
}
/**
 * Get the record payload for create/update operations
 */
function getRecordPayload(record: DnsRecordProps) {
  return {
    type: record.type,
    name: record.name,
    content: record.content,
    ttl: record.ttl || 1,
    proxied: record.proxied || false,
    priority: record.priority,
    comment: record.comment,
  };
}
/**
 * Convert a Cloudflare DNS record response to our DnsRecord type
 */
function convertCloudflareRecord(
  record: CloudflareDnsRecord,
  zoneId: string,
): DnsRecord {
  return {
    id: record.id,
    name: record.name,
    type: record.type as DnsRecordProps["type"],
    content: record.content,
    ttl: record.ttl,
    proxied: record.proxied,
    priority: record.priority,
    comment: record.comment,
    tags: record.tags,
    createdAt: new Date(record.created_on).getTime(),
    modifiedAt: new Date(record.modified_on).getTime(),
    zoneId,
  };
}
</file>

<file path="alchemy/src/cloudflare/durable-object-namespace.ts">
/**
 * Properties for creating a Durable Object Namespace
 */
export interface DurableObjectNamespaceInput {
  className: string;
  scriptName?: string | undefined;
  environment?: string | undefined;
  sqlite?: boolean | undefined;
  namespaceId?: string | undefined;
}
/**
 * @example
 * // Create a basic Durable Object namespace for stateful chat rooms
 * const rooms = new DurableObjectNamespace("chat-rooms", {
 *   className: "ChatRoom"
 * });
 *
 * @example
 * // Create a Durable Object with SQLite storage for user data
 * const users = new DurableObjectNamespace("user-store", {
 *   className: "User",
 *   sqlite: true
 * });
 *
 * @example
 * // Create a Durable Object in production for game state management
 * const game = new DurableObjectNamespace("game-state", {
 *   className: "GameState",
 *   scriptName: "game-worker",
 *   environment: "production"
 * });
 */
export class DurableObjectNamespace implements DurableObjectNamespaceInput {
  public readonly type = "durable_object_namespace" as const;
  // alias for bindingName to be consistent with other bindings
  public readonly className: string;
  public readonly scriptName?: string | undefined;
  public readonly environment?: string | undefined;
  public readonly sqlite?: boolean | undefined;
  public readonly namespaceId?: string | undefined;
  constructor(
    public readonly id: string,
    input: DurableObjectNamespaceInput,
  ) {
    this.className = input.className;
    this.scriptName = input.scriptName;
    this.environment = input.environment;
    this.sqlite = input.sqlite;
  }
}
</file>

<file path="alchemy/src/cloudflare/event-source.ts">
import type { QueueConsumerSettings } from "./queue-consumer.js";
import type { Queue } from "./queue.js";
/**
 * Base interface for event sources that can be bound to a Worker
 */
export type EventSource = QueueEventSource | Queue;
/**
 * Configuration for a Queue as an event source for a Worker
 */
export interface QueueEventSource {
  /**
   * The queue to consume messages from
   */
  readonly queue: Queue;
  /**
   * Optional settings for configuring how the Worker consumes the queue
   */
  readonly settings?: QueueConsumerSettings;
}
/**
 * Checks if an event source is a QueueEventSource
 * @param eventSource - The event source to check
 * @returns true if the event source is a QueueEventSource, false otherwise
 */
export function isQueueEventSource(
  eventSource: any,
): eventSource is QueueEventSource {
  return "queue" in eventSource;
}
</file>

<file path="alchemy/src/cloudflare/hyperdrive.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { handleApiError } from "./api-error.js";
import { createCloudflareApi, type CloudflareApiOptions } from "./api.js";
/**
 * Origin configuration for a PostgreSQL database connection
 */
export interface HyperdriveOrigin {
  /**
   * Database name
   */
  database: string;
  /**
   * Database host
   */
  host: string;
  /**
   * Database password
   * Use alchemy.secret() to securely store this value
   */
  password: Secret;
  /**
   * Database port
   * @default 5432
   */
  port?: number;
  /**
   * Connection scheme
   * @default "postgres"
   */
  scheme?: "postgres";
  /**
   * Database user
   */
  user: string;
}
/**
 * Origin configuration for a database connection with access tokens
 */
export interface HyperdriveOriginWithAccess {
  /**
   * Access client ID
   */
  access_client_id: string;
  /**
   * Access client secret
   * Use alchemy.secret() to securely store this value
   */
  access_client_secret: Secret;
  /**
   * Database host
   */
  host: string;
  /**
   * Database name
   */
  database: string;
  /**
   * Database port
   * @default 5432
   */
  port?: number;
  /**
   * Connection scheme
   * @default "postgres"
   */
  scheme?: "postgres";
  /**
   * Database user
   */
  user: string;
}
/**
 * Caching configuration for Hyperdrive
 */
export interface HyperdriveCaching {
  /**
   * Whether caching is disabled
   * @default false
   */
  disabled?: boolean;
}
/**
 * mTLS configuration for Hyperdrive
 */
export interface HyperdriveMtls {
  /**
   * CA certificate ID
   */
  ca_certificate_id?: string;
  /**
   * mTLS certificate ID
   */
  mtls_certificate_id?: string;
  /**
   * SSL mode
   * @default "verify-full"
   */
  sslmode?: "verify-ca" | "verify-full";
}
/**
 * Properties for creating or updating a Cloudflare Hyperdrive.
 */
export interface HyperdriveProps extends CloudflareApiOptions {
  /**
   * Name of the Hyperdrive configuration
   */
  name: string;
  /**
   * Database connection origin configuration
   */
  origin: HyperdriveOrigin | HyperdriveOriginWithAccess;
  /**
   * Caching configuration
   */
  caching?: HyperdriveCaching;
  /**
   * mTLS configuration
   */
  mtls?: HyperdriveMtls;
  /**
   * UUID of the hyperdrive (only used for update/delete operations)
   * This is provided by Cloudflare and is different from the resource ID
   * @internal
   */
  hyperdriveId?: string;
}
/**
 * Output returned after Cloudflare Hyperdrive creation/update.
 * IMPORTANT: The interface name MUST match the exported resource name.
 */
export interface Hyperdrive
  extends Resource<"cloudflare::Hyperdrive">,
    Omit<HyperdriveProps, "origin"> {
  /**
   * The ID of the resource
   */
  id: string;
  /**
   * The Cloudflare-generated UUID of the hyperdrive
   */
  hyperdriveId: string;
  /**
   * Database connection origin configuration
   */
  origin: HyperdriveOrigin | HyperdriveOriginWithAccess;
  /**
   * Resource type identifier for binding.
   * @internal
   */
  type: "hyperdrive";
}
/**
 * Represents a Cloudflare Hyperdrive configuration.
 *
 * @example
 * // Create a basic Hyperdrive connection to a PostgreSQL database
 * const basicHyperdrive = await Hyperdrive("my-postgres-db", {
 *   name: "my-postgres-db",
 *   origin: {
 *     database: "postgres",
 *     host: "database.example.com",
 *     password: alchemy.secret("your-password"),
 *     port: 5432,
 *     user: "postgres"
 *   }
 * });
 *
 * @example
 * // Create a Hyperdrive with caching disabled
 * const noCacheHyperdrive = await Hyperdrive("no-cache-db", {
 *   name: "no-cache-db",
 *   origin: {
 *     database: "postgres",
 *     host: "database.example.com",
 *     password: alchemy.secret(process.env.DB_PASSWORD),
 *     port: 5432,
 *     user: "postgres"
 *   },
 *   caching: {
 *     disabled: true
 *   }
 * });
 *
 * @example
 * // Create a Hyperdrive with mTLS configuration
 * const mtlsHyperdrive = await Hyperdrive("secure-db", {
 *   name: "secure-db",
 *   origin: {
 *     database: "postgres",
 *     host: "database.example.com",
 *     password: alchemy.secret(process.env.DB_PASSWORD),
 *     port: 5432,
 *     user: "postgres"
 *   },
 *   mtls: {
 *     ca_certificate_id: "00000000-0000-0000-0000-0000000000",
 *     mtls_certificate_id: "00000000-0000-0000-0000-0000000000",
 *     sslmode: "verify-full"
 *   }
 * });
 *
 * @example
 * // Create a Hyperdrive with access client credentials
 * const accessHyperdrive = await Hyperdrive("access-db", {
 *   name: "access-db",
 *   origin: {
 *     database: "postgres",
 *     host: "database.example.com",
 *     access_client_id: "client-id",
 *     access_client_secret: alchemy.secret(process.env.ACCESS_CLIENT_SECRET),
 *     port: 5432,
 *     user: "postgres"
 *   }
 * });
 */
export const Hyperdrive = Resource(
  "cloudflare::Hyperdrive",
  async function (
    this: Context<Hyperdrive>,
    id: string,
    props: HyperdriveProps,
  ): Promise<Hyperdrive> {
    const api = await createCloudflareApi(props);
    const configsPath = `/accounts/${api.accountId}/hyperdrive/configs`;
    // For create operations, we don't have a hyperdriveId yet
    // For update/delete operations, we need to use the hyperdriveId from props or output
    const hyperdriveId = props.hyperdriveId || this.output?.hyperdriveId;
    const configPath = hyperdriveId
      ? `${configsPath}/${hyperdriveId}`
      : `${configsPath}`;
    if (this.phase === "delete") {
      if (!hyperdriveId) {
        console.warn(`No hyperdriveId found for ${id}, skipping delete`);
        return this.destroy();
      }
      try {
        const deleteResponse = await api.delete(configPath);
        // Only swallow 404 Not Found errors, all other errors should be handled
        if (!deleteResponse.ok && deleteResponse.status !== 404) {
          await handleApiError(deleteResponse, "delete", "hyperdrive", id);
        }
      } catch (error) {
        console.error(`Error deleting Hyperdrive ${id}:`, error);
        throw error;
      }
      return this.destroy();
    }
    let response: Response | undefined;
    let apiResource: any;
    // Prepare request body with unwrapped secrets
    const requestBody = prepareRequestBody(props);
    try {
      if (this.phase === "update" && hyperdriveId) {
        // Update existing hyperdrive
        response = await api.put(configPath, requestBody);
      } else {
        // Create new hyperdrive
        if (hyperdriveId) {
          // If we have a hyperdriveId but we're in create phase, it could be because
          // the resource exists but wasn't in state. Do a GET to check.
          const getResponse = await api.get(configPath);
          if (getResponse.status === 200) {
            // Hyperdrive exists, update it
            console.log(
              `Hyperdrive '${id}' already exists. Updating existing resource.`,
            );
            response = await api.put(configPath, requestBody);
          } else if (getResponse.status === 404) {
            // Hyperdrive doesn't exist, create new
            response = await api.post(configsPath, {
              ...requestBody,
              // Ensure name is set correctly if not already set
              name: props.name || id,
            });
          } else {
            // Unexpected error during GET check
            await handleApiError(getResponse, "get", "hyperdrive", id);
          }
        } else {
          // No hyperdriveId, create new
          response = await api.post(configsPath, {
            ...requestBody,
            // Ensure name is set correctly if not already set
            name: props.name || id,
          });
        }
      }
      if (!response?.ok) {
        const action = this.phase === "update" ? "update" : "create";
        await handleApiError(response!, action, "hyperdrive", id);
      }
      const data: { result: Record<string, any> } = await response!.json();
      apiResource = data.result;
    } catch (error) {
      console.error(`Error ${this.phase} Hyperdrive '${id}':`, error);
      throw error;
    }
    // Construct the output object from API response and props
    return this({
      id,
      hyperdriveId: apiResource.id, // Store the Cloudflare-assigned UUID
      name: apiResource.name,
      origin: props.origin, // Keep the original origin with secrets
      caching: apiResource.caching,
      mtls: apiResource.mtls,
      type: "hyperdrive",
    });
  },
);
/**
 * Prepare the request body by unwrapping secret values
 */
function prepareRequestBody(props: HyperdriveProps): any {
  const requestBody: any = { ...props };
  // Remove internal props
  delete requestBody.hyperdriveId;
  // Deep clone and unwrap secrets in the origin object
  if ("password" in props.origin) {
    // Regular origin with password
    requestBody.origin = {
      ...props.origin,
      password: props.origin.password.unencrypted,
      scheme: props.origin.scheme ?? "postgres",
    };
  } else if ("access_client_secret" in props.origin) {
    // Origin with access client secret
    requestBody.origin = {
      ...props.origin,
      access_client_secret: props.origin.access_client_secret.unencrypted,
    };
  }
  return requestBody;
}
</file>

<file path="alchemy/src/cloudflare/index.ts">
export * from "./account-api-token.js";
export * from "./ai-gateway.js";
export * from "./ai.js";
export * from "./api-error.js";
export * from "./api.js";
export * from "./assets.js";
export * from "./bindings.js";
export * from "./bound.js";
export * from "./browser-rendering.js";
export * from "./bucket.js";
export * from "./bundle/external.js";
export * from "./bundle/local-dev-cloudflare-shim.js";
export * from "./custom-domain.js";
export * from "./d1-database.js";
export * from "./dns-records.js";
export * from "./durable-object-namespace.js";
export * from "./hyperdrive.js";
export * from "./kv-namespace.js";
export * from "./nuxt.js";
export * from "./permission-groups.js";
export * from "./pipeline.js";
export * from "./queue-consumer.js";
export * from "./queue.js";
export * from "./r2-rest-state-store.js";
export * from "./redwood.js";
export * from "./route.js";
export * from "./tanstack-start.js";
export * from "./vectorize-index.js";
export * from "./vectorize-metadata-index.js";
export * from "./vite.js";
export * from "./website.js";
export * from "./worker.js";
export { Workflow } from "./workflow.js";
export * from "./wrangler.json.js";
export * from "./zone.js";
</file>

<file path="alchemy/src/cloudflare/kv-namespace.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { withExponentialBackoff } from "../util/retry.js";
import { handleApiError } from "./api-error.js";
import {
  createCloudflareApi,
  type CloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
/**
 * Properties for creating or updating a KV Namespace
 */
export interface KVNamespaceProps extends CloudflareApiOptions {
  /**
   * Title of the namespace
   */
  title: string;
  /**
   * KV pairs to store in the namespace
   * Only used for initial setup or updates
   */
  values?: KVPair[];
  /**
   * Whether to adopt an existing namespace with the same title if it exists
   * If true and a namespace with the same title exists, it will be adopted rather than creating a new one
   *
   * @default false
   */
  adopt?: boolean;
  /**
   * Whether to delete the namespace.
   * If set to false, the namespace will remain but the resource will be removed from state
   *
   * @default true
   */
  delete?: boolean;
}
/**
 * Key-value pair to store in a KV Namespace
 */
export interface KVPair {
  /**
   * Key name
   */
  key: string;
  /**
   * Value to store (string or JSON object)
   */
  value: string | object;
  /**
   * Optional expiration in seconds from now
   */
  expiration?: number;
  /**
   * Optional expiration timestamp in seconds since epoch
   */
  expirationTtl?: number;
  /**
   * Optional metadata for the key
   */
  metadata?: any;
}
/**
 * Output returned after KV Namespace creation/update
 */
export interface KVNamespace
  extends Resource<"cloudflare::KVNamespace">,
    KVNamespaceProps {
  type: "kv_namespace";
  /**
   * The ID of the namespace
   */
  namespaceId: string;
  /**
   * Time at which the namespace was created
   */
  createdAt: number;
  /**
   * Time at which the namespace was last modified
   */
  modifiedAt: number;
}
/**
 * A Cloudflare KV Namespace is a key-value store that can be used to store data for your application.
 *
 * @see https://developers.cloudflare.com/kv/concepts/kv-namespaces/
 *
 * @example
 * // Create a basic KV namespace for storing user data
 * const users = await KVNamespace("users", {
 *   title: "user-data"
 * });
 *
 * @example
 * // Create a KV namespace with initial values and TTL
 * const sessions = await KVNamespace("sessions", {
 *   title: "user-sessions",
 *   values: [{
 *     key: "session_123",
 *     value: { userId: "user_456", role: "admin" },
 *     expirationTtl: 3600 // Expires in 1 hour
 *   }]
 * });
 *
 * @example
 * // Create a KV namespace with metadata for caching
 * const assets = await KVNamespace("assets", {
 *   title: "static-assets",
 *   values: [{
 *     key: "main.js",
 *     value: "content...",
 *     metadata: {
 *       contentType: "application/javascript",
 *       etag: "abc123"
 *     }
 *   }]
 * });
 *
 * @example
 * // Adopt an existing namespace if it already exists instead of failing
 * const existingNamespace = await KVNamespace("existing-ns", {
 *   title: "existing-namespace",
 *   adopt: true,
 *   values: [{
 *     key: "config",
 *     value: { setting: "updated-value" }
 *   }]
 * });
 *
 * @example
 * // When removing from Alchemy state, keep the namespace in Cloudflare
 * const preservedNamespace = await KVNamespace("preserve-ns", {
 *   title: "preserved-namespace",
 *   delete: false
 * });
 */
export const KVNamespace = Resource(
  "cloudflare::KVNamespace",
  async function (
    this: Context<KVNamespace>,
    id: string,
    props: KVNamespaceProps,
  ) {
    // Create Cloudflare API client with automatic account discovery
    const api = await createCloudflareApi(props);
    if (this.phase === "delete") {
      // For delete operations, we need to check if the namespace ID exists in the output
      const namespaceId = this.output?.namespaceId;
      if (namespaceId && props.delete !== false) {
        await deleteKVNamespace(api, namespaceId);
      }
      // Return minimal output for deleted state
      return this.destroy();
    }
    // For create or update operations
    // If this.phase is "update", we expect this.output to exist
    let namespaceId =
      this.phase === "update" ? this.output?.namespaceId || "" : "";
    let createdAt =
      this.phase === "update"
        ? this.output?.createdAt || Date.now()
        : Date.now();
    if (this.phase === "update" && namespaceId) {
      // Can't update a KV namespace title directly, just work with existing ID
    } else {
      try {
        // Try to create the KV namespace
        const { id } = await createKVNamespace(api, props);
        createdAt = Date.now();
        namespaceId = id;
      } catch (error) {
        // Check if this is a "namespace already exists" error and adopt is enabled
        if (
          props.adopt &&
          error instanceof Error &&
          error.message.includes("already exists")
        ) {
          console.log(`Namespace '${props.title}' already exists, adopting it`);
          // Find the existing namespace by title
          const existingNamespace = await findKVNamespaceByTitle(
            api,
            props.title,
          );
          if (!existingNamespace) {
            throw new Error(
              `Failed to find existing namespace '${props.title}' for adoption`,
            );
          }
          // Use the existing namespace ID
          namespaceId = existingNamespace.id;
          createdAt = existingNamespace.createdAt || Date.now();
        } else {
          // Re-throw the error if adopt is false or it's not a "namespace already exists" error
          throw error;
        }
      }
    }
    await insertKVRecords(api, namespaceId, props);
    return this({
      type: "kv_namespace",
      namespaceId: namespaceId,
      title: props.title,
      values: props.values,
      createdAt: createdAt,
      modifiedAt: Date.now(),
    });
  },
);
export async function createKVNamespace(
  api: CloudflareApi,
  props: KVNamespaceProps,
): Promise<{ id: string }> {
  const createResponse = await api.post(
    `/accounts/${api.accountId}/storage/kv/namespaces`,
    {
      title: props.title,
    },
  );
  if (!createResponse.ok) {
    await handleApiError(createResponse, "create", "kv_namespace", props.title);
  }
  return { id: ((await createResponse.json()) as any).result.id };
}
export async function deleteKVNamespace(
  api: CloudflareApi,
  namespaceId: string,
) {
  // Delete KV namespace
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/storage/kv/namespaces/${namespaceId}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    await handleApiError(deleteResponse, "delete", "kv_namespace", namespaceId);
  }
}
export async function insertKVRecords(
  api: CloudflareApi,
  namespaceId: string,
  props: KVNamespaceProps,
) {
  if (props.values && props.values.length > 0) {
    // Process KV pairs in batches of 10000 (API limit)
    const BATCH_SIZE = 10000;
    for (let i = 0; i < props.values.length; i += BATCH_SIZE) {
      const batch = props.values.slice(i, i + BATCH_SIZE);
      const bulkPayload = batch.map((entry) => {
        const item: any = {
          key: entry.key,
          value:
            typeof entry.value === "string"
              ? entry.value
              : JSON.stringify(entry.value),
        };
        if (entry.expiration) {
          item.expiration = entry.expiration;
        }
        if (entry.expirationTtl) {
          item.expiration_ttl = entry.expirationTtl;
        }
        if (entry.metadata) {
          item.metadata = entry.metadata;
        }
        return item;
      });
      await withExponentialBackoff(
        async () => {
          const bulkResponse = await api.put(
            `/accounts/${api.accountId}/storage/kv/namespaces/${namespaceId}/bulk`,
            bulkPayload,
          );
          if (!bulkResponse.ok) {
            const errorData: any = await bulkResponse.json().catch(() => ({
              errors: [{ message: bulkResponse.statusText }],
            }));
            const errorMessage =
              errorData.errors?.[0]?.message || bulkResponse.statusText;
            // Throw error to trigger retry
            throw new Error(`Error writing KV batch: ${errorMessage}`);
          }
          return bulkResponse;
        },
        (error) => {
          // Retry on "namespace not found" errors as they're likely propagation delays
          return error.message?.includes("not found");
        },
        5, // 5 retry attempts
        1000, // Start with 1 second delay
      );
    }
  }
}
/**
 * Interface representing a KV namespace as returned by Cloudflare API
 */
interface CloudflareKVNamespace {
  id: string;
  title: string;
  supports_url_encoding?: boolean;
  created_on?: string;
}
/**
 * Find a KV namespace by title with pagination support
 */
export async function findKVNamespaceByTitle(
  api: CloudflareApi,
  title: string,
): Promise<{ id: string; createdAt?: number } | null> {
  let page = 1;
  const perPage = 100; // Maximum allowed by API
  let hasMorePages = true;
  while (hasMorePages) {
    const response = await api.get(
      `/accounts/${api.accountId}/storage/kv/namespaces?page=${page}&per_page=${perPage}`,
    );
    if (!response.ok) {
      await handleApiError(response, "list", "kv_namespace", "all");
    }
    const data = (await response.json()) as {
      result: CloudflareKVNamespace[];
      result_info: {
        count: number;
        page: number;
        per_page: number;
        total_count: number;
      };
      success: boolean;
      errors: any[];
    };
    const namespaces = data.result;
    const resultInfo = data.result_info;
    // Look for a namespace with matching title
    const match = namespaces.find((ns) => ns.title === title);
    if (match) {
      return {
        id: match.id,
        // Convert ISO string to timestamp if available, otherwise use current time
        createdAt: match.created_on
          ? new Date(match.created_on).getTime()
          : undefined,
      };
    }
    // Check if we've seen all pages
    hasMorePages =
      resultInfo.page * resultInfo.per_page < resultInfo.total_count;
    page++;
  }
  // No matching namespace found
  return null;
}
</file>

<file path="alchemy/src/cloudflare/nuxt.ts">
import type { Assets } from "./assets.js";
import type { Bindings } from "./bindings.js";
import { Website, type WebsiteProps } from "./website.js";
import type { Worker } from "./worker.js";
/**
 * Properties for creating a Nuxt resource.
 * Extends WebsiteProps, allowing customization of the underlying Website.
 */
export interface NuxtProps<B extends Bindings> extends WebsiteProps<B> {}
/**
 * Represents the output of a Nuxt resource deployment.
 * It resolves to the underlying Cloudflare Worker type, ensuring type safety.
 * Prevents overriding the internal ASSETS binding.
 */
export type Nuxt<B extends Bindings> = B extends { ASSETS: any }
  ? never
  : Worker<B & { ASSETS: Assets }>;
/**
 * Creates and deploys a Nuxt application using the Cloudflare Workers preset.
 *
 * This resource simplifies deploying Nuxt applications by providing sensible
 * defaults for the build command, main entrypoint, and assets directory
 * based on the `cloudflare-module` preset output.
 *
 * It wraps the underlying `Website` resource.
 *
 * @param id A unique identifier for the resource.
 * @param props Configuration options for the Nuxt deployment, overriding defaults.
 * @returns A promise that resolves to the deployed Cloudflare Worker details.
 *
 * @example
 * // Deploy a basic Nuxt site with default settings
 * const nuxtSite = await Nuxt("my-nuxt-app");
 *
 * @example
 * // Deploy with custom bindings and build command
 * const db = await D1Database("my-db");
 * const nuxtSiteWithDb = await Nuxt("my-nuxt-app-with-db", {
 *   command: "npm run build:cloudflare", // Specify a custom build command
 *   bindings: {
 *     DB: db, // Add custom bindings
 *   },
 * });
 */
export async function Nuxt<B extends Bindings>(
  id: string,
  props?: Partial<NuxtProps<B>>,
): Promise<Nuxt<B>> {
  // Call the underlying Website resource with Nuxt defaults
  return Website(id, {
    ...props,
    // Default build command, can be overridden by props.command
    command: props?.command ?? "bun run build",
    // Default entry point for cloudflare-module preset
    main: props?.main ?? "./index.ts",
    // Default static assets directory for cloudflare-module preset
    assets: props?.assets ?? "./.output/public",
    // Ensure nodejs_compat flag is included for Nuxt compatibility
    compatibilityFlags: ["nodejs_compat", ...(props?.compatibilityFlags ?? [])],
    // Enable wrangler by default, common for Nuxt/Cloudflare deployments
    wrangler: props?.wrangler ?? true,
  });
}
</file>

<file path="alchemy/src/cloudflare/permission-groups.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { createCloudflareApi, type CloudflareApiOptions } from "./api.js";
/**
 * Cloudflare permission group as returned by the API
 */
export interface PermissionGroup {
  /**
   * Unique identifier for the permission group
   */
  id: string;
  /**
   * Human-readable name of the permission group
   */
  name: string;
  /**
   * Scopes included in this permission group
   */
  scopes: string[];
}
/**
 * Response from the Cloudflare permission groups API
 */
interface PermissionGroupsResponse {
  result: PermissionGroup[];
  success: boolean;
  errors: any[];
  messages: any[];
}
/**
 * All Cloudflare permission groups mapped by name to ID
 *
 * @see https://developers.cloudflare.com/r2/api/tokens/#permissions
 */
export type PermissionGroups = Resource<"cloudflare::PermissionGroups"> & {
  /**
   * Admin Read & Write - Allows create, list, delete buckets and edit bucket configurations
   * plus list, write, and read object access
   */
  "Workers R2 Storage Write": PermissionGroup;
  /**
   * Admin Read only - Allows list buckets and view bucket configuration
   * plus list and read object access
   */
  "Workers R2 Storage Read": PermissionGroup;
  /**
   * Object Read & Write - Allows read, write, and list objects in specific buckets
   */
  "Workers R2 Storage Bucket Item Write": PermissionGroup;
  /**
   * Object Read only - Allows read and list objects in specific buckets
   */
  "Workers R2 Storage Bucket Item Read": PermissionGroup;
  /**
   * Dynamically discovered permission groups
   */
  [name: string]: PermissionGroup;
};
/**
 * Lists all permission groups available for the Cloudflare account
 * and returns a typed map of permission names to their IDs.
 *
 * This is primarily used when creating API tokens for Cloudflare services like R2.
 *
 * Note: Requires a Cloudflare API Key or Token with account read access.
 * The API token must have permission to read token permission groups.
 * The OAuth token from `wrangler login` is NOT sufficient for this operation.
 *
 * @example
 * // Get all permission groups including those for R2
 * const permissions = await PermissionGroups("cloudflare-permissions");
 *
 * // Use with AccountApiToken to create a token with proper permissions
 * const token = await AccountApiToken("r2-token", {
 *   name: "R2 Read-Only Token",
 *   policies: [
 *     {
 *       effect: "allow",
 *       resources: {
 *         "com.cloudflare.edge.r2.bucket.abc123_default_my-bucket": "*"
 *       },
 *       permissionGroups: [
 *         {
 *           id: permissions["Workers R2 Storage Bucket Item Read"]
 *         }
 *       ]
 *     }
 *   ]
 * });
 */
export const PermissionGroups = Resource(
  "cloudflare::PermissionGroups",
  async function (
    this: Context<PermissionGroups>,
    id: string,
    options: CloudflareApiOptions = {},
  ): Promise<PermissionGroups> {
    // Only create and update phases are supported
    if (this.phase === "delete") {
      return this.destroy();
    }
    // Initialize API client
    const api = await createCloudflareApi(options);
    // Fetch permission groups from Cloudflare API
    const response = await api.get(
      `/accounts/${api.accountId}/tokens/permission_groups`,
    );
    if (!response.ok) {
      throw new Error(
        `Failed to fetch permission groups: ${response.statusText}`,
      );
    }
    const data = (await response.json()) as PermissionGroupsResponse;
    if (!data.success || !data.result) {
      throw new Error(
        `API returned error: ${data.errors?.[0]?.message || "Unknown error"}`,
      );
    }
    return this(
      Object.fromEntries(
        data.result.map((group) => [group.name, group]),
      ) as PermissionGroups,
    );
  },
);
</file>

<file path="alchemy/src/cloudflare/pipeline.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  type CloudflareApi,
  createCloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
/**
 * Settings for compression of pipeline output
 */
export interface CompressionSettings {
  /**
   * Type of compression to use for pipeline output
   * @default "gzip"
   */
  type: "gzip" | "none";
}
/**
 * Settings for batching behavior of pipeline output
 */
export interface BatchSettings {
  /**
   * Maximum size of batch in megabytes before delivery (1-100 MB)
   * @default 100
   */
  maxMb?: number;
  /**
   * Maximum number of rows in a batch before delivery (1-10,000,000 rows)
   * @default 10000000
   */
  maxRows?: number;
  /**
   * Maximum duration of a batch in seconds before delivery (1-300 seconds)
   * @default 300
   */
  maxSeconds?: number;
}
/**
 * Configuration for a pipeline HTTP source
 */
export interface HttpSource {
  /**
   * Format of the source data
   * @default "json"
   */
  format: "json";
  /**
   * Type of source
   */
  type: "http";
  /**
   * Whether authentication is required
   * @default true
   */
  authentication?: boolean;
  /**
   * CORS configuration for HTTP endpoint source
   */
  cors?: {
    /**
     * Allowed origins for CORS requests
     * @default ["*"]
     */
    origins: string[];
  };
}
/**
 * Configuration for a pipeline binding source
 */
export interface BindingSource {
  /**
   * Format of the source data
   * @default "json"
   */
  format: "json";
  /**
   * Type of source
   */
  type: "binding";
}
/**
 * Configuration for a pipeline source
 */
export type PipelineSource = HttpSource | BindingSource;
/**
 * Configuration for an R2 destination
 */
export interface R2DestinationConfig {
  /**
   * Type of destination (R2)
   */
  type: "r2";
  /**
   * Format of the output data
   * @default "json"
   */
  format: "json" | "ndjson";
  /**
   * Path configuration for the R2 destination
   */
  path: {
    /**
     * R2 bucket name
     */
    bucket: string;
    /**
     * Optional prefix for files in the bucket
     */
    prefix?: string;
    /**
     * Optional filename pattern
     * @default "${slug}${extension}"
     */
    filename?: string;
    /**
     * Optional filepath pattern
     * @default "${date}/${hour}"
     */
    filepath?: string;
  };
  /**
   * Compression settings
   */
  compression?: CompressionSettings;
  /**
   * Batch settings
   */
  batch?: BatchSettings;
  /**
   * Credentials for the R2 bucket
   * Required for R2 destinations
   */
  credentials: {
    /**
     * Access key ID for the R2 bucket
     */
    accessKeyId: Secret;
    /**
     * Secret access key for the R2 bucket
     */
    secretAccessKey: Secret;
    /**
     * Endpoint for the R2 bucket
     */
    endpoint?: string;
  };
}
/**
 * Allowed destination types
 */
export type PipelineDestination = R2DestinationConfig;
/**
 * Properties for creating or updating a Pipeline
 */
export interface PipelineProps extends CloudflareApiOptions {
  /**
   * Name of the pipeline
   *
   * @default id
   */
  name?: string;
  /**
   * Source configuration for the pipeline
   */
  source: PipelineSource[];
  /**
   * Destination configuration for the pipeline
   */
  destination: PipelineDestination;
  /**
   * Compression settings for the pipeline
   * @default { type: "gzip" }
   */
  compression?: CompressionSettings;
  /**
   * Whether to delete the pipeline.
   * If set to false, the pipeline will remain but the resource will be removed from state
   *
   * @default true
   */
  delete?: boolean;
}
/**
 * Base type for pipeline records
 */
export interface PipelineRecord {
  [key: string]: any;
}
/**
 * Output returned after Pipeline creation/update
 */
export interface Pipeline<T extends PipelineRecord = PipelineRecord>
  extends Resource<"cloudflare::Pipeline">,
    PipelineProps {
  /**
   * Type identifier for the Pipeline resource
   */
  type: "pipeline";
  /**
   * The unique ID of the pipeline
   */
  id: string;
  /**
   * The name of the pipeline
   */
  name: string;
  /**
   * HTTP endpoint URL for the pipeline
   */
  endpoint: string;
  /**
   * Version of the pipeline
   */
  version: number;
}
/**
 * Creates and manages Cloudflare Pipelines.
 *
 * Pipelines provide a managed data pipeline service that lets you collect, transform,
 * and route data to various destinations like R2 buckets.
 *
 * @example
 * // Create a basic pipeline with an R2 bucket destination
 * const bucket = await R2Bucket("logs-bucket", {
 *   name: "logs-bucket"
 * });
 *
 * const accessKey = alchemy.secret(process.env.R2_ACCESS_KEY_ID!);
 * const secretKey = alchemy.secret(process.env.R2_SECRET_ACCESS_KEY!);
 *
 * const pipeline = await Pipeline("logs-pipeline", {
 *   name: "logs-pipeline",
 *   destination: {
 *     type: "r2",
 *     format: "json",
 *     path: {
 *       bucket: bucket.name,
 *       prefix: "app-logs",
 *     },
 *     credentials: {
 *       accessKeyId: accessKey,
 *       secretAccessKey: secretKey
 *     }
 *   },
 *   batch: {
 *     maxMb: 50,
 *     maxSeconds: 60
 *   }
 * });
 *
 * @example
 * // Create a pipeline with custom source configuration
 * const customPipeline = await Pipeline("custom-pipeline", {
 *   name: "custom-pipeline",
 *   source: [{
 *     type: "http",
 *     format: "json",
 *     authentication: true,
 *     cors: {
 *       origins: ["https://example.com"]
 *     }
 *   }],
 *   destination: {
 *     type: "r2",
 *     format: "json",
 *     path: {
 *       bucket: "my-bucket",
 *       prefix: "data"
 *     },
 *     credentials: {
 *       accessKeyId: alchemy.secret(process.env.R2_ACCESS_KEY_ID!),
 *       secretAccessKey: alchemy.secret(process.env.R2_SECRET_ACCESS_KEY!)
 *     },
 *     compression: {
 *       type: "gzip"
 *     }
 *   }
 * });
 *
 * @see https://developers.cloudflare.com/pipelines/
 */
export const Pipeline = Resource("cloudflare::Pipeline", async function <
  T extends PipelineRecord = PipelineRecord,
>(this: Context<Pipeline<T>>, id: string, props: PipelineProps): Promise<
  Pipeline<T>
> {
  const api = await createCloudflareApi(props);
  const pipelineName = props.name ?? id;
  if (this.phase === "delete") {
    if (props.delete !== false) {
      // Delete Pipeline
      await deletePipeline(api, pipelineName);
    }
    // Return void (a deleted pipeline has no content)
    return this.destroy();
  }
  let pipelineData: CloudflarePipelineResponse;
  if (this.phase === "create") {
    pipelineData = await createPipeline(api, pipelineName, props);
  } else {
    // Update operation
    if (this.output?.id) {
      // Check if name is being changed, which is not allowed
      if (props.name !== this.output.name) {
        throw new Error(
          "Cannot update Pipeline name after creation. Pipeline name is immutable.",
        );
      }
      // Update the pipeline with new settings
      pipelineData = await updatePipeline(api, pipelineName, props);
    } else {
      // If no ID exists, fall back to creating a new pipeline
      console.log(
        "No existing Pipeline ID found, creating new Cloudflare Pipeline:",
        pipelineName,
      );
      pipelineData = await createPipeline(api, pipelineName, props);
    }
  }
  return this({
    type: "pipeline",
    id: pipelineData.result.id,
    name: pipelineName,
    endpoint: pipelineData.result.endpoint,
    version: pipelineData.result.version,
    source: pipelineData.result.source!.map((s) => ({
      type: s.type as "http" | "binding",
      format: s.format as "json",
      authentication: s.authentication,
      cors: s.cors,
    })),
    destination: props.destination, // Use the input destination, not the API response
    compression: props.compression,
    accountId: api.accountId,
  });
});
interface CloudflarePipelineResponse {
  result: {
    id: string;
    name: string;
    endpoint: string;
    version: number;
    source: Array<{
      type: "http" | "binding";
      format: string;
      authentication?: boolean;
      cors?: {
        origins: string[];
      };
    }>;
    destination: {
      type: string;
      format: string;
      path?: {
        bucket: string;
        prefix?: string;
        filename?: string;
        filepath?: string;
      };
      compression?: {
        type: string;
      };
      batch: {
        max_bytes?: number;
        max_rows?: number;
        max_duration_s?: number;
      };
    };
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Get a pipeline
 */
export async function getPipeline(
  api: CloudflareApi,
  pipelineName: string,
): Promise<CloudflarePipelineResponse> {
  const response = await api.get(
    `/accounts/${api.accountId}/pipelines/${pipelineName}`,
  );
  if (!response.ok) {
    return await handleApiError(response, "getting", "Pipeline", pipelineName);
  }
  return (await response.json()) as CloudflarePipelineResponse;
}
/**
 * Delete a pipeline
 */
export async function deletePipeline(
  api: CloudflareApi,
  pipelineName: string,
): Promise<void> {
  // Delete Pipeline
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/pipelines/${pipelineName}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting Cloudflare Pipeline '${pipelineName}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * Create a new pipeline
 */
export async function createPipeline(
  api: CloudflareApi,
  pipelineName: string,
  props: PipelineProps,
): Promise<CloudflarePipelineResponse> {
  // Prepare the create payload
  const createPayload = preparePipelinePayload(api, pipelineName, props);
  const createResponse = await api.post(
    `/accounts/${api.accountId}/pipelines`,
    createPayload,
  );
  if (!createResponse.ok) {
    return await handleApiError(
      createResponse,
      "creating",
      "Pipeline",
      pipelineName,
    );
  }
  return (await createResponse.json()) as CloudflarePipelineResponse;
}
/**
 * Update a pipeline
 */
export async function updatePipeline(
  api: CloudflareApi,
  pipelineName: string,
  props: PipelineProps,
): Promise<CloudflarePipelineResponse> {
  // Get current pipeline to build update payload
  const currentPipeline = await getPipeline(api, pipelineName);
  // Prepare the update payload
  const updatePayload = preparePipelinePayload(
    api,
    pipelineName,
    props,
    currentPipeline,
  );
  const updateResponse = await api.put(
    `/accounts/${api.accountId}/pipelines/${pipelineName}`,
    updatePayload,
  );
  if (!updateResponse.ok) {
    return await handleApiError(
      updateResponse,
      "updating",
      "Pipeline",
      pipelineName,
    );
  }
  return (await updateResponse.json()) as CloudflarePipelineResponse;
}
/**
 * Helper function to prepare pipeline payload for create/update operations
 */
function preparePipelinePayload(
  api: CloudflareApi,
  pipelineName: string,
  props: PipelineProps,
  currentPipeline?: CloudflarePipelineResponse,
): any {
  // Prepare the payload with name and source
  const payload: any = {
    name: pipelineName,
    source: props.source ||
      currentPipeline?.result.source || [
        {
          type: "http",
          format: "json",
          authentication: true,
          cors: { origins: ["*"] },
        },
      ],
  };
  // Handle destination
  if (props.destination) {
    payload.destination = { ...props.destination };
    // Handle special formatting for R2 destination
    const r2Dest = props.destination as R2DestinationConfig;
    // Format credentials for API
    if (payload.destination.credentials) {
      payload.destination.credentials = {
        access_key_id: r2Dest.credentials.accessKeyId.unencrypted,
        secret_access_key: r2Dest.credentials.secretAccessKey.unencrypted,
        endpoint:
          r2Dest.credentials.endpoint ??
          `https://${api.accountId}.r2.cloudflarestorage.com`,
      };
    }
    // Format batch settings
    payload.destination.batch = convertBatchSettings(payload.destination.batch);
  } else if (currentPipeline?.result.destination) {
    payload.destination = currentPipeline.result.destination;
  } else if (!props.destination && !currentPipeline) {
    throw new Error(
      "An R2 destination is required for creating/updating a pipeline",
    );
  }
  // Add compression if not specified
  if (!payload.destination.compression) {
    payload.destination.compression = { type: "gzip" };
  }
  return payload;
}
/**
 * List all pipelines in an account
 */
export async function listPipelines(
  api: CloudflareApi,
): Promise<{ name: string; id: string }[]> {
  const response = await api.get(`/accounts/${api.accountId}/pipelines`);
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list pipelines: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as {
    success: boolean;
    errors?: Array<{ code: number; message: string }>;
    results?: Array<{
      name: string;
      id: string;
    }>;
  };
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list pipelines: ${errorMessage}`);
  }
  // Transform API response
  return (data.results || []).map((pipeline) => ({
    name: pipeline.name,
    id: pipeline.id,
  }));
}
/**
 * Helper function to convert batch settings to the format expected by the API
 */
interface CloudflareBatchSettings {
  max_bytes?: number;
  max_rows?: number;
  max_duration_s?: number;
}
function convertBatchSettings(batch?: BatchSettings): CloudflareBatchSettings {
  const result: CloudflareBatchSettings = {};
  if (batch?.maxMb !== undefined) {
    // Convert MB to bytes
    result.max_bytes = batch.maxMb * 1024 * 1024;
  }
  if (batch?.maxRows !== undefined) {
    result.max_rows = batch.maxRows;
  }
  if (batch?.maxSeconds !== undefined) {
    result.max_duration_s = batch.maxSeconds;
  }
  return result;
}
</file>

<file path="alchemy/src/cloudflare/queue-consumer.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  createCloudflareApi,
  type CloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
import type { Queue } from "./queue.js";
/**
 * Settings for configuring a Queue Consumer
 */
export interface QueueConsumerSettings {
  /**
   * Number of messages to deliver in a batch
   * @default 10
   */
  batchSize?: number;
  /**
   * Maximum number of concurrent consumer worker invocations
   * @default 2
   */
  maxConcurrency?: number;
  /**
   * Maximum number of retries for each message
   * @default 3
   */
  maxRetries?: number;
  /**
   * Maximum time in milliseconds to wait for batch to fill
   * @default 500
   */
  maxWaitTimeMs?: number;
  /**
   * Time in seconds to delay retry after a failure
   * @default 30
   */
  retryDelay?: number;
}
/**
 * Properties for creating or updating a Queue Consumer
 */
export interface QueueConsumerProps extends CloudflareApiOptions {
  /**
   * The queue to consume
   * Either queue or queueId must be provided
   */
  queue?: Queue;
  /**
   * The queue ID to consume (alternative to providing a queue)
   * Either queue or queueId must be provided
   */
  queueId?: string;
  /**
   * Name of the worker script that will consume the queue
   */
  scriptName: string;
  /**
   * Settings for the consumer
   */
  settings?: QueueConsumerSettings;
  /**
   * Whether to delete the consumer.
   * If set to false, the consumer will remain but the resource will be removed from state
   * @default true
   */
  delete?: boolean;
}
/**
 * Output returned after Queue Consumer creation/update
 */
export interface QueueConsumer
  extends Resource<"cloudflare::QueueConsumer">,
    QueueConsumerProps {
  /**
   * Unique ID for the consumer
   */
  id: string;
  /**
   * Type identifier for Cloudflare Queue Consumer
   */
  type: "worker";
  /**
   * ID of the queue being consumed
   */
  queueId: string;
  /**
   * Time when the consumer was created
   */
  createdOn?: string;
}
/**
 * Creates a consumer for a Cloudflare Queue that processes messages using a Worker.
 *
 * @example
 * // Create a queue consumer with default settings
 * const queue = await Queue("notifications", {
 *   name: "notifications"
 * });
 *
 * const consumer = await QueueConsumer("notification-processor", {
 *   queue,
 *   scriptName: "notification-worker"
 * });
 *
 * @example
 * // Create a consumer with custom settings
 * const batchConsumer = await QueueConsumer("batch-processor", {
 *   queue,
 *   scriptName: "batch-worker",
 *   settings: {
 *     batchSize: 50,         // Process 50 messages at once
 *     maxConcurrency: 10,    // Allow 10 concurrent invocations
 *     maxRetries: 5,         // Retry failed messages up to 5 times
 *     maxWaitTimeMs: 2000,   // Wait up to 2 seconds to fill a batch
 *     retryDelay: 60         // Wait 60 seconds before retrying failed messages
 *   }
 * });
 *
 * @see https://developers.cloudflare.com/queues/platform/consumers/
 */
export const QueueConsumer = Resource(
  "cloudflare::QueueConsumer",
  async function (
    this: Context<QueueConsumer>,
    id: string,
    props: QueueConsumerProps,
  ): Promise<QueueConsumer> {
    const api = await createCloudflareApi(props);
    // Get queueId from either props.queue or props.queueId
    const queueId = props.queue?.id || props.queueId;
    if (!queueId) {
      throw new Error("Either queue or queueId must be provided");
    }
    if (this.phase === "delete") {
      console.log(`Deleting Queue Consumer for queue ${queueId}`);
      if (props.delete !== false && this.output?.id) {
        // Delete the consumer
        await deleteQueueConsumer(api, queueId, this.output.id);
      }
      // Return void (a deleted consumer has no content)
      return this.destroy();
    }
    let consumerData: CloudflareQueueConsumerResponse;
    if (this.phase === "create") {
      consumerData = await createQueueConsumer(api, queueId, props);
    } else if (this.output?.id) {
      consumerData = await updateQueueConsumer(
        api,
        queueId,
        this.output.id,
        props,
      );
    } else {
      consumerData = await createQueueConsumer(api, queueId, props);
    }
    return this({
      id: consumerData.result.consumer_id,
      queueId,
      queue: props.queue,
      type: "worker",
      scriptName: props.scriptName,
      settings: consumerData.result.settings
        ? {
            batchSize: consumerData.result.settings.batch_size,
            maxConcurrency: consumerData.result.settings.max_concurrency,
            maxRetries: consumerData.result.settings.max_retries,
            maxWaitTimeMs: consumerData.result.settings.max_wait_time_ms,
            retryDelay: consumerData.result.settings.retry_delay,
          }
        : undefined,
      createdOn: consumerData.result.created_on,
      accountId: api.accountId,
    });
  },
);
/**
 * Response from Cloudflare API for Queue Consumer operations
 */
interface CloudflareQueueConsumerResponse {
  result: {
    consumer_id: string;
    script_name: string;
    settings?: {
      batch_size?: number;
      max_concurrency?: number;
      max_retries?: number;
      max_wait_time_ms?: number;
      retry_delay?: number;
    };
    type: "worker";
    queue_id?: string;
    created_on?: string;
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Create a new Queue Consumer
 */
export async function createQueueConsumer(
  api: CloudflareApi,
  queueId: string,
  props: QueueConsumerProps,
): Promise<CloudflareQueueConsumerResponse> {
  // Prepare the create payload
  const createPayload: any = {
    script_name: props.scriptName,
    type: "worker",
  };
  // Add settings if provided
  if (props.settings) {
    createPayload.settings = {};
    if (props.settings.batchSize !== undefined) {
      createPayload.settings.batch_size = props.settings.batchSize;
    }
    if (props.settings.maxConcurrency !== undefined) {
      createPayload.settings.max_concurrency = props.settings.maxConcurrency;
    }
    if (props.settings.maxRetries !== undefined) {
      createPayload.settings.max_retries = props.settings.maxRetries;
    }
    if (props.settings.maxWaitTimeMs !== undefined) {
      createPayload.settings.max_wait_time_ms = props.settings.maxWaitTimeMs;
    }
    if (props.settings.retryDelay !== undefined) {
      createPayload.settings.retry_delay = props.settings.retryDelay;
    }
  }
  const createResponse = await api.post(
    `/accounts/${api.accountId}/queues/${queueId}/consumers`,
    createPayload,
  );
  if (!createResponse.ok) {
    return await handleApiError(
      createResponse,
      "creating",
      "Queue Consumer",
      `for queue ${queueId}`,
    );
  }
  return (await createResponse.json()) as CloudflareQueueConsumerResponse;
}
/**
 * Delete a Queue Consumer
 */
export async function deleteQueueConsumer(
  api: CloudflareApi,
  queueId: string,
  consumerId: string,
): Promise<void> {
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/queues/${queueId}/consumers/${consumerId}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting Queue Consumer '${consumerId}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * Update a Queue Consumer
 */
async function updateQueueConsumer(
  api: CloudflareApi,
  queueId: string,
  consumerId: string,
  props: QueueConsumerProps,
): Promise<CloudflareQueueConsumerResponse> {
  // Prepare the update payload
  const updatePayload: any = {
    script_name: props.scriptName,
    type: "worker",
  };
  // Add settings if provided
  if (props.settings) {
    updatePayload.settings = {};
    if (props.settings.batchSize !== undefined) {
      updatePayload.settings.batch_size = props.settings.batchSize;
    }
    if (props.settings.maxConcurrency !== undefined) {
      updatePayload.settings.max_concurrency = props.settings.maxConcurrency;
    }
    if (props.settings.maxRetries !== undefined) {
      updatePayload.settings.max_retries = props.settings.maxRetries;
    }
    if (props.settings.maxWaitTimeMs !== undefined) {
      updatePayload.settings.max_wait_time_ms = props.settings.maxWaitTimeMs;
    }
    if (props.settings.retryDelay !== undefined) {
      updatePayload.settings.retry_delay = props.settings.retryDelay;
    }
  }
  // Use PUT to update the consumer
  const updateResponse = await api.put(
    `/accounts/${api.accountId}/queues/${queueId}/consumers/${consumerId}`,
    updatePayload,
  );
  if (!updateResponse.ok) {
    return await handleApiError(
      updateResponse,
      "updating",
      "Queue Consumer",
      consumerId,
    );
  }
  return (await updateResponse.json()) as CloudflareQueueConsumerResponse;
}
export interface ListQueueConsumersResponse {
  id: string;
  scriptName: string;
  queueId: string;
  queueName: string;
  createdOn: string;
  settings?: QueueConsumerSettings;
}
/**
 * List all consumers for a queue
 */
export async function listQueueConsumers(
  api: CloudflareApi,
  queueId: string,
): Promise<ListQueueConsumersResponse[]> {
  const response = await api.get(
    `/accounts/${api.accountId}/queues/${queueId}/consumers`,
  );
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list queue consumers: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as {
    success: boolean;
    errors?: Array<{ code: number; message: string }>;
    result?: Array<{
      consumer_id: string;
      script: string;
      queue_id: string;
      queue_name: string;
      created_on: string;
      settings?: {
        batch_size?: number;
        max_concurrency?: number;
        max_retries?: number;
        max_wait_time_ms?: number;
        retry_delay?: number;
      };
    }>;
  };
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list queue consumers: ${errorMessage}`);
  }
  // Transform API response
  return (data.result || []).map((consumer) => ({
    id: consumer.consumer_id,
    scriptName: consumer.script,
    queueId: consumer.queue_id,
    queueName: consumer.queue_name,
    createdOn: consumer.created_on,
    settings: consumer.settings
      ? {
          batchSize: consumer.settings.batch_size,
          maxConcurrency: consumer.settings.max_concurrency,
          maxRetries: consumer.settings.max_retries,
          maxWaitTimeMs: consumer.settings.max_wait_time_ms,
          retryDelay: consumer.settings.retry_delay,
        }
      : undefined,
  }));
}
</file>

<file path="alchemy/src/cloudflare/queue.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  type CloudflareApi,
  createCloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
/**
 * Settings for a Cloudflare Queue
 */
export interface QueueSettings {
  /**
   * Delay in seconds before message delivery
   * Queue will not deliver messages until this time has elapsed
   */
  deliveryDelay?: number;
  /**
   * Whether delivery is paused
   * If true, the queue will not deliver messages to consumers
   */
  deliveryPaused?: boolean;
  /**
   * Period in seconds to retain messages
   * Messages will be automatically deleted after this time
   */
  messageRetentionPeriod?: number;
}
/**
 * Properties for creating or updating a Cloudflare Queue
 */
export interface QueueProps extends CloudflareApiOptions {
  /**
   * Name of the queue
   * Required during creation
   * Cannot be changed after creation
   *
   * @default id
   */
  name?: string;
  /**
   * Settings for the queue
   * These can be updated after queue creation
   */
  settings?: QueueSettings;
  /**
   * Whether to delete the queue.
   * If set to false, the queue will remain but the resource will be removed from state
   *
   * @default true
   */
  delete?: boolean;
}
export function isQueue(eventSource: any): eventSource is Queue {
  return "Kind" in eventSource && eventSource.Kind === "cloudflare::Queue";
}
/**
 * Output returned after Cloudflare Queue creation/update
 */
export interface Queue<Body = unknown>
  extends Resource<"cloudflare::Queue">,
    QueueProps {
  /**
   * Type identifier for Cloudflare Queue
   */
  type: "queue";
  /**
   * The unique ID of the queue
   */
  id: string;
  /**
   * The name of the queue
   */
  name: string;
  /**
   * Time when the queue was created
   */
  createdOn: string;
  /**
   * Modified timestamp
   */
  modifiedOn: string;
  /**
   * Phantom property to allow type inference
   */
  Body: Body;
  Batch: MessageBatch<Body>;
}
interface CloudflareQueueResponse {
  result: {
    queue_id?: string;
    queue_name: string;
    created_on?: string;
    modified_on?: string;
    settings?: {
      delivery_delay?: number;
      delivery_paused?: boolean;
      message_retention_period?: number;
    };
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Creates and manages Cloudflare Queues.
 *
 * Queues provide a managed queue system for reliable message delivery
 * between workers and other systems.
 *
 * @example
 * // Create a basic queue with default settings
 * const basicQueue = await Queue("my-app-queue", {
 *   name: "my-app-queue"
 * });
 *
 * @example
 * // Create a queue with custom settings
 * const customQueue = await Queue("delayed-queue", {
 *   name: "delayed-queue",
 *   settings: {
 *     deliveryDelay: 30, // 30 second delay before message delivery
 *     messageRetentionPeriod: 86400 // Store messages for 1 day
 *   }
 * });
 *
 * @example
 * // Create a paused queue for later activation
 * const pausedQueue = await Queue("paused-queue", {
 *   name: "paused-queue",
 *   settings: {
 *     deliveryPaused: true
 *   }
 * });
 *
 * @see https://developers.cloudflare.com/queues/
 */
export const Queue = Resource("cloudflare::Queue", async function <
  T = unknown,
>(this: Context<Queue<T>>, id: string, props: QueueProps = {}): Promise<
  Queue<T>
> {
  const api = await createCloudflareApi(props);
  const queueName = props.name ?? id;
  if (this.phase === "delete") {
    console.log("Deleting Cloudflare Queue:", queueName);
    if (props.delete !== false) {
      // Delete Queue
      await deleteQueue(api, this.output?.id);
    }
    // Return void (a deleted queue has no content)
    return this.destroy();
  }
  let queueData: CloudflareQueueResponse;
  if (this.phase === "create") {
    console.log("Creating Cloudflare Queue:", queueName);
    queueData = await createQueue(api, queueName, props);
  } else {
    // Update operation
    if (this.output?.id) {
      console.log("Updating Cloudflare Queue:", queueName);
      // Check if name is being changed, which is not allowed
      if (props.name !== this.output.name) {
        throw new Error(
          "Cannot update Queue name after creation. Queue name is immutable.",
        );
      }
      // Update the queue with new settings
      queueData = await updateQueue(api, this.output.id, props);
    } else {
      // If no ID exists, fall back to creating a new queue
      console.log(
        "No existing Queue ID found, creating new Cloudflare Queue:",
        queueName,
      );
      queueData = await createQueue(api, queueName, props);
    }
  }
  return this({
    type: "queue",
    id: queueData.result.queue_id || "",
    name: queueName,
    settings: queueData.result.settings
      ? {
          deliveryDelay: queueData.result.settings.delivery_delay,
          deliveryPaused: queueData.result.settings.delivery_paused,
          messageRetentionPeriod:
            queueData.result.settings.message_retention_period,
        }
      : undefined,
    createdOn: queueData.result.created_on || new Date().toISOString(),
    modifiedOn: queueData.result.modified_on || new Date().toISOString(),
    accountId: api.accountId,
    // phantom properties
    Body: undefined as T,
    Batch: undefined! as MessageBatch<T>,
  });
});
/**
 * Create a new Cloudflare Queue
 */
export async function createQueue(
  api: CloudflareApi,
  queueName: string,
  props: QueueProps,
): Promise<CloudflareQueueResponse> {
  // Prepare the create payload
  const createPayload: any = {
    queue_name: queueName,
  };
  // Add settings if provided
  if (props.settings) {
    createPayload.settings = {};
    if (props.settings.deliveryDelay !== undefined) {
      createPayload.settings.delivery_delay = props.settings.deliveryDelay;
    }
    if (props.settings.deliveryPaused !== undefined) {
      createPayload.settings.delivery_paused = props.settings.deliveryPaused;
    }
    if (props.settings.messageRetentionPeriod !== undefined) {
      createPayload.settings.message_retention_period =
        props.settings.messageRetentionPeriod;
    }
  }
  const createResponse = await api.post(
    `/accounts/${api.accountId}/queues`,
    createPayload,
  );
  if (!createResponse.ok) {
    return await handleApiError(createResponse, "creating", "Queue", queueName);
  }
  return (await createResponse.json()) as CloudflareQueueResponse;
}
/**
 * Get a Cloudflare Queue
 */
export async function getQueue(
  api: CloudflareApi,
  queueId: string,
): Promise<CloudflareQueueResponse> {
  const response = await api.get(
    `/accounts/${api.accountId}/queues/${queueId}`,
  );
  if (!response.ok) {
    return await handleApiError(response, "getting", "Queue", queueId);
  }
  return (await response.json()) as CloudflareQueueResponse;
}
/**
 * Delete a Cloudflare Queue
 */
export async function deleteQueue(
  api: CloudflareApi,
  queueId?: string,
): Promise<void> {
  if (!queueId) {
    console.log("No Queue ID provided, skipping delete");
    return;
  }
  // Delete Queue
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/queues/${queueId}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting Cloudflare Queue '${queueId}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * Update a Cloudflare Queue
 *
 * Note: According to Cloudflare API, the queue name cannot be changed after creation.
 * Only the settings can be updated.
 */
export async function updateQueue(
  api: CloudflareApi,
  queueId: string,
  props: QueueProps,
): Promise<CloudflareQueueResponse> {
  // Prepare the update payload - only include settings
  const updatePayload: any = {};
  // Add settings if provided
  if (props.settings) {
    updatePayload.settings = {};
    if (props.settings.deliveryDelay !== undefined) {
      updatePayload.settings.delivery_delay = props.settings.deliveryDelay;
    }
    if (props.settings.deliveryPaused !== undefined) {
      updatePayload.settings.delivery_paused = props.settings.deliveryPaused;
    }
    if (props.settings.messageRetentionPeriod !== undefined) {
      updatePayload.settings.message_retention_period =
        props.settings.messageRetentionPeriod;
    }
  }
  // Use PATCH for partial updates (only settings can be updated)
  const updateResponse = await api.patch(
    `/accounts/${api.accountId}/queues/${queueId}`,
    updatePayload,
  );
  if (!updateResponse.ok) {
    return await handleApiError(updateResponse, "updating", "Queue", queueId);
  }
  return (await updateResponse.json()) as CloudflareQueueResponse;
}
/**
 * List all Cloudflare Queues in an account
 */
export async function listQueues(
  api: CloudflareApi,
): Promise<{ name: string; id: string }[]> {
  const response = await api.get(`/accounts/${api.accountId}/queues`);
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list queues: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as {
    success: boolean;
    errors?: Array<{ code: number; message: string }>;
    result?: Array<{
      queue_name: string;
      queue_id: string;
    }>;
  };
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list queues: ${errorMessage}`);
  }
  // Transform API response
  return (data.result || []).map((queue) => ({
    name: queue.queue_name,
    id: queue.queue_id,
  }));
}
</file>

<file path="alchemy/src/cloudflare/r2-rest-state-store.ts">
import type { Scope } from "../scope.js";
import { deserialize, serialize } from "../serde.js";
import type { State, StateStore } from "../state.js";
import { withExponentialBackoff } from "../util/retry.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  type CloudflareApi,
  type CloudflareApiOptions,
  createCloudflareApi,
} from "./api.js";
import { createBucket, getBucket } from "./bucket.js";
/**
 * Options for CloudflareR2StateStore
 */
export interface CloudflareR2StateStoreOptions extends CloudflareApiOptions {
  /**
   * The prefix to use for object keys in the R2 bucket
   * This allows multiple state stores to use the same R2 bucket
   */
  prefix?: string;
  /**
   * The R2 bucket name to use
   * Required - the bucket must already exist
   */
  bucketName?: string;
}
/**
 * State store implementation using Cloudflare R2 API
 * Uses R2 for immediate consistency compared to KV's eventual consistency
 */
export class R2RestStateStore implements StateStore {
  private api: CloudflareApi;
  private prefix: string;
  private bucketName: string;
  private initialized = false;
  /**
   * Create a new CloudflareR2StateStore
   *
   * @param scope The scope this store belongs to
   * @param options Options for the state store
   */
  constructor(
    public readonly scope: Scope,
    private readonly options: CloudflareR2StateStoreOptions = {},
  ) {
    // Use the scope's chain to build the prefix, similar to how FileSystemStateStore builds its directory
    const scopePath = scope.chain.join("/");
    this.prefix = options.prefix
      ? `${options.prefix}${scopePath}/`
      : `alchemy/${scopePath}/`;
    this.bucketName = options.bucketName ?? "alchemy-state";
    // We'll initialize the API in init() to allow for async creation
    this.api = null as any;
  }
  /**
   * Initialize the R2 client
   */
  async init(): Promise<void> {
    if (this.initialized) return;
    // Create Cloudflare API client with automatic account discovery
    this.api = await createCloudflareApi(this.options);
    // Check if the alchemy state bucket exists
    try {
      await withExponentialBackoff(
        () => getBucket(this.api, this.bucketName),
        isRetryableError,
        5,
        1000,
      );
    } catch (error) {
      // If not, create the alchemy state bucket
      if (error instanceof CloudflareApiError && error.status === 404) {
        try {
          await withExponentialBackoff(
            () => createBucket(this.api, this.bucketName),
            isRetryableError,
            5,
            1000,
          );
        } catch (error) {
          // this can happen when the bucket is being created in parallel
          if (error instanceof CloudflareApiError && error.status === 409) {
            // Bucket already exists, continue
          } else {
            throw error;
          }
        }
      }
    }
    this.initialized = true;
  }
  /**
   * R2 buckets cannot be deleted programmatically via this method
   */
  async deinit(): Promise<void> {
    // We don't delete the bucket here, only via explicit resource deletion
  }
  /**
   * List all resources in the state store
   */
  async list(): Promise<string[]> {
    await this.ensureInitialized();
    // Using pagination to get all objects
    let keys: string[] = [];
    let cursor: string | null = null;
    do {
      const params = new URLSearchParams({
        prefix: this.prefix,
        limit: "1000",
        delimiter: "/",
      });
      if (cursor) {
        params.append("cursor", cursor);
      }
      const listPath = `/accounts/${this.api.accountId}/r2/buckets/${this.bucketName}/objects?${params.toString()}`;
      const response = await withExponentialBackoff(
        async () => {
          const response = await this.api.get(listPath);
          if (!response.ok) {
            await handleApiError(response, "list", "bucket", this.bucketName);
          }
          return response;
        },
        // Retry on transient errors
        isRetryableError,
        5, // 5 retry attempts
        1000, // Start with 1 second delay
      );
      const data = (await response.json()) as any;
      // The result structure may be under "result" key in Cloudflare's API
      const result = data.result || data;
      const objects = result.objects || result;
      // Add keys to our list, removing the prefix and converting from storage format
      keys = keys.concat(
        objects.map((obj: any) => {
          const keyName = obj.key || obj.name;
          return this.convertKeyFromStorage(keyName.slice(this.prefix.length));
        }),
      );
      // Update cursor for next page if available
      cursor =
        result.truncated || result.cursor_pagination
          ? result.cursor || null
          : null;
    } while (cursor);
    return keys;
  }
  /**
   * Count the number of items in the state store
   */
  async count(): Promise<number> {
    const keys = await this.list();
    return keys.length;
  }
  /**
   * Get a state by key
   *
   * @param key The key to look up
   * @returns The state or undefined if not found
   */
  async get(key: string): Promise<State | undefined> {
    await this.ensureInitialized();
    try {
      const response = await withExponentialBackoff(
        async () => {
          const response = await this.api.get(
            `/accounts/${this.api.accountId}/r2/buckets/${this.bucketName}/objects/${this.getObjectKey(key)}`,
          );
          if (!response.ok && response.status !== 404) {
            await handleApiError(response, "get", "object", key);
          }
          return response;
        },
        // Retry on transient errors
        isRetryableError,
        5, // 5 retry attempts
        1000, // Start with 1 second delay
      );
      if (response.status === 404) {
        return undefined;
      }
      // Parse and deserialize the state data
      const rawData = await response.json();
      const state = (await deserialize(this.scope, rawData)) as State;
      // Create a new state object with proper output
      return {
        ...state,
        output: {
          ...(state.output || {}),
          Scope: this.scope,
        },
      };
    } catch (error: any) {
      if (error.message?.includes("404")) {
        return undefined;
      }
      throw error;
    }
  }
  /**
   * Get multiple states by their keys
   *
   * @param ids Array of keys to fetch
   * @returns Record mapping keys to their states
   */
  async getBatch(ids: string[]): Promise<Record<string, State>> {
    const result: Record<string, State> = {};
    // R2 REST API doesn't have a batch get operation, so we need to make multiple requests
    const promises = ids.map(async (id) => {
      const state = await this.get(id);
      if (state) {
        result[id] = state;
      }
    });
    await Promise.all(promises);
    return result;
  }
  /**
   * Get all states in the store
   *
   * @returns Record mapping all keys to their states
   */
  async all(): Promise<Record<string, State>> {
    const keys = await this.list();
    return this.getBatch(keys);
  }
  /**
   * Set a state for a key
   *
   * @param key The key to set
   * @param value The state to store
   */
  async set(key: string, value: State): Promise<void> {
    await this.ensureInitialized();
    const objectKey = this.getObjectKey(key);
    // Serialize the state to handle cyclic structures
    const serializedData = await serialize(this.scope, value);
    // Using withExponentialBackoff for reliability
    await withExponentialBackoff(
      async () => {
        const response = await this.api.put(
          `/accounts/${this.api.accountId}/r2/buckets/${this.bucketName}/objects/${objectKey}`,
          serializedData,
          {
            headers: {
              "Content-Type": "application/json",
            },
          },
        );
        if (!response.ok) {
          await handleApiError(response, "put", "object", objectKey);
        }
        return response;
      },
      // Retry on transient errors
      isRetryableError,
      5, // 5 retry attempts
      1000, // Start with 1 second delay
    );
  }
  /**
   * Delete a state by key
   *
   * @param key The key to delete
   */
  async delete(key: string): Promise<void> {
    await this.ensureInitialized();
    await withExponentialBackoff(
      async () => {
        const response = await this.api.delete(
          `/accounts/${this.api.accountId}/r2/buckets/${this.bucketName}/objects/${this.getObjectKey(key)}`,
        );
        if (!response.ok && response.status !== 404) {
          await handleApiError(response, "delete", "object", key);
        }
        return response;
      },
      isRetryableError,
      5, // 5 retry attempts
      1000, // Start with 1 second delay
    );
  }
  /**
   * Convert key for storage by replacing slashes with colons
   * since R2 treats slashes as directory separators
   *
   * @param key The original key
   * @returns Key with slashes replaced by colons
   */
  private convertKeyForStorage(key: string): string {
    return key.replaceAll("/", ":");
  }
  /**
   * Convert key from storage by replacing colons with slashes
   *
   * @param key The storage key
   * @returns Key with colons replaced by slashes
   */
  private convertKeyFromStorage(key: string): string {
    return key.replaceAll(":", "/");
  }
  /**
   * Get the full object key for storage
   *
   * @param key The original key
   * @returns The key with prefix for use in the R2 bucket
   */
  private getObjectKey(key: string): string {
    return `${this.prefix}${this.convertKeyForStorage(key)}`;
  }
  /**
   * Ensure the store is initialized before operations
   */
  private async ensureInitialized(): Promise<void> {
    if (!this.initialized) {
      await this.init();
    }
  }
}
function isRetryableError(error: any): boolean {
  if (error instanceof CloudflareApiError) {
    return (
      error.status === 500 ||
      error.status === 502 ||
      error.status === 503 ||
      error.message.includes("timeout") ||
      error.message.includes("internal error")
    );
  }
  return false;
}
</file>

<file path="alchemy/src/cloudflare/redwood.ts">
import path from "node:path";
import type { Assets } from "./assets.js";
import type { Bindings } from "./bindings.js";
import { Website, type WebsiteProps } from "./website.js";
import type { Worker } from "./worker.js";
export interface RedwoodProps<B extends Bindings> extends WebsiteProps<B> {}
// don't allow the ASSETS to be overridden
export type Redwood<B extends Bindings> = B extends { ASSETS: any }
  ? never
  : Worker<B & { ASSETS: Assets }>;
/**
 * Deploy a RedwoodJS application to Cloudflare Pages with automatically configured defaults.
 *
 * This resource handles the deployment of RedwoodJS applications with optimized settings for
 * Cloudflare Workers, including proper build commands and compatibility flags.
 *
 * @example
 * // Deploy a basic RedwoodJS application with default settings
 * const redwoodApp = await Redwood("my-redwood-app");
 *
 * @example
 * // Deploy with a database binding
 * import { D1Database } from alchemy/cloudflare";
 *
 * const database = await D1Database("redwood-db");
 *
 * const redwoodApp = await Redwood("redwood-with-db", {
 *   bindings: {
 *     DB: database
 *   }
 * });
 *
 * @param id - Unique identifier for the RedwoodJS application
 * @param props - Configuration properties for the RedwoodJS deployment
 * @returns A Cloudflare Worker resource representing the deployed RedwoodJS application
 */
export async function Redwood<B extends Bindings>(
  id: string,
  props?: Partial<RedwoodProps<B>>,
): Promise<Redwood<B>> {
  return Website(id, {
    ...props,
    command: props?.command ?? "bun run clean && RWSDK_DEPLOY=1 bun run build",
    wrangler:
      props?.wrangler === false
        ? false
        : {
            main: props?.main ?? path.join("src", "worker.tsx"),
          },
    main: props?.main ?? path.join("dist", "worker", "worker.js"),
    assets: props?.assets ?? path.join("dist", "client"),
    compatibilityFlags: ["nodejs_compat", ...(props?.compatibilityFlags ?? [])],
    compatibilityDate: props?.compatibilityDate ?? "2025-04-02",
  });
}
</file>

<file path="alchemy/src/cloudflare/response.ts">
/**
 * Cloudflare API response format
 */
export interface CloudflareResponse<T = unknown> {
  result: T;
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
</file>

<file path="alchemy/src/cloudflare/route.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  createCloudflareApi,
  type CloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
import type { Worker } from "./worker.js";
/**
 * Properties for creating or updating a Route
 */
export interface RouteProps extends CloudflareApiOptions {
  /**
   * URL pattern for the route
   * @example "example.com/*"
   */
  pattern: string;
  /**
   * Worker script for the route
   * This can be a Worker resource or script name as a string
   */
  script: Worker | string;
  /**
   * Zone ID for the route
   */
  zoneId: string;
}
/**
 * Output returned after Route creation/update
 */
export interface Route extends Resource<"cloudflare::Route">, RouteProps {
  /**
   * The unique ID of the route
   */
  id: string;
  /**
   * The URL pattern for the route
   */
  pattern: string;
  /**
   * The Worker script name for the route
   */
  script: string;
  /**
   * The Zone ID for the route
   */
  zoneId: string;
}
/**
 * Creates and manages Cloudflare Worker Routes.
 *
 * Routes map URL patterns to Worker scripts, allowing you to control which
 * requests are handled by your Workers.
 *
 * @example
 * // Create a route that maps all requests on a domain to a Worker
 * const basicRoute = await Route("main-route", {
 *   pattern: "example.com/*",
 *   script: "my-worker",
 *   zoneId: "your-zone-id"
 * });
 *
 * @example
 * // Create a route using a Worker resource
 * const worker = await Worker("api-worker", {
 *   script: `
 *     export default {
 *       fetch(request, env) {
 *         return new Response("Hello from API!");
 *       }
 *     }
 *   `
 * });
 *
 * const apiRoute = await Route("api-route", {
 *   pattern: "api.example.com/*",
 *   script: worker,
 *   zoneId: "your-zone-id"
 * });
 *
 * @see https://developers.cloudflare.com/workers/configuration/routes/
 */
export const Route = Resource(
  "cloudflare::Route",
  async function (
    this: Context<Route>,
    id: string,
    props: RouteProps,
  ): Promise<Route> {
    const api = await createCloudflareApi(props);
    // Get script name from script prop (either a string or a Worker resource)
    const scriptName =
      typeof props.script === "string" ? props.script : props.script.name;
    // Get zone ID from props
    const { zoneId } = props;
    if (this.phase === "delete") {
      console.log("Deleting Route:", props.pattern);
      // Only delete if we have an ID
      if (this.output?.id) {
        await deleteRoute(api, zoneId, this.output.id);
      }
      // Return void (a deleted route has no content)
      return this.destroy();
    }
    let routeData: CloudflareRouteResponse;
    if (this.phase === "update" && this.output?.id) {
      console.log("Updating Route:", props.pattern);
      // Update existing route
      routeData = await updateRoute(
        api,
        zoneId,
        this.output.id,
        props.pattern,
        scriptName,
      );
    } else {
      console.log("Creating Route:", props.pattern);
      // Create new route
      routeData = await createRoute(api, zoneId, props.pattern, scriptName);
    }
    // Return the route resource
    return this({
      id: routeData.result.id,
      pattern: routeData.result.pattern,
      script: routeData.result.script,
      zoneId,
    });
  },
);
interface CloudflareRouteResponse {
  result: {
    id: string;
    pattern: string;
    script: string;
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Create a new route
 */
async function createRoute(
  api: CloudflareApi,
  zoneId: string,
  pattern: string,
  script: string,
): Promise<CloudflareRouteResponse> {
  const createResponse = await api.post(`/zones/${zoneId}/workers/routes`, {
    pattern,
    script,
  });
  if (!createResponse.ok) {
    return await handleApiError(createResponse, "creating", "Route", pattern);
  }
  return (await createResponse.json()) as CloudflareRouteResponse;
}
/**
 * Update a route
 */
async function updateRoute(
  api: CloudflareApi,
  zoneId: string,
  routeId: string,
  pattern: string,
  script: string,
): Promise<CloudflareRouteResponse> {
  const updateResponse = await api.put(
    `/zones/${zoneId}/workers/routes/${routeId}`,
    {
      pattern,
      script,
    },
  );
  if (!updateResponse.ok) {
    return await handleApiError(updateResponse, "updating", "Route", pattern);
  }
  return (await updateResponse.json()) as CloudflareRouteResponse;
}
/**
 * Delete a route
 */
async function deleteRoute(
  api: CloudflareApi,
  zoneId: string,
  routeId: string,
): Promise<void> {
  const deleteResponse = await api.delete(
    `/zones/${zoneId}/workers/routes/${routeId}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting Route '${routeId}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * Get a route by ID
 */
export async function getRoute(
  api: CloudflareApi,
  zoneId: string,
  routeId: string,
): Promise<CloudflareRouteResponse> {
  const response = await api.get(`/zones/${zoneId}/workers/routes/${routeId}`);
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to get route ${routeId}: ${response.statusText}`,
      response,
    );
  }
  return (await response.json()) as CloudflareRouteResponse;
}
/**
 * List all routes for a zone
 */
export async function listRoutes(
  api: CloudflareApi,
  zoneId: string,
): Promise<CloudflareRouteResponse> {
  const response = await api.get(`/zones/${zoneId}/workers/routes`);
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list routes: ${response.statusText}`,
      response,
    );
  }
  return (await response.json()) as CloudflareRouteResponse;
}
</file>

<file path="alchemy/src/cloudflare/tanstack-start.ts">
import type { Assets } from "./assets.js";
import type { Bindings } from "./bindings.js";
import { Website, type WebsiteProps } from "./website.js";
import type { Worker } from "./worker.js";
export interface TanStackStartProps<B extends Bindings>
  extends WebsiteProps<B> {}
// don't allow the ASSETS to be overriden
export type TanStackStart<B extends Bindings> = B extends { ASSETS: any }
  ? never
  : Worker<B & { ASSETS: Assets }>;
export async function TanStackStart<B extends Bindings>(
  id: string,
  props?: Partial<TanStackStartProps<B>>,
): Promise<TanStackStart<B>> {
  return Website(id, {
    ...props,
    command: props?.command ?? "bun run build",
    wrangler: props?.wrangler ?? true,
    main: props?.main ?? ".output/server/index.mjs",
    compatibilityFlags: ["nodejs_compat", ...(props?.compatibilityFlags ?? [])],
    assets: props?.assets ?? ".output/public",
  });
}
</file>

<file path="alchemy/src/cloudflare/types.ts">
/**
 * Cloudflare API response format
 */
export interface CloudflareApiResponse<T> {
  /**
   * API response result
   */
  result: T;
  /**
   * Success status
   */
  success: boolean;
  /**
   * Error details if success is false
   */
  errors: CloudflareApiError[];
  /**
   * Response messages
   */
  messages: string[];
  /**
   * Result information (typically for paginated results)
   */
  result_info?: {
    page: number;
    per_page: number;
    total_pages: number;
    count: number;
    total_count: number;
  };
}
/**
 * Cloudflare API error format
 */
export interface CloudflareApiError {
  /**
   * Error code
   */
  code: number;
  /**
   * Error message
   */
  message: string;
}
/**
 * Helper to extract and handle Cloudflare API errors
 *
 * @param response Fetch response object
 * @returns Formatted error message
 */
export async function extractCloudflareError(
  response: Response,
): Promise<string> {
  try {
    const data = (await response.json()) as CloudflareApiResponse<any>;
    if (data.errors && data.errors.length > 0) {
      return data.errors.map((e) => `Error ${e.code}: ${e.message}`).join(", ");
    }
    return `HTTP ${response.status}: ${response.statusText}`;
  } catch (e) {
    return `HTTP ${response.status}: ${response.statusText}`;
  }
}
</file>

<file path="alchemy/src/cloudflare/user.ts">
import { handleApiError } from "../neon/api-error.js";
import type { Secret } from "../secret.js";
import {
  getCloudflareAuthHeaders,
  type CloudflareAuthOptions,
} from "./auth.js";
export interface CloudflareAccount {
  name: string;
  id: string;
  type: "standard" | "zero_rating" | "full_control";
  settings: {
    enforce_twofactor: boolean;
    api_access_enabled: null;
    access_approval_expiry: null;
    abuse_contact_email: null;
  };
  legacy_flags: {
    enterprise_zone_quota: {
      maximum: number;
      current: number;
      available: number;
    };
  };
}
export interface CloudflareUserInfo {
  apiToken?: Secret;
  apiKey?: Secret;
  email: string;
  username: string;
  accounts: CloudflareAccount[];
  organizations: CloudflareOrganization[];
  tokenPermissions: string[] | undefined;
  first_name: string | null;
  last_name: string | null;
  telephone: string | null;
  country: string | null;
  zipcode: string | null;
  two_factor_authentication_enabled: boolean;
  two_factor_authentication_locked: boolean;
  has_pro_zones: boolean;
  has_business_zones: boolean;
  has_enterprise_zones: boolean;
  suspended: boolean;
  betas: string[];
}
export interface CloudflareOrganization {
  id: string;
  name: string;
  status: string;
  permissions: string[];
  roles: string[];
}
const accountCache: Record<string, CloudflareAccount[]> = {};
export async function getCloudflareAccounts(
  options: CloudflareAuthOptions,
): Promise<CloudflareAccount[]> {
  const cacheKey = JSON.stringify({
    apiKey: options.apiKey?.unencrypted,
    apiToken: options.apiToken?.unencrypted,
    email: options.email,
  });
  if (accountCache[cacheKey]) {
    return accountCache[cacheKey];
  }
  const headers = await getCloudflareAuthHeaders(options);
  const accounts = await fetch(
    "https://api.cloudflare.com/client/v4/accounts",
    {
      headers,
    },
  );
  if (accounts.ok) {
    return (accountCache[cacheKey] ??= ((await accounts.json()) as any).result);
  } else {
    return await handleApiError(accounts, "get", "accounts");
  }
}
const emailCache: Record<string, string> = {};
export async function getUserEmailFromApiKey(apiKey: string): Promise<string> {
  if (emailCache[apiKey]) {
    return emailCache[apiKey];
  }
  try {
    const baseUrl = "https://api.cloudflare.com/client/v4";
    // Call the /user endpoint to get user information
    const response = await fetch(`${baseUrl}/user`, {
      headers: {
        "Content-Type": "application/json",
        "X-Auth-Key": apiKey,
      },
    });
    if (!response.ok) {
      throw new Error(
        `Failed to get user information: ${response.status} ${response.statusText}`,
      );
    }
    const data = (await response.json()) as {
      success: boolean;
      result: {
        id: string;
        email: string;
        name: string;
        [key: string]: any;
      };
    };
    if (!data.success || !data.result || !data.result.email) {
      throw new Error("Cloudflare API did not return valid user information");
    }
    emailCache[apiKey] = data.result.email;
    return data.result.email;
  } catch (error) {
    console.error("Error retrieving email from Cloudflare API:", error);
    throw new Error(
      "Failed to automatically discover email for API Key authentication",
    );
  }
}
</file>

<file path="alchemy/src/cloudflare/vectorize-index.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  createCloudflareApi,
  type CloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
/**
 * Properties for creating or updating a Vectorize Index
 */
export interface VectorizeIndexProps extends CloudflareApiOptions {
  /**
   * Name of the index
   */
  name: string;
  /**
   * Optional description of the index
   */
  description?: string;
  /**
   * Dimensions of the vectors
   */
  dimensions: number;
  /**
   * Distance metric used for vector similarity
   */
  metric: "cosine" | "euclidean" | "dot_product";
  /**
   * Whether to delete the index if removed
   * If set to false, the index will remain but the resource will be removed from state
   *
   * @default true
   */
  delete?: boolean;
  /**
   * Whether to adopt an existing index with the same name if it exists
   * If true and an index with the same name exists, it will be adopted rather than creating a new one
   *
   * @default false
   */
  adopt?: boolean;
}
/**
 * Output returned after Vectorize Index creation/update
 */
export interface VectorizeIndex
  extends Resource<"cloudflare::VectorizeIndex">,
    VectorizeIndexProps {
  type: "vectorize";
  /**
   * The unique identifier for the index (same as name)
   */
  id: string;
  /**
   * Time at which the index was created
   */
  createdAt?: number;
}
/**
 * Creates and manages Cloudflare Vectorize Indexes.
 *
 * Vectorize is Cloudflare's vector database that enables vector search within Cloudflare Workers.
 *
 * @example
 * // Create a basic vector index for text embeddings
 * const basicIndex = await VectorizeIndex("text-embeddings", {
 *   name: "text-embeddings",
 *   config: {
 *     dimensions: 768,
 *     metric: "cosine"
 *   }
 * });
 *
 * @example
 * // Create a vector index with a description
 * const descIndex = await VectorizeIndex("image-embeddings", {
 *   name: "image-embeddings",
 *   description: "Vector index for image embeddings using CLIP model",
 *   config: {
 *     dimensions: 512,
 *     metric: "cosine"
 *   }
 * });
 *
 * @example
 * // Adopt an existing index if it already exists instead of failing
 * const existingIndex = await VectorizeIndex("existing-index", {
 *   name: "existing-index",
 *   adopt: true,
 *   config: {
 *     dimensions: 1024,
 *     metric: "euclidean"
 *   }
 * });
 *
 * @see https://developers.cloudflare.com/vectorize/
 */
export const VectorizeIndex = Resource(
  "cloudflare::VectorizeIndex",
  async function (
    this: Context<VectorizeIndex>,
    id: string,
    props: VectorizeIndexProps,
  ): Promise<VectorizeIndex> {
    const api = await createCloudflareApi(props);
    const indexName = props.name || id;
    if (this.phase === "delete") {
      console.log("Deleting Vectorize index:", indexName);
      if (props.delete !== false) {
        // Delete Vectorize index
        await deleteIndex(api, indexName);
      }
      // Return void (a deleted index has no content)
      return this.destroy();
    }
    let indexData: CloudflareVectorizeResponse;
    if (this.phase === "create") {
      console.log("Creating Vectorize index:", indexName);
      try {
        indexData = await createIndex(api, indexName, {
          ...props,
          name: indexName,
        });
      } catch (error) {
        // Check if this is a "index already exists" error and adopt is enabled
        if (
          props.adopt &&
          error instanceof CloudflareApiError &&
          error.message.includes("already exists")
        ) {
          console.log(`Index ${indexName} already exists, adopting it`);
          // Find the existing index
          indexData = await getIndex(api, indexName);
        } else {
          // Re-throw the error if adopt is false or it's not a "index already exists" error
          throw error;
        }
      }
    } else {
      // Update operation is not supported by Vectorize API
      throw new Error(
        "Updating Vectorize indexes is not supported by the Cloudflare API. " +
          "To change an index, delete it and create a new one with the desired configuration.",
      );
    }
    return this({
      type: "vectorize",
      id: indexName,
      name: indexName,
      description: props.description,
      dimensions: indexData.result.config.dimensions,
      metric: indexData.result.config.metric as
        | "cosine"
        | "euclidean"
        | "dot_product",
      accountId: api.accountId,
      createdAt: indexData.result.created_on
        ? new Date(indexData.result.created_on).getTime()
        : undefined,
    });
  },
);
interface CloudflareVectorizeResponse {
  result: {
    name: string;
    description?: string;
    created_on?: string;
    config: {
      dimensions: number;
      metric: string;
    };
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Create a new Vectorize index
 */
export async function createIndex(
  api: CloudflareApi,
  indexName: string,
  props: VectorizeIndexProps,
): Promise<CloudflareVectorizeResponse> {
  // Create new Vectorize index
  const createPayload: any = {
    name: indexName,
    config: {
      dimensions: props.dimensions,
      metric: props.metric,
    },
  };
  if (props.description) {
    createPayload.description = props.description;
  }
  const createResponse = await api.post(
    `/accounts/${api.accountId}/vectorize/v2/indexes`,
    createPayload,
  );
  if (!createResponse.ok) {
    return await handleApiError(
      createResponse,
      "creating",
      "Vectorize index",
      indexName,
    );
  }
  return (await createResponse.json()) as CloudflareVectorizeResponse;
}
/**
 * Get a Vectorize index
 */
export async function getIndex(
  api: CloudflareApi,
  indexName: string,
): Promise<CloudflareVectorizeResponse> {
  const response = await api.get(
    `/accounts/${api.accountId}/vectorize/v2/indexes/${indexName}`,
  );
  if (!response.ok) {
    return await handleApiError(
      response,
      "getting",
      "Vectorize index",
      indexName,
    );
  }
  return (await response.json()) as CloudflareVectorizeResponse;
}
/**
 * Delete a Vectorize index
 */
export async function deleteIndex(
  api: CloudflareApi,
  indexName: string,
): Promise<void> {
  // Delete Vectorize index
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/vectorize/v2/indexes/${indexName}`,
  );
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    const errorData: any = await deleteResponse.json().catch(() => ({
      errors: [{ message: deleteResponse.statusText }],
    }));
    throw new CloudflareApiError(
      `Error deleting Vectorize index '${indexName}': ${errorData.errors?.[0]?.message || deleteResponse.statusText}`,
      deleteResponse,
    );
  }
}
/**
 * List all Vectorize indexes in an account
 */
export async function listIndexes(
  api: CloudflareApi,
): Promise<{ name: string; description?: string }[]> {
  const response = await api.get(
    `/accounts/${api.accountId}/vectorize/v2/indexes`,
  );
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list indexes: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as {
    success: boolean;
    errors?: Array<{ code: number; message: string }>;
    result?: Array<{
      name: string;
      description?: string;
    }>;
  };
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list indexes: ${errorMessage}`);
  }
  // Transform API response
  return (data.result || []).map((index) => ({
    name: index.name,
    description: index.description,
  }));
}
/**
 * Update a Vectorize index
 *
 * Note: The Cloudflare Vectorize API does not support updating indexes.
 * This function will always throw an error.
 */
export async function updateIndex(
  api: CloudflareApi,
  indexName: string,
  props: VectorizeIndexProps,
): Promise<CloudflareVectorizeResponse> {
  throw new Error(
    "Updating Vectorize indexes is not supported by the Cloudflare API. To change an index, delete it and create a new one.",
  );
}
</file>

<file path="alchemy/src/cloudflare/vectorize-metadata-index.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  createCloudflareApi,
  type CloudflareApi,
  type CloudflareApiOptions,
} from "./api.js";
import type { VectorizeIndex } from "./vectorize-index.js";
/**
 * Properties for creating or deleting a Vectorize Metadata Index
 */
export interface VectorizeMetadataIndexProps extends CloudflareApiOptions {
  /**
   * Parent Vectorize Index
   */
  index: VectorizeIndex;
  /**
   * Name of the property in the metadata to create an index for
   */
  propertyName: string;
  /**
   * Type of the metadata index
   */
  indexType: "string" | "number" | "boolean";
}
/**
 * Output returned after Vectorize Metadata Index creation/deletion
 */
export interface VectorizeMetadataIndex
  extends Resource<"cloudflare::VectorizeMetadataIndex">,
    VectorizeMetadataIndexProps {
  /**
   * ID of this metadata index (derived from propertyName)
   */
  id: string;
  /**
   * Mutation ID returned by the API after creation
   */
  mutationId?: string;
}
/**
 * Creates and manages Cloudflare Vectorize Metadata Indexes.
 *
 * Vectorize Metadata Indexes enable filtering based on metadata properties when querying vectors.
 * Each Vectorize Index can have up to 10 metadata indexes.
 *
 * @example
 * // First create a Vectorize Index
 * const vectorIndex = await VectorizeIndex("documents", {
 *   name: "documents",
 *   config: {
 *     dimensions: 768,
 *     metric: "cosine"
 *   }
 * });
 *
 * // Then create a metadata index for the "category" property
 * const categoryIndex = await VectorizeMetadataIndex("category-index", {
 *   index: vectorIndex,
 *   propertyName: "category",
 *   indexType: "string"
 * });
 *
 * @example
 * // Create a metadata index for a numeric property
 * const yearIndex = await VectorizeMetadataIndex("year-index", {
 *   index: vectorIndex,
 *   propertyName: "year",
 *   indexType: "number"
 * });
 *
 * @see https://developers.cloudflare.com/vectorize/
 */
export const VectorizeMetadataIndex = Resource(
  "cloudflare::VectorizeMetadataIndex",
  async function (
    this: Context<VectorizeMetadataIndex>,
    id: string,
    props: VectorizeMetadataIndexProps,
  ): Promise<VectorizeMetadataIndex> {
    const api = await createCloudflareApi(props);
    const indexName = props.index.name;
    const propertyName = props.propertyName;
    if (this.phase === "delete") {
      // Delete metadata index
      try {
        await deleteMetadataIndex(api, indexName, propertyName);
      } catch (error) {
        if (
          error instanceof CloudflareApiError &&
          error.status === 400 &&
          error.message.includes("does not exist")
        ) {
          // Index doesn't exist, which is what we want
        } else {
          throw error;
        }
      }
      return this.destroy();
    }
    if (this.phase === "update") {
      // Update operation is not supported
      throw new Error(
        "Updating Vectorize metadata indexes is not supported by the Cloudflare API. " +
          "To change a metadata index, delete it and create a new one with the desired configuration.",
      );
    }
    const indexData = await createMetadataIndex(api, indexName, props);
    return this({
      id: propertyName, // Use propertyName as ID
      index: props.index,
      propertyName: props.propertyName,
      indexType: props.indexType,
      accountId: api.accountId,
      mutationId: indexData.result.mutationId,
    });
  },
);
interface CloudflareMetadataIndexResponse {
  result: {
    mutationId: string;
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
interface CloudflareMetadataIndexListResponse {
  result: {
    metadataIndexes: Array<{
      propertyName: string;
      indexType: "string" | "number" | "boolean";
    }>;
  };
  success: boolean;
  errors: Array<{ code: number; message: string }>;
  messages: string[];
}
/**
 * Create a new Vectorize metadata index
 */
export async function createMetadataIndex(
  api: CloudflareApi,
  indexName: string,
  props: VectorizeMetadataIndexProps,
): Promise<CloudflareMetadataIndexResponse> {
  // Create new metadata index
  const createPayload = {
    propertyName: props.propertyName,
    indexType: props.indexType,
  };
  const createResponse = await api.post(
    `/accounts/${api.accountId}/vectorize/v2/indexes/${indexName}/metadata_index/create`,
    createPayload,
  );
  if (!createResponse.ok) {
    return await handleApiError(
      createResponse,
      "creating",
      "Vectorize metadata index",
      props.propertyName,
    );
  }
  return (await createResponse.json()) as CloudflareMetadataIndexResponse;
}
/**
 * Delete a Vectorize metadata index
 */
export async function deleteMetadataIndex(
  api: CloudflareApi,
  indexName: string,
  propertyName: string,
): Promise<void> {
  const deleteResponse = await api.post(
    `/accounts/${api.accountId}/vectorize/v2/indexes/${indexName}/metadata_index/delete`,
    {
      propertyName,
    },
  );
  if (!deleteResponse.ok) {
    await handleApiError(
      deleteResponse,
      "deleting",
      "Vectorize metadata index",
      propertyName,
    );
  }
}
/**
 * List all metadata indexes for a Vectorize index
 */
export async function listMetadataIndexes(
  api: CloudflareApi,
  indexName: string,
): Promise<
  { propertyName: string; indexType: "string" | "number" | "boolean" }[]
> {
  const response = await api.get(
    `/accounts/${api.accountId}/vectorize/v2/indexes/${indexName}/metadata_index/list`,
  );
  if (response.status === 410) {
    // Gone
    return [];
  }
  if (!response.ok) {
    throw new CloudflareApiError(
      `Failed to list metadata indexes: ${response.statusText}`,
      response,
    );
  }
  const data = (await response.json()) as CloudflareMetadataIndexListResponse;
  if (!data.success) {
    const errorMessage = data.errors?.[0]?.message || "Unknown error";
    throw new Error(`Failed to list metadata indexes: ${errorMessage}`);
  }
  return data.result.metadataIndexes;
}
</file>

<file path="alchemy/src/cloudflare/vite.ts">
import fs from "node:fs/promises";
import path from "node:path";
import type { Assets } from "./assets.js";
import type { Bindings } from "./bindings.js";
import { Website, type WebsiteProps } from "./website.js";
import type { Worker } from "./worker.js";
export interface ViteProps<B extends Bindings> extends WebsiteProps<B> {}
// don't allow the ASSETS to be overriden
export type Vite<B extends Bindings> = B extends { ASSETS: any }
  ? never
  : Worker<B & { ASSETS: Assets }>;
export async function Vite<B extends Bindings>(
  id: string,
  props: ViteProps<B>,
): Promise<Vite<B>> {
  return Website(id, {
    ...props,
    assets:
      props.assets ??
      (await (async () => {
        try {
          await fs.access(path.join("dist", "client", "index.html"));
          return path.join(".", "dist", "client");
        } catch {
          return path.join(".", "dist");
        }
      })()),
  });
}
</file>

<file path="alchemy/src/cloudflare/website.ts">
import fs from "node:fs/promises";
import path from "node:path";
import { alchemy } from "../alchemy.js";
import { Exec } from "../os/exec.js";
import { Assets } from "./assets.js";
import type { Bindings } from "./bindings.js";
import { Worker, type AssetsConfig, type WorkerProps } from "./worker.js";
import { WranglerJson } from "./wrangler.json.js";
export interface WebsiteProps<B extends Bindings>
  extends Omit<WorkerProps<B>, "name" | "assets" | "entrypoint"> {
  /**
   * The command to run to build the site
   */
  command: string;
  /**
   * The name of the worker
   *
   * @default id
   */
  name?: string;
  /**
   * The entrypoint to your server
   *
   * @default - a simple server that serves static assets is generated
   */
  main?: string;
  /**
   * The directory containing your static assets
   *
   * @default "./dist"
   */
  assets?:
    | string
    | ({
        dist?: string;
      } & AssetsConfig);
  /**
   * @default process.cwd()
   */
  cwd?: string;
  /**
   * Write a wrangler.jsonc file
   *
   * @default - no wrangler.jsonc file is written
   */
  wrangler?:
    | boolean
    | string
    | {
        path?: string;
        // override main
        main?: string;
      };
}
export type Website<B extends Bindings> = B extends { ASSETS: any }
  ? never
  : Worker<B & { ASSETS: Assets }>;
export async function Website<B extends Bindings>(
  id: string,
  props: WebsiteProps<B>,
): Promise<Website<B>> {
  if (props.bindings?.ASSETS) {
    throw new Error("ASSETS binding is reserved for internal use");
  }
  return alchemy.run(id, async () => {
    // building the site requires a wrangler.jsonc file to start
    // - so initialize an empty one if it doesn't exist
    const cwd = path.resolve(props.cwd || process.cwd());
    const fileName =
      typeof props.wrangler === "boolean"
        ? "wrangler.jsonc"
        : typeof props.wrangler === "string"
          ? props.wrangler
          : (props.wrangler?.path ?? "wrangler.jsonc");
    const wranglerPath =
      fileName && path.relative(cwd, path.join(cwd, fileName));
    const wranglerMain =
      typeof props.wrangler === "object"
        ? (props.wrangler.main ?? props.main)
        : props.main;
    if (props.wrangler) {
      try {
        await fs.access(wranglerPath!);
      } catch {
        await fs.writeFile(
          wranglerPath!,
          JSON.stringify(
            {
              name: id,
              main: wranglerMain,
              compatibility_date: new Date().toISOString().split("T")[0],
            },
            null,
            2,
          ),
        );
      }
    }
    await Exec("build", {
      command: props.command,
    });
    const worker = await Worker("worker", {
      ...props,
      name: props.name ?? id,
      entrypoint: props.main,
      assets: {
        html_handling: "auto-trailing-slash",
        not_found_handling: "single-page-application",
        run_worker_first: false,
        ...(typeof props.assets === "string" ? {} : props.assets),
      },
      script: props.main
        ? undefined
        : `
export default {
  async fetch(request, env) {
    return new Response("Not Found", { status: 404 });
  },
};`,
      url: true,
      adopt: true,
      bindings: {
        ...props.bindings,
        ASSETS: await Assets("assets", {
          path:
            typeof props.assets === "string"
              ? props.assets
              : (props.assets?.dist ?? "dist"),
        }),
      },
    });
    if (props.wrangler) {
      await WranglerJson("wrangler.jsonc", {
        path: wranglerPath,
        worker,
        main: wranglerMain,
      });
    }
    return worker as Website<B>;
  });
}
</file>

<file path="alchemy/src/cloudflare/worker-metadata.ts">
/**
 * Metadata returned by Cloudflare API for a worker script
 */
export interface WorkerScriptMetadata {
  /**
   * Worker ID
   */
  id: string;
  /**
   * Default environment information
   */
  default_environment?: WorkerDefaultEnvironment;
  /**
   * Worker creation timestamp
   */
  created_on: string;
  /**
   * Worker last modification timestamp
   */
  modified_on: string;
  /**
   * Worker usage model
   */
  usage_model: string;
  /**
   * Worker environments
   */
  environments?: WorkerEnvironment[];
}
/**
 * Worker script information
 */
export interface WorkerScriptInfo {
  /**
   * Script creation timestamp
   */
  created_on: string;
  /**
   * Script last modification timestamp
   */
  modified_on: string;
  /**
   * Script ID
   */
  id: string;
  /**
   * Script tag
   */
  tag: string;
  /**
   * Script tags
   */
  tags: string[];
  /**
   * Deployment ID
   */
  deployment_id: string;
  /**
   * Tail consumers
   */
  tail_consumers: any;
  /**
   * Whether logpush is enabled
   */
  logpush: boolean;
  /**
   * Observability settings
   */
  observability: {
    /**
     * Whether observability is enabled
     */
    enabled: boolean;
    /**
     * Head sampling rate
     */
    head_sampling_rate: number | null;
  };
  /**
   * Whether the script has assets
   */
  has_assets: boolean;
  /**
   * Whether the script has modules
   */
  has_modules: boolean;
  /**
   * Script etag
   */
  etag: string;
  /**
   * Script handlers
   */
  handlers: string[];
  /**
   * Where the script was last deployed from
   */
  last_deployed_from: string;
  /**
   * Script usage model
   */
  usage_model: string;
}
/**
 * Worker environment information
 */
export interface WorkerEnvironment {
  /**
   * Environment name
   */
  environment: string;
  /**
   * Environment creation timestamp
   */
  created_on: string;
  /**
   * Environment last modification timestamp
   */
  modified_on: string;
}
/**
 * Default environment with script information
 */
export interface WorkerDefaultEnvironment extends WorkerEnvironment {
  /**
   * Script information
   */
  script: WorkerScriptInfo;
}
</file>

<file path="alchemy/src/cloudflare/worker-migration.ts">
export type WorkerMigrations = SingleStepMigration | MultiStepMigration;
export function isSingleStepMigration(
  migration: WorkerMigrations,
): migration is SingleStepMigration {
  return (
    "deleted_classes" in migration ||
    "new_classes" in migration ||
    "new_sqlite_classes" in migration ||
    "renamed_classes" in migration ||
    "transferred_classes" in migration
  );
}
export interface SingleStepMigration {
  /**
   * A list of classes to delete Durable Object namespaces from
   */
  deleted_classes?: string[];
  /**
   * A list of classes to create Durable Object namespaces from
   */
  new_classes?: string[];
  /**
   * A list of classes to create Durable Object namespaces with SQLite from
   */
  new_sqlite_classes?: string[];
  /**
   * Tag to set as the latest migration tag
   */
  new_tag?: string;
  /**
   * Tag used to verify against the latest migration tag for this Worker.
   * If they don't match, the upload is rejected.
   */
  old_tag?: string;
  /**
   * A list of classes with Durable Object namespaces that were renamed
   */
  renamed_classes?: RenamedClass[];
  /**
   * A list of transfers for Durable Object namespaces from a different Worker
   * and class to a class defined in this Worker
   */
  transferred_classes?: TransferredClass[];
}
/**
 * Represents a renamed class in a Durable Object migration
 */
export interface RenamedClass {
  /**
   * Original class name
   */
  from: string;
  /**
   * New class name
   */
  to: string;
}
/**
 * Represents a transferred class in a Durable Object migration
 */
export interface TransferredClass {
  /**
   * Original class name
   */
  from: string;
  /**
   * Original script name
   */
  from_script: string;
  /**
   * New class name in this Worker
   */
  to: string;
}
export function isMultiStepMigration(
  migration: WorkerMigrations,
): migration is MultiStepMigration {
  return "steps" in migration;
}
/**
 * Represents a multi-step migration for Durable Objects
 */
export interface MultiStepMigration {
  /**
   * Tag to set as the latest migration tag
   */
  new_tag?: string;
  /**
   * Tag used to verify against the latest migration tag for this Worker.
   * If they don't match, the upload is rejected.
   */
  old_tag?: string;
  /**
   * Migrations to apply in order
   */
  steps: MigrationStep[];
}
/**
 * Represents a single step in a Durable Object migration
 */
export interface MigrationStep {
  /**
   * A list of classes to delete Durable Object namespaces from
   */
  deleted_classes?: string[];
  /**
   * A list of classes to create Durable Object namespaces from
   */
  new_classes?: string[];
  /**
   * A list of classes to create Durable Object namespaces with SQLite from
   */
  new_sqlite_classes?: string[];
  /**
   * A list of classes with Durable Object namespaces that were renamed
   */
  renamed_classes?: RenamedClass[];
  /**
   * A list of transfers for Durable Object namespaces from a different Worker
   * and class to a class defined in this Worker
   */
  transferred_classes?: TransferredClass[];
}
</file>

<file path="alchemy/src/cloudflare/worker.ts">
import * as crypto from "node:crypto";
import * as fs from "node:fs/promises";
import type { Context } from "../context.js";
import type { BundleProps } from "../esbuild/bundle.js";
import { Resource } from "../resource.js";
import { getContentType } from "../util/content-type.js";
import { withExponentialBackoff } from "../util/retry.js";
import { slugify } from "../util/slugify.js";
import { CloudflareApiError, handleApiError } from "./api-error.js";
import {
  type CloudflareApi,
  type CloudflareApiOptions,
  createCloudflareApi,
} from "./api.js";
import type { Assets } from "./assets.js";
import { type Bindings, Self, type WorkerBindingSpec } from "./bindings.js";
import type { Bound } from "./bound.js";
import { bundleWorkerScript } from "./bundle/bundle-worker.js";
import type { DurableObjectNamespace } from "./durable-object-namespace.js";
import { type EventSource, isQueueEventSource } from "./event-source.js";
import {
  QueueConsumer,
  deleteQueueConsumer,
  listQueueConsumers,
} from "./queue-consumer.js";
import { isQueue } from "./queue.js";
import type { WorkerScriptMetadata } from "./worker-metadata.js";
import type { SingleStepMigration } from "./worker-migration.js";
import { type Workflow, upsertWorkflow } from "./workflow.js";
/**
 * Configuration options for static assets
 */
export interface AssetsConfig {
  /**
   * The contents of a _headers file (used to attach custom headers on asset responses)
   */
  _headers?: string;
  /**
   * The contents of a _redirects file (used to apply redirects or proxy paths ahead of asset serving)
   */
  _redirects?: string;
  /**
   * Determines the redirects and rewrites of requests for HTML content
   * @default "auto-trailing-slash"
   */
  html_handling?:
    | "auto-trailing-slash"
    | "force-trailing-slash"
    | "drop-trailing-slash"
    | "none";
  /**
   * Determines the response when a request does not match a static asset, and there is no Worker script
   */
  not_found_handling?: "none" | "404-page" | "single-page-application";
  /**
   * When true, requests will always invoke the Worker script.
   * Otherwise, attempt to serve an asset matching the request, falling back to the Worker script.
   */
  run_worker_first?: boolean;
  /**
   * When true and the incoming request matches an asset, that will be served instead of invoking the Worker script.
   * When false, requests will always invoke the Worker script.
   * @default true
   * @deprecated
   */
  serve_directly?: boolean;
}
/**
 * Properties for creating or updating a Worker
 */
export interface WorkerProps<B extends Bindings = Bindings>
  extends CloudflareApiOptions {
  /**
   * The worker script content (JavaScript or WASM)
   * One of script, entryPoint, or bundle must be provided
   */
  script?: string;
  /**
   * Path to the entry point file
   *
   * Will be bundled using esbuild
   *
   * One of script, entryPoint, or bundle must be provided
   */
  entrypoint?: string;
  /**
   * The project root directory used to resolve aliases.
   *
   * @default process.cwd()
   */
  projectRoot?: string;
  /**
   * Bundle options when using entryPoint
   *
   * Ignored if bundle is provided
   */
  bundle?: Omit<BundleProps, "entryPoint">;
  /**
   * Module format for the worker script
   * - 'esm' - ECMAScript modules (default)
   * - 'cjs' - CommonJS modules
   * @default 'esm'
   */
  format?: "esm" | "cjs";
  /**
   * Name for the worker
   *
   * @default id
   */
  name?: string;
  /**
   * Bindings to attach to the worker
   */
  bindings?: B;
  /**
   * Environment variables to attach to the worker
   *
   * These will be converted to plain_text bindings
   */
  env?: {
    [key: string]: string;
  };
  /**
   * Whether to enable a workers.dev URL for this worker
   *
   * If true, the worker will be available at {name}.{subdomain}.workers.dev
   * @default false
   */
  url?: boolean;
  /**
   * Observability configuration for the worker
   *
   * Controls whether worker logs are enabled
   * @default { enabled: true }
   */
  observability?: {
    /**
     * Whether to enable worker logs
     * @default true
     */
    enabled?: boolean;
  };
  /**
   * Migrations to apply to the worker
   */
  migrations?: SingleStepMigration;
  /**
   * Whether to adopt the Worker if it already exists when creating
   */
  adopt?: boolean;
  /**
   * The compatibility date for the worker
   * @default "2025-04-26"
   */
  compatibilityDate?: string;
  /**
   * The compatibility flags for the worker
   */
  compatibilityFlags?: string[];
  /**
   * Configuration for static assets
   */
  assets?: AssetsConfig;
  /**
   * Cron expressions for the trigger.
   *
   * Uses standard cron syntax (e.g. "0 0 * * *" for daily at midnight)
   *
   * To clear all cron triggers, pass an empty array.
   *
   * @see https://developers.cloudflare.com/workers/configuration/cron-triggers/#examples
   */
  crons?: string[];
  /**
   * Event sources that this worker will consume.
   *
   * Can include queues, streams, or other event sources.
   */
  eventSources?: EventSource[];
}
/**
 * Output returned after Worker creation/update
 */
export interface Worker<B extends Bindings = Bindings>
  extends Resource<"cloudflare::Worker">,
    Omit<WorkerProps<B>, "url" | "script"> {
  type: "service";
  /**
   * The ID of the worker
   */
  id: string;
  /**
   * The name of the worker
   */
  name: string;
  /**
   * Time at which the worker was created
   */
  createdAt: number;
  /**
   * Time at which the worker was last updated
   */
  updatedAt: number;
  /**
   * The worker's URL if enabled
   * Format: {name}.{subdomain}.workers.dev
   */
  url?: string;
  /**
   * The bindings that were created
   */
  bindings: B | undefined;
  /**
   * Configuration for static assets
   */
  assets?: AssetsConfig;
  // phantom property (for typeof myWorker.Env)
  Env: {
    [bindingName in keyof B]: Bound<B[bindingName]>;
  };
  /**
   * The compatibility date for the worker
   */
  compatibilityDate: string;
  /**
   * The compatibility flags for the worker
   */
  compatibilityFlags: string[];
}
/**
 * A Cloudflare Worker is a serverless function that can be deployed to the Cloudflare network.
 *
 * @example
 * // Create a basic HTTP handler worker with custom domain routing
 * // and workers.dev URL:
 * const api = await Worker("api", {
 *   name: "api-worker",
 *   entrypoint: "./src/api.ts",
 *   routes: ["api.example.com/*"],
 *   url: true
 * });
 *
 * await Route("route", {
 *   zoneId: zone.zoneId,
 *   worker: api,
 *   pattern: "api.example.com/*",
 * });
 *
 * @example
 * // Create a real-time chat worker using Durable Objects
 * // for state management:
 * const chatRooms = new DurableObjectNamespace("chat-rooms");
 * const userStore = new DurableObjectNamespace("user-store");
 *
 * const chat = await Worker("chat", {
 *   name: "chat-worker",
 *   entrypoint: "./src/chat.ts",
 *   bindings: {
 *     ROOMS: chatRooms,
 *     USERS: userStore
 *   },
 * });
 *
 * @example
 * // Create a worker with KV namespace for caching and data storage:
 * const cache = await KVNamespace("cache-store");
 * const settings = await KVNamespace("user-settings");
 *
 * const cacheWorker = await Worker("cache", {
 *   name: "cache-worker",
 *   entrypoint: "./src/cache.ts",
 *   bindings: {
 *     CACHE: cache,
 *     SETTINGS: settings
 *   }
 * });
 *
 * @example
 * // Create a worker with R2 bucket for object storage:
 * const uploads = await R2Bucket("uploads", {
 *   name: "user-uploads"
 * });
 * const assets = await R2Bucket("assets", {
 *   name: "static-assets",
 *   allowPublicAccess: true
 * });
 *
 * const storageWorker = await Worker("storage", {
 *   name: "storage-worker",
 *   entrypoint: "./src/storage.ts",
 *   bindings: {
 *     UPLOADS: uploads,
 *     ASSETS: assets
 *   }
 * });
 *
 * @example
 * // Create a worker with static assets:
 * const staticAssets = await Assets("static", {
 *   path: "./src/assets"
 * });
 *
 * const frontendWorker = await Worker("frontend", {
 *   name: "frontend-worker",
 *   entrypoint: "./src/worker.ts",
 *   bindings: {
 *     ASSETS: staticAssets
 *   }
 * });
 *
 * @example
 * // Create a worker with scheduled cron triggers:
 * const cronWorker = await Worker("scheduled-tasks", {
 *   name: "cron-worker",
 *   entrypoint: "./src/scheduled.ts",
 *   crons: ['* 15 * * *', '0 0 * * *', '0 12 * * MON']
 * })
 *
 * @see
 * https://developers.cloudflare.com/workers/
 */
export const Worker = Resource(
  "cloudflare::Worker",
  {
    alwaysUpdate: true,
  },
  async function <const B extends Bindings>(
    this: Context<Worker<NoInfer<B>>>,
    id: string,
    props: WorkerProps<B>,
  ): Promise<Worker<B>> {
    // Validate input - we need either script, entryPoint, or bundle
    if (!props.script && !props.entrypoint) {
      throw new Error("One of script or entryPoint must be provided");
    }
    // Create Cloudflare API client with automatic account discovery
    const api = await createCloudflareApi(props);
    // Use the provided name
    const workerName = props.name ?? id;
    const oldBindings = await this.get<Bindings>("bindings");
    const compatibilityDate = props.compatibilityDate ?? "2025-04-20";
    const compatibilityFlags = props.compatibilityFlags ?? [];
    const uploadWorkerScript = async (props: WorkerProps<B>) => {
      // Get the script content - either from props.script, or by bundling
      const scriptContent =
        props.script ??
        (await bundleWorkerScript({
          ...props,
          compatibilityDate,
          compatibilityFlags,
        }));
      // Find any assets bindings
      const assetsBindings: { name: string; assets: Assets }[] = [];
      const workflowsBindings: Workflow[] = [];
      if (props.bindings) {
        for (const [bindingName, binding] of Object.entries(props.bindings)) {
          if (typeof binding === "object") {
            if (binding.type === "assets") {
              assetsBindings.push({ name: bindingName, assets: binding });
            } else if (binding.type === "workflow") {
              workflowsBindings.push(binding);
            }
          }
        }
      }
      // Upload any assets and get completion tokens
      let assetUploadResult: AssetUploadResult | undefined;
      if (assetsBindings.length > 0) {
        // We'll use the first asset binding for now
        // In the future, we might want to support multiple asset bindings
        const assetBinding = assetsBindings[0];
        // Upload the assets and get the completion token
        assetUploadResult = await uploadAssets(
          api,
          workerName,
          assetBinding.assets,
          props.assets,
        );
      }
      // Prepare metadata with bindings
      const scriptMetadata = await prepareWorkerMetadata(
        this,
        oldBindings,
        {
          ...props,
          compatibilityDate,
          compatibilityFlags,
          workerName,
        },
        assetUploadResult,
      );
      await putWorker(api, workerName, scriptContent, scriptMetadata);
      for (const workflow of workflowsBindings) {
        await upsertWorkflow(api, {
          workflowName: workflow.workflowName,
          className: workflow.className,
          scriptName: workerName,
        });
      }
      await Promise.all(
        props.eventSources?.map((eventSource) => {
          if (isQueue(eventSource) || isQueueEventSource(eventSource)) {
            const queue = isQueue(eventSource)
              ? eventSource
              : eventSource.queue;
            return QueueConsumer(`${queue.id}-consumer`, {
              queue,
              scriptName: workerName,
              accountId: api.accountId,
              settings: isQueueEventSource(eventSource)
                ? eventSource.settings
                : undefined,
            });
          }
          throw new Error(`Unsupported event source type: ${eventSource}`);
        }) ?? [],
      );
      // TODO: it is less than ideal that this can fail, resulting in state problem
      await this.set("bindings", props.bindings);
      // Handle worker URL if requested
      const workerUrl = await configureURL(
        this,
        api,
        workerName,
        props.url ?? false,
      );
      // Get current timestamp
      const now = Date.now();
      // Update cron triggers
      if (props.crons) {
        const res = await api.put(
          `/accounts/${api.accountId}/workers/scripts/${workerName}/schedules`,
          props.crons.map((cron) => ({ cron })),
        );
        if (!res.ok) {
          await handleApiError(
            res,
            "updating cron triggers",
            "worker",
            workerName,
          );
        }
      }
      return { scriptMetadata, workerUrl, now };
    };
    if (this.phase === "delete") {
      if (
        Object.values(props.bindings ?? {}).some((binding) => binding === Self)
      ) {
        // remove the Self bindings or else we can't remove (LOL)
        await uploadWorkerScript({
          ...props,
          bindings: Object.fromEntries(
            Object.entries(props.bindings ?? {}).filter(
              ([_, binding]) => binding !== Self,
            ),
          ) as B,
        });
      }
      await withExponentialBackoff(
        () =>
          deleteWorker(this, api, {
            ...props,
            workerName,
          }),
        (err) =>
          (err.status === 400 &&
            err.message.includes(
              "is still referenced by service bindings in Workers",
            )) ||
          err.status === 500 ||
          err.status === 503,
        10,
        100,
      );
      return this.destroy();
    }
    if (this.phase === "create") {
      if (!props.adopt) {
        await assertWorkerDoesNotExist(this, api, workerName);
      }
    }
    const { scriptMetadata, workerUrl, now } = await uploadWorkerScript(props);
    // Construct the output
    return this({
      ...props,
      type: "service",
      id,
      entrypoint: props.entrypoint,
      name: workerName,
      compatibilityDate,
      compatibilityFlags,
      format: props.format || "esm", // Include format in the output
      bindings: props.bindings ?? ({} as B),
      env: props.env,
      observability: scriptMetadata.observability,
      createdAt: now,
      updatedAt: now,
      eventSources: props.eventSources,
      url: workerUrl,
      // Include assets configuration in the output
      assets: props.assets,
      // Include cron triggers in the output
      crons: props.crons,
      // phantom property
      Env: undefined!,
    });
  },
);
async function deleteWorker<B extends Bindings>(
  ctx: Context<Worker<B>>,
  api: CloudflareApi,
  props: WorkerProps<B> & { workerName: string },
) {
  const workerName = props.workerName;
  // Delete any queue consumers attached to this worker first
  await deleteQueueConsumers(ctx, api, workerName);
  // Delete worker
  const deleteResponse = await api.delete(
    `/accounts/${api.accountId}/workers/scripts/${workerName}`,
  );
  // Check for success (2xx status code)
  if (!deleteResponse.ok && deleteResponse.status !== 404) {
    await handleApiError(deleteResponse, "delete", "worker", workerName);
  }
  // Disable the URL if it was enabled
  if (ctx.output?.url) {
    try {
      await api.post(
        `/accounts/${api.accountId}/workers/scripts/${workerName}/subdomain`,
        JSON.stringify({ enabled: false }),
        {
          headers: { "Content-Type": "application/json" },
        },
      );
    } catch (error) {
      console.warn("Failed to disable worker URL during deletion:", error);
    }
  }
  // Return minimal output for deleted state
  return;
}
async function putWorker(
  api: CloudflareApi,
  workerName: string,
  scriptContent: string,
  scriptMetadata: WorkerMetadata,
) {
  return withExponentialBackoff(
    async () => {
      const scriptName =
        scriptMetadata.main_module ?? scriptMetadata.body_part!;
      // Create FormData for the upload
      const formData = new FormData();
      // Add the actual script content as a named file part
      formData.append(
        scriptName,
        new Blob([scriptContent], {
          type: scriptMetadata.main_module
            ? "application/javascript+module"
            : "application/javascript",
        }),
        scriptName,
      );
      // Add metadata as JSON
      formData.append(
        "metadata",
        new Blob([JSON.stringify(scriptMetadata)], {
          type: "application/json",
        }),
      );
      // Upload worker script with bindings
      const uploadResponse = await api.put(
        `/accounts/${api.accountId}/workers/scripts/${workerName}`,
        formData,
        {
          headers: {
            "Content-Type": "multipart/form-data",
          },
        },
      );
      // Check if the upload was successful
      if (!uploadResponse.ok) {
        await handleApiError(
          uploadResponse,
          "uploading worker script",
          "worker",
          workerName,
        );
      }
      return formData;
    },
    (err) => err.status === 404 || err.status === 500 || err.status === 503,
    10,
    100,
  );
}
interface WorkerMetadata {
  compatibility_date: string;
  compatibility_flags?: string[];
  bindings: WorkerBindingSpec[];
  observability: {
    enabled: boolean;
  };
  migrations?: SingleStepMigration;
  main_module?: string;
  body_part?: string;
  tags?: string[];
  assets?: {
    jwt?: string;
    keep_assets?: boolean;
    config?: AssetsConfig;
  };
  cron_triggers?: {
    cron: string;
    suspended: boolean;
  }[];
}
interface AssetUploadResult {
  completionToken: string;
  assetConfig?: AssetsConfig;
}
/**
 * Creates asset configuration object from provided config or defaults
 */
function createAssetConfig(config?: AssetsConfig): AssetsConfig {
  const assetConfig: AssetsConfig = {
    html_handling: "auto-trailing-slash",
  };
  if (config) {
    if (config._headers !== undefined) {
      assetConfig._headers = config._headers;
    }
    if (config._redirects !== undefined) {
      assetConfig._redirects = config._redirects;
    }
    if (config.html_handling !== undefined) {
      assetConfig.html_handling = config.html_handling;
    }
    if (config.not_found_handling !== undefined) {
      assetConfig.not_found_handling = config.not_found_handling;
    }
    if (config.run_worker_first !== undefined) {
      assetConfig.run_worker_first = config.run_worker_first;
    }
    if (config.serve_directly !== undefined) {
      assetConfig.serve_directly = config.serve_directly;
    }
  }
  return assetConfig;
}
async function prepareWorkerMetadata<B extends Bindings>(
  ctx: Context<Worker<B>>,
  oldBindings: Bindings | undefined,
  props: WorkerProps & {
    compatibilityDate: string;
    compatibilityFlags: string[];
    workerName: string;
  },
  assetUploadResult?: AssetUploadResult,
): Promise<WorkerMetadata> {
  // Prepare metadata with bindings
  const meta: WorkerMetadata = {
    compatibility_date: props.compatibilityDate,
    compatibility_flags: props.compatibilityFlags,
    bindings: [],
    observability: {
      enabled: props.observability?.enabled !== false,
    },
    // TODO(sam): base64 encode instead? 0 collision risk vs readability.
    tags: [`alchemy:id:${slugify(ctx.fqn)}`],
    migrations: {
      new_classes: props.migrations?.new_classes ?? [],
      deleted_classes: props.migrations?.deleted_classes ?? [],
      renamed_classes: props.migrations?.renamed_classes ?? [],
      transferred_classes: props.migrations?.transferred_classes ?? [],
      new_sqlite_classes: props.migrations?.new_sqlite_classes ?? [],
    },
  };
  // If we have asset upload results, add them to the metadata
  if (assetUploadResult) {
    meta.assets = {
      jwt: assetUploadResult.completionToken,
    };
    // Initialize config from assetUploadResult if it exists
    if (assetUploadResult.assetConfig) {
      meta.assets.config = {
        ...assetUploadResult.assetConfig,
      };
    }
    // If there's no config from assetUploadResult but we have props.assets,
    // we need to create the config ourselves (this handles the case when no assets were uploaded)
    if (!meta.assets.config && props.assets) {
      meta.assets.config = createAssetConfig(props.assets);
    }
  }
  const bindings = (props.bindings ?? {}) as Bindings;
  // Convert bindings to the format expected by the API
  for (const [bindingName, binding] of Object.entries(bindings)) {
    // Create a copy of the binding to avoid modifying the original
    if (typeof binding === "string") {
      meta.bindings.push({
        type: "plain_text",
        name: bindingName,
        text: binding,
      });
    } else if (binding === Self) {
      meta.bindings.push({
        type: "service",
        name: bindingName,
        service: props.workerName,
      });
    } else if (binding.type === "d1") {
      meta.bindings.push({
        type: "d1",
        name: bindingName,
        id: binding.id,
      });
    } else if (binding.type === "kv_namespace") {
      meta.bindings.push({
        type: "kv_namespace",
        name: bindingName,
        namespace_id: binding.namespaceId,
      });
    } else if (binding.type === "service") {
      meta.bindings.push({
        type: "service",
        name: bindingName,
        service: binding.id,
      });
    } else if (binding.type === "durable_object_namespace") {
      meta.bindings.push({
        type: "durable_object_namespace",
        name: bindingName,
        class_name: binding.className,
        script_name: binding.scriptName,
        environment: binding.environment,
        namespace_id: binding.namespaceId,
      });
      configureClassMigration(binding, binding.id, binding.className);
    } else if (binding.type === "r2_bucket") {
      meta.bindings.push({
        type: "r2_bucket",
        name: bindingName,
        bucket_name: binding.name,
      });
    } else if (binding.type === "assets") {
      meta.bindings.push({
        type: "assets",
        name: bindingName,
      });
    } else if (binding.type === "secret") {
      meta.bindings.push({
        type: "secret_text",
        name: bindingName,
        text: binding.unencrypted,
      });
    } else if (binding.type === "workflow") {
      meta.bindings.push({
        type: "workflow",
        name: bindingName,
        workflow_name: binding.workflowName,
        class_name: binding.className,
        // this should be set if the Workflow is in another script ...
        // script_name: ??,
      });
      // it's unclear whether this is needed, but it works both ways
      // configureClassMigration(binding, binding.id, binding.className);
    } else if (binding.type === "queue") {
      meta.bindings.push({
        type: "queue",
        name: bindingName,
        queue_name: binding.name,
      });
    } else if (binding.type === "pipeline") {
      meta.bindings.push({
        type: "pipelines",
        name: bindingName,
        pipeline: binding.name,
      });
    } else if (binding.type === "vectorize") {
      meta.bindings.push({
        type: "vectorize",
        name: bindingName,
        index_name: binding.name,
      });
    } else if (binding.type === "ai_gateway") {
      // AI Gateway binding - just needs the name property
      meta.bindings.push({
        type: "ai",
        name: bindingName,
      });
    } else if (binding.type === "hyperdrive") {
      // Hyperdrive binding
      meta.bindings.push({
        type: "hyperdrive",
        name: bindingName,
        id: binding.hyperdriveId,
      });
    } else if (binding.type === "browser") {
      meta.bindings.push({
        type: "browser",
        name: bindingName,
      });
    } else if (binding.type === "ai") {
      meta.bindings.push({
        type: "ai",
        name: bindingName,
      });
    } else {
      // @ts-expect-error - we should never reach here
      throw new Error(`Unsupported binding type: ${binding.type}`);
    }
  }
  function configureClassMigration(
    binding: DurableObjectNamespace | Workflow,
    stableId: string,
    className: string,
  ) {
    const oldBinding: DurableObjectNamespace | Workflow | undefined =
      Object.values(oldBindings ?? {})
        ?.filter(
          (b) =>
            typeof b === "object" &&
            (b.type === "durable_object_namespace" || b.type === "workflow"),
        )
        ?.find((b) => b.id === stableId);
    if (!oldBinding) {
      if (binding.type === "durable_object_namespace" && binding.sqlite) {
        meta.migrations!.new_sqlite_classes!.push(className);
      } else {
        meta.migrations!.new_classes!.push(className);
      }
    } else if (oldBinding.className !== className) {
      meta.migrations!.renamed_classes!.push({
        from: oldBinding.className,
        to: className,
      });
    }
  }
  // Convert env variables to plain_text bindings
  // TODO(sam): remove Worker.env in favor of always bindings
  if (props.env) {
    for (const [key, value] of Object.entries(props.env)) {
      meta.bindings.push({
        name: key,
        type: "plain_text",
        text: value,
      });
    }
  }
  // Determine if we're using ESM or service worker format
  const isEsModule = props.format !== "cjs"; // Default to ESM unless CJS is specified
  const scriptName = isEsModule ? "worker.js" : "script";
  if (isEsModule) {
    // For ES modules format
    meta.main_module = scriptName;
  } else {
    // For service worker format (CJS)
    meta.body_part = scriptName;
  }
  if (process.env.DEBUG) {
    console.log(meta);
  }
  return meta;
}
async function assertWorkerDoesNotExist<B extends Bindings>(
  ctx: Context<Worker<B>>,
  api: CloudflareApi,
  workerName: string,
) {
  const response = await api.get(
    `/accounts/${api.accountId}/workers/scripts/${workerName}`,
  );
  if (response.status === 404) {
    return true;
  }
  if (response.status === 200) {
    const metadata = await getWorkerScriptMetadata(api, workerName);
    if (!metadata) {
      throw new Error(
        `Worker exists but failed to fetch metadata: ${response.status} ${response.statusText}`,
      );
    }
    if (
      metadata.default_environment?.script.tags.includes(
        `alchemy:id:${slugify(ctx.fqn)}`,
      )
    ) {
      return true;
    }
    throw new Error(
      `Worker with name '${workerName}' already exists. Please use a unique name.`,
    );
  }
  throw new Error(
    `Error checking if worker exists: ${response.status} ${response.statusText} ${await response.text()}`,
  );
}
async function configureURL<B extends Bindings>(
  ctx: Context<Worker<B>>,
  api: CloudflareApi,
  workerName: string,
  url: boolean,
) {
  let workerUrl;
  if (url) {
    // Enable the workers.dev subdomain for this worker
    await api.post(
      `/accounts/${api.accountId}/workers/scripts/${workerName}/subdomain`,
      { enabled: true, previews_enabled: true },
      {
        headers: { "Content-Type": "application/json" },
      },
    );
    // Get the account's workers.dev subdomain
    const subdomainResponse = await api.get(
      `/accounts/${api.accountId}/workers/subdomain`,
    );
    if (!subdomainResponse.ok) {
      throw new Error(
        `Could not fetch workers.dev subdomain: ${subdomainResponse.status} ${subdomainResponse.statusText}`,
      );
    }
    const subdomainData: {
      result: {
        subdomain: string;
      };
    } = await subdomainResponse.json();
    const subdomain = subdomainData.result?.subdomain;
    if (subdomain) {
      workerUrl = `https://${workerName}.${subdomain}.workers.dev`;
      // Add a delay when the subdomain is first created.
      // This is to prevent an issue where a negative cache-hit
      // causes the subdomain to be unavailable for 30 seconds.
      if (ctx.phase === "create" || !ctx.output?.url) {
        await new Promise((resolve) => setTimeout(resolve, 3000));
      }
    }
  } else if (url === false && ctx.output?.url) {
    // Explicitly disable URL if it was previously enabled
    const response = await api.post(
      `/accounts/${api.accountId}/workers/scripts/${workerName}/subdomain`,
      JSON.stringify({ enabled: false }),
      {
        headers: { "Content-Type": "application/json" },
      },
    );
    if (!response.ok) {
      throw new Error(
        `Failed to disable worker URL: ${response.status} ${response.statusText}`,
      );
    }
  }
  return workerUrl;
}
async function getWorkerScriptMetadata(
  api: CloudflareApi,
  workerName: string,
): Promise<WorkerScriptMetadata | undefined> {
  const response = await api.get(
    `/accounts/${api.accountId}/workers/services/${workerName}`,
  );
  if (response.status === 404) {
    return undefined;
  }
  if (!response.ok) {
    throw new Error(
      `Error getting worker script metadata: ${response.status} ${response.statusText}`,
    );
  }
  return ((await response.json()) as any).result as WorkerScriptMetadata;
}
async function getWorkerBindings(
  api: CloudflareApi,
  workerName: string,
  environment = "production",
) {
  const response = await api.get(
    `/accounts/${api.accountId}/workers/services/${workerName}/environments/${environment}/bindings`,
    {
      headers: {
        Authorization: `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`,
        "Content-Type": "application/json",
      },
    },
  );
  if (response.status === 404) {
    return undefined;
  }
  if (!response.ok) {
    throw new Error(
      `Failed to fetch bindings: ${response.status} ${response.statusText}`,
    );
  }
  const data: any = await response.json();
  return data.result;
}
/**
 * Interface for a file's metadata to be uploaded
 */
interface FileMetadata {
  hash: string;
  size: number;
}
/**
 * Response from the assets upload session API
 */
interface UploadSessionResponse {
  result: {
    jwt: string;
    buckets: string[][];
  };
  success: boolean;
  errors: any[];
  messages: any[];
}
/**
 * Response from the file upload API
 */
interface UploadResponse {
  result: {
    jwt: string;
    buckets?: string[][];
  };
  success: boolean;
  errors: any[];
  messages: any[];
}
/**
 * Uploads assets to Cloudflare and returns a completion token
 *
 * @param api CloudflareApi instance
 * @param workerName Name of the worker
 * @param assets Assets resource containing files to upload
 * @param assetConfig Configuration for the assets
 * @returns Completion token for the assets upload
 */
async function uploadAssets(
  api: CloudflareApi,
  workerName: string,
  assets: Assets,
  assetConfig?: WorkerProps["assets"],
): Promise<AssetUploadResult> {
  // Process the assets configuration once at the beginning
  const processedConfig = createAssetConfig(assetConfig);
  // Generate the file manifest
  const fileMetadata: Record<string, FileMetadata> = {};
  // Process each file in the assets
  for (const file of assets.files) {
    const { hash, size } = await calculateFileMetadata(file.filePath);
    // Use the relative path as the key, ensuring it starts with a slash
    const key = file.path.startsWith("/") ? file.path : `/${file.path}`;
    fileMetadata[key] = { hash, size };
  }
  // Start the upload session
  const uploadSessionUrl = `/accounts/${api.accountId}/workers/scripts/${workerName}/assets-upload-session`;
  const uploadSessionResponse = await api.post(
    uploadSessionUrl,
    JSON.stringify({ manifest: fileMetadata }),
    {
      headers: { "Content-Type": "application/json" },
    },
  );
  if (!uploadSessionResponse.ok) {
    throw new Error(
      `Failed to start assets upload session: ${uploadSessionResponse.status} ${uploadSessionResponse.statusText}`,
    );
  }
  const sessionData =
    (await uploadSessionResponse.json()) as UploadSessionResponse;
  // If there are no buckets, assets are already uploaded or empty
  if (!sessionData.result.buckets || sessionData.result.buckets.length === 0) {
    return {
      completionToken: sessionData.result.jwt,
      assetConfig: processedConfig,
    };
  }
  // Upload the files in batches as specified by the API
  let completionToken = sessionData.result.jwt;
  const buckets = sessionData.result.buckets;
  // Process each bucket of files
  for (const bucket of buckets) {
    const formData = new FormData();
    let totalBytes = 0;
    // Add each file in the bucket to the form
    for (const fileHash of bucket) {
      // Find the file with this hash
      const file = assets.files.find((f) => {
        const filePath = f.path.startsWith("/") ? f.path : `/${f.path}`;
        return fileMetadata[filePath]?.hash === fileHash;
      });
      if (!file) {
        throw new Error(`Could not find file with hash ${fileHash}`);
      }
      // Read the file content
      const fileContent = await fs.readFile(file.filePath);
      // Convert to base64 as required by the API when using base64=true
      const base64Content = fileContent.toString("base64");
      // Add the file to the form with the hash as the key and set the correct content type
      const blob = new Blob([base64Content], {
        type: getContentType(file.filePath),
      });
      totalBytes += blob.size;
      formData.append(fileHash, blob, fileHash);
    }
    // Upload this batch of files
    const uploadResponse = await api.post(
      `/accounts/${api.accountId}/workers/assets/upload?base64=true`,
      formData,
      {
        headers: {
          Authorization: `Bearer ${completionToken}`,
          "Content-Type": "multipart/form-data",
        },
      },
    );
    if (!uploadResponse.ok) {
      throw new Error(
        `Failed to upload asset files: ${uploadResponse.status} ${uploadResponse.statusText}`,
      );
    }
    const uploadData = (await uploadResponse.json()) as UploadResponse;
    // Update the completion token for the next batch
    if (uploadData.result.jwt) {
      completionToken = uploadData.result.jwt;
    }
  }
  // Return the final completion token with asset configuration
  return {
    completionToken,
    assetConfig: processedConfig,
  };
}
/**
 * Calculate the SHA-256 hash and size of a file
 *
 * @param filePath Path to the file
 * @returns Hash (first 32 chars of SHA-256) and size of the file
 */
async function calculateFileMetadata(
  filePath: string,
): Promise<{ hash: string; size: number }> {
  const hash = crypto.createHash("sha256");
  const fileContent = await fs.readFile(filePath);
  hash.update(fileContent);
  const fileHash = hash.digest("hex").substring(0, 32); // First 32 chars of hash
  return {
    hash: fileHash,
    size: fileContent.length,
  };
}
/**
 * Lists and deletes all queue consumers for a specific worker
 * @param ctx Worker context containing eventSources
 * @param api CloudflareApi instance
 * @param workerName Name of the worker script
 */
async function deleteQueueConsumers<B extends Bindings>(
  ctx: Context<Worker<B>>,
  api: CloudflareApi,
  workerName: string,
): Promise<void> {
  const eventSources = ctx.output?.eventSources || [];
  // Extract queue IDs from event sources
  const queueIds = eventSources.flatMap((eventSource) => {
    if (isQueue(eventSource)) {
      return [eventSource.id];
    }
    if (isQueueEventSource(eventSource)) {
      return [eventSource.queue.id];
    }
    return [];
  });
  // Process each queue associated with this worker
  await Promise.all(
    queueIds.map(async (queueId) => {
      try {
        // List all consumers for this queue
        const consumers = await listQueueConsumers(api, queueId);
        // Filter consumers by worker name
        const workerConsumers = consumers.filter(
          (consumer) => consumer.scriptName === workerName,
        );
        // Delete all consumers for this worker in parallel
        await Promise.all(
          workerConsumers.map(async (consumer) => {
            console.log(
              `Deleting queue consumer ${consumer.id} for worker ${workerName}`,
            );
            // Use the deleteQueueConsumer function from queue-consumer.ts
            await deleteQueueConsumer(api, consumer.queueId, consumer.id);
          }),
        );
      } catch (err) {
        if (err instanceof CloudflareApiError && err.status === 404) {
          // this is OK
        } else {
          throw err;
        }
      }
    }),
  );
}
</file>

<file path="alchemy/src/cloudflare/workflow.ts">
import { handleApiError } from "./api-error.js";
import type { CloudflareApi } from "./api.js";
export interface WorkflowProps {
  /**
   * Name of the workflow
   *
   * @maxLength 64
   * @minLength 1
   * @default - className if provided, otherwise id
   */
  workflowName?: string;
  /**
   * Name of the class that implements the workflow
   *
   * @maxLength 255
   * @minLength 1
   * @default - workflowName if provided, otherwise id
   */
  className?: string;
}
export class Workflow<PARAMS = unknown> {
  public readonly type = "workflow";
  /**
   * Phantom property to preserve workflow params at the type level.
   *
   * No value exists.
   */
  public readonly _PARAMS: PARAMS = undefined!;
  public readonly workflowName: string;
  public readonly className: string;
  constructor(
    public readonly id: string,
    props: WorkflowProps = {},
  ) {
    this.workflowName = props.workflowName ?? props.className ?? id;
    this.className = props.className ?? this.workflowName;
  }
}
export interface WorkflowMetadata {
  id: string; // uuid
  class_name: string;
  created_on: string; // date-time
  modified_on: string; // date-time
  name: string; // maxLength: 64, minLength: 1
  script_name: string;
  triggered_on: string; // date-time
  version_id: string; // uuid
}
export async function upsertWorkflow(
  api: CloudflareApi,
  props: WorkflowProps & {
    workflowName: string;
    scriptName: string;
  },
) {
  const response = await api.put(
    `/accounts/${api.accountId}/workflows/${props.workflowName}`,
    {
      class_name: props.className,
      script_name: props.scriptName,
    },
  );
  if (!response.ok) {
    await handleApiError(response, "create", "workflow", props.workflowName);
  }
  const body = (await response.json()) as {
    result: WorkflowMetadata;
  };
  return body.result;
}
</file>

<file path="alchemy/src/cloudflare/zone-settings.ts">
/**
 * Common response fields for all settings
 */
export interface CloudflareSettingBase {
  /**
   * The identifier of the setting
   */
  id: string;
  /**
   * When the setting was last modified
   */
  modified_on: string | null;
  /**
   * Whether the setting can be modified
   */
  editable: boolean;
}
/**
 * Value types for each setting
 */
export type SSLValue = "off" | "flexible" | "full" | "strict";
export type MinTLSVersionValue = "1.0" | "1.1" | "1.2" | "1.3";
export type TLS13Value = "on" | "off" | "zrt";
export type CacheLevelValue = "aggressive" | "basic" | "simplified";
// Boolean setting values
export type AlwaysUseHTTPSValue = "on" | "off";
export type AutomaticHTTPSRewritesValue = "on" | "off";
export type BrotliValue = "on" | "off";
export type DevelopmentModeValue = "on" | "off";
export type EarlyHintsValue = "on" | "off";
export type EmailObfuscationValue = "on" | "off";
export type HotlinkProtectionValue = "on" | "off";
export type HTTP2Value = "on" | "off";
export type HTTP3Value = "on" | "off";
export type IPv6Value = "on" | "off";
export type WebSocketsValue = "on" | "off";
export type ZeroRTTValue = "on" | "off";
/**
 * Common response fields for boolean settings that use "on"/"off"
 */
export interface CloudflareBooleanSetting extends CloudflareSettingBase {
  /**
   * The value of the setting
   */
  value: "on" | "off";
}
/**
 * Advanced DDoS protection setting
 * @see https://developers.cloudflare.com/api/resources/zones/#advanced-ddos
 */
export interface AdvancedDDoSSetting extends CloudflareBooleanSetting {
  id: "advanced_ddos";
  value: "on" | "off";
}
/**
 * Always Online setting
 * When enabled, Cloudflare serves limited copies of web pages from the Internet Archive if your server is offline
 */
export interface AlwaysOnlineSetting extends CloudflareBooleanSetting {
  id: "always_online";
  value: "on" | "off";
}
/**
 * Always Use HTTPS setting
 * Redirects all HTTP traffic to HTTPS
 */
export interface AlwaysUseHTTPSSetting extends CloudflareSettingBase {
  id: "always_use_https";
  value: AlwaysUseHTTPSValue;
}
/**
 * Automatic HTTPS Rewrites setting
 * Automatically rewrites HTTP URLs to HTTPS
 */
export interface AutomaticHTTPSRewritesSetting extends CloudflareSettingBase {
  id: "automatic_https_rewrites";
  value: AutomaticHTTPSRewritesValue;
}
/**
 * Automatic Platform Optimization setting
 */
export interface AutomaticPlatformOptimizationSetting
  extends CloudflareSettingBase {
  id: "automatic_platform_optimization";
  value: {
    enabled: boolean;
    cf: boolean;
    wordpress: boolean;
    wordpress_plugin: boolean;
    cache_by_device_type: boolean;
  };
}
/**
 * Brotli compression setting
 */
export interface BrotliSetting extends CloudflareSettingBase {
  id: "brotli";
  value: BrotliValue;
}
/**
 * Browser Cache TTL setting
 */
export interface BrowserCacheTTLSetting extends CloudflareSettingBase {
  id: "browser_cache_ttl";
  value: number;
}
/**
 * Browser Check setting
 */
export interface BrowserCheckSetting extends CloudflareSettingBase {
  id: "browser_check";
  value: "on" | "off";
}
/**
 * Cache Level setting
 */
export interface CacheLevelSetting extends CloudflareSettingBase {
  id: "cache_level";
  value: CacheLevelValue;
}
/**
 * Challenge TTL setting
 */
export interface ChallengeTTLSetting extends CloudflareSettingBase {
  id: "challenge_ttl";
  value: number;
}
/**
 * Ciphers setting
 */
export interface CiphersSetting extends CloudflareSettingBase {
  id: "ciphers";
  value: string[];
}
/**
 * Development Mode setting
 */
export interface DevelopmentModeSetting extends CloudflareSettingBase {
  id: "development_mode";
  value: DevelopmentModeValue;
}
/**
 * Early Hints setting
 */
export interface EarlyHintsSetting extends CloudflareSettingBase {
  id: "early_hints";
  value: EarlyHintsValue;
}
/**
 * Email Obfuscation setting
 */
export interface EmailObfuscationSetting extends CloudflareSettingBase {
  id: "email_obfuscation";
  value: EmailObfuscationValue;
}
/**
 * Hotlink Protection setting
 */
export interface HotlinkProtectionSetting extends CloudflareSettingBase {
  id: "hotlink_protection";
  value: HotlinkProtectionValue;
}
/**
 * HTTP/2 setting
 */
export interface HTTP2Setting extends CloudflareSettingBase {
  id: "http2";
  value: HTTP2Value;
}
/**
 * HTTP/3 setting
 */
export interface HTTP3Setting extends CloudflareSettingBase {
  id: "http3";
  value: HTTP3Value;
}
/**
 * IP Geolocation setting
 */
export interface IPGeolocationSetting extends CloudflareSettingBase {
  id: "ip_geolocation";
  value: "on" | "off";
}
/**
 * IPv6 setting
 */
export interface IPv6Setting extends CloudflareSettingBase {
  id: "ipv6";
  value: IPv6Value;
}
/**
 * Minimum TLS Version setting
 */
export interface MinTLSVersionSetting extends CloudflareSettingBase {
  id: "min_tls_version";
  value: MinTLSVersionValue;
}
/**
 * Opportunistic Encryption setting
 */
export interface OpportunisticEncryptionSetting extends CloudflareSettingBase {
  id: "opportunistic_encryption";
  value: "on" | "off";
}
/**
 * SSL setting
 */
export interface SSLSetting extends CloudflareSettingBase {
  id: "ssl";
  value: SSLValue;
  certificate_status?: string;
  validation_errors?: Array<{
    message: string;
  }>;
}
/**
 * TLS 1.3 setting
 */
export interface TLS13Setting extends CloudflareSettingBase {
  id: "tls_1_3";
  value: TLS13Value;
}
/**
 * WebSockets setting
 */
export interface WebSocketsSetting extends CloudflareSettingBase {
  id: "websockets";
  value: WebSocketsValue;
}
/**
 * Zero-RTT setting
 */
export interface ZeroRTTSetting extends CloudflareSettingBase {
  id: "0rtt";
  value: ZeroRTTValue;
}
/**
 * All possible zone settings
 */
export type CloudflareZoneSetting =
  | AdvancedDDoSSetting
  | AlwaysOnlineSetting
  | AlwaysUseHTTPSSetting
  | AutomaticHTTPSRewritesSetting
  | AutomaticPlatformOptimizationSetting
  | BrotliSetting
  | BrowserCacheTTLSetting
  | BrowserCheckSetting
  | CacheLevelSetting
  | ChallengeTTLSetting
  | CiphersSetting
  | DevelopmentModeSetting
  | EarlyHintsSetting
  | EmailObfuscationSetting
  | HotlinkProtectionSetting
  | HTTP2Setting
  | HTTP3Setting
  | IPGeolocationSetting
  | IPv6Setting
  | MinTLSVersionSetting
  | OpportunisticEncryptionSetting
  | SSLSetting
  | TLS13Setting
  | WebSocketsSetting
  | ZeroRTTSetting;
/**
 * Input for updating a zone setting
 */
export interface UpdateZoneSettingParams {
  /**
   * The value to set
   */
  value: CloudflareZoneSetting["value"];
}
/**
 * Response for zone settings operations
 */
export interface CloudflareZoneSettingResponse {
  /**
   * Whether the API call was successful
   */
  success: boolean;
  /**
   * Any error messages
   */
  errors: Array<{
    code: number;
    message: string;
  }>;
  /**
   * Any informational messages
   */
  messages: Array<{
    code: number;
    message: string;
  }>;
  /**
   * The settings that were operated on
   */
  result: CloudflareZoneSetting[];
}
/**
 * Response for a single zone setting operation
 */
export interface CloudflareZoneSettingSingleResponse {
  /**
   * Whether the API call was successful
   */
  success: boolean;
  /**
   * Any error messages
   */
  errors: Array<{
    code: number;
    message: string;
  }>;
  /**
   * Any informational messages
   */
  messages: Array<{
    code: number;
    message: string;
  }>;
  /**
   * The setting that was operated on
   */
  result: CloudflareZoneSetting;
}
</file>

<file path="alchemy/src/cloudflare/zone.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { handleApiError } from "./api-error.js";
import { createCloudflareApi, type CloudflareApiOptions } from "./api.js";
import type {
  AlwaysUseHTTPSValue,
  AutomaticHTTPSRewritesValue,
  BrotliValue,
  CloudflareZoneSettingResponse,
  DevelopmentModeValue,
  EarlyHintsValue,
  EmailObfuscationValue,
  HTTP2Value,
  HTTP3Value,
  HotlinkProtectionValue,
  IPv6Value,
  MinTLSVersionValue,
  SSLValue,
  TLS13Value,
  UpdateZoneSettingParams,
  WebSocketsValue,
  ZeroRTTValue,
} from "./zone-settings.js";
/**
 * Properties for creating or updating a Zone
 */
export interface ZoneProps extends CloudflareApiOptions {
  /**
   * The domain name for the zone
   */
  name: string;
  /**
   * Whether to delete the zone
   * @default false
   */
  delete?: boolean;
  /**
   * The type of zone to create
   * "full" - Full zone implies that DNS is hosted with Cloudflare
   * "partial" - Partial zone is typically a partner-hosted zone or a CNAME setup
   * "secondary" - Secondary zone is a zone that mirrors the primary zone
   * @default "full"
   */
  type?: "full" | "partial" | "secondary";
  /**
   * Whether to jump start the zone
   * When enabled, Cloudflare will attempt to fetch existing DNS records
   * @default true
   */
  jumpStart?: boolean;
  /**
   * Settings to apply to the zone
   */
  settings?: {
    /**
     * Enable SSL/TLS encryption for the zone
     * "off" - SSL disabled
     * "flexible" - Encrypts traffic between browser and Cloudflare
     * "full" - Encrypts traffic between browser and server, allows self-signed certs
     * "strict" - Encrypts traffic between browser and server, requires valid cert
     */
    ssl?: SSLValue;
    /**
     * Enable Always Use HTTPS
     * Redirects all HTTP traffic to HTTPS
     * @default "off"
     */
    alwaysUseHttps?: AlwaysUseHTTPSValue;
    /**
     * Enable Automatic HTTPS Rewrites
     * Automatically rewrites HTTP URLs to HTTPS
     * @default "off"
     */
    automaticHttpsRewrites?: AutomaticHTTPSRewritesValue;
    /**
     * Enable TLS 1.3
     * Enables the latest version of TLS encryption
     * @default "off"
     */
    tls13?: TLS13Value;
    /**
     * Enable Early Hints
     * Speeds up page loads by serving Link headers
     * @default "off"
     */
    earlyHints?: EarlyHintsValue;
    /**
     * Enable Email Obfuscation
     * Obfuscates email addresses on the site
     * @default "off"
     */
    emailObfuscation?: EmailObfuscationValue;
    /**
     * Enable Browser Cache TTL
     * Sets the browser cache TTL in seconds
     */
    browserCacheTtl?: number;
    /**
     * Enable Development Mode
     * Disables caching and enables real-time updates
     * @default "off"
     */
    developmentMode?: DevelopmentModeValue;
    /**
     * Enable HTTP/2
     * @default "on"
     */
    http2?: HTTP2Value;
    /**
     * Enable HTTP/3
     * @default "on"
     */
    http3?: HTTP3Value;
    /**
     * Enable IPv6
     * @default "on"
     */
    ipv6?: IPv6Value;
    /**
     * Enable WebSockets
     * @default "on"
     */
    websockets?: WebSocketsValue;
    /**
     * Enable Zero-RTT
     * @default "off"
     */
    zeroRtt?: ZeroRTTValue;
    /**
     * Enable Brotli compression
     * @default "on"
     */
    brotli?: BrotliValue;
    /**
     * Enable Hotlink Protection
     * @default "off"
     */
    hotlinkProtection?: HotlinkProtectionValue;
    /**
     * Minimum TLS Version
     * @default "1.0"
     */
    minTlsVersion?: MinTLSVersionValue;
  };
}
/**
 * Output returned after Zone creation/update
 */
export interface Zone extends Resource<"cloudflare::Zone"> {
  /**
   * The ID of the zone
   */
  id: string;
  /**
   * The domain name for the zone
   */
  name: string;
  /**
   * The type of zone
   */
  type: "full" | "partial" | "secondary";
  /**
   * The status of the zone
   */
  status: string;
  /**
   * Whether the zone is paused
   */
  paused: boolean;
  /**
   * The account ID the zone belongs to
   */
  accountId: string;
  /**
   * The nameservers assigned to the zone
   */
  nameservers: string[];
  /**
   * The original nameservers for the zone
   */
  originalNameservers: string[] | null;
  /**
   * Time at which the zone was created
   */
  createdAt: number;
  /**
   * Time at which the zone was last modified
   */
  modifiedAt: number;
  /**
   * Time at which the zone was activated
   */
  activatedAt: number | null;
  /**
   * The zone's current settings
   */
  settings: {
    ssl: SSLValue;
    alwaysUseHttps: AlwaysUseHTTPSValue;
    automaticHttpsRewrites: AutomaticHTTPSRewritesValue;
    tls13: TLS13Value;
    earlyHints: EarlyHintsValue;
    emailObfuscation: EmailObfuscationValue;
    browserCacheTtl: number;
    developmentMode: DevelopmentModeValue;
    http2: HTTP2Value;
    http3: HTTP3Value;
    ipv6: IPv6Value;
    websockets: WebSocketsValue;
    zeroRtt: ZeroRTTValue;
    brotli: BrotliValue;
    hotlinkProtection: HotlinkProtectionValue;
    minTlsVersion: MinTLSVersionValue;
  };
}
/**
 * A Cloudflare Zone represents a domain and its configuration settings on Cloudflare.
 * Zones allow you to manage DNS, SSL/TLS, caching, security and other settings for a domain.
 *
 * @example
 * // Create a basic zone with default settings
 * const basicZone = await Zone("example.com", {
 *   name: "example.com",
 *   type: "full",
 *   jumpStart: true
 * });
 *
 * @example
 * // Create a zone with enhanced security settings
 * const secureZone = await Zone("secure.example.com", {
 *   name: "secure.example.com",
 *   type: "full",
 *   settings: {
 *     ssl: "strict",
 *     alwaysUseHttps: "on",
 *     automaticHttpsRewrites: "on",
 *     minTlsVersion: "1.3",
 *     tls13: "zrt"
 *   }
 * });
 *
 * @example
 * // Create a zone with optimized performance settings
 * const fastZone = await Zone("fast.example.com", {
 *   name: "fast.example.com",
 *   settings: {
 *     browserCacheTtl: 7200,
 *     brotli: "on",
 *     zeroRtt: "on",
 *     http2: "on",
 *     http3: "on",
 *     earlyHints: "on"
 *   }
 * });
 *
 * @example
 * // Create a development zone with specific features
 * const devZone = await Zone("dev.example.com", {
 *   name: "dev.example.com",
 *   settings: {
 *     developmentMode: "on",
 *     emailObfuscation: "on",
 *     hotlinkProtection: "on",
 *     ipv6: "on",
 *     websockets: "on"
 *   }
 * });
 *
 * @see https://developers.cloudflare.com/dns/zone-setups/
 */
export const Zone = Resource(
  "cloudflare::Zone",
  async function (
    this: Context<Zone>,
    id: string,
    props: ZoneProps,
  ): Promise<Zone> {
    // Create Cloudflare API client with automatic account discovery
    const api = await createCloudflareApi(props);
    if (this.phase === "delete") {
      if (this.output?.id && props.delete !== false) {
        const deleteResponse = await api.delete(`/zones/${this.output.id}`);
        if (!deleteResponse.ok && deleteResponse.status !== 404) {
          await handleApiError(
            deleteResponse,
            "delete",
            "zone",
            this.output.id,
          );
        }
      } else {
        console.warn(`Zone '${props.name}' not found, skipping delete`);
      }
      return this.destroy();
    }
    if (this.phase === "update" && this.output?.id) {
      // Get zone details to verify it exists
      const response = await api.get(`/zones/${this.output.id}`);
      if (!response.ok) {
        throw new Error(
          `Error getting zone '${props.name}': ${response.statusText}`,
        );
      }
      const zoneData = ((await response.json()) as { result: CloudflareZone })
        .result;
      // Update zone settings if provided
      if (props.settings) {
        await updateZoneSettings(api, this.output.id, props.settings);
        // Add a small delay to ensure settings are propagated
        await new Promise((resolve) => setTimeout(resolve, 2000));
      }
      return this({
        id: zoneData.id,
        name: zoneData.name,
        type: zoneData.type,
        status: zoneData.status,
        paused: zoneData.paused,
        accountId: zoneData.account.id,
        nameservers: zoneData.name_servers,
        originalNameservers: zoneData.original_name_servers,
        createdAt: new Date(zoneData.created_on).getTime(),
        modifiedAt: new Date(zoneData.modified_on).getTime(),
        activatedAt: zoneData.activated_on
          ? new Date(zoneData.activated_on).getTime()
          : null,
        settings: await getZoneSettings(api, zoneData.id),
      });
    }
    // Create new zone
    const response = await api.post("/zones", {
      name: props.name,
      type: props.type || "full",
      jump_start: props.jumpStart !== false,
      account: {
        id: api.accountId,
      },
    });
    const body = await response.text();
    let zoneData;
    if (!response.ok) {
      if (response.status === 400 && body.includes("already exists")) {
        // Zone already exists, fetch it instead
        console.warn(
          `Zone '${props.name}' already exists during Zone create, adopting it...`,
        );
        const getResponse = await api.get(`/zones?name=${props.name}`);
        if (!getResponse.ok) {
          throw new Error(
            `Error fetching existing zone '${props.name}': ${getResponse.statusText}`,
          );
        }
        const zones = (
          (await getResponse.json()) as { result: CloudflareZone[] }
        ).result;
        if (zones.length === 0) {
          throw new Error(
            `Zone '${props.name}' does not exist, but the name is reserved for another user.`,
          );
        }
        zoneData = zones[0];
      } else {
        throw new Error(
          `Error creating zone '${props.name}': ${response.statusText}\n${body}`,
        );
      }
    } else {
      zoneData = (JSON.parse(body) as { result: CloudflareZone }).result;
    }
    // Update zone settings if provided
    if (props.settings) {
      await updateZoneSettings(api, zoneData.id, props.settings);
      // Add a small delay to ensure settings are propagated
      await new Promise((resolve) => setTimeout(resolve, 2000));
    }
    return this({
      id: zoneData.id,
      name: zoneData.name,
      type: zoneData.type,
      status: zoneData.status,
      paused: zoneData.paused,
      accountId: zoneData.account.id,
      nameservers: zoneData.name_servers,
      originalNameservers: zoneData.original_name_servers,
      createdAt: new Date(zoneData.created_on).getTime(),
      modifiedAt: new Date(zoneData.modified_on).getTime(),
      activatedAt: zoneData.activated_on
        ? new Date(zoneData.activated_on).getTime()
        : null,
      settings: await getZoneSettings(api, zoneData.id),
    });
  },
);
/**
 * Helper function to update zone settings
 */
async function updateZoneSettings(
  api: any,
  zoneId: string,
  settings: ZoneProps["settings"],
): Promise<void> {
  if (!settings) return;
  const settingsMap = {
    ssl: "ssl",
    alwaysUseHttps: "always_use_https",
    automaticHttpsRewrites: "automatic_https_rewrites",
    tls13: "tls_1_3",
    earlyHints: "early_hints",
    emailObfuscation: "email_obfuscation",
    browserCacheTtl: "browser_cache_ttl",
    developmentMode: "development_mode",
    http2: "http2",
    http3: "http3",
    ipv6: "ipv6",
    websockets: "websockets",
    zeroRtt: "0rtt",
    brotli: "brotli",
    hotlinkProtection: "hotlink_protection",
    minTlsVersion: "min_tls_version",
  };
  await Promise.all(
    Object.entries(settings)
      .filter(([_, value]) => value !== undefined)
      .map(async ([key, value]) => {
        const settingId = settingsMap[key as keyof typeof settings];
        if (!settingId) return;
        const response = await api.patch(
          `/zones/${zoneId}/settings/${settingId}`,
          {
            value,
          } as UpdateZoneSettingParams,
        );
        if (!response.ok) {
          const data = await response.text();
          if (response.status === 400 && data.includes("already enabled")) {
            console.warn(`Warning: Setting '${key}' already enabled`);
            return;
          }
          throw new Error(
            `Failed to update zone setting ${key}: ${response.statusText}`,
          );
        }
      }),
  );
}
/**
 * Helper function to get current zone settings
 */
async function getZoneSettings(
  api: any,
  zoneId: string,
): Promise<Zone["settings"]> {
  const settingsResponse = await api.get(`/zones/${zoneId}/settings`);
  if (!settingsResponse.ok) {
    throw new Error(
      `Failed to fetch zone settings: ${settingsResponse.status} ${settingsResponse.statusText}`,
    );
  }
  const result =
    (await settingsResponse.json()) as CloudflareZoneSettingResponse;
  const settingsData = result.result;
  // Helper to get setting value with default
  const getSetting = <T>(id: string, defaultValue: T): T => {
    const setting = settingsData.find((s: any) => s.id === id);
    return (setting?.value as T) ?? defaultValue;
  };
  return {
    ssl: getSetting("ssl", "off"),
    alwaysUseHttps: getSetting("always_use_https", "off"),
    automaticHttpsRewrites: getSetting("automatic_https_rewrites", "off"),
    tls13: getSetting("tls_1_3", "off"),
    earlyHints: getSetting("early_hints", "off"),
    emailObfuscation: getSetting("email_obfuscation", "off"),
    browserCacheTtl: getSetting("browser_cache_ttl", 14400),
    developmentMode: getSetting("development_mode", "off"),
    http2: getSetting("http2", "on"),
    http3: getSetting("http3", "on"),
    ipv6: getSetting("ipv6", "on"),
    websockets: getSetting("websockets", "on"),
    zeroRtt: getSetting("0rtt", "off"),
    brotli: getSetting("brotli", "on"),
    hotlinkProtection: getSetting("hotlink_protection", "off"),
    minTlsVersion: getSetting("min_tls_version", "1.0"),
  };
}
/**
 * Cloudflare Zone response format
 */
export interface CloudflareZone {
  id: string;
  name: string;
  type: "full" | "partial" | "secondary";
  status: string;
  paused: boolean;
  account: {
    id: string;
  };
  name_servers: string[];
  original_name_servers: string[] | null;
  created_on: string;
  modified_on: string;
  activated_on: string | null;
}
</file>

<file path="alchemy/src/dns/godaddy.ts">
export type UpdateNameserversOptions = {
  domain: string;
  apiKey: string;
  apiSecret: string;
  nameservers: string[];
};
export async function updateNameservers(options: UpdateNameserversOptions) {
  const url = `https://api.godaddy.com/v1/domains/${options.domain}/nameservers`;
  const response = await fetch(url, {
    method: "PUT",
    headers: {
      Authorization: `sso-key ${options.apiKey}:${options.apiSecret}`,
      "Content-Type": "application/json",
      Accept: "application/json",
    },
    body: JSON.stringify({
      nameservers: options.nameservers,
    }),
  });
  if (response.ok) {
    console.log(` Nameservers updated for ${options.domain}`);
  } else {
    const error = await response.json();
    console.error(" Failed to update nameservers:", error);
  }
}
</file>

<file path="alchemy/src/dns/import-dns.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { DEFAULT_RECORD_TYPES, type DnsRecordType } from "./record.js";
/**
 * DNS record response structure from Cloudflare DNS API
 * with both data (original) and content (for compatibility)
 */
export interface DnsApiRecord {
  name: string;
  type: DnsRecordType;
  TTL: number;
  data: string;
  content: string; // Added for compatibility with DnsRecords
  ttl: number; // Normalized ttl (lowercase)
  priority?: number; // Priority for MX and SRV records
}
/**
 * Cloudflare DNS-over-HTTPS API response structure
 */
interface CloudflareDNSResponse {
  Status: number;
  TC: boolean;
  RD: boolean;
  RA: boolean;
  AD: boolean;
  CD: boolean;
  Question: Array<{
    name: string;
    type: number;
  }>;
  Answer?: {
    name: string;
    type: number;
    TTL: number;
    data: string;
  }[];
}
/**
 * Properties for importing DNS records
 */
export interface ImportDnsRecordsProps {
  /**
   * The domain to fetch DNS records for
   */
  domain: string;
  /**
   * Specific record types to fetch. If not provided, defaults to all supported types.
   */
  recordTypes?: DnsRecordType[];
  /**
   * Bump the resource to force a new import
   */
  bump?: number;
}
/**
 * Output returned after DNS records import
 */
export interface ImportDnsRecords
  extends Resource<"dns::ImportDnsRecords">,
    ImportDnsRecordsProps {
  /**
   * The DNS records as a flat array, directly compatible with DnsRecords function
   */
  records: DnsApiRecord[];
  /**
   * Time at which the records were imported
   */
  importedAt: number;
}
/**
 * Map numeric DNS record type to string type
 */
function mapDnsRecordType(type: number): DnsRecordType {
  const typeMap: Record<number, DnsRecordType> = {
    1: "A",
    2: "NS",
    5: "CNAME",
    6: "SOA",
    15: "MX",
    16: "TXT",
    28: "AAAA",
    33: "SRV",
    12: "PTR",
  };
  return typeMap[type] || "A";
}
/**
 * Import DNS records for a domain using Cloudflare's DNS-over-HTTPS API.
 * This resource allows you to fetch DNS records for a domain and store them
 * in a structured format.
 *
 * @example
 * // Import all default record types
 * const allRecords = await ImportDnsRecords("example.com", {
 *   domain: "example.com"
 * });
 *
 * @example
 * // Import only specific record types
 * const specificRecords = await ImportDnsRecords("example.com", {
 *   domain: "example.com",
 *   recordTypes: ["A", "MX"]
 * });
 *
 * @example
 * // Import DNS records and transfer them to a Cloudflare zone
 * const dnsRecords = await ImportDnsRecords("dns-records", {
 *   domain: "example.com",
 * });
 *
 * const zone = await Zone("example.com", {
 *   name: "example.com",
 *   type: "full",
 * });
 *
 * // Records are directly compatible with DnsRecords function
 * await DnsRecords("transfer-dns-records", {
 *   zoneId: zone.id,
 *   records: dnsRecords.records,
 * });
 */
export const ImportDnsRecords = Resource(
  "dns::ImportDnsRecords",
  async function (
    this: Context<ImportDnsRecords>,
    id: string,
    props: ImportDnsRecordsProps,
  ): Promise<ImportDnsRecords> {
    // For delete phase, just return destroyed state since this is a read-only resource
    if (this.phase === "delete") {
      return this.destroy();
    }
    const recordTypes = props.recordTypes || DEFAULT_RECORD_TYPES;
    const allRecords: DnsApiRecord[] = [];
    for (const type of recordTypes) {
      try {
        const res = await fetch(
          `https://cloudflare-dns.com/dns-query?name=${props.domain}&type=${type}`,
          {
            headers: {
              accept: "application/dns-json",
            },
          },
        );
        if (!res.ok) {
          throw new Error(`Failed to fetch ${type} records: ${res.statusText}`);
        }
        const data = (await res.json()) as CloudflareDNSResponse;
        if (data.Answer) {
          // Transform records to be compatible with DnsRecords function
          const compatRecords = data.Answer.map((record) => {
            const recordType = mapDnsRecordType(record.type);
            const result: DnsApiRecord = {
              name: record.name,
              type: recordType,
              TTL: record.TTL,
              data: record.data,
              content: record.data, // Default mapping
              ttl: record.TTL, // Normalized lowercase ttl
            };
            // Special handling for MX records to split priority and content
            if (recordType === "MX") {
              const parts = record.data.split(" ");
              if (parts.length >= 2) {
                const priority = Number.parseInt(parts[0], 10);
                // Join the rest as hostname in case there are spaces
                const hostname = parts.slice(1).join(" ");
                if (!Number.isNaN(priority)) {
                  result.priority = priority;
                  result.content = hostname;
                }
              }
            }
            return result;
          });
          allRecords.push(...compatRecords);
        }
      } catch (error) {
        console.warn(
          `Failed to fetch ${type} records for ${props.domain}:`,
          error,
        );
      }
    }
    // Return the resource with fetched records as a flat array
    return this({
      domain: props.domain,
      recordTypes: [...recordTypes],
      records: allRecords,
      importedAt: Date.now(),
    });
  },
);
</file>

<file path="alchemy/src/dns/index.ts">
export * from "./import-dns.js";
export * from "./record.js";
</file>

<file path="alchemy/src/dns/record.ts">
/**
 * DNS record types supported across different providers
 */
export type DnsRecordType =
  | "A"
  | "AAAA"
  | "MX"
  | "TXT"
  | "NS"
  | "CNAME"
  | "SOA"
  | "SRV"
  | "PTR";
/**
 * Default DNS record types to fetch
 */
export const DEFAULT_RECORD_TYPES: readonly DnsRecordType[] = [
  "A",
  "AAAA",
  "MX",
  "TXT",
  "NS",
  "CNAME",
  "SOA",
  "SRV",
] as const;
/**
 * Base DNS record interface with common properties
 */
export interface DnsRecordBase {
  /**
   * DNS record name (e.g., "example.com", "subdomain.example.com")
   */
  name: string;
  /**
   * Record type (A, AAAA, CNAME, etc.)
   */
  type: DnsRecordType;
}
/**
 * DNS record response structure from DNS-over-HTTPS APIs
 */
export interface DohDnsRecord extends DnsRecordBase {
  /**
   * Time To Live in seconds
   */
  TTL: number;
  /**
   * Record data/content (varies by record type)
   */
  data: string;
}
/**
 * Comprehensive DNS record structure for creating/managing records
 */
export interface DnsRecord extends DnsRecordBase {
  /**
   * DNS record content (e.g., IP address, hostname)
   */
  content: string;
  /**
   * Time To Live (TTL) in seconds
   * Setting to 1 means 'automatic'
   * Value must be between 60 and 86400, with minimum reduced to 30 for Enterprise zones
   * @default 1
   */
  ttl?: number;
  /**
   * Whether the record is receiving proxied traffic through Cloudflare
   * @default false
   */
  proxied?: boolean;
  /**
   * Comments or notes about the record
   */
  comment?: string;
  /**
   * Record tags
   */
  tags?: string[];
  /**
   * Priority value for MX/SRV records
   */
  priority?: number;
}
/**
 * DNS record with provider-specific ID and metadata
 */
export interface DnsRecordWithMetadata extends DnsRecord {
  /**
   * Record ID
   */
  id: string;
  /**
   * Zone or domain ID the record belongs to
   */
  zoneId: string;
  /**
   * Time at which the record was created
   */
  createdAt: number;
  /**
   * Time at which the record was last modified
   */
  modifiedAt?: number;
}
</file>

<file path="alchemy/src/esbuild/bundle.ts">
import esbuild from "esbuild";
import crypto from "node:crypto";
import fs from "node:fs/promises";
import path from "node:path";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
/**
 * Properties for creating or updating an esbuild bundle
 */
export interface BundleProps extends Partial<esbuild.BuildOptions> {
  /**
   * Entry point for the bundle
   * Path to the source file to bundle (e.g., "src/handler.ts")
   */
  entryPoint: string;
  /**
   * Output directory for the bundle
   * Directory where the bundled file will be written
   */
  outdir?: string;
  /**
   * Output filename for the bundle
   * Full path to the output file, overrides outdir if specified
   */
  outfile?: string;
  /**
   * Bundle format
   * iife: Immediately Invoked Function Expression
   * cjs: CommonJS
   * esm: ECMAScript Modules
   */
  format?: "iife" | "cjs" | "esm";
  /**
   * Target environment
   * Examples: 'node16', 'node18', 'es2020'
   */
  target?: string | string[];
  /**
   * Whether to minify the output
   */
  minify?: boolean;
  /**
   * Whether to generate sourcemaps
   * inline: Include sourcemap in bundle
   * external: Generate separate .map file
   * both: Generate both inline and external
   */
  sourcemap?: boolean | "inline" | "external" | "both";
  /**
   * External packages to exclude from bundle
   * Array of package names to mark as external
   */
  external?: string[];
  /**
   * Platform to target
   * browser: Browser environment
   * node: Node.js environment
   * neutral: Platform-agnostic
   */
  platform?: "browser" | "node" | "neutral";
  /**
   * Additional esbuild options
   * Any other valid esbuild BuildOptions
   */
  options?: Partial<esbuild.BuildOptions>;
}
/**
 * Output returned after bundle creation/update
 */
export interface Bundle<P extends BundleProps = BundleProps>
  extends Resource<"esbuild::Bundle">,
    BundleProps {
  /**
   * Path to the bundled file
   * Absolute or relative path to the generated bundle
   */
  path: P extends { outdir: string } | { outfile: string } ? string : undefined;
  /**
   * SHA-256 hash of the bundle contents
   * Used for cache busting and content verification
   */
  hash: string;
  /**
   * The content of the bundle (the .js or .mjs file)
   */
  content: string;
}
/**
 * esbuild Bundle Resource
 *
 * Creates and manages bundled JavaScript/TypeScript files using esbuild.
 * Supports various output formats, sourcemaps, and platform targets.
 *
 * @example
 * // Bundle a TypeScript file for Node.js
 * const bundle = await Bundle("handler", {
 *   entryPoint: "src/handler.ts",
 *   outdir: ".alchemy/.out",
 *   format: "esm",
 *   platform: "node",
 *   target: "node18"
 * });
 */
export const Bundle = Resource(
  "esbuild::Bundle",
  {
    alwaysUpdate: true,
  },
  async function <Props extends BundleProps>(
    this: Context<Bundle<any>>,
    id: string,
    props: Props,
  ): Promise<Bundle<Props>> {
    if (this.phase === "delete") {
      if (this.output.path) {
        try {
          await fs.rm(this.output.path, { force: true });
        } catch (error) {
          if (error instanceof Error && error.message.includes("ENOENT")) {
            // File doesn't exist, so we can ignore the error
          } else {
            throw error;
          }
        }
      }
      return this.destroy();
    }
    const result = await bundle(props);
    const bundlePath = Object.entries(result.metafile!.outputs).find(
      ([_, output]) => {
        if (output.entryPoint === undefined) {
          return false;
        }
        // resolve to absolute and then relative to ensure consistent result (e.g. ./src/handler.ts instead of src/handler.ts)
        const relativeOutput = path.relative(
          process.cwd(),
          path.resolve(output.entryPoint),
        );
        return (
          relativeOutput ===
          path.relative(
            process.cwd(),
            path.resolve(process.cwd(), props.entryPoint),
          )
        );
      },
    )?.[0];
    const outputFile = result.outputFiles?.[0];
    if (outputFile === undefined && bundlePath === undefined) {
      throw new Error("Failed to create bundle");
    }
    if (outputFile) {
      return this({
        ...props,
        path: bundlePath,
        hash: outputFile.hash,
        content: outputFile.text,
      });
    }
    const content = await fs.readFile(bundlePath!, "utf-8");
    return this({
      ...props,
      path: bundlePath,
      hash: crypto.createHash("sha256").update(content).digest("hex"),
      content,
    });
  },
);
export async function bundle(props: BundleProps) {
  const { entryPoint, options: _, ...rest } = props;
  const options = {
    ...rest,
    ...props.options,
    write: !(props.outdir === undefined && props.outfile === undefined),
    // write:
    //   props.outdir === undefined && props.outfile === undefined ? false : true,
    // write: false,
    entryPoints: [props.entryPoint],
    outdir: props.outdir ? props.outdir : props.outfile ? undefined : ".out",
    outfile: props.outfile,
    bundle: true,
    format: props.format,
    target: props.target,
    minify: props.minify,
    sourcemap: props.sourcemap,
    external: [...(props.external ?? []), ...(props.options?.external ?? [])],
    platform: props.platform,
    metafile: true,
  };
  if (process.env.DEBUG) {
    console.log(options);
  }
  return await esbuild.build(options);
}
</file>

<file path="alchemy/src/esbuild/index.ts">
export * from "./bundle.js";
</file>

<file path="alchemy/src/fs/copy-file.ts">
import fs from "node:fs";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
/**
 * Properties for creating a CopyFile resource
 */
export interface CopyFileProps {
  /**
   * Source path of the file to copy
   */
  src: string;
  /**
   * Destination path where the file should be copied to
   */
  dest: string;
  /**
   * Whether to overwrite the destination file if it already exists
   * @default true
   */
  overwrite?: boolean;
}
/**
 * Output returned after CopyFile creation/update
 */
export interface CopyFile extends Resource<"fs::CopyFile">, CopyFileProps {
  /**
   * Time at which the object was created
   */
  createdAt: number;
  /**
   * Whether the file was successfully copied
   */
  copied: boolean;
}
/**
 * CopyFile Resource
 *
 * Copies a file from a source location to a destination location.
 *
 * @example
 * // Copy a file to a new location
 * const copiedFile = await CopyFile("config-copy", {
 *   src: "config.json",
 *   dest: "backup/config.json"
 * });
 *
 * @example
 * // Copy a file without overwriting if destination exists
 * const safeCopy = await CopyFile("safe-copy", {
 *   src: "data.json",
 *   dest: "backup/data.json",
 *   overwrite: false
 * });
 */
export const CopyFile = Resource(
  "fs::CopyFile",
  async function (
    this: Context<CopyFile>,
    id: string,
    props: CopyFileProps,
  ): Promise<CopyFile> {
    const { src, dest, overwrite = true } = props;
    if (this.phase === "delete") {
      // When deleting, remove the destination file
      await ignore("ENOENT", async () => fs.promises.unlink(dest));
      return this.destroy();
    }
    try {
      // Check if source file exists
      await fs.promises.access(src, fs.constants.F_OK);
      // If this is an update and the destination has changed, delete the old file
      if (
        this.phase === "update" &&
        this.output?.dest &&
        this.output.dest !== dest
      ) {
        await ignore("ENOENT", async () =>
          fs.promises.unlink(this.output.dest),
        );
      }
      // Check if destination file exists
      const destinationExists = await fs.promises
        .access(dest, fs.constants.F_OK)
        .then(() => true)
        .catch(() => false);
      // Copy file if destination doesn't exist or overwrite is true
      if (!destinationExists || overwrite) {
        await fs.promises.copyFile(src, dest);
      }
      return this({
        src,
        dest,
        overwrite,
        copied: true,
        createdAt: Date.now(),
      });
    } catch (error) {
      console.error(`Error copying file from ${src} to ${dest}:`, error);
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/fs/file-collection.ts">
/**
 * Collection of files with their contents
 */
export type FileCollection = {
  /**
   * Type identifier for FileCollection
   */
  type: "fs::FileCollection";
  /**
   * Map of relative paths to file contents
   */
  files: {
    [relativePath: string]: string;
  };
};
export function isFileCollection(value: unknown): value is FileCollection {
  return (
    typeof value === "object" &&
    value !== null &&
    "type" in value &&
    value.type === "fs::FileCollection"
  );
}
</file>

<file path="alchemy/src/fs/file-ref.ts">
/**
 * Reference to a file in the filesystem
 */
export type FileRef = {
  /**
   * Type identifier for FileRef
   */
  kind: "fs::FileRef";
  /**
   * Path to the file
   */
  path: string;
};
export function isFileRef(value: unknown): value is FileRef {
  return (
    typeof value === "object" &&
    value !== null &&
    "kind" in value &&
    value.kind === "fs::FileRef"
  );
}
</file>

<file path="alchemy/src/fs/file-system-state-store.ts">
import fs from "node:fs";
import path from "node:path";
import type { Scope } from "../scope.js";
import { deserialize, serialize } from "../serde.js";
import type { State, StateStore } from "../state.js";
import { ignore } from "../util/ignore.js";
const stateRootDir = path.join(process.cwd(), ".alchemy");
export class FileSystemStateStore implements StateStore {
  public readonly dir: string;
  private initialized = false;
  constructor(public readonly scope: Scope) {
    this.dir = path.join(stateRootDir, ...scope.chain);
  }
  async init(): Promise<void> {
    if (this.initialized) {
      return;
    }
    this.initialized = true;
    await fs.promises.mkdir(this.dir, { recursive: true });
  }
  async deinit(): Promise<void> {
    await ignore("ENOENT", () => fs.promises.rmdir(this.dir));
  }
  async count(): Promise<number> {
    return Object.keys(await this.list()).length;
  }
  async list(): Promise<string[]> {
    try {
      const files = await fs.promises.readdir(this.dir, {
        withFileTypes: true,
      });
      return files
        .filter((dirent) => dirent.isFile() && dirent.name.endsWith(".json"))
        .map((dirent) => dirent.name.replace(/\.json$/, ""))
        .map((key) => key.replaceAll(":", "/"));
    } catch (error: any) {
      if (error.code === "ENOENT") {
        return [];
      }
      throw error;
    }
  }
  async get(key: string): Promise<State | undefined> {
    try {
      const content = await fs.promises.readFile(this.getPath(key), "utf8");
      const state = (await deserialize(
        this.scope,
        JSON.parse(content),
      )) as State;
      if (state.output === undefined) {
        state.output = {} as any;
      }
      state.output.Scope = this.scope;
      return state;
    } catch (error: any) {
      if (error.code === "ENOENT") {
        return undefined;
      }
      throw error;
    }
  }
  async set(key: string, value: State): Promise<void> {
    await this.init();
    await fs.promises.writeFile(
      this.getPath(key),
      JSON.stringify(await serialize(this.scope, value), null, 2),
    );
  }
  async delete(key: string): Promise<void> {
    try {
      return await fs.promises.unlink(this.getPath(key));
    } catch (error: any) {
      if (error.code === "ENOENT") {
        return;
      }
      throw error;
    }
  }
  async all(): Promise<Record<string, State>> {
    return this.getBatch(await this.list());
  }
  async getBatch(ids: string[]): Promise<Record<string, State>> {
    return Object.fromEntries(
      (
        await Promise.all(
          Array.from(ids).flatMap(async (id) => {
            const s = await this.get(id);
            if (s === undefined) {
              return [] as const;
            }
            return [[id, s]] as const;
          }),
        )
      ).flat(),
    );
  }
  private getPath(key: string): string {
    if (key.includes(":")) {
      throw new Error(`ID cannot include colons: ${key}`);
    }
    if (key.includes("/")) {
      key = key.replaceAll("/", ":");
    }
    return path.join(this.dir, `${key}.json`);
  }
}
</file>

<file path="alchemy/src/fs/file.ts">
import fs from "node:fs";
import path from "node:path";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
import { alchemy } from "../alchemy.js";
import type { FileCollection } from "./file-collection.js";
import type { FileRef } from "./file-ref.js";
declare module "../alchemy.js" {
  interface Alchemy {
    /**
     * Creates a reference to a file in the filesystem.
     * Used in template string interpolation to include file contents,
     * commonly for documentation generation.
     *
     * @param path Path to the file
     * @returns Promise resolving to a FileRef
     *
     * @example
     * // Include a file in documentation generation
     * await Document("api-docs", {
     *   prompt: await alchemy`
     *     Generate docs using the contents of:
     *     ${alchemy.file("./README.md")}
     *   `
     * });
     */
    file(path: string): Promise<FileRef>;
    /**
     * Creates a collection of files with their contents.
     * Used in template string interpolation to include multiple file contents,
     * commonly for bulk documentation generation.
     *
     * @param paths Array of file paths to include in collection
     * @returns Promise resolving to a FileCollection
     *
     * @example
     * // Include multiple source files in documentation generation
     * await Document("provider-docs", {
     *   prompt: await alchemy`
     *     Generate comprehensive docs for these files:
     *     ${alchemy.files([
     *       "src/types.ts",
     *       "src/resource.ts",
     *       "src/provider.ts"
     *     ])}
     *   `
     * });
     */
    files(paths: string[]): Promise<FileCollection>;
    files(path: string, ...paths: string[]): Promise<FileCollection>;
    /**
     * Gets all of the files in a directory.
     * @param path Path to the directory
     * @param props Optional properties
     * @returns Promise resolving to a FileCollection
     *
     * @example
     * // Get all files in a directory
     * const files = await alchemy.folder("./docs");
     *
     */
    folder(
      path: string,
      props?: {
        /**
         * Whether to recursively get all files in the directory
         * @default false
         */
        recursive?: boolean;
      },
    ): Promise<FileCollection>;
  }
}
alchemy.file = async (path: string) => ({
  kind: "fs::FileRef",
  path,
});
alchemy.files = async (
  ...args: [paths: string[]] | [...paths: string[]]
): Promise<FileCollection> => {
  const paths: string[] =
    typeof args[0] === "string" ? (args as string[]) : args[0];
  return {
    type: "fs::FileCollection",
    files: Object.fromEntries(
      await Promise.all(
        paths.map(async (path) => [
          path,
          await fs.promises.readFile(path, "utf-8"),
        ]),
      ),
    ),
  };
};
alchemy.folder = async (dir: string, props?: { recursive?: boolean }) => {
  const files = await fs.promises.readdir(dir, {
    recursive: props?.recursive ?? false,
  });
  return alchemy.files(files.map((file) => path.join(dir, file)));
};
/**
 * Base file resource type
 */
export interface File extends Resource<"fs::File"> {
  /**
   * Path to the file
   */
  path: string;
  /**
   * Content of the file
   */
  content: string;
}
/**
 * File Resource
 *
 * Creates and manages files in the filesystem with automatic directory creation
 * and proper cleanup on deletion.
 *
 * @example
 * // Create a simple text file
 * const config = await File("config.txt", {
 *   path: "config.txt",
 *   content: "some configuration data"
 * });
 *
 * @example
 * // Create a file in a nested directory
 * const log = await File("logs/app.log", {
 *   path: "logs/app.log",
 *   content: "application log entry"
 * });
 *
 * @example
 * // Update file content and path
 * let file = await File("config.json", {
 *   path: "config.json",
 *   content: '{ "version": "1.0.0" }'
 * });
 *
 * // Later, update the path and content (old file will be removed)
 * file = await File("config.json", {
 *   path: "config/config.json",
 *   content: '{ "version": "1.0.1" }'
 * });
 */
export const File = Resource(
  "fs::File",
  async function (
    this: Context<File>,
    id: string,
    props: {
      path: string;
      content: string;
    },
  ): Promise<File> {
    const filePath = props?.path ?? id;
    if (this.phase === "delete") {
      await ignore("ENOENT", async () => fs.promises.unlink(filePath));
      return this.destroy();
    }
    if (
      this.phase === "update" &&
      this.output &&
      this.output.path !== filePath
    ) {
      // If path has changed, delete the old file
      console.log(
        `File: Path changed from ${this.output.path} to ${filePath}, removing old file`,
      );
      await ignore("ENOENT", async () => fs.promises.unlink(this.output.path));
    }
    // Create directory and write file
    await fs.promises.mkdir(path.dirname(filePath), {
      recursive: true,
    });
    await fs.promises.writeFile(filePath, props.content);
    return this({
      path: filePath,
      content: props.content,
    });
  },
);
</file>

<file path="alchemy/src/fs/folder.ts">
import fs from "node:fs";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
export interface FolderProps {
  /**
   * The path of the folder
   */
  path?: string;
  /**
   * Whether to delete the folder during the delete phase
   * @default true
   */
  delete?: boolean;
  /**
   * Whether to clean the folder during the deletion phase (even if it contains existing files)
   * @default false
   */
  clean?: boolean;
  /**
   * Whether to create the folder recursively
   * @default true
   */
  recursive?: boolean;
}
/**
 * Base folder resource type
 */
export interface Folder extends Resource<"fs::Folder"> {
  path: string;
}
/**
 * Folder Resource
 *
 * Creates and manages directories in the filesystem with automatic parent
 * directory creation and cleanup on deletion.
 *
 * @example
 * // Create a directory using id as path
 * const dir = await Folder("uploads");
 *
 * @example
 * // Create a directory with explicit path
 * const dir = await Folder("uploads", {
 *   path: "uploads"
 * });
 *
 * @example
 * // Create a nested directory structure
 * const logs = await Folder("var/log/app", {
 *   path: "var/log/app"
 * });
 */
export const Folder = Resource(
  "fs::Folder",
  async function (
    this: Context<Folder>,
    id: string,
    props?: FolderProps,
  ): Promise<Folder> {
    const dirPath = props?.path ?? id;
    if (this.phase === "delete") {
      if (props?.delete !== false) {
        // we just do a best effort attempt
        await ignore(["ENOENT", "ENOTEMPTY"], async () =>
          fs.promises.rmdir(dirPath, { recursive: props?.clean ?? false }),
        );
      }
      return this.destroy();
    }
    await ignore("EEXIST", async () =>
      fs.promises.mkdir(dirPath, { recursive: props?.recursive ?? true }),
    );
    return this({
      path: dirPath,
    });
  },
);
</file>

<file path="alchemy/src/fs/index.ts">
export * from "./copy-file.js";
export * from "./file-collection.js";
export * from "./file-ref.js";
export * from "./file-system-state-store.js";
export * from "./file.js";
export * from "./folder.js";
export * from "./static-astro-file.js";
export * from "./static-css-file.js";
export * from "./static-html-file.js";
export * from "./static-json-file.js";
export * from "./static-text-file.js";
export * from "./static-typescript-file.js";
export * from "./static-vue-file.js";
export * from "./static-yaml-file.js";
</file>

<file path="alchemy/src/fs/static-astro-file.ts">
import { File } from "./file.js";
export type StaticAstroFile = File;
/**
 * Creates a static Astro component file
 *
 * @example
 * // Create an Astro component file with content
 * const header = await StaticAstroFile("Header.astro",
 *   `---
 *   import Logo from '../components/Logo.astro';
 *   const navItems = ['Home', 'About', 'Contact'];
 *   ---
 *
 *   <header class="header">
 *     <Logo />
 *     <nav>
 *       <ul>
 *         {navItems.map(item => (
 *           <li><a href={`/${item.toLowerCase()}`}>{item}</a></li>
 *         ))}
 *       </ul>
 *     </nav>
 *   </header>
 *
 *   <style>
 *     .header {
 *       display: flex;
 *       justify-content: space-between;
 *       padding: 1rem;
 *     }
 *   </style>`
 * );
 */
export function StaticAstroFile(
  id: string,
  ...args: [content: string] | [path: string, content: string]
): Promise<StaticAstroFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  return File(id, {
    path,
    content,
  });
}
</file>

<file path="alchemy/src/fs/static-css-file.ts">
import { File } from "./file.js";
export type StaticCSSFile = File;
/**
 * Creates a static CSS file
 *
 * @example
 * // Create a CSS file with styles
 * const styles = await StaticCSSFile("styles.css",
 *   `.container {
 *     max-width: 1200px;
 *     margin: 0 auto;
 *     padding: 0 1rem;
 *   }
 *
 *   .button {
 *     background-color: #0062ff;
 *     color: white;
 *     border: none;
 *     padding: 0.5rem 1rem;
 *     border-radius: 4px;
 *   }`
 * );
 */
export function StaticCSSFile(
  id: string,
  ...args: [content: string] | [path: string, content: string]
): Promise<StaticCSSFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  return File(id, {
    path,
    content,
  });
}
</file>

<file path="alchemy/src/fs/static-html-file.ts">
import { File } from "./file.js";
export type StaticHTMLFile = File;
/**
 * Creates a static HTML file
 *
 * @example
 * // Create an HTML file with content
 * const page = await StaticHTMLFile("index.html",
 *   `<!DOCTYPE html>
 *   <html lang="en">
 *   <head>
 *     <meta charset="UTF-8">
 *     <meta name="viewport" content="width=device-width, initial-scale=1.0">
 *     <title>My Website</title>
 *     <link rel="stylesheet" href="styles.css">
 *   </head>
 *   <body>
 *     <header>
 *       <h1>Welcome to My Website</h1>
 *     </header>
 *     <main>
 *       <p>This is the main content of the page.</p>
 *     </main>
 *     <footer>
 *       <p>&copy; 2024 My Company</p>
 *     </footer>
 *   </body>
 *   </html>`
 * );
 */
export function StaticHTMLFile(
  id: string,
  ...args: [content: string] | [path: string, content: string]
): Promise<StaticHTMLFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  return File(id, {
    path,
    content,
  });
}
</file>

<file path="alchemy/src/fs/static-json-file.ts">
import { File } from "./file.js";
/**
 * Creates a JSON file with formatted content
 *
 * @example
 * // Create a JSON configuration file
 * const config = await StaticJsonFile("config.json", {
 *   api: {
 *     endpoint: "https://api.example.com",
 *     version: "v1"
 *   },
 *   features: ["auth", "logging"]
 * });
 */
export type StaticJsonFile = File;
export async function StaticJsonFile(
  id: string,
  ...args: [content: any] | [path: string, content: any]
): Promise<StaticJsonFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  const prettier = await import("prettier");
  return File(id, {
    path,
    content: await prettier.format(JSON.stringify(content), {
      parser: "json",
      editor: {
        tabWidth: 2,
        indentWidth: 2,
      },
    }),
  });
}
</file>

<file path="alchemy/src/fs/static-text-file.ts">
import { File } from "./file.js";
/**
 * Creates a plain text file
 *
 * @example
 * // Create a text file with content
 * const readme = await TextFile("README.md",
 *   "# Project Name\n\nProject description goes here."
 * );
 */
export type StaticTextFile = File;
export function StaticTextFile(
  id: string,
  ...args: [content: string] | [path: string, content: string]
): Promise<StaticTextFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  return File(id, {
    path,
    content,
  });
}
</file>

<file path="alchemy/src/fs/static-typescript-file.ts">
import { File } from "./file.js";
/**
 * Creates a TypeScript file with formatted content using prettier
 *
 * @example
 * // Create a TypeScript file
 * const component = await StaticTypeScriptFile("Component.ts", `
 *   interface Props {
 *     name: string;
 *     age: number;
 *   }
 *
 *   export function Component({ name, age }: Props) {
 *     return <div>Hello {name}, you are {age} years old</div>;
 *   }
 * `);
 */
export type StaticTypeScriptFile = File;
export async function StaticTypeScriptFile(
  id: string,
  ...args: [content: string] | [path: string, content: string]
): Promise<StaticTypeScriptFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  const prettier = await import("prettier");
  return File(id, {
    path,
    content: await prettier.format(content, {
      parser: "typescript",
      editor: {
        tabWidth: 2,
        indentWidth: 2,
      },
    }),
  });
}
</file>

<file path="alchemy/src/fs/static-vue-file.ts">
import { File } from "./file.js";
export type StaticVueFile = File;
/**
 * Creates a static Vue component file
 *
 * @example
 * // Create a Vue component file with content
 * const button = await StaticVueFile("Button.vue",
 *   `<template>
 *     <button class="btn">{{ text }}</button>
 *   </template>
 *
 *   <script>
 *   export default {
 *     props: {
 *       text: String
 *     }
 *   }
 *   </script>
 *
 *   <style>
 *   .btn {
 *     padding: 0.5rem 1rem;
 *   }
 *   </style>`
 * );
 */
export function StaticVueFile(
  id: string,
  ...args: [content: string] | [path: string, content: string]
): Promise<StaticVueFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  return File(id, {
    path,
    content,
  });
}
</file>

<file path="alchemy/src/fs/static-yaml-file.ts">
import { File } from "./file.js";
/**
 * Creates a YAML file with formatted content
 *
 * @example
 * // Create a YAML configuration file
 * const config = await StaticYamlFile("config.yaml", {
 *   server: {
 *     host: "localhost",
 *     port: 3000
 *   },
 *   database: {
 *     url: "postgresql://localhost:5432/db",
 *     pool: {
 *       min: 1,
 *       max: 10
 *     }
 *   }
 * });
 */
export type StaticYamlFile = File;
export async function StaticYamlFile(
  id: string,
  ...args: [content: any] | [path: string, content: any]
): Promise<StaticYamlFile> {
  const [path, content] = args.length === 1 ? [id, args[0]] : args;
  const yaml = await import("yaml");
  return File(id, {
    path,
    content: yaml.stringify(content),
  });
}
</file>

<file path="alchemy/src/github/client.ts">
import { Octokit } from "@octokit/rest";
import { exec } from "node:child_process";
import { promisify } from "node:util";
// Convert exec to promise-based
const execAsync = promisify(exec);
/**
 * Try to get a GitHub token from the GitHub CLI
 */
export async function getGitHubTokenFromCLI(): Promise<string | null> {
  try {
    // Check if GitHub CLI is installed
    const { stdout: ghVersion } = await execAsync("gh --version");
    if (!ghVersion) return null;
    // Get the auth token
    const { stdout: token } = await execAsync("gh auth token");
    return token?.trim() || null;
  } catch (error) {
    return null;
  }
}
/**
 * Get GitHub authentication token with the following priority:
 * 1. Explicit token provided in props
 * 2. GITHUB_ACCESS_TOKEN environment variable (for actions with admin permissions)
 * 3. GITHUB_TOKEN environment variable
 * 4. GitHub CLI token (if gh is installed and authenticated)
 *
 * @param token Optional token to use
 * @returns The resolved token or null if not available
 */
export async function getGitHubToken(token?: string): Promise<string | null> {
  return (
    token ||
    process.env.GITHUB_ACCESS_TOKEN ||
    process.env.GITHUB_TOKEN ||
    (await getGitHubTokenFromCLI())
  );
}
/**
 * Create an authenticated Octokit client
 *
 * @param options Options for creating the client
 * @returns An authenticated Octokit client
 */
export async function createGitHubClient(
  options: { token?: string } = {},
): Promise<Octokit> {
  const token = await getGitHubToken(options.token);
  return new Octokit({
    auth: token,
  });
}
/**
 * Verifies GitHub authentication and provides helpful error messages
 *
 * @param octokit Octokit client
 * @param owner Repository owner
 * @param repo Repository name
 */
export async function verifyGitHubAuth(
  octokit: Octokit,
  owner: string,
  repo: string,
): Promise<void> {
  try {
    // Make a test request to check authentication
    await octokit.rest.repos.get({
      owner,
      repo,
    });
  } catch (error: any) {
    if (error.status === 401) {
      console.error(
        "\n GitHub authentication failed. Please try one of the following:",
      );
      console.error(
        "1. Run 'gh auth login' to authenticate with the GitHub CLI",
      );
      console.error(
        "2. Set the GITHUB_TOKEN environment variable with a personal access token",
      );
      console.error("3. Pass a token directly to the constructor");
      console.error(
        "\nTo create a token, visit: https://github.com/settings/tokens",
      );
      console.error(
        "Required scopes: 'repo' for private repos or 'public_repo' for public repos\n",
      );
      throw new Error("GitHub authentication failed");
    }
    if (error.status === 403) {
      console.error(
        "\n Insufficient permissions. You need admin access to the repository.",
      );
      console.error(
        "Make sure your token has the 'repo' scope for private repos or 'public_repo' for public repos\n",
      );
      throw new Error("Insufficient GitHub permissions");
    }
    if (error.status === 404) {
      console.error(`\n Repository not found: ${owner}/${repo}`);
      console.error(
        "Make sure the repository exists and you have access to it\n",
      );
      throw new Error("GitHub repository not found");
    }
    throw error;
  }
}
</file>

<file path="alchemy/src/github/index.ts">
export * from "./repository-environment.js";
export * from "./secret.js";
</file>

<file path="alchemy/src/github/repository-environment.ts">
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { createGitHubClient, verifyGitHubAuth } from "./client.js";
/**
 * Properties for creating or updating a GitHub Repository Environment
 */
export interface RepositoryEnvironmentProps {
  /**
   * Repository owner (user or organization)
   */
  owner: string;
  /**
   * Repository name
   */
  repository: string;
  /**
   * Environment name
   */
  name: string;
  /**
   * Wait timer before allowing deployments to proceed (in minutes)
   * Must be between 0 and 43200 (30 days)
   * @default 0
   */
  waitTimer?: number;
  /**
   * Determine whether to prevent self-reviews on pull requests
   * Note: Requires at least one reviewer when enabled
   * @default false
   */
  preventSelfReview?: boolean;
  /**
   * Determine whether administrators can bypass deployment protection rules
   * @default true
   */
  adminBypass?: boolean;
  /**
   * Required reviewers for deployments to this environment
   */
  reviewers?: {
    /**
     * GitHub usernames or user IDs that can approve deployments
     * Can be numeric IDs or string usernames (which will be resolved to IDs)
     */
    users?: Array<number | string>;
    /**
     * GitHub team names or team IDs that can approve deployments
     * Can be numeric IDs or string team names (which will be resolved to IDs)
     * Note: For team names, should be in the format "org/team-name"
     */
    teams?: Array<number | string>;
  };
  /**
   * Deployment branch policy for the environment
   */
  deploymentBranchPolicy?: {
    /**
     * Whether to restrict deployments to protected branches
     * @default false
     */
    protectedBranches?: boolean;
    /**
     * Whether to allow custom branch policies
     * When true, specific branch patterns can be specified using createDeploymentBranchPolicy
     * @default false
     */
    customBranchPolicies?: boolean;
  };
  /**
   * Branch patterns for deployment when customBranchPolicies is true
   * For example: ["main", "releases/*"]
   * @default []
   */
  branchPatterns?: string[];
  /**
   * Optional GitHub API token (overrides environment variable)
   * If not provided, will use GITHUB_TOKEN environment variable
   * @default process.env.GITHUB_TOKEN
   */
  token?: string;
}
/**
 * Output returned after Repository Environment creation/update
 */
export interface RepositoryEnvironment
  extends Resource<"github::RepositoryEnvironment">,
    RepositoryEnvironmentProps {
  /**
   * The ID of the resource
   */
  id: string;
  /**
   * The numeric ID of the environment in GitHub
   */
  environmentId: number;
  /**
   * Time at which the object was created/updated
   */
  updatedAt: string;
}
/**
 * Resource for managing GitHub repository environments
 *
 * Note: If preventSelfReview is true, at least one reviewer must be specified.
 *
 * Branch policies are efficiently managed with proper diffing:
 * - Only manages branch patterns configured through this resource
 * - Preserves any manually added branch patterns outside this resource
 * - When updating, only modifies patterns that have changed from previous state
 * - Compares against previous resource state, not current environment state
 * - Safely handles policy type changes
 *
 * @example
 * // Create a basic environment with no protection rules
 * const devEnv = await RepositoryEnvironment("dev-environment", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   name: "development"
 * });
 *
 * @example
 * // Create a production environment with approval requirements
 * const prodEnv = await RepositoryEnvironment("prod-environment", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   name: "production",
 *   waitTimer: 10, // 10 minute delay
 *   preventSelfReview: true,
 *   reviewers: {
 *     teams: ["platform-team"], // team name
 *     users: ["security-admin"] // username
 *   },
 *   deploymentBranchPolicy: {
 *     protectedBranches: true,
 *     customBranchPolicies: false
 *   }
 * });
 *
 * @example
 * // Create an environment with reviewer IDs
 * const stagingEnv = await RepositoryEnvironment("staging-environment", {
 *   owner: "my-org",
 *   repository: "my-repo",
 *   name: "staging",
 *   reviewers: {
 *     teams: [1234567], // team ID
 *     users: [7654321]  // user ID
 *   },
 *   deploymentBranchPolicy: {
 *     protectedBranches: false,
 *     customBranchPolicies: true
 *   },
 *   branchPatterns: ["main", "release/*"]
 * });
 */
export const RepositoryEnvironment = Resource(
  "github::RepositoryEnvironment",
  async function (
    this: Context<RepositoryEnvironment>,
    id: string,
    props: RepositoryEnvironmentProps,
  ): Promise<RepositoryEnvironment> {
    // Create authenticated Octokit client
    const octokit = await createGitHubClient({
      token: props.token,
    });
    // Verify authentication and permissions
    if (!this.quiet) {
      await verifyGitHubAuth(octokit, props.owner, props.repository);
    }
    if (this.phase === "delete") {
      if (this.output?.id) {
        try {
          // Delete the environment
          await octokit.rest.repos.deleteAnEnvironment({
            owner: props.owner,
            repo: props.repository,
            environment_name: props.name,
          });
        } catch (error: any) {
          // Ignore 404 errors (environment already deleted)
          if (error.status === 404) {
            console.log("Environment doesn't exist, ignoring");
          } else {
            throw error;
          }
        }
      }
      // Return void (a deleted resource has no content)
      return this.destroy();
    }
    try {
      // Check if the environment already exists
      let environmentId: number | undefined = undefined; // Use undefined instead of 0
      try {
        const { data: environments } =
          await octokit.rest.repos.getAllEnvironments({
            owner: props.owner,
            repo: props.repository,
          });
        const existingEnv = environments.environments?.find(
          (env) => env.name.toLowerCase() === props.name.toLowerCase(),
        );
        if (existingEnv?.id) {
          environmentId = existingEnv.id;
        }
      } catch (error: any) {
        // If it's a 404, the environment doesn't exist, which is fine
        if (error.status !== 404) {
          throw error;
        }
      }
      // Convert reviewers to API format
      const reviewers: { type: "User" | "Team"; id: number }[] = [];
      // Process user reviewers
      if (props.reviewers?.users && props.reviewers.users.length > 0) {
        for (const user of props.reviewers.users) {
          if (typeof user === "number") {
            // If a numeric ID is provided, use it directly
            reviewers.push({
              type: "User" as const,
              id: user,
            });
          } else {
            // If a username string is provided, look up the ID
            const { data: userData } = await octokit.rest.users.getByUsername({
              username: user,
            });
            reviewers.push({
              type: "User" as const,
              id: userData.id,
            });
          }
        }
      }
      // Process team reviewers
      if (props.reviewers?.teams && props.reviewers.teams.length > 0) {
        for (const team of props.reviewers.teams) {
          if (typeof team === "number") {
            // If a numeric ID is provided, use it directly
            reviewers.push({
              type: "Team" as const,
              id: team,
            });
          } else {
            // If a team name string is provided, look up the ID
            // Check if team name is in the format 'org/team-name'
            const teamParts = team.includes("/")
              ? team.split("/")
              : [props.owner, team];
            if (teamParts.length !== 2) {
              throw new Error(
                `Invalid team format: ${team}. Expected format: "org/team-slug" or just "team-slug"`,
              );
            }
            const [org, teamSlug] = teamParts;
            const { data: teamData } = await octokit.rest.teams.getByName({
              org,
              team_slug: teamSlug,
            });
            reviewers.push({
              type: "Team" as const,
              id: teamData.id,
            });
          }
        }
      }
      // Create or update the environment
      if (environmentId === undefined) {
        // Create the environment
        const { data: createdEnv } =
          await octokit.rest.repos.createOrUpdateEnvironment({
            owner: props.owner,
            repo: props.repository,
            environment_name: props.name,
            wait_timer: props.waitTimer,
            prevent_self_review: props.preventSelfReview,
            reviewers: reviewers.length > 0 ? reviewers : undefined,
            deployment_branch_policy: props.deploymentBranchPolicy
              ? {
                  protected_branches:
                    props.deploymentBranchPolicy.protectedBranches ?? false,
                  custom_branch_policies:
                    props.deploymentBranchPolicy.customBranchPolicies ?? false,
                }
              : undefined,
          });
        environmentId = createdEnv.id;
        // If there are specific branch patterns, set them
        if (
          props.deploymentBranchPolicy?.customBranchPolicies === true &&
          props.branchPatterns &&
          props.branchPatterns.length > 0
        ) {
          // Add branch patterns one by one
          for (const pattern of props.branchPatterns) {
            await octokit.rest.repos.createDeploymentBranchPolicy({
              owner: props.owner,
              repo: props.repository,
              environment_name: props.name,
              name: pattern,
            });
          }
        }
      } else {
        // Update the environment
        await octokit.rest.repos.createOrUpdateEnvironment({
          owner: props.owner,
          repo: props.repository,
          environment_name: props.name,
          wait_timer: props.waitTimer,
          prevent_self_review: props.preventSelfReview,
          reviewers: reviewers.length > 0 ? reviewers : undefined,
          deployment_branch_policy: props.deploymentBranchPolicy
            ? {
                protected_branches:
                  props.deploymentBranchPolicy.protectedBranches ?? false,
                custom_branch_policies:
                  props.deploymentBranchPolicy.customBranchPolicies ?? false,
              }
            : undefined,
        });
        // If there are specific branch patterns, update them
        if (props.deploymentBranchPolicy?.customBranchPolicies === true) {
          // Get existing branch policies to understand what's currently configured
          const { data: existingPolicies } =
            await octokit.rest.repos.listDeploymentBranchPolicies({
              owner: props.owner,
              repo: props.repository,
              environment_name: props.name,
            });
          const existingPatterns = existingPolicies.branch_policies.map(
            (policy) => policy.name!,
          );
          const newPatterns: string[] = props.branchPatterns || [];
          // For updates, keep track of which branch policies we should manage
          // This set identifies patterns that were previously managed by this resource
          // If we don't have previous props, use an empty set
          const previouslyManagedPatterns: Set<string> = new Set(
            this.phase === "update" &&
              this.props?.deploymentBranchPolicy?.customBranchPolicies === true
              ? this.props.branchPatterns || []
              : [],
          );
          // Patterns to add (in new config but not in existing)
          const patternsToAdd = newPatterns.filter(
            (pattern) => !existingPatterns.includes(pattern),
          );
          // Patterns to delete (were managed by us previously but not in new config)
          const patternsToDelete = existingPatterns.filter(
            (pattern) =>
              previouslyManagedPatterns.has(pattern) &&
              !newPatterns.includes(pattern),
          );
          // Delete policies that are no longer needed
          for (const patternToDelete of patternsToDelete) {
            const policy = existingPolicies.branch_policies.find(
              (p) => p.name === patternToDelete,
            );
            if (policy?.id) {
              await octokit.rest.repos.deleteDeploymentBranchPolicy({
                owner: props.owner,
                repo: props.repository,
                environment_name: props.name,
                branch_policy_id: policy.id,
              });
            }
          }
          // Add new branch patterns
          for (const pattern of patternsToAdd) {
            await octokit.rest.repos.createDeploymentBranchPolicy({
              owner: props.owner,
              repo: props.repository,
              environment_name: props.name,
              name: pattern,
            });
          }
        }
      }
      // Get the updated environment details
      const { data: env } = await octokit.rest.repos.getEnvironment({
        owner: props.owner,
        repo: props.repository,
        environment_name: props.name,
      });
      // Return environment details
      return this({
        id: `${props.owner}/${props.repository}/${props.name}`,
        environmentId: environmentId || env.id,
        owner: props.owner,
        repository: props.repository,
        name: props.name,
        waitTimer: props.waitTimer,
        preventSelfReview: props.preventSelfReview,
        adminBypass: props.adminBypass,
        reviewers: props.reviewers,
        deploymentBranchPolicy: props.deploymentBranchPolicy,
        branchPatterns: props.branchPatterns,
        token: props.token,
        updatedAt: new Date().toISOString(),
      });
    } catch (error: any) {
      if (
        error.status === 403 &&
        error.message?.includes("Must have admin rights")
      ) {
        console.error(
          "\n Error creating/updating GitHub environment: You must have admin rights to the repository.",
        );
        console.error(
          "Make sure your GitHub token has the required permissions (repo scope for private repos).\n",
        );
      } else {
        console.error(
          "Error creating/updating GitHub environment:",
          error.message,
        );
      }
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/github/secret.ts">
import sodium from "libsodium-wrappers";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { createGitHubClient, verifyGitHubAuth } from "./client.js";
/**
 * Properties for creating or updating a GitHub Secret
 */
export interface GitHubSecretProps {
  /**
   * Repository owner (user or organization)
   */
  owner: string;
  /**
   * Repository name
   */
  repository: string;
  /**
   * Secret name
   */
  name: string;
  /**
   * Secret value (will be stored securely on GitHub)
   */
  value: Secret;
  /**
   * Optional environment name to create an environment secret
   * If set, the secret will be created in the specified environment instead of at the repository level
   */
  environment?: string;
  /**
   * Optional GitHub API token (overrides environment variable)
   * If not provided, will use GITHUB_TOKEN environment variable
   * Token must have 'repo' scope for private repositories
   * or 'public_repo' scope for public repositories
   */
  token?: Secret;
}
/**
 * Output returned after Secret creation/update
 */
export interface GitHubSecretOutput
  extends Resource<"github::Secret">,
    Omit<GitHubSecretProps, "value"> {
  /**
   * The ID of the resource
   */
  id: string;
  /**
   * Time at which the object was created/updated
   */
  updatedAt: string;
}
/**
 * Resource for managing GitHub repository and environment secrets
 *
 * Authentication is handled in the following order:
 * 1. `token` parameter in the resource props (if provided)
 * 2. `GITHUB_TOKEN` environment variable
 *
 * The token must have the following permissions:
 * - 'repo' scope for private repositories
 * - 'public_repo' scope for public repositories
 *
 * @example
 * // Create a repository secret using GITHUB_TOKEN environment variable:
 * const secret = await GitHubSecret("my-secret", {
 *   owner: "my-github-username",
 *   repository: "my-repo",
 *   name: "API_KEY",
 *   value: alchemy.secret("my-secret-value")
 * });
 *
 * @example
 * // Create an environment secret:
 * const secret = await GitHubSecret("my-env-secret", {
 *   owner: "my-github-username",
 *   repository: "my-repo",
 *   environmentName: "production",
 *   name: "DEPLOY_KEY",
 *   value: alchemy.secret("my-secret-deploy-key")
 * });
 *
 * @example
 * // Create a secret with a custom GitHub token:
 * const secret = await GitHubSecret("my-secret", {
 *   owner: "my-github-username",
 *   repository: "my-repo",
 *   name: "API_KEY",
 *   value: alchemy.secret("my-secret-value"),
 *   token: alchemy.secret(process.env.CUSTOM_GITHUB_TOKEN)
 * });
 *
 * @example
 * // Create multiple secrets with environment variables:
 * const secrets = await Promise.all([
 *   GitHubSecret("aws-secret", {
 *     owner: "my-github-username",
 *     repository: "cloud-app",
 *     name: "AWS_ROLE_ARN",
 *     value: alchemy.secret(process.env.AWS_ROLE_ARN)
 *   }),
 *   GitHubSecret("cf-secret", {
 *     owner: "my-github-username",
 *     repository: "cloud-app",
 *     name: "CLOUDFLARE_API_KEY",
 *     value: alchemy.secret(process.env.CLOUDFLARE_API_KEY)
 *   })
 * ]);
 *
 * @example
 * // Create a secret in a secure scope with a password:
 * await alchemy.run("secure-scope", {
 *   password: process.env.SECRET_PASSPHRASE
 * }, async () => {
 *   const secret = await GitHubSecret("deploy-secret", {
 *     owner: "my-github-username",
 *     repository: "my-app",
 *     name: "DEPLOY_TOKEN",
 *     value: alchemy.secret(process.env.DEPLOY_TOKEN),
 *     token: alchemy.secret(process.env.GITHUB_TOKEN)
 *   });
 * });
 */
export const GitHubSecret = Resource(
  "github::Secret",
  async function (
    this: Context<GitHubSecretOutput>,
    id: string,
    props: GitHubSecretProps,
  ): Promise<GitHubSecretOutput> {
    // Create authenticated Octokit client - will automatically handle token resolution
    /// TODO: use fetch
    const octokit = await createGitHubClient({
      token: props.token?.unencrypted,
    });
    // Verify authentication and permissions
    if (!this.quiet) {
      await verifyGitHubAuth(octokit, props.owner, props.repository);
    }
    // Determine if we're working with an environment secret or repository secret
    const isEnvironmentSecret = !!props.environment;
    if (this.phase === "delete") {
      if (this.output?.id) {
        try {
          // Delete the secret
          if (isEnvironmentSecret) {
            await octokit.rest.actions.deleteEnvironmentSecret({
              owner: props.owner,
              repo: props.repository,
              environment_name: props.environment!,
              secret_name: props.name,
            });
          } else {
            await octokit.rest.actions.deleteRepoSecret({
              owner: props.owner,
              repo: props.repository,
              secret_name: props.name,
            });
          }
        } catch (error: any) {
          // Ignore 404 errors (secret already deleted)
          if (error.status === 404) {
            console.log("Secret doesn't exist, ignoring");
          } else {
            throw error;
          }
        }
      }
      // Return void (a deleted resource has no content)
      return this.destroy();
    }
    try {
      // Check if we're transitioning between secret types (repo <-> environment)
      if (this.phase === "update") {
        const wasEnvironmentSecret = !!this.output.environment;
        const secretTypeChanged = isEnvironmentSecret !== wasEnvironmentSecret;
        // If secret type changed, we need to delete the old one first
        if (secretTypeChanged) {
          console.log(
            `Secret type changed from ${wasEnvironmentSecret ? "environment" : "repository"} to ${isEnvironmentSecret ? "environment" : "repository"} secret. Deleting the old secret first.`,
          );
          try {
            if (wasEnvironmentSecret) {
              // Delete the old environment secret
              await octokit.rest.actions.deleteEnvironmentSecret({
                owner: this.output.owner,
                repo: this.output.repository,
                environment_name: this.output.environment!,
                secret_name: this.output.name,
              });
            } else {
              // Delete the old repository secret
              await octokit.rest.actions.deleteRepoSecret({
                owner: this.output.owner,
                repo: this.output.repository,
                secret_name: this.output.name,
              });
            }
          } catch (error: any) {
            // Log but don't fail if the old secret doesn't exist or can't be deleted
            if (error.status === 404) {
              console.log(
                "Old secret not found, continuing with creation of new secret",
              );
            } else {
              throw error;
            }
          }
        }
      }
      let publicKey;
      // Get the appropriate public key for encrypting secrets
      if (isEnvironmentSecret) {
        // Get the environment's public key
        const { data } = await octokit.rest.actions.getEnvironmentPublicKey({
          owner: props.owner,
          repo: props.repository,
          environment_name: props.environment!,
        });
        publicKey = data;
      } else {
        // Get the repository's public key
        const { data } = await octokit.rest.actions.getRepoPublicKey({
          owner: props.owner,
          repo: props.repository,
        });
        publicKey = data;
      }
      // Encrypt the secret value using libsodium
      const encryptedValue = await encryptString(
        props.value.unencrypted,
        publicKey.key,
      );
      // Create or update the secret with the encrypted value and key_id
      if (isEnvironmentSecret) {
        await octokit.rest.actions.createOrUpdateEnvironmentSecret({
          owner: props.owner,
          repo: props.repository,
          environment_name: props.environment!,
          secret_name: props.name,
          encrypted_value: encryptedValue,
          key_id: publicKey.key_id,
        });
      } else {
        await octokit.rest.actions.createOrUpdateRepoSecret({
          owner: props.owner,
          repo: props.repository,
          secret_name: props.name,
          encrypted_value: encryptedValue,
          key_id: publicKey.key_id,
        });
      }
      // GitHub doesn't return the secret details on create/update, so we need to construct it
      const idParts = [props.owner, props.repository];
      if (isEnvironmentSecret) {
        idParts.push(props.environment!);
      }
      idParts.push(props.name);
      return this({
        id: idParts.join("/"),
        owner: props.owner,
        repository: props.repository,
        name: props.name,
        environment: props.environment,
        token: props.token,
        updatedAt: new Date().toISOString(),
      });
    } catch (error: any) {
      if (
        error.status === 403 &&
        error.message?.includes("Must have admin rights")
      ) {
        console.error(
          "\n Error creating/updating GitHub secret: You must have admin rights to the repository.",
        );
        console.error(
          "Make sure your GitHub token has the required permissions (repo scope for private repos).\n",
        );
      } else {
        console.error("Error creating/updating GitHub secret:", error.message);
      }
      throw error;
    }
  },
);
/**
 * Encrypt a value for GitHub using libsodium
 * Based on GitHub's documentation for encrypting secrets
 *
 * @param value - The secret value to encrypt
 * @param publicKey - The base64-encoded public key from GitHub
 * @returns The base64-encoded encrypted value
 */
async function encryptString(
  value: string,
  publicKey: string,
): Promise<string> {
  // Initialize libsodium
  await sodium.ready;
  // Convert the public key from base64 to binary
  const binKey = sodium.from_base64(publicKey, sodium.base64_variants.ORIGINAL);
  // Convert the message to a Uint8Array
  const binMessage = sodium.from_string(value);
  // Encrypt the message with the public key using libsodium's sealed box
  const encryptedBin = sodium.crypto_box_seal(binMessage, binKey);
  // Convert the encrypted message to base64
  return sodium.to_base64(encryptedBin, sodium.base64_variants.ORIGINAL);
}
</file>

<file path="alchemy/src/internal/docs/providers.ts">
import { type } from "arktype";
import fs from "node:fs/promises";
import path from "node:path";
import { Data } from "../../ai/data.js";
import { Document } from "../../ai/document.js";
import { alchemy } from "../../alchemy.js";
import { Folder } from "../../fs/folder.js";
function getArg(arg: string) {
  const idx = process.argv.findIndex((a) => a === arg);
  return idx > -1 ? process.argv[idx + 1] : undefined;
}
const onlyProviderName = getArg("--provider");
const onlyResourceName = getArg("--resource");
export interface DocsProps {
  /**
   * The output directory for the docs.
   */
  outDir: string | Folder;
  /**
   * The source directory for the docs.
   */
  srcDir: string;
  /**
   * Whether to filter the docs.
   * If true, include all docs.
   * If false, include none.
   * If a number, include that many providers.
   *
   * @default true (all docs)
   */
  filter?: boolean | number;
  /**
   * Whether to run in parallel.
   *
   * @default true
   */
  parallel?: boolean;
}
export type Providers = {
  dir: string;
  provider: string;
  documents: Document[];
}[];
export async function Providers({
  srcDir,
  outDir,
  filter,
  parallel = true,
}: DocsProps): Promise<Providers> {
  outDir = typeof outDir === "string" ? outDir : outDir.path;
  const exclude = [
    "util",
    "test",
    "vitepress",
    "vite",
    "shadcn",
    "internal",
    "web",
  ];
  // Get all folders in the alchemy/src directory
  const providers = (
    await fs.readdir(srcDir, {
      withFileTypes: true,
    })
  )
    .filter((dirent) => dirent.isDirectory() && !exclude.includes(dirent.name))
    .map((dirent) => path.join(dirent.parentPath, dirent.name));
  if (parallel) {
    return await Promise.all(
      providers.map((provider) =>
        generateProviderDocs({ provider, outDir, parallel }),
      ),
    );
  }
  const generatedProviders = [];
  for (const provider of providers) {
    generatedProviders.push(
      await generateProviderDocs({ provider, outDir, parallel }),
    );
  }
  return generatedProviders;
}
async function generateProviderDocs({
  provider,
  outDir,
  parallel,
}: {
  provider: string;
  outDir: string;
  parallel: boolean;
}) {
  const providerName = path.basename(provider);
  const files = (
    await fs.readdir(path.resolve(provider), {
      withFileTypes: true,
    })
  )
    .filter((dirent) => dirent.isFile())
    .map((dirent) =>
      path.relative(process.cwd(), path.resolve(provider, dirent.name)),
    )
    .filter((file) => file.endsWith(".ts") && !file.endsWith("index.ts"));
  type Group = (typeof groups)[number];
  const {
    object: { groups },
  } = await Data(`docs/${providerName}`, {
    model: {
      id: "o3-mini",
      provider: "openai",
      options: {
        reasoningEffort: "high",
      },
    },
    freeze: onlyProviderName === undefined || onlyProviderName !== providerName,
    temperature: 0.1,
    schema: type({
      groups: type({
        identifier: type("string").describe(
          "The identifier of the file's primary exported Resource/Function/Type, e.g. Bucket or StaticSite, AstroFile, TypeScriptFile",
        ),
        filename: type("string").describe(
          "The filename of the Resource's Document, e.g. bucket.md or static-site.md",
        ),
        category: type("'Resource'|'Client'|'Utility'|'Types'").describe(
          "The classification of the Resource's Document, one of: Resource, Client, Utility, or Types.",
        ),
      }).array(),
    }),
    system: await alchemy`
      You are a technical writer tasked with identifying the distinct documents that need to be written for a document group (folder) in a documentation site.
      You will be provided with a list of documents and instructions on how to classify them.
      Each document has a title, file name, and category.
    `,
    prompt: await alchemy`
      Identify and classify the documents that need to be written for the '${provider}' Service's Alchemy Resources.
      For background knowledge on Alchemy, see ${alchemy.file("./README.md")}.
      For background knowledge on the structure of an Alchemy Resource, see ${alchemy.file("./.cursorrules")}.
      The ${provider} Service has the following resources:
      ${alchemy.files(files)}
      A file is considered a "Resource" if it contains a const <ResourceName> = Resource(...) call or if it is a function that calls a Resource function, e.g. const TypeScriptFile = () => File(...), or it is the Workflow or DurableObject classes.
      A file is considered a "Client" if it exposes a wrapper around creating a SDK client or fetch.
      A file is considered a "Utility" if it contains utility functions that are not resources or clients.
      A file is considered a "Types" if it contains just type definitions and maybe helpers around working with those types.
      The title should be simply the name of the resource's const in code (with spaces added in between each word), e.g. "Bucket" or "Function", except with spaces, e.g. "StaticSite" for "const StaticSite". Maintain all other casing.
      // "Resource Name"
      const ResourceName = Resource(...)
    `,
  });
  const providerDocsDir = (await Folder(path.join(outDir, providerName))).path;
  let documents: Document[] = [];
  if (parallel) {
    documents = await Promise.all(
      groups.filter((g) => g.category === "Resource").map(generateDocument),
    );
  } else {
    for (const g of groups.filter((g) => g.category === "Resource")) {
      documents.push(await generateDocument(g));
    }
  }
  async function generateDocument(g: Group) {
    return Document(`docs/${providerName}/${g.identifier}`, {
      title: g.identifier,
      path: path.join(
        providerDocsDir,
        `${g.filename.replace(".ts", "").replace(".md", "")}.md`,
      ),
      freeze:
        onlyResourceName !== undefined && onlyResourceName !== g.identifier,
      model: {
        id: "claude-3-5-sonnet-latest",
        provider: "anthropic",
        // options: {
        //   reasoningEffort: "high",
        // },
      },
      prompt: await alchemy`
        You are a technical writer writing API documentation for an Alchemy IaC Resource.
        See ${alchemy.file("./README.md")} to understand the overview of Alchemy.
        See ${alchemy.file("./.cursorrules")} to better understand the structure and convention of an Alchemy Resource.
        Relevant files for the ${providerName} Service:
        ${alchemy.files(files)}
        Write concise documentation for the "${g.identifier}" Resource.
        > [!CAUTION]
        > Avoid the temptation to over explain or over describe. Focus on concise, simple, high value snippets. One heading and 0-1 descriptions per snippet.
        > [!TIP]
        > Make sure the examples follow a natural progression from the minimal example to logical next steps of how the Resource might be used.
        Each document must follow the following format:
        # ${g.identifier}
        (simple description with an external link to the provider's website)
        e.g.
        The Efs component lets you add [Amazon Elastic File System (EFS)](https://docs.aws.amazon.com/efs/latest/ug/whatisefs.html) to your app.
        # Minimal Example
        (brief 1-2 sentences of what it does)
        \`\`\`ts
        import { ${g.identifier.replaceAll(" ", "")} } from "alchemy/${providerName}";
        (example)
        \`\`\`
        # (one heading per variation)
        (brief 1-2 sentences of what it does)
        \`\`\`ts
        import { ${g.identifier.replaceAll(" ", "")} } from "alchemy/${providerName}";
        (example)
        \`\`\`
        Before writing the document, think through:
        1. What is the minimal, most common example use case for this resource?
        2. What are the variations (e.g. combination of different options) that are also commonly used, e.g. specifying the memory size of a lambda function.
        3. Make sure to draw from the examples and your understanding of Alchemy.
        Refer to alchemy docs to understand the context of how this documentation is consumed:
        - ${alchemy.file("./alchemy-web/docs/what-is-alchemy.md")}
        - ${alchemy.file("./alchemy-web/docs/getting-started.md")}
        - ${alchemy.folder("./alchemy-web/docs/concepts/")}
        ${
          providerName === "cloudflare"
            ? await alchemy`# Bind to a Worker
        (if it is a Cloudflare Resource)
        (brief 1-2 sentences of what it does)
        \`\`\`ts
        import { Worker, ${g.identifier.replaceAll(" ", "")} } from "alchemy/${providerName}";
        const myResource = await ${g.identifier.replaceAll(" ", "")}("my-resource", {
          // ...
        });
        await Worker("my-worker", {
          name: "my-worker",
          script: "console.log('Hello, world!')",
          bindings: {
            myResource,
          },
        });
        \`\`\``
            : ""
        }
      `,
    });
  }
  return {
    dir: providerDocsDir,
    provider: providerName,
    documents,
  };
}
</file>

<file path="alchemy/src/neon/api-error.ts">
/**
 * Error class for Neon API errors
 */
export class NeonApiError extends Error {
  /**
   * HTTP status code
   */
  public readonly status: number;
  /**
   * HTTP status text
   */
  public readonly statusText: string;
  /**
   * Error data from the API response
   */
  public readonly errorData?: any;
  /**
   * Create a new NeonApiError
   */
  constructor(message: string, response: Response, errorData?: any) {
    super(message);
    this.name = "NeonApiError";
    this.status = response.status;
    this.statusText = response.statusText;
    this.errorData = errorData;
    // Capture stack trace
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, NeonApiError);
    }
  }
}
/**
 * Handle API errors and throw NeonApiError with context
 *
 * @param response Response object from fetch
 * @param action Action that was being performed
 * @param resourceType Type of resource
 * @param resourceId ID of the resource
 */
export async function handleApiError(
  response: Response,
  action: "get" | "create" | "update" | "delete" | "list",
  resourceType: string,
  resourceId?: string,
): Promise<never> {
  const resourceDisplay = resourceId ? `'${resourceId}'` : "";
  let errorData: any;
  try {
    errorData = await response.json();
  } catch (e) {
    // If we can't parse JSON, just use the response text
    try {
      errorData = { message: await response.text() };
    } catch (textError) {
      errorData = { message: response.statusText };
    }
  }
  let message = `Error ${action} ${resourceType} ${resourceDisplay}: `;
  if (errorData?.error?.message) {
    message += errorData.error.message;
  } else if (errorData?.message) {
    message += errorData.message;
  } else if (errorData?.error) {
    message +=
      typeof errorData.error === "string"
        ? errorData.error
        : JSON.stringify(errorData.error);
  } else {
    message += response.statusText;
  }
  throw new NeonApiError(message, response, errorData);
}
</file>

<file path="alchemy/src/neon/api.ts">
import type { Secret } from "../secret.js";
import { withExponentialBackoff } from "../util/retry.js";
/**
 * Options for Neon API requests
 */
export interface NeonApiOptions {
  /**
   * Base URL for Neon API
   * @default https://console.neon.tech/api/v2
   */
  baseUrl?: string;
  /**
   * API Key to use (overrides NEON_API_KEY env var)
   */
  apiKey?: Secret;
}
/**
 * Create a NeonApi instance with environment variable fallback
 * @param options API options
 * @returns NeonApi instance
 */
export function createNeonApi(options: Partial<NeonApiOptions> = {}): NeonApi {
  return new NeonApi({
    baseUrl: options.baseUrl,
    apiKey: options.apiKey,
  });
}
/**
 * Get authentication headers for Neon API
 * @param options NeonApiOptions
 * @returns Headers for authentication
 */
export async function getNeonAuthHeaders(
  options: Partial<NeonApiOptions>,
): Promise<Record<string, string>> {
  const apiKey = options.apiKey?.unencrypted ?? process.env.NEON_API_KEY;
  if (!apiKey) {
    throw new Error(
      "Neon API key is required. Set NEON_API_KEY environment variable or provide apiKey option.",
    );
  }
  return {
    "Content-Type": "application/json",
    Accept: "application/json",
    Authorization: `Bearer ${apiKey}`,
  };
}
/**
 * Neon API client using raw fetch
 */
export class NeonApi {
  public readonly baseUrl: string;
  /**
   * Create a new Neon API client
   * Use createNeonApi factory function instead of direct constructor
   *
   * @param options API options
   */
  constructor(private readonly options: NeonApiOptions) {
    this.baseUrl = options.baseUrl ?? "https://console.neon.tech/api/v2";
  }
  /**
   * Make a fetch request to the Neon API
   *
   * @param path API path (without base URL)
   * @param init Fetch init options
   * @returns Raw Response object from fetch
   */
  async fetch(path: string, init: RequestInit = {}): Promise<Response> {
    let headers: Record<string, string> = {};
    if (Array.isArray(init.headers)) {
      init.headers.forEach(([key, value]) => {
        headers[key] = value;
      });
    } else if (init.headers instanceof Headers) {
      init.headers.forEach((value, key) => {
        headers[key] = value;
      });
    } else if (init.headers) {
      headers = init.headers as Record<string, string>;
    }
    headers = {
      ...(await getNeonAuthHeaders(this.options)),
      ...headers,
    };
    // Use withExponentialBackoff for automatic retry on network errors
    return withExponentialBackoff(
      () =>
        fetch(`${this.baseUrl}${path}`, {
          ...init,
          headers,
        }),
      (error) => {
        // Only retry on network-related errors
        const errorMsg = (error as Error).message || "";
        const isNetworkError =
          errorMsg.includes("socket connection was closed") ||
          errorMsg.includes("ECONNRESET") ||
          errorMsg.includes("ETIMEDOUT") ||
          errorMsg.includes("ECONNREFUSED");
        return isNetworkError || error?.status?.toString().startsWith("5");
      },
      5, // Maximum 5 attempts (1 initial + 4 retries)
      1000, // Start with 1s delay, will exponentially increase
    );
  }
  /**
   * Helper for GET requests
   */
  async get(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "GET" });
  }
  /**
   * Helper for POST requests
   */
  async post(
    path: string,
    body: any,
    init: RequestInit = {},
  ): Promise<Response> {
    const requestBody =
      body instanceof FormData
        ? body
        : typeof body === "string"
          ? body
          : JSON.stringify(body);
    return this.fetch(path, { ...init, method: "POST", body: requestBody });
  }
  /**
   * Helper for PUT requests
   */
  async put(
    path: string,
    body: any,
    init: RequestInit = {},
  ): Promise<Response> {
    const requestBody = body instanceof FormData ? body : JSON.stringify(body);
    return this.fetch(path, { ...init, method: "PUT", body: requestBody });
  }
  /**
   * Helper for PATCH requests
   */
  async patch(
    path: string,
    body: any,
    init: RequestInit = {},
  ): Promise<Response> {
    return this.fetch(path, {
      ...init,
      method: "PATCH",
      body: JSON.stringify(body),
    });
  }
  /**
   * Helper for DELETE requests
   */
  async delete(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "DELETE" });
  }
}
</file>

<file path="alchemy/src/neon/index.ts">
export * from "./api-error.js";
export * from "./api.js";
export * from "./project.js";
</file>

<file path="alchemy/src/neon/project.ts">
import { alchemy } from "../alchemy.js";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import type { Secret } from "../secret.js";
import { handleApiError } from "./api-error.js";
import { createNeonApi, type NeonApiOptions } from "./api.js";
/**
 * A Neon region where projects can be provisioned
 */
export type NeonRegion =
  | "aws-us-east-1"
  | "aws-us-east-2"
  | "aws-us-west-2"
  | "aws-eu-central-1"
  | "aws-eu-west-2"
  | "aws-ap-southeast-1"
  | "aws-ap-southeast-2"
  | "aws-sa-east-1"
  | "azure-eastus2"
  | "azure-westus3"
  | "azure-gwc";
/**
 * Properties for creating or updating a Neon project
 */
export interface NeonProjectProps extends NeonApiOptions {
  /**
   * Name of the project
   */
  name: string;
  /**
   * Region where the project will be provisioned
   * @default "aws-us-east-1"
   */
  region_id?: NeonRegion;
  /**
   * PostgreSQL version to use
   * @default 16
   */
  pg_version?: 14 | 15 | 16 | 17;
  /**
   * Whether to create a default branch and endpoint
   * @default true
   */
  default_endpoint?: boolean;
  /**
   * Default branch name
   * @default "main"
   */
  default_branch_name?: string;
  /**
   * Existing project ID to update
   * Used internally during update operations
   * @internal
   */
  existing_project_id?: string;
}
/**
 * A Neon database
 */
export interface NeonDatabase {
  /**
   * Database ID
   */
  id: number;
  /**
   * ID of the branch this database belongs to
   */
  branch_id: string;
  /**
   * Database name
   */
  name: string;
  /**
   * Name of the database owner role
   */
  owner_name: string;
  /**
   * Time at which the database was created
   */
  created_at: string;
  /**
   * Time at which the database was last updated
   */
  updated_at: string;
}
/**
 * A Neon database role
 */
export interface NeonRole {
  /**
   * ID of the branch this role belongs to
   */
  branch_id: string;
  /**
   * Role name
   */
  name: string;
  /**
   * Role password (only included during creation)
   */
  password?: string;
  /**
   * Whether this role is protected from deletion
   */
  protected: boolean;
  /**
   * Time at which the role was created
   */
  created_at: string;
  /**
   * Time at which the role was last updated
   */
  updated_at: string;
}
/**
 * A Neon branch
 */
export interface NeonBranch {
  /**
   * Branch ID
   */
  id: string;
  /**
   * ID of the project this branch belongs to
   */
  project_id: string;
  /**
   * Branch name
   */
  name: string;
  /**
   * Current state of the branch
   */
  current_state: string;
  /**
   * Pending state of the branch
   */
  pending_state: string;
  /**
   * Time at which the branch was created
   */
  created_at: string;
  /**
   * Time at which the branch was last updated
   */
  updated_at: string;
}
/**
 * A Neon compute endpoint
 */
export interface NeonEndpoint {
  /**
   * Endpoint ID
   */
  id: string;
  /**
   * Host for connecting to this endpoint
   */
  host: string;
  /**
   * ID of the project this endpoint belongs to
   */
  project_id: string;
  /**
   * ID of the branch this endpoint belongs to
   */
  branch_id: string;
  /**
   * Endpoint type (read_write, read_only)
   */
  type: string;
  /**
   * Current state of the endpoint
   */
  current_state: string;
  /**
   * Pending state of the endpoint
   */
  pending_state: string;
  /**
   * Region ID where this endpoint is provisioned
   */
  region_id: string;
  /**
   * Minimum compute units for autoscaling
   */
  autoscaling_limit_min_cu: number;
  /**
   * Maximum compute units for autoscaling
   */
  autoscaling_limit_max_cu: number;
  /**
   * Whether connection pooler is enabled
   */
  pooler_enabled: boolean;
  /**
   * Connection pooler mode
   */
  pooler_mode: string;
  /**
   * Whether this endpoint is disabled
   */
  disabled: boolean;
  /**
   * Whether passwordless access is enabled
   */
  passwordless_access: boolean;
  /**
   * Time at which the endpoint was created
   */
  created_at: string;
  /**
   * Time at which the endpoint was last updated
   */
  updated_at: string;
  /**
   * Proxy host for this endpoint
   */
  proxy_host: string;
  /**
   * Endpoint settings
   */
  settings: {
    /**
     * PostgreSQL settings
     */
    pg_settings: Record<string, any>;
  };
}
/**
 * A Neon connection URI
 */
export interface NeonConnectionUri {
  /**
   * Connection URI string
   */
  connection_uri: Secret;
  /**
   * Connection parameters
   */
  connection_parameters: {
    database: string;
    host: string;
    port: number;
    user: string;
    password: Secret;
  };
}
/**
 * A Neon operation
 */
export interface NeonOperation {
  /**
   * Operation ID
   */
  id: string;
  /**
   * ID of the project this operation belongs to
   */
  project_id: string;
  /**
   * ID of the branch this operation affects, if applicable
   */
  branch_id?: string;
  /**
   * ID of the endpoint this operation affects, if applicable
   */
  endpoint_id?: string;
  /**
   * Action being performed
   */
  action: string;
  /**
   * Current status of the operation
   */
  status: string;
  /**
   * Number of failures encountered
   */
  failures_count: number;
  /**
   * Time at which the operation was created
   */
  created_at: string;
  /**
   * Time at which the operation was last updated
   */
  updated_at: string;
}
/**
 * API response structure for Neon projects
 */
interface NeonApiResponse {
  project: {
    id: string;
    name: string;
    region_id: string;
    pg_version: number;
    created_at: string;
    updated_at: string;
    proxy_host?: string;
    [key: string]: any;
  };
  connection_uris?: Array<{
    connection_uri: string;
    connection_parameters: {
      database: string;
      host: string;
      port: number;
      user: string;
      password: string;
    };
  }>;
  roles?: Array<{
    branch_id: string;
    name: string;
    password?: string;
    protected: boolean;
    created_at: string;
    updated_at: string;
  }>;
  databases?: Array<{
    id: number;
    branch_id: string;
    name: string;
    owner_name: string;
    created_at: string;
    updated_at: string;
  }>;
  operations?: Array<{
    id: string;
    project_id: string;
    branch_id?: string;
    endpoint_id?: string;
    action: string;
    status: string;
    failures_count: number;
    created_at: string;
    updated_at: string;
  }>;
  branch?: {
    id: string;
    project_id: string;
    name: string;
    current_state: string;
    pending_state: string;
    created_at: string;
    updated_at: string;
  };
  endpoints?: Array<{
    id: string;
    host: string;
    project_id: string;
    branch_id: string;
    type: string;
    current_state: string;
    pending_state: string;
    region_id: string;
    autoscaling_limit_min_cu: number;
    autoscaling_limit_max_cu: number;
    pooler_enabled: boolean;
    pooler_mode: string;
    disabled: boolean;
    passwordless_access: boolean;
    created_at: string;
    updated_at: string;
    proxy_host: string;
    settings: {
      pg_settings: Record<string, any>;
    };
  }>;
}
/**
 * Output returned after Neon project creation/update
 * IMPORTANT: The interface name MUST match the exported resource name
 */
export interface NeonProject
  extends Resource<"neon::Project">,
    Omit<NeonProjectProps, "apiKey" | "existing_project_id"> {
  /**
   * The ID of the project
   */
  id: string;
  /**
   * Time at which the project was created
   */
  created_at: string;
  /**
   * Time at which the project was last updated
   */
  updated_at: string;
  /**
   * Hostname for proxy access
   */
  proxy_host?: string;
  /**
   * Connection URIs for the databases
   */
  connection_uris: [NeonConnectionUri, ...NeonConnectionUri[]];
  /**
   * Database roles created with the project
   */
  roles: [NeonRole, ...NeonRole[]];
  /**
   * Databases created with the project
   */
  databases?: [NeonDatabase, ...NeonDatabase[]];
  /**
   * Default branch information
   */
  branch?: NeonBranch;
  /**
   * Compute endpoints for the project
   */
  endpoints: [NeonEndpoint, ...NeonEndpoint[]];
}
/**
 * Creates a Neon serverless PostgreSQL project.
 *
 * @example
 * // Create a basic Neon project with default settings:
 * const project = await NeonProject("my-project", {
 *   name: "My Project"
 * });
 *
 * @example
 * // Create a Neon project in a specific region with a specific PostgreSQL version:
 * const euProject = await NeonProject("my-eu-project", {
 *   name: "My EU Project",
 *   region_id: "aws-eu-west-1",
 *   pg_version: 16,
 *   apiKey: alchemy.secret(process.env.NEON_API_KEY)
 * });
 *
 * @example
 * // Create a Neon project with a custom default branch name:
 * const devProject = await NeonProject("dev-project", {
 *   name: "Development Project",
 *   default_branch_name: "development"
 * });
 */
export const NeonProject = Resource(
  "neon::Project",
  async function (
    this: Context<NeonProject>,
    id: string,
    props: NeonProjectProps,
  ): Promise<NeonProject> {
    const api = createNeonApi(props);
    const projectId = props.existing_project_id || this.output?.id;
    if (this.phase === "delete") {
      try {
        // Check if the project exists before attempting to delete
        if (projectId) {
          const deleteResponse = await api.delete(`/projects/${projectId}`);
          if (!deleteResponse.ok && deleteResponse.status !== 404) {
            await handleApiError(deleteResponse, "delete", "project", id);
          }
        }
      } catch (error) {
        console.error(`Error deleting Neon project ${id}:`, error);
        throw error;
      }
      return this.destroy();
    }
    let response: NeonApiResponse;
    try {
      if (this.phase === "update" && projectId) {
        // Update existing project
        // Neon only allows updating the project name
        const projectResponse = await api.patch(`/projects/${projectId}`, {
          project: {
            name: props.name,
          },
        });
        if (!projectResponse.ok) {
          await handleApiError(projectResponse, "update", "project", id);
        }
        const initialData = await projectResponse.json();
        // Reify project properties to get complete data
        response = await getProject(
          api,
          projectId,
          initialData as Partial<NeonApiResponse>,
        );
      } else {
        // Check if a project with this ID already exists
        if (projectId) {
          const getResponse = await api.get(`/projects/${projectId}`);
          if (getResponse.ok) {
            // Project exists, update it
            const projectResponse = await api.patch(`/projects/${projectId}`, {
              project: {
                name: props.name,
              },
            });
            if (!projectResponse.ok) {
              await handleApiError(projectResponse, "update", "project", id);
            }
            const initialData = await projectResponse.json();
            // Reify project properties to get complete data
            response = await getProject(
              api,
              projectId,
              initialData as Partial<NeonApiResponse>,
            );
          } else if (getResponse.status !== 404) {
            // Unexpected error during GET check
            await handleApiError(getResponse, "get", "project", id);
            throw new Error("Failed to check if project exists");
          } else {
            // Project doesn't exist, create new
            response = await createNewProject(api, props);
          }
        } else {
          // No output ID, create new project
          response = await createNewProject(api, props);
        }
      }
      // Wait for any pending operations to complete
      if (response.operations && response.operations.length > 0) {
        await waitForOperations(api, response.operations);
      }
      // Get the latest project state after operations complete
      if (response.project?.id) {
        // Reify project properties to get complete data
        response = await getProject(api, response.project.id, response);
      }
      return this({
        id: response.project.id,
        name: response.project.name,
        region_id: response.project.region_id as NeonRegion,
        pg_version: response.project.pg_version as 14 | 15 | 16 | 17,
        created_at: response.project.created_at,
        updated_at: response.project.updated_at,
        proxy_host: response.project.proxy_host,
        // Pass through the provided props except apiKey (which is sensitive)
        default_endpoint: props.default_endpoint,
        default_branch_name: props.default_branch_name,
        baseUrl: props.baseUrl,
        // Add all available data
        // @ts-ignore - api ensures they're non-empty
        connection_uris: response.connection_uris,
        // @ts-ignore
        roles: response.roles,
        // @ts-ignore
        databases: response.databases,
        // @ts-ignore
        branch: response.branch,
        // @ts-ignore
        endpoints: response.endpoints,
      });
    } catch (error) {
      console.error(`Error ${this.phase} Neon project '${id}':`, error);
      throw error;
    }
  },
);
/**
 * Helper function to create a new Neon project
 */
async function createNewProject(
  api: any,
  props: NeonProjectProps,
): Promise<NeonApiResponse> {
  const defaultEndpoint = props.default_endpoint ?? true;
  const projectResponse = await api.post("/projects", {
    project: {
      name: props.name,
      region_id: props.region_id || "aws-us-east-1",
      pg_version: props.pg_version || 16,
      default_endpoint: defaultEndpoint,
      branch: defaultEndpoint
        ? { name: props.default_branch_name || "main" }
        : undefined,
    },
  });
  if (!projectResponse.ok) {
    await handleApiError(projectResponse, "create", "project");
  }
  return (await projectResponse.json()) as NeonApiResponse;
}
/**
 * Helper function to get complete project details by fetching all related data
 *
 * @param api The Neon API client
 * @param projectId The project ID
 * @param initialData Initial project data (optional)
 * @returns Complete project data with all related resources
 */
async function getProject(
  api: any,
  projectId: string,
  initialData: Partial<NeonApiResponse> = {},
): Promise<NeonApiResponse> {
  // Get the latest project details
  const updatedData = await getProjectDetails(api, projectId);
  // Start with a copy of the initial data
  const responseData = { ...initialData };
  // Check if we have a branch ID from the initial data
  const branchId = initialData.branch?.id;
  if (branchId) {
    // Get the branch details
    const branchData = await getBranchDetails(api, projectId, branchId);
    // Update with the latest branch data
    responseData.branch = branchData.branch;
    // Also fetch the latest endpoint details for this branch
    const endpointData = await getEndpointDetails(api, projectId, branchId);
    // Update with the latest endpoint data if available
    if (endpointData.endpoints && endpointData.endpoints.length > 0) {
      responseData.endpoints = endpointData.endpoints;
    }
  }
  // Preserve all data from the original response
  // Only update properties that might have changed during operations
  return {
    ...responseData,
    connection_uris: (
      updatedData.connection_uris || responseData.connection_uris
    )?.map((uri) => ({
      connection_uri: alchemy.secret(uri.connection_uri),
      connection_parameters: {
        database: uri.connection_parameters.database,
        host: uri.connection_parameters.host,
        port: uri.connection_parameters.port ?? 5432,
        user: uri.connection_parameters.user ?? "neondb_owner",
        password: alchemy.secret(uri.connection_parameters.password),
      },
    })),
    project: updatedData.project,
    branch: updatedData.branch || responseData.branch,
    endpoints: updatedData.endpoints || responseData.endpoints,
  } as NeonApiResponse;
}
/**
 * Wait for operations to complete
 *
 * @param api The Neon API client
 * @param operations Operations to wait for
 * @throws Error if an operation fails or times out
 * @returns Promise that resolves when all operations complete
 */
async function waitForOperations(
  api: any,
  operations: Array<{
    id: string;
    project_id: string;
    status: string;
    action: string;
  }>,
): Promise<void> {
  const pendingOperations = operations.filter(
    (op) => op.status !== "finished" && op.status !== "failed",
  );
  if (pendingOperations.length === 0) {
    return;
  }
  // Maximum wait time in milliseconds (5 minutes)
  const maxWaitTime = 5 * 60 * 1000;
  // Initial delay between retries in milliseconds
  const initialRetryDelay = 500;
  // Maximum delay between retries
  const maxRetryDelay = 10000;
  // Backoff factor for exponential backoff
  const backoffFactor = 1.5;
  for (const operation of pendingOperations) {
    let totalWaitTime = 0;
    let retryDelay = initialRetryDelay;
    let operationStatus = operation.status;
    while (
      operationStatus !== "finished" &&
      operationStatus !== "failed" &&
      totalWaitTime < maxWaitTime
    ) {
      // Wait before checking again with exponential backoff
      await new Promise((resolve) => setTimeout(resolve, retryDelay));
      totalWaitTime += retryDelay;
      // Increase delay for next retry with exponential backoff, up to max
      retryDelay = Math.min(retryDelay * backoffFactor, maxRetryDelay);
      // Check operation status
      const operationResponse = await api.get(
        `/projects/${operation.project_id}/operations/${operation.id}`,
      );
      if (operationResponse.ok) {
        const operationData = await operationResponse.json();
        operationStatus = operationData.operation?.status;
      } else {
        throw new Error(
          `Failed to check operation ${operation.id} status: HTTP ${operationResponse.status}`,
        );
      }
    }
    if (operationStatus === "failed") {
      throw new Error(`Operation ${operation.id} (${operation.action}) failed`);
    }
    if (totalWaitTime >= maxWaitTime) {
      throw new Error(
        `Timeout waiting for operation ${operation.id} (${operation.action}) to complete`,
      );
    }
  }
  // Explicitly return when all operations are complete
  return;
}
/**
 * Get the latest project details
 *
 * @param api The Neon API client
 * @param projectId The project ID
 * @returns Project details including branch and endpoints
 * @throws Error if project details cannot be retrieved
 */
async function getProjectDetails(
  api: any,
  projectId: string,
): Promise<NeonApiResponse> {
  const response = await api.get(`/projects/${projectId}`);
  if (!response.ok) {
    throw new Error(`Failed to get project details: HTTP ${response.status}`);
  }
  return (await response.json()) as NeonApiResponse;
}
/**
 * Get the latest branch details
 *
 * @param api The Neon API client
 * @param projectId The project ID
 * @param branchId The branch ID
 * @returns Branch details
 * @throws Error if branch details cannot be retrieved
 */
async function getBranchDetails(
  api: any,
  projectId: string,
  branchId: string,
): Promise<{ branch: NeonBranch }> {
  const response = await api.get(`/projects/${projectId}/branches/${branchId}`);
  if (!response.ok) {
    throw new Error(`Failed to get branch details: HTTP ${response.status}`);
  }
  return (await response.json()) as { branch: NeonBranch };
}
/**
 * Get the latest endpoint details for a branch
 *
 * @param api The Neon API client
 * @param projectId The project ID
 * @param branchId The branch ID
 * @returns Endpoint details for the branch
 * @throws Error if endpoint details cannot be retrieved
 */
async function getEndpointDetails(
  api: any,
  projectId: string,
  branchId: string,
): Promise<{ endpoints: NeonEndpoint[] }> {
  const response = await api.get(
    `/projects/${projectId}/branches/${branchId}/endpoints`,
  );
  if (!response.ok) {
    throw new Error(`Failed to get endpoint details: HTTP ${response.status}`);
  }
  return (await response.json()) as { endpoints: NeonEndpoint[] };
}
</file>

<file path="alchemy/src/os/exec.ts">
import { spawn, type SpawnOptions } from "node:child_process";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
/**
 * Properties for executing a shell command
 */
export interface ExecProps {
  /**
   * The command to execute (including any arguments)
   */
  command: string;
  /**
   * Whether to memoize the command (only re-run if the command changes)
   *
   * @default false
   */
  memoize?: boolean;
  /**
   * Working directory for the command
   */
  cwd?: string;
  /**
   * Environment variables to set
   */
  env?: Record<string, string>;
  /**
   * Whether to inherit stdio from parent process
   * @default true
   */
  inheritStdio?: boolean;
}
/**
 * Output returned after command execution
 */
export interface Exec extends Resource<"os::Exec">, ExecProps {
  /**
   * Unique identifier for this execution
   */
  id: string;
  /**
   * Exit code of the command
   */
  exitCode: number;
  /**
   * Standard output from the command (only available when inheritStdio is false)
   */
  stdout: string;
  /**
   * Standard error from the command (only available when inheritStdio is false)
   */
  stderr: string;
  /**
   * Time at which the command was executed
   */
  executedAt: number;
  /**
   * Whether the command has completed execution
   */
  completed: boolean;
}
/**
 * Execute a shell command
 *
 * @example
 * // Run a simple command with inherited stdio (default)
 * const result = await Exec("list-files", {
 *   command: "ls -la"
 * });
 *
 * @example
 * // Run a command and capture output instead of inheriting stdio
 * const result = await Exec("list-files", {
 *   command: "ls -la",
 *   inheritStdio: false
 * });
 *
 * console.log(result.stdout);
 *
 * @example
 * // Run a command in a specific directory with custom environment
 * const build = await Exec("build-project", {
 *   command: "npm run build",
 *   cwd: "./my-project",
 *   env: { NODE_ENV: "production" }
 * });
 *
 * @example
 * // Run a memoized command that only re-executes when the command changes
 * const memoizedCmd = await Exec("status-check", {
 *   command: "git status",
 *   memoize: true
 * });
 *
 * // This won't actually run the command again if nothing has changed
 * await Exec("status-check", {
 *   command: "git status",
 *   memoize: true
 * });
 */
export const Exec = Resource(
  "os::Exec",
  {
    alwaysUpdate: true,
  },
  async function (
    this: Context<Exec>,
    id: string,
    props: ExecProps,
  ): Promise<Exec> {
    if (this.phase === "delete") {
      // Nothing to actually delete for an exec command
      return this.destroy();
    }
    if (
      this.phase === "update" &&
      props.memoize &&
      this.output?.command === props.command
    ) {
      // If memoize is enabled and the command hasn't changed, return the existing output
      return this.output;
    }
    // Default values
    let stdout = "";
    let stderr = "";
    let exitCode = 0;
    // Default to inheriting stdio unless explicitly set to false
    const inheritStdio = props.inheritStdio !== false;
    try {
      // Parse the command into command and args
      const [cmd, ...args] = props.command.split(/\s+/);
      // Use spawn for better stdio control
      const childProcess = spawn(cmd, args, {
        cwd: props.cwd || process.cwd(),
        env: { ...process.env, ...props.env },
        shell: true, // Use shell to handle complex commands
        stdio: inheritStdio ? "inherit" : "pipe", // Inherit stdio when requested
      });
      if (!inheritStdio) {
        // If not inheriting stdio, collect output manually
        childProcess.stdout?.on("data", (data) => {
          stdout += data.toString();
        });
        childProcess.stderr?.on("data", (data) => {
          stderr += data.toString();
        });
      }
      // Wait for the process to complete
      exitCode = await new Promise<number>((resolve, reject) => {
        childProcess.on("close", (code) => {
          resolve(code || 0);
        });
        childProcess.on("error", (err) => {
          stderr += err.toString();
          resolve(1);
        });
      });
    } catch (error: any) {
      // If not throwing, capture the error information
      exitCode = 1;
      stderr += String(error);
    }
    if (exitCode !== 0) {
      throw new Error(
        `Command failed with exit code ${exitCode}: ${props.command}\n${stderr}`,
      );
    }
    // Return the execution result
    return this({
      id,
      command: props.command,
      cwd: props.cwd,
      env: props.env,
      memoize: props.memoize,
      inheritStdio,
      exitCode,
      stdout,
      stderr,
      executedAt: Date.now(),
      completed: true,
    });
  },
);
const defaultOptions: SpawnOptions = {
  stdio: "inherit",
  env: {
    ...process.env,
  },
  shell: true,
};
/**
 * Execute a shell command.
 */
export async function exec(
  command: string,
  options?: Partial<SpawnOptions>,
): Promise<void> {
  const [cmd, ...args] = command.split(/\s+/);
  return new Promise((resolve, reject) => {
    const child = spawn(cmd, args, {
      ...defaultOptions,
      ...options,
      env: {
        ...defaultOptions.env,
        ...options?.env,
      },
    });
    child.on("close", (code) => {
      if (code === 0) {
        resolve();
      } else {
        reject(new Error(`Command failed with exit code ${code}`));
      }
    });
    child.on("error", (err) => {
      reject(err);
    });
  });
}
</file>

<file path="alchemy/src/os/index.ts">
export * from "./exec.js";
</file>

<file path="alchemy/src/stripe/product.ts">
import Stripe from "stripe";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
type ProductType = Stripe.Product.Type;
/**
 * Properties for creating a Stripe product
 */
export interface ProductProps {
  /**
   * The product's name
   */
  name: string;
  /**
   * The product's description
   */
  description?: string;
  /**
   * Whether the product is active
   */
  active?: boolean;
  /**
   * A list of up to 8 URLs of images for this product
   */
  images?: string[];
  /**
   * A URL of the product's thumbnail
   */
  url?: string;
  /**
   * Whether this product is shipped (physical goods)
   */
  shippable?: boolean;
  /**
   * Product type: good, service
   */
  type?: ProductType;
  /**
   * Unit label to use on invoices
   */
  unitLabel?: string;
  /**
   * A label for the product to be displayed on Checkout
   */
  statementDescriptor?: string;
  /**
   * Set of key-value pairs for this product
   */
  metadata?: Record<string, string>;
  /**
   * Default tax code for the product
   */
  taxCode?: string;
}
/**
 * Output from the Stripe product
 */
export interface Product extends Resource<"stripe::Product">, ProductProps {
  /**
   * The ID of the product
   */
  id: string;
  /**
   * Time at which the object was created
   */
  createdAt: number;
  /**
   * Has the value true if the object exists in live mode or the value false if the object exists in test mode
   */
  livemode: boolean;
  /**
   * Time at which the object was last updated
   */
  updatedAt: number;
  /**
   * Whether this product can be used for Checkout/Payment Links
   */
  packageDimensions?: {
    height: number;
    length: number;
    weight: number;
    width: number;
  };
}
/**
 * Create and manage Stripe products
 *
 * @example
 * // Create a basic digital product
 * const digitalProduct = await Product("basic-software", {
 *   name: "Basic Software License",
 *   description: "Single-user license for basic software package",
 *   metadata: {
 *     type: "digital",
 *     features: "basic"
 *   }
 * });
 *
 * @example
 * // Create a physical product with shipping details
 * const physicalProduct = await Product("premium-hardware", {
 *   name: "Premium Hardware Kit",
 *   description: "Complete hardware kit with premium components",
 *   shippable: true,
 *   images: ["https://example.com/hardware-kit.jpg"],
 *   unitLabel: "kit",
 *   statementDescriptor: "PREMIUM HW KIT"
 * });
 *
 * @example
 * // Create a service product with tax code
 * const serviceProduct = await Product("consulting", {
 *   name: "Professional Consulting",
 *   description: "Expert consulting services",
 *   type: "service",
 *   taxCode: "txcd_10000000",
 *   metadata: {
 *     industry: "technology",
 *     expertise: "cloud"
 *   }
 * });
 */
export const Product = Resource(
  "stripe::Product",
  async function (
    this: Context<Product>,
    id: string,
    props: ProductProps,
  ): Promise<Product> {
    // Get Stripe API key from context or environment
    const apiKey = process.env.STRIPE_API_KEY;
    if (!apiKey) {
      throw new Error("STRIPE_API_KEY environment variable is required");
    }
    // Initialize Stripe client
    const stripe = new Stripe(apiKey);
    if (this.phase === "delete") {
      try {
        if (this.phase === "delete" && this.output?.id) {
          await stripe.products.update(this.output.id, { active: false });
        }
      } catch (error) {
        // Ignore if the product doesn't exist
        console.error("Error deactivating product:", error);
      }
      // Return a minimal output for deleted state
      return this.destroy();
    }
    try {
      let product: Stripe.Product;
      if (this.phase === "update" && this.output?.id) {
        // Update existing product
        product = await stripe.products.update(this.output.id, {
          name: props.name,
          description: props.description,
          active: props.active,
          images: props.images,
          url: props.url,
          statement_descriptor: props.statementDescriptor,
          metadata: props.metadata,
          tax_code: props.taxCode,
        });
      } else {
        // Create new product
        product = await stripe.products.create({
          name: props.name,
          description: props.description,
          active: props.active,
          images: props.images,
          url: props.url,
          shippable: props.shippable,
          type: props.type as Stripe.ProductCreateParams.Type,
          unit_label: props.unitLabel,
          statement_descriptor: props.statementDescriptor,
          metadata: props.metadata,
          tax_code: props.taxCode,
        });
      }
      return this({
        id: product.id,
        name: product.name,
        description: product.description || undefined,
        active: product.active,
        images: product.images || undefined,
        url: product.url || undefined,
        shippable: product.shippable || undefined,
        type: product.type as ProductType,
        unitLabel: product.unit_label || undefined,
        statementDescriptor: product.statement_descriptor || undefined,
        metadata: product.metadata || undefined,
        taxCode:
          typeof product.tax_code === "string" ? product.tax_code : undefined,
        createdAt: product.created,
        livemode: product.livemode,
        updatedAt: product.updated,
        packageDimensions: product.package_dimensions || undefined,
      });
    } catch (error) {
      console.error("Error creating/updating product:", error);
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/stripe/webhook.ts">
import Stripe from "stripe";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
export type EnabledEvent = Stripe.WebhookEndpointUpdateParams.EnabledEvent;
/**
 * Properties for creating a Stripe webhook endpoint
 */
export interface WebhookEndpointProps {
  /**
   * The URL of the webhook endpoint
   */
  url: string;
  /**
   * The list of events to enable for this endpoint
   */
  enabledEvents: EnabledEvent[];
  /**
   * Description of the webhook
   */
  description?: string;
  /**
   * Whether the webhook is active
   */
  active?: boolean;
  /**
   * The API version events are rendered as for this webhook
   */
  apiVersion?: string;
  /**
   * Whether to include mounted endpoint events automatically
   */
  connect?: boolean;
  /**
   * Webhook endpoint metadata
   */
  metadata?: Record<string, string>;
}
/**
 * Output from the Stripe webhook endpoint
 */
export interface WebhookEndpoint
  extends Resource<"stripe::WebhookEndpoint">,
    WebhookEndpointProps {
  /**
   * The ID of the webhook
   */
  id: string;
  /**
   * The webhook endpoint's secret key, used to verify signatures on received events
   */
  secret: string;
  /**
   * The webhook endpoint's application
   */
  application?: string;
  /**
   * Time at which the object was created
   */
  createdAt: number;
  /**
   * Has the value true if the object exists in live mode or the value false if the object exists in test mode
   */
  livemode: boolean;
  /**
   * Time at which the object was last updated
   */
  updatedAt: number;
  /**
   * The status of the webhook
   */
  status: string;
}
/**
 * Create and manage Stripe webhook endpoints
 *
 * @example
 * // Create a basic webhook for payment events
 * const paymentWebhook = await WebhookEndpoint("payment-webhook", {
 *   url: "https://api.example.com/stripe/payments",
 *   enabledEvents: [
 *     "payment_intent.succeeded",
 *     "payment_intent.payment_failed"
 *   ],
 *   description: "Webhook for payment notifications"
 * });
 *
 * @example
 * // Create a webhook for subscription management
 * const subscriptionWebhook = await WebhookEndpoint("subscription-webhook", {
 *   url: "https://api.example.com/stripe/subscriptions",
 *   enabledEvents: [
 *     "customer.subscription.created",
 *     "customer.subscription.updated",
 *     "customer.subscription.deleted",
 *     "invoice.payment_succeeded",
 *     "invoice.payment_failed"
 *   ],
 *   description: "Webhook for subscription lifecycle events"
 * });
 *
 * @example
 * // Create a webhook for Connect platform events
 * const connectWebhook = await WebhookEndpoint("connect-webhook", {
 *   url: "https://api.example.com/stripe/connect",
 *   enabledEvents: [
 *     "account.updated",
 *     "account.application.deauthorized",
 *     "payout.created",
 *     "payout.failed"
 *   ],
 *   connect: true,
 *   metadata: {
 *     platform: "connect",
 *     environment: "production"
 *   }
 * });
 */
export const WebhookEndpoint = Resource(
  "stripe::WebhookEndpoint",
  async function (
    this: Context<WebhookEndpoint>,
    id: string,
    props: WebhookEndpointProps,
  ) {
    // Get Stripe API key from context or environment
    const apiKey = process.env.STRIPE_API_KEY;
    if (!apiKey) {
      throw new Error("STRIPE_API_KEY environment variable is required");
    }
    // Initialize Stripe client
    const stripe = new Stripe(apiKey);
    if (this.phase === "delete") {
      try {
        // Get the webhook ID from the stored output
        if (this.phase === "delete" && this.output?.id) {
          await stripe.webhookEndpoints.del(this.output.id);
        }
      } catch (error) {
        // Ignore if the webhook doesn't exist
        console.error("Error deleting webhook:", error);
      }
      return this.destroy();
    }
    try {
      let webhook: Stripe.WebhookEndpoint;
      if (this.phase === "update" && this.output?.id) {
        // Update existing webhook
        webhook = await stripe.webhookEndpoints.update(this.output.id, {
          url: props.url,
          enabled_events: props.enabledEvents,
          description: props.description,
          disabled: props.active === false,
          metadata: props.metadata,
        });
      } else {
        // Create new webhook
        webhook = await stripe.webhookEndpoints.create({
          url: props.url,
          enabled_events: props.enabledEvents,
          description: props.description,
          metadata: props.metadata,
        });
        // For connect parameter, need to handle it separately if it exists
        if (props.connect !== undefined) {
          // Note: connect is specified at creation time and cannot be updated
          console.log(
            "Note: 'connect' parameter will be applied at creation time only",
          );
        }
      }
      // Store the secret if available
      let secret = "";
      if (webhook.secret) {
        secret = webhook.secret;
      } else if (this.phase === "update" && this.output?.secret) {
        secret = this.output.secret;
      }
      return this({
        id: webhook.id,
        url: webhook.url,
        enabledEvents: webhook.enabled_events as EnabledEvent[],
        description: webhook.description || undefined,
        active: webhook.status === "enabled",
        apiVersion: webhook.api_version || undefined,
        // connect: !!webhook.connect,
        metadata: webhook.metadata || undefined,
        secret: secret,
        application: webhook.application || undefined,
        createdAt: webhook.created,
        livemode: webhook.livemode,
        updatedAt: webhook.created, // Using created timestamp as updated
        status: webhook.status,
      });
    } catch (error) {
      console.error("Error creating/updating webhook:", error);
      throw error;
    }
  },
);
</file>

<file path="alchemy/src/test/bun.ts">
/// <reference types="bun" />
import { afterAll, beforeAll, it } from "bun:test";
import path from "node:path";
import { alchemy } from "../alchemy.js";
import { R2RestStateStore } from "../cloudflare/r2-rest-state-store.js";
import { Scope } from "../scope.js";
import type { StateStoreType } from "../state.js";
/**
 * Extend the Alchemy interface to include test functionality
 */
declare module "../alchemy.js" {
  interface Alchemy {
    test: typeof test;
  }
}
/**
 * Add test functionality to alchemy instance
 */
alchemy.test = test;
/**
 * Options for configuring test behavior
 */
export interface TestOptions {
  /**
   * Whether to suppress logging output.
   * @default false.
   */
  quiet?: boolean;
  /**
   * Password to use for test resources.
   * @default "test-password".
   */
  password?: string;
  /**
   * Override the default state store for the test.
   */
  stateStore?: StateStoreType;
  /**
   * Prefix to use for the scope to isolate tests and environments.
   */
  prefix?: string;
}
/**
 * Test function type definition with overloads
 */
type test = {
  /**
   * Create a test with default options
   * @param name Test name
   * @param fn Test function
   * @param timeout Optional timeout in milliseconds
   */
  (name: string, fn: (scope: Scope) => Promise<any>, timeout?: number): void;
  /**
   * Create a test with custom options
   * @param name Test name
   * @param options Test configuration options
   * @param fn Test function
   * @param timeout Optional timeout in milliseconds
   */
  (
    name: string,
    options: TestOptions,
    fn: (scope: Scope) => Promise<any>,
    timeout?: number,
  ): void;
  /**
   * Skip test conditionally
   * @param condition If true, test will be skipped
   */
  skipIf(condition: boolean): test;
  beforeAll(fn: (scope: Scope) => Promise<void>): void;
  afterAll(fn: (scope: Scope) => Promise<void>): void;
  /**
   * Current test scope
   */
  scope: Scope;
};
/**
 * Creates a test helper function that provides scoped resource management
 *
 * @param meta Import meta object from the test file
 * @param defaultOptions Default options to apply to all tests
 * @returns Test function with scope management
 *
 * @example
 * ```typescript
 * const test = alchemy.test(import.meta);
 *
 * describe("My Resource", () => {
 *   test("create and delete", async (scope) => {
 *     try {
 *       const resource = await MyResource("test", { ... });
 *       expect(resource.id).toBeTruthy();
 *     } finally {
 *       await alchemy.destroy(scope);
 *     }
 *   });
 * });
 * ```
 */
export function test(meta: ImportMeta, defaultOptions?: TestOptions): test {
  defaultOptions = defaultOptions ?? {};
  if (
    defaultOptions.stateStore === undefined &&
    // process.env.CI &&
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
  ) {
    defaultOptions.stateStore = (scope) =>
      new R2RestStateStore(scope, {
        apiKey: alchemy.secret(process.env.CLOUDFLARE_API_KEY),
        email: process.env.CLOUDFLARE_EMAIL,
        bucketName: process.env.CLOUDFLARE_BUCKET_NAME!,
      });
  }
  // Add skipIf functionality
  test.skipIf = (condition: boolean) => {
    if (condition) {
      // TODO: proxy through to bun:test.skipIf
      return (...args: any[]) => {};
    }
    return test;
  };
  // Create local test scope based on filename
  const scope = new Scope({
    scopeName: `${defaultOptions.prefix ? `${defaultOptions.prefix}-` : ""}${path.basename(meta.filename)}`,
    // parent: globalTestScope,
    stateStore: defaultOptions?.stateStore,
    phase: "up",
  });
  test.beforeAll = (fn: (scope: Scope) => Promise<void>) => {
    return beforeAll(() => scope.run(() => fn(scope)));
  };
  test.afterAll = (fn: (scope: Scope) => Promise<void>) => {
    return afterAll(() => scope.run(() => fn(scope)));
  };
  return test as test;
  function test(
    ...args:
      | [
          name: string,
          options: TestOptions,
          fn: (scope: Scope) => Promise<void>,
        ]
      | [name: string, fn: (scope: Scope) => Promise<void>]
  ) {
    const testName = args[0];
    const _options = typeof args[1] === "object" ? args[1] : undefined;
    const timeout =
      typeof args[args.length - 1] === "number"
        ? (args[args.length - 1] as number)
        : 120000;
    const spread = (obj: any) =>
      obj && typeof obj === "object"
        ? Object.fromEntries(
            Object.entries(obj).flatMap(([k, v]) =>
              v !== undefined ? [[k, v]] : [],
            ),
          )
        : {};
    // Merge options with defaults
    const options: TestOptions = {
      quiet: false,
      password: "test-password",
      ...spread(defaultOptions),
      ...spread(_options),
    };
    const fn = typeof args[1] === "function" ? args[1] : args[2]!;
    return it(
      testName,
      async () =>
        alchemy.run(
          testName,
          {
            ...options,
            parent: scope,
          },
          async (scope) => {
            // Enter test scope since bun calls from different scope
            await scope.run(() => fn(scope));
          },
        ),
      timeout,
    );
  }
}
</file>

<file path="alchemy/src/test/prune.ts">
import * as esbuild from "esbuild";
import { glob } from "glob";
import { exec, spawn } from "node:child_process";
import path from "node:path";
import { promisify } from "node:util";
const execAsync = promisify(exec);
/**
 * Runs only tests that have changed dependencies
 * @param directory Directory to scan for test files
 * @param baseCommit Optional base commit to compare against
 */
export async function runChangedTests(
  directory: string,
  baseCommit?: string,
): Promise<void> {
  const changedTests = await findChangedTestFiles(directory, baseCommit);
  if (changedTests.length === 0) {
    console.log("No tests affected by recent changes.");
    return;
  }
  // Run the tests with bun using spawn for stdio inheritance
  return new Promise<void>((resolve, reject) => {
    console.log(`bun test ${changedTests.join(" ")}`);
    // resolve();
    const child = spawn("bun", ["test", ...changedTests], { stdio: "inherit" });
    child.on("close", (code) => {
      if (code === 0) resolve();
      else reject(new Error(`Tests exited with code ${code}`));
    });
    child.on("error", reject);
  });
}
/**
 * Identifies test files that have changed or depend on changed files
 * @param directory Directory to scan for test files
 * @param baseCommit Optional base commit to compare against (defaults to HEAD~1)
 * @returns Array of changed test files
 */
export async function findChangedTestFiles(
  directory: string,
  baseCommit = "HEAD~1",
): Promise<string[]> {
  // 1. Find all test files
  const testFiles = await findTestFiles(directory);
  // 2. Get git changed files
  const changedFiles = await getChangedFiles(baseCommit);
  // 3. Process each test file
  const changedTestFiles: string[] = [];
  for (const testFile of testFiles) {
    // Get dependency tree for the test file
    const dependencies = await getDependencies(testFile);
    // Check if any dependencies have changed
    const changedDependencies = [...dependencies].filter((dep) =>
      changedFiles.has(dep),
    );
    if (changedDependencies.length > 0) {
      changedTestFiles.push(testFile);
    }
  }
  return changedTestFiles.map((p) => path.relative(process.cwd(), p));
}
/**
 * Finds all test files in a directory
 * @param directory Directory to scan
 * @returns Array of test file paths
 */
async function findTestFiles(directory: string): Promise<string[]> {
  return await glob(path.join(directory, "**/*.test.ts"));
}
/**
 * Gets list of files changed since a base commit
 * @param baseCommit Base commit to compare against
 * @returns Set of changed file paths
 */
async function getChangedFiles(baseCommit: string): Promise<Set<string>> {
  // Get changed files from git
  const { stdout: gitOutput } = await execAsync(
    `git diff --name-only ${baseCommit}`,
  );
  // Convert to set of absolute paths
  const changedFiles = new Set<string>();
  const { stdout: workDir } = await execAsync("git rev-parse --show-toplevel");
  const rootDir = workDir.trim();
  gitOutput
    .split("\n")
    .filter((line) => line.trim().length > 0)
    .forEach((file) => {
      changedFiles.add(path.resolve(rootDir, file));
    });
  return changedFiles;
}
/**
 * Gets dependency tree for a test file
 * @param testFile Path to test file
 * @returns Set of dependency file paths
 */
async function getDependencies(testFile: string): Promise<Set<string>> {
  const dependencies = new Set<string>();
  // Add the test file itself to dependencies
  const absTestPath = path.resolve(testFile);
  dependencies.add(absTestPath);
  try {
    // Use esbuild with metafile to get dependencies
    const result = await esbuild.build({
      entryPoints: [testFile],
      write: false,
      platform: "node",
      format: "esm",
      bundle: true,
      metafile: true,
      external: ["@cloudflare/workers-types", "bun:test"],
      logLevel: "error",
    });
    if (!result.metafile) {
      return dependencies;
    }
    // Function to normalize paths for comparison
    const normalizePath = (p: string) => path.resolve(p).replace(/\\/g, "/");
    // Process imports from the metafile
    const { inputs } = result.metafile;
    for (const filePath in inputs) {
      // Skip node_modules and non-local imports
      if (
        filePath.includes("node_modules") ||
        filePath.includes("bun:") ||
        !filePath.endsWith(".ts")
      ) {
        continue;
      }
      const absolutePath = normalizePath(filePath);
      dependencies.add(absolutePath);
    }
    return dependencies;
  } catch (error) {
    console.error(`Error analyzing dependencies for ${testFile}:`, error);
    // Return at least the test file itself
    return dependencies;
  }
}
</file>

<file path="alchemy/src/util/content-type.ts">
import path from "node:path";
// Common MIME types
const mimeTypes: Record<string, string> = {
  ".html": "text/html",
  ".htm": "text/html",
  ".css": "text/css",
  ".js": "application/javascript",
  ".json": "application/json",
  ".xml": "application/xml",
  ".txt": "text/plain",
  ".md": "text/markdown",
  ".png": "image/png",
  ".jpg": "image/jpeg",
  ".jpeg": "image/jpeg",
  ".gif": "image/gif",
  ".webp": "image/webp",
  ".svg": "image/svg+xml",
  ".ico": "image/x-icon",
  ".pdf": "application/pdf",
  ".zip": "application/zip",
  ".woff": "font/woff",
  ".woff2": "font/woff2",
  ".ttf": "font/ttf",
  ".otf": "font/otf",
  ".eot": "application/vnd.ms-fontobject",
  ".mp4": "video/mp4",
  ".webm": "video/webm",
  ".mp3": "audio/mpeg",
  ".wav": "audio/wav",
};
/**
 * Gets the content type for a file based on its extension
 *
 * @param filePath Path to the file
 * @returns The content type for the file
 */
export function getContentType(filePath: string): string {
  const extension = path.extname(filePath).toLowerCase();
  return mimeTypes[extension] || "application/octet-stream";
}
</file>

<file path="alchemy/src/util/dedent.ts">
/**
 * Removes common indentation from template literals to make them more readable in code.
 * This allows writing multi-line strings with proper indentation in the source code
 * while removing that indentation in the output string.
 *
 * @example
 * const message = dedent`
 *   This is a multi-line string
 *   that will have its indentation removed.
 *     This line has extra indentation that will be preserved.
 * `;
 * // Result:
 * // "This is a multi-line string
 * // that will have its indentation removed.
 * //   This line has extra indentation that will be preserved."
 */
export function dedent(
  strings: TemplateStringsArray,
  ...values: any[]
): string {
  // Combine the template strings and values
  const result = strings.reduce((acc, str, i) => {
    return acc + str + (values[i] !== undefined ? values[i] : "");
  }, "");
  // Split into lines
  const lines = result.split("\n");
  // Remove ALL leading blank/whitespace-only lines
  while (lines.length > 0 && lines[0].trim() === "") {
    lines.shift();
  }
  // Remove ALL trailing blank/whitespace-only lines
  while (lines.length > 0 && lines[lines.length - 1].trim() === "") {
    lines.pop();
  }
  // If there are no lines left after trimming, return an empty string
  if (lines.length === 0) {
    return "";
  }
  // Find the minimum indentation level (excluding empty/whitespace lines)
  const minIndent = lines
    .filter((line) => line.trim().length > 0) // Only consider non-blank lines for indent calculation
    .reduce((min, line) => {
      const indent = line.match(/^[ \t]*/)?.[0].length || 0;
      // Handle potentially infinite min if all lines are blank (though handled by early return)
      return indent < min ? indent : min;
    }, Number.POSITIVE_INFINITY);
  // If minIndent remains Infinity (only blank lines existed), return empty string.
  // This case should be caught by the lines.length check above, but belt-and-suspenders.
  if (minIndent === Number.POSITIVE_INFINITY) {
    return "";
  }
  // Remove the common indentation from each line
  const dedented = lines.map((line) => {
    // Preserve internal blank lines as empty strings, don't try to substring them
    if (line.trim().length === 0) {
      return "";
    }
    // Apply dedent only to lines with content
    return line.substring(minIndent);
  });
  // Join the lines back together
  return dedented.join("\n");
}
</file>

<file path="alchemy/src/util/ignore.ts">
export async function ignore<T>(
  codes: string | string[],
  fn: () => Promise<T>,
): Promise<T | undefined> {
  try {
    return await fn();
  } catch (error: any) {
    const errorCode = error.code || error.name;
    if (
      Array.isArray(codes) ? codes.includes(errorCode) : errorCode === codes
    ) {
      return undefined;
    }
    throw error;
  }
}
</file>

<file path="alchemy/src/util/retry.ts">
/**
 * Utility function for exponential backoff retry
 * Retries an operation with exponential backoff when a retryable error occurs
 *
 * @param operation The async operation to execute and potentially retry
 * @param isRetryable Function to determine if an error should trigger a retry
 * @param maxAttempts Maximum number of attempts before giving up
 * @param initialDelayMs Initial delay in milliseconds before first retry
 * @returns Result of the operation
 * @throws The last error encountered if all retries fail
 */
export async function withExponentialBackoff<T>(
  operation: () => Promise<T>,
  isRetryable: (error: any) => boolean,
  maxAttempts = 5,
  initialDelayMs = 100,
): Promise<T> {
  let attempt = 0;
  let delay = initialDelayMs;
  while (true) {
    try {
      return await operation();
    } catch (error) {
      attempt++;
      if (attempt >= maxAttempts || !isRetryable(error)) {
        console.warn("Failed after ", attempt, " attempts");
        throw error;
      }
      // Exponential backoff with jitter
      const jitter = Math.random() * 0.1 * delay;
      await new Promise((resolve) => setTimeout(resolve, delay + jitter));
      delay *= 2; // Double the delay for next attempt
    }
  }
}
</file>

<file path="alchemy/src/util/rm.ts">
import fs from "node:fs/promises";
export async function rm(path: string) {
  try {
    await fs.rm(path, { recursive: true, force: true });
  } catch (error: any) {
    if (error.code !== "ENOENT") {
      throw error;
    }
  }
}
</file>

<file path="alchemy/src/util/sha256.ts">
import { createHash } from "node:crypto";
export function sha256(value: string): string {
  return createHash("sha256").update(value).digest("hex");
}
</file>

<file path="alchemy/src/util/slugify.ts">
export function slugify(str: string, delimiter = "-") {
  return str.toLowerCase().replace(/[^a-z0-9]/gi, delimiter);
}
</file>

<file path="alchemy/src/web/vitepress/config.ts">
import path from "node:path";
import type { DefaultTheme, HeadConfig, ThemeOptions } from "vitepress";
import { StaticTypeScriptFile } from "../../fs/static-typescript-file.js";
export type VitePressConfigProps = {
  cwd: string;
  title?: string;
  description?: string;
  head?: HeadConfig[];
  theme?: ThemeOptions;
  themeConfig: DefaultTheme.Config;
};
export type VitePressConfig = Awaited<ReturnType<typeof VitePressConfig>>;
export function VitePressConfig(props: VitePressConfigProps) {
  return StaticTypeScriptFile(
    path.join(props.cwd, ".vitepress", "config.mts"),
    `import { transformerTwoslash } from "@shikijs/vitepress-twoslash";
import footnotePlugin from "markdown-it-footnote";
import { defineConfig } from "vitepress";
// https://vitepress.dev/reference/site-config
export default defineConfig({
  title: ${JSON.stringify(props.title || "Alchemy")},
  description: ${JSON.stringify(props.description || "Alchemy Docs")},
  head: ${JSON.stringify(props.head || [])},
  markdown: {
    // @ts-ignore
    codeTransformers: [transformerTwoslash()],
    theme: ${JSON.stringify(
      props.theme ?? {
        light: "light-plus",
        dark: "dark-plus",
      },
    )},
    config: (md) => md.use(footnotePlugin),
  },
  // https://vitepress.dev/reference/default-theme-config
  themeConfig: ${JSON.stringify({
    ...props.themeConfig,
    search: props.themeConfig.search ?? { provider: "local" },
    nav: props.themeConfig.nav ?? [{ text: "Home", link: "/" }],
    sidebar: props.themeConfig.sidebar ?? [],
    socialLinks: props.themeConfig.socialLinks ?? [],
  })}
});
`,
  );
}
</file>

<file path="alchemy/src/web/vitepress/custom-theme.ts">
import { type } from "arktype";
import path from "node:path";
import type { ModelConfig } from "../../ai/client.js";
import { CSSFile } from "../../ai/css-file.js";
import { Data } from "../../ai/data.js";
import { TypeScriptFile } from "../../ai/typescript-file.js";
import { VueFile } from "../../ai/vue-file.js";
import { alchemy } from "../../alchemy.js";
import type { Context } from "../../context.js";
import { Folder } from "../../fs/folder.js";
import { Resource } from "../../resource.js";
import type { Secret } from "../../secret.js";
/**
 * Theme component props for customizing the layout
 */
export interface ThemeComponentProps {
  /**
   * Name of the component
   */
  name: string;
  /**
   * Description of what the component does
   */
  description: string;
  /**
   * Features or functionality to include in the component
   */
  features?: string[];
}
/**
 * Properties for creating or updating a VitePress custom theme
 */
export interface CustomThemeProps {
  /**
   * Output directory for the theme files
   */
  outDir: string;
  /**
   * Title of the theme
   */
  title: string;
  /**
   * Description of the theme
   */
  description: string;
  /**
   * Components to include in the theme
   */
  components?: ThemeComponentProps[];
  /**
   * Whether to include dark mode support
   * @default true
   */
  darkMode?: boolean;
  /**
   * Custom CSS variables for theming
   */
  customCssVars?: Record<string, string>;
  /**
   * Custom plugins to add to the theme
   */
  plugins?: string[];
  /**
   * User prompt describing the design of the theme
   */
  prompt: string;
  /**
   * Optional extension to the built-in system prompt
   */
  systemPromptExtension?: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration for the AI generator
   */
  model?: ModelConfig;
  /**
   * Temperature for controlling randomness in generation
   * @default 0.7
   */
  temperature?: number;
}
/**
 * A generated file in the custom theme
 */
export interface ThemeFile {
  /**
   * Path to the file
   */
  path: string;
  /**
   * Content of the file
   */
  content: string;
}
/**
 * Output for the VitePress custom theme resource
 */
export interface CustomTheme
  extends CustomThemeProps,
    Resource<"vitepress::CustomTheme"> {
  /**
   * Path to the generated theme directory
   */
  themePath: string;
  /**
   * List of generated files
   */
  files: ThemeFile[];
  /**
   * Time at which the theme was created
   */
  createdAt: number;
  /**
   * Time at which the theme was last updated
   */
  updatedAt: number;
}
/**
 * Resource for generating a custom VitePress theme using AI.
 *
 * Generates the necessary theme files including:
 * - Theme entry file (index.ts)
 * - Layout component (Layout.vue)
 * - Additional components based on configuration
 * - Style sheets and utilities
 *
 * @example
 * // Create a basic custom theme
 * const theme = await CustomTheme("docs-theme", {
 *   outDir: "./.vitepress/theme",
 *   title: "My Custom Theme",
 *   description: "A clean, minimal theme for documentation",
 *   prompt: "Create a clean documentation theme with a sidebar and search"
 * });
 *
 * @example
 * // Create a theme with specific components
 * const complexTheme = await CustomTheme("blog-theme", {
 *   outDir: "./.vitepress/theme",
 *   title: "Blog Theme",
 *   description: "A theme for technical blogs",
 *   components: [
 *     {
 *       name: "PostList",
 *       description: "Component that displays a list of blog posts with pagination",
 *       features: ["thumbnail images", "post dates", "categories", "excerpts"]
 *     },
 *     {
 *       name: "TableOfContents",
 *       description: "Component that displays the current page's table of contents",
 *       features: ["sticky positioning", "active link highlighting"]
 *     }
 *   ],
 *   darkMode: true,
 *   prompt: "Create a modern blog theme with post listings and detailed article pages"
 * });
 *
 * @example
 * // Create a theme with custom CSS variables
 * const brandedTheme = await CustomTheme("branded-theme", {
 *   outDir: "./.vitepress/theme",
 *   title: "Branded Docs",
 *   description: "A themed documentation site with custom branding",
 *   customCssVars: {
 *     "--vp-c-brand": "#3a70b0",
 *     "--vp-c-brand-light": "#5785bc",
 *     "--vp-c-brand-lighter": "#79a1ce",
 *     "--vp-c-brand-dark": "#2c5989",
 *     "--vp-c-brand-darker": "#1e3d5c"
 *   },
 *   prompt: "Create a documentation theme with custom branding and color scheme"
 * });
 */
export const CustomTheme = Resource(
  "vitepress::CustomTheme",
  async function (
    this: Context<CustomTheme>,
    id: string,
    props: CustomThemeProps,
  ): Promise<CustomTheme> {
    // Handle deletion
    if (this.phase === "delete") {
      // No need to actually delete files, as they're not critical infrastructure
      // In a real implementation, you might want to clean up files
      return this.destroy();
    }
    // Ensure the output directory exists
    await Folder(props.outDir);
    // Create components directory if it doesn't exist
    await Folder(path.join(props.outDir, "components"));
    // Build the system prompt with optional extension
    const systemPrompt = `
You are creating a custom VitePress theme.
A VitePress custom theme consists of multiple files:
1. An entry file (index.ts or index.js) that exports the theme object
2. A Layout component (Layout.vue) that handles the overall page structure
3. Optional additional Vue components for specific functionality
4. Optional style files for theming and customization
The theme entry file must export an object with:
- Layout: The root layout component (required)
- enhanceApp: Function to enhance the Vue app (optional)
- extends: Another theme to extend (optional)
Follow these guidelines:
1. Use Vue 3 Composition API and <script setup> syntax
2. Ensure the theme is SSR-compatible
3. Use the useData() composable to access page and site data
4. Handle different page layouts (home, 404, regular pages)
5. Include proper TypeScript types
6. Use modern JavaScript/TypeScript features
7. Include clear comments explaining key functionality
8. Make components reusable and customizable
9. Include support for dark mode if requested
${props.systemPromptExtension || ""}
`;
    // Generate the theme entry file (index.ts)
    const indexFile = await TypeScriptFile(`${id}-index`, {
      path: path.join(props.outDir, "index.ts"),
      prompt: await alchemy`
Create a VitePress theme entry file (index.ts) for a theme named "${props.title}".
The theme should:
- Export a default theme object with the required properties
- Import the Layout component
- Include a proper enhanceApp function
- Include TypeScript types
- Have clear comments explaining the code
${props.description ? `Theme description: ${props.description}` : ""}
${props.plugins?.length ? `Include these plugins: ${props.plugins.join(", ")}` : ""}
The output should be a complete, well-structured TypeScript file.
`,
      system: `${systemPrompt}
You are writing a TypeScript entry file for a VitePress theme.`,
      baseURL: props.baseURL,
      apiKey: props.apiKey,
      model: props.model,
      temperature: props.temperature,
    });
    // Generate the Layout component
    const layoutFile = await VueFile(`${id}-layout`, {
      path: path.join(props.outDir, "Layout.vue"),
      prompt: await alchemy`
Create a Layout.vue component for a VitePress theme named "${props.title}".
The layout should:
- Use <script setup> with the Composition API
- Import and use the useData() composable
- Handle different page types (regular pages, home pages, 404 pages)
- Include a <Content /> component to render the page content
- Have a clean, modern design
- Include proper TypeScript types
- Use Vue's Teleport for elements like modals if needed
The layout should use modular components for different parts of the UI, such as:
- NavBar/Header component for navigation
- Sidebar component for documentation navigation
- Footer component
- Home page specific components (like hero sections)
- 404 page component
These components should be imported from the components directory.
${props.description ? `Theme description: ${props.description}` : ""}
${props.darkMode !== false ? "Include support for dark mode" : "Dark mode is not required"}
The layout should follow the user's requirements:
${props.prompt}
The output should be a complete, well-structured Vue component file.
`,
      system: `${systemPrompt}
You are writing a Vue component for a VitePress theme Layout.
Import smaller components from the components directory using relative paths (e.g., import NavBar from './components/NavBar.vue').
Break down the layout into logical components like NavBar, Sidebar, Footer, etc., which will be generated separately.`,
      baseURL: props.baseURL,
      apiKey: props.apiKey,
      model: props.model,
      temperature: props.temperature,
    });
    // Extract component imports from the Layout.vue file
    const componentImportsData = await Data(`${id}-component-imports`, {
      schema: type({
        components: type({
          name: type("string").describe(
            "Component name as used in the import statement (e.g., NavBar, Footer)",
          ),
          path: type("string").describe(
            "Import path as written in the import statement (e.g., './components/NavBar.vue')",
          ),
          purpose: type("string").describe(
            "A clear description of the component's purpose, functionality, and responsibilities in the layout",
          ),
        }).array(),
      }),
      prompt: await alchemy`
Analyze the following Layout.vue file and extract information about all the component imports:
${layoutFile.content}
For each component import:
1. Extract the component name (e.g., NavBar)
2. Extract the import path (e.g., ./components/NavBar.vue)
3. Infer the purpose of the component based on its name and usage in the file
Return a structured list of all component imports found in the file.
Only include components that are imported from local files (not from VitePress or other libraries).
Focus on components that are likely Vue components (.vue files).
`,
      system:
        "You are a code analyzer tasked with extracting component imports from a Vue file. Be precise and thorough in identifying all local component imports.",
      baseURL: props.baseURL,
      apiKey: props.apiKey,
      model: props.model,
      temperature: props.temperature || 0.2, // Lower temperature for more deterministic extraction
    });
    // Generate the detected components
    const autoComponentFiles = await Promise.all(
      componentImportsData.object.components.map(async (component) => {
        const componentName = component.name;
        const componentPath = component.path;
        const componentPurpose = component.purpose;
        // Extract the relative path from the import
        const relativePath = componentPath.startsWith("./")
          ? componentPath.slice(2) // Remove './'
          : componentPath.startsWith("/")
            ? componentPath.slice(1) // Remove '/'
            : componentPath;
        // Compute the full file path
        const fullPath = path.join(props.outDir, relativePath);
        return VueFile(`${id}-component-${componentName}`, {
          path: fullPath,
          prompt: await alchemy`
Create a Vue component named "${componentName}" for a VitePress theme.
Component purpose: ${componentPurpose}
The component should:
- Use <script setup> with the Composition API
- Have a clean, focused design for its specific purpose
- Include proper TypeScript types
- Be reusable and customizable
- Include clear comments explaining key functionality
- Fit seamlessly with the overall theme design described below
This component will be used in the following layout context:
${layoutFile.content}
${props.description ? `Theme description: ${props.description}` : ""}
${props.darkMode !== false ? "Include support for dark mode" : "Dark mode is not required"}
The component should follow the user's theme requirements:
${props.prompt}
`,
          system: `${systemPrompt}
You are writing a Vue component for a VitePress theme. This component (${componentName}) is intended to ${componentPurpose}.
Make sure it integrates well with the overall layout and theme style.`,
          baseURL: props.baseURL,
          apiKey: props.apiKey,
          model: props.model,
          temperature: props.temperature,
        });
      }),
    );
    // Generate user-specified components if provided
    const userComponentFiles = await Promise.all(
      (props.components || []).map(async (component) => {
        return VueFile(`${id}-user-component-${component.name}`, {
          path: path.join(props.outDir, "components", `${component.name}.vue`),
          prompt: await alchemy`
Create a Vue component named "${component.name}" for a VitePress theme.
Component description: ${component.description}
The component should:
- Use <script setup> with the Composition API
- Have a clean, focused design for its specific purpose
- Include proper TypeScript types
- Be reusable and customizable
- Include clear comments
${
  component.features?.length
    ? `Include these features:
${component.features.map((f) => `- ${f}`).join("\n")}`
    : ""
}
Make sure the component integrates well with the overall theme.
The output should be a complete, well-structured Vue component file.
`,
          system: `${systemPrompt}
You are writing a Vue component for a VitePress theme.`,
          baseURL: props.baseURL,
          apiKey: props.apiKey,
          model: props.model,
          temperature: props.temperature,
        });
      }),
    );
    // Generate styles file
    const stylesFile = await CSSFile(`${id}-styles`, {
      path: path.join(props.outDir, "styles.css"),
      prompt: await alchemy`
Create a CSS styles file for a VitePress theme named "${props.title}".
The styles should:
- Define a cohesive set of styles for the theme
- Include CSS variables for customization
- Use modern CSS features
- Be well-organized with clear comments
${props.darkMode !== false ? "- Include dark mode variants using :root.dark selectors" : ""}
${props.description ? `Theme description: ${props.description}` : ""}
${
  props.customCssVars
    ? `Include these custom CSS variables:
${Object.entries(props.customCssVars)
  .map(([key, value]) => `${key}: ${value};`)
  .join("\n")}`
    : ""
}
Style according to the user's requirements:
${props.prompt}
The output should be a complete, well-structured CSS file.
`,
      system: `${systemPrompt}
You are writing CSS styles for a VitePress theme.`,
      baseURL: props.baseURL,
      apiKey: props.apiKey,
      model: props.model,
      temperature: props.temperature,
    });
    // Collect all generated files
    const allFiles = [
      indexFile,
      layoutFile,
      ...autoComponentFiles,
      ...userComponentFiles,
      stylesFile,
    ];
    // Create file objects for resource output
    const files = allFiles.map((file) => ({
      path: file.path,
      content: file.content,
    }));
    // Get the current timestamp
    const now = Date.now();
    // Return the resource using this() to construct output
    return this({
      ...props,
      themePath: props.outDir,
      files,
      createdAt: this.output?.createdAt || now,
      updatedAt: now,
    });
  },
);
</file>

<file path="alchemy/src/web/vitepress/dependencies.ts">
import { exec } from "node:child_process";
import { promisify } from "node:util";
import type { Context } from "../../context.js";
import { Resource } from "../../resource.js";
const execAsync = promisify(exec);
export type InstallDependencies = Resource<"project::InstallDependencies">;
export const InstallDependencies = Resource(
  "project::InstallDependencies",
  {
    alwaysUpdate: true,
  },
  async function (
    this: Context<InstallDependencies>,
    id: string,
    {
      cwd,
      dependencies,
      devDependencies,
    }: {
      cwd: string;
      dependencies?: Record<string, string>;
      devDependencies?: Record<string, string>;
    },
  ) {
    if (this.phase === "delete") {
      return this.destroy();
    }
    await installDependencies(cwd, dependencies);
    await installDependencies(cwd, devDependencies, "-D");
    await execAsync("bun install", { cwd });
    return this({});
  },
);
function isInstallableVersion(version: string) {
  // TODO: file:// ?
  return !version.startsWith("workspace:");
}
export function fixedDependencies(dependencies?: Record<string, string>) {
  if (!dependencies) return {};
  return Object.fromEntries(
    Object.entries(dependencies).filter(
      ([, value]) => !isInstallableVersion(value),
    ),
  );
}
export async function installDependencies(
  cwd: string,
  dependencies: Record<string, string> | undefined,
  ...args: string[]
) {
  if (!dependencies) return;
  const deps = Object.entries(dependencies)
    .filter(([, value]) => isInstallableVersion(value))
    .map(([pkg, version]) => `${pkg}@${version}`)
    .join(" ");
  const cmd = `bun add ${args.join(" ")} ${deps}`;
  console.log(cmd);
  await execAsync(cmd, { cwd });
}
</file>

<file path="alchemy/src/web/vitepress/home-page.ts">
import yaml from "yaml";
import { Document } from "../../ai/document.js";
import { alchemy } from "../../alchemy.js";
import { StaticTextFile } from "../../fs/static-text-file.js";
import type { Secret } from "../../secret.js";
/**
 * Image that can be themed for light/dark mode
 */
export interface ThemeableImage {
  /**
   * Image source URL
   */
  src?: string;
  /**
   * Image alt text
   */
  alt?: string;
  /**
   * Light theme image URL
   */
  light?: string;
  /**
   * Dark theme image URL
   */
  dark?: string;
}
/**
 * Hero action button configuration
 */
export interface HeroAction {
  /**
   * Color theme of the button
   * @default "brand"
   */
  theme?: "brand" | "alt";
  /**
   * Label of the button
   */
  text: string;
  /**
   * Destination link of the button
   */
  link: string;
  /**
   * Link target attribute
   */
  target?: string;
  /**
   * Link rel attribute
   */
  rel?: string;
}
/**
 * Hero section configuration
 */
export interface Hero {
  /**
   * The string shown top of text. Comes with brand color
   * and expected to be short, such as product name.
   */
  name?: string;
  /**
   * The main text for the hero section. This will be defined
   * as h1 tag.
   */
  text: string;
  /**
   * Tagline displayed below text
   */
  tagline?: string;
  /**
   * The image displayed next to the text and tagline area
   */
  image?: string | ThemeableImage;
  /**
   * Action buttons to display in home hero section
   */
  actions?: HeroAction[];
}
/**
 * Feature item configuration
 */
export interface Feature {
  /**
   * Show icon on each feature box
   */
  icon?: string | ThemeableImage;
  /**
   * Title of the feature
   */
  title: string;
  /**
   * Details of the feature
   */
  details: string;
  /**
   * Link when clicked on feature component
   */
  link?: string;
  /**
   * Link text to be shown inside feature component
   */
  linkText?: string;
  /**
   * Link rel attribute
   */
  rel?: string;
  /**
   * Link target attribute
   */
  target?: string;
}
/**
 * VitePress home page configuration
 */
export interface HomePageConfig {
  /**
   * Use home page layout
   */
  layout: "home";
  /**
   * Hero section configuration
   */
  hero?: Hero;
  /**
   * Features section configuration
   */
  features?: Feature[];
  /**
   * Whether to apply default markdown styles
   * @default true
   */
  markdownStyles?: boolean;
}
/**
 * Properties for creating or updating a VitePress HomePage
 */
export interface HomePageProps {
  /**
   * Output directory for the home page markdown file
   */
  outFile: string;
  /**
   * Title of the home page document
   */
  title: string;
  /**
   * Hero section configuration
   */
  hero?: Hero;
  /**
   * Features section configuration
   */
  features?: Feature[];
  /**
   * User prompt describing the design of the home page
   */
  prompt?: string;
  /**
   * Optional extension to the built-in system prompt
   */
  system?: string;
  /**
   * Base URL for the OpenAI API
   * @default 'https://api.openai.com/v1'
   */
  baseURL?: string;
  /**
   * OpenAI API key to use for generating content
   * If not provided, will use OPENAI_API_KEY environment variable
   */
  apiKey?: Secret;
  /**
   * Model configuration for the AI generator
   */
  model?: import("../../ai/client").ModelConfig;
  /**
   * Temperature for controlling randomness in generation
   * @default 0.7
   */
  temperature?: number;
}
/**
 * Output type for the HomePage resource
 */
export type HomePage = StaticTextFile | Document;
/**
 * Parse YAML frontmatter to home page config
 */
export function parseHomePage(content: string): HomePageConfig {
  const match = content.match(/^---\n([\s\S]*?)\n---/);
  if (!match) {
    throw new Error("Invalid frontmatter format");
  }
  return yaml.parse(match[1]) as HomePageConfig;
}
/**
 * Resource for generating a VitePress homepage using AI.
 * Creates an index.md file with the appropriate frontmatter and content
 * based on the provided prompt and configuration.
 *
 * @example
 * // Create a basic home page with just a prompt
 * const homePage = await HomePage("docs-home", {
 *   outDir: "./docs",
 *   title: "My Project Documentation",
 *   prompt: "Create a welcoming homepage for a JavaScript utility library with modern design"
 * });
 *
 * @example
 * // Create a home page with hero and features configuration
 * const detailedHome = await HomePage("product-home", {
 *   outDir: "./website",
 *   title: "Product Landing Page",
 *   prompt: "Create an engaging product page for our cloud database service",
 *   hero: {
 *     name: "CloudDB",
 *     text: "The database built for the cloud era",
 *     tagline: "Scalable, reliable, and developer-friendly",
 *     image: "/images/cloud-db-logo.png",
 *     actions: [
 *       { text: "Get Started", link: "/guide/", theme: "brand" },
 *       { text: "View on GitHub", link: "https://github.com/org/cloud-db" }
 *     ]
 *   },
 *   features: [
 *     {
 *       icon: "",
 *       title: "Lightning Fast",
 *       details: "Optimized for performance at any scale"
 *     },
 *     {
 *       icon: "",
 *       title: "Secure by Default",
 *       details: "Enterprise-grade security built in"
 *     }
 *   ]
 * });
 *
 * @example
 * // Create a home page with custom model settings
 * const customHome = await HomePage("docs-home", {
 *   outDir: "./docs",
 *   title: "API Documentation",
 *   prompt: "Create a technical homepage for our REST API documentation",
 *   model: {
 *     id: "gpt-4o",
 *     provider: "openai"
 *   },
 *   temperature: 0.3,
 *   systemPromptExtension: "Make sure to use technical terminology appropriate for developers."
 * });
 */
export async function HomePage(
  id: string,
  props: HomePageProps,
): Promise<HomePage> {
  // Build the system prompt with optional extension
  const systemPrompt = `
You are creating a VitePress homepage (index.md file).
VitePress uses YAML frontmatter to configure the homepage.
The homepage must have "layout: home" in its frontmatter.
The homepage can include:
- A hero section with name, text, tagline, image, and action buttons
- A features section with multiple feature items (title, icon, details)
- Additional markdown content below the frontmatter
Follow these guidelines:
1. Start with YAML frontmatter (--- at beginning and end)
2. Include "layout: home" in the frontmatter
3. Use the provided hero and features configuration if supplied
4. Add any additional sections or content based on the user's prompt
5. Create visually appealing, well-structured content
6. Ensure all links are properly formatted
7. Use appropriate markdown formatting for headings, lists, etc.
${props.system || ""}
`;
  // Convert hero and features to YAML strings if provided
  const heroYaml = props.hero ? JSON.stringify(props.hero, null, 2) : "";
  const featuresYaml = props.features
    ? JSON.stringify(props.features, null, 2)
    : "";
  if (props.prompt) {
    return Document(id, {
      title: props.title,
      path: props.outFile,
      baseURL: props.baseURL,
      apiKey: props.apiKey,
      model: props.model ?? {
        id: "claude-3-7-sonnet-latest",
        provider: "anthropic",
      },
      temperature: props.temperature ?? 0.7,
      prompt: await alchemy`
    ${systemPrompt}
    Create a VitePress homepage based on the following description:
    ${props.prompt}
    ${
      props.hero
        ? `Use this hero section configuration:
    \`\`\`json
    ${heroYaml}
    \`\`\``
        : ""
    }
    ${
      props.features
        ? `Use these features:
    \`\`\`json
    ${featuresYaml}
    \`\`\``
        : ""
    }
        The output should be a complete index.md file with proper YAML frontmatter and markdown content.
        `,
    });
  }
  return StaticTextFile(
    id,
    props.outFile,
    `---
${yaml.stringify({
  layout: "home",
  name: props.title,
  hero: props.hero,
  features: props.features,
})}
---
`,
  );
}
</file>

<file path="alchemy/src/web/vitepress/index.ts">
export * from "./config.js";
export * from "./custom-theme.js";
export * from "./home-page.js";
export * from "./process-front-matter-files.js";
export * from "./vitepress.js";
</file>

<file path="alchemy/src/web/vitepress/process-front-matter-files.ts">
import fs from "node:fs/promises";
import path from "node:path";
/**
 * Process markdown files with frontmatter to generate navigation items
 * @param directoryPath The directory containing markdown files
 * @param linkPrefix The prefix for navigation links
 * @returns Sorted array of navigation items with text and link properties
 */
export async function processFrontmatterFiles(
  directoryPath: string,
  linkPrefix: string,
): Promise<
  {
    text: string;
    link: string;
    items?: {
      text: string;
      link: string;
      items?: { text: string; link: string }[];
    }[];
  }[]
> {
  const entries = await fs.readdir(directoryPath, { withFileTypes: true });
  const processedEntries = await Promise.all(
    entries
      .filter((entry) => !entry.name.endsWith("index.md"))
      .map(async (entry) => {
        const fullPath = path.join(directoryPath, entry.name);
        if (entry.isDirectory()) {
          // Process subdirectory recursively
          const items = await processFrontmatterFiles(
            fullPath,
            `${linkPrefix}/${entry.name}`,
          );
          // Create section for subdirectory
          return {
            text: entry.name.charAt(0).toUpperCase() + entry.name.slice(1),
            collapsed: false,
            items,
            order: 10000, // Default order for directories
          };
        }
        // Process markdown file
        if (!entry.name.endsWith(".md")) {
          return null;
        }
        const content = await fs.readFile(fullPath, "utf-8");
        const frontmatterMatch = content.match(/^---\n([\s\S]*?)\n---/);
        let order = 10000;
        let title;
        if (frontmatterMatch) {
          const frontmatter = frontmatterMatch[1];
          const orderMatch = frontmatter.match(/order:\s*(\d+)/);
          if (orderMatch) {
            order = Number.parseFloat(orderMatch[1]);
          }
          const titleMatch = frontmatter.match(/title:\s*(.+)/);
          if (titleMatch) {
            title = titleMatch[1].trim();
          }
        }
        // If no title in frontmatter, try to get first heading
        if (!title) {
          const headingMatch = content.match(/^#\s+(.+)$/m);
          if (headingMatch) {
            title = headingMatch[1].trim();
          }
        }
        // Fall back to filename if no title found
        if (!title) {
          const name = entry.name.replace(".md", "");
          title = name.charAt(0).toUpperCase() + name.slice(1);
        }
        return {
          text: title,
          link: `${linkPrefix}/${entry.name}`,
          order,
        };
      }),
  );
  // Filter out null entries and sort by order
  return processedEntries
    .filter((entry) => entry !== null)
    .sort((a, b) => a.order - b.order)
    .map(({ text, link, items }) =>
      items ? { text, items, collapsed: true } : { text, link },
    ) as any;
}
</file>

<file path="alchemy/src/web/vitepress/vitepress.ts">
import { exec } from "node:child_process";
import fs from "node:fs/promises";
import path from "node:path";
import { promisify } from "node:util";
import type { Context } from "../../context.js";
import { Folder } from "../../fs/folder.js";
import { StaticJsonFile } from "../../fs/static-json-file.js";
import { StaticTextFile } from "../../fs/static-text-file.js";
import { StaticTypeScriptFile } from "../../fs/static-typescript-file.js";
import { Resource } from "../../resource.js";
import { InstallDependencies, fixedDependencies } from "./dependencies.js";
const execAsync = promisify(exec);
export interface VitePressProjectProps {
  /**
   * The name/path of the project
   */
  name: string;
  /**
   * The title of the documentation site
   */
  title?: string;
  /**
   * The description of the documentation site
   */
  description?: string;
  /**
   * Whether to use TypeScript for config and theme files
   * @default true
   */
  typescript?: boolean;
  /**
   * The scripts to add to the project
   */
  scripts?: Record<string, string>;
  /**
   * The tsconfig to use
   */
  tsconfig?: {
    extends?: string;
    references?: string[];
    compilerOptions?: Record<string, any>;
  };
  /**
   * Force overwrite the project config files during the update phase
   * @default false
   */
  overwrite?: boolean;
  /**
   * The dependencies to install
   */
  dependencies?: Record<string, string>;
  /**
   * The dev dependencies to install
   */
  devDependencies?: Record<string, string>;
  /**
   * The theme options to use
   */
  // theme?: ThemeOptions;
  /**
   * The theme config to use
   */
  // themeConfig: DefaultTheme.Config;
  /**
   * Whether to delete the project folder during the delete phase
   * @default true
   */
  delete?: boolean;
  /**
   * The directory to initialize the project in.
   *
   * @default {@link name}
   */
  dir?: string;
}
export interface VitePressProject extends VitePressProjectProps, Resource {
  /**
   * The name/path of the project
   */
  name: string;
  /**
   * The directory of the project
   */
  dir: string;
}
export const VitepressProject = Resource(
  "project::VitepressProject",
  {
    alwaysUpdate: true,
  },
  async function (
    this: Context<VitePressProject>,
    id: string,
    props: VitePressProjectProps,
  ): Promise<VitePressProject> {
    const dir = props.dir ?? props.name;
    if (this.phase === "delete") {
      try {
        if (props.delete !== false) {
          if (await fs.exists(dir)) {
            await fs.rm(dir, { recursive: true, force: true });
            // // Delete the entire project directory
            // await execAsync(`rm -rf ${dir}`);
          }
        }
      } catch (error) {
        console.error(`Error deleting VitePress project ${id}:`, error);
      }
      return this.destroy();
    }
    const cwd = path.relative(
      process.cwd(),
      (
        await Folder("dir", {
          path: dir,
          delete: props.delete,
        })
      ).path,
    );
    // Initialize package.json
    await StaticJsonFile(path.join(cwd, "package.json"), {
      name: props.name,
      scripts: {
        "docs:gen": "bun alchemy.run.ts",
        "docs:dev": "vitepress dev",
        "docs:build": "vitepress build",
        "docs:preview": "vitepress preview",
        ...props.scripts,
      },
      dependencies: fixedDependencies(props.dependencies || {}),
      devDependencies: fixedDependencies(props.devDependencies || {}),
    });
    await InstallDependencies("dependencies", {
      cwd,
      dependencies: props.dependencies,
      devDependencies: {
        vue: "latest",
        vitepress: "latest",
        "@shikijs/vitepress-twoslash": "latest",
        "markdown-it-footnote": "latest",
        ...props.devDependencies,
      },
    });
    // Create .vitepress directory and config
    await Folder(path.join(cwd, ".vitepress"));
    await Folder(path.join(cwd, ".vitepress", "theme"));
    await Promise.all([
      StaticTextFile(path.join(cwd, ".gitignore"), ".vitepress/cache\n"),
      // StaticJsonFile(path.join(cwd, "tsconfig.json"), {
      //   extends: props.tsconfig?.extends,
      //   references: props.tsconfig?.references?.map((path) => ({ path })),
      //   compilerOptions: props.tsconfig?.compilerOptions ?? {
      //     target: "ES2020",
      //     module: "ESNext",
      //     moduleResolution: "Node",
      //     allowJs: true,
      //     skipLibCheck: true,
      //     forceConsistentCasingInFileNames: true,
      //   },
      // }),
      //       TypeScriptFile(
      //         path.join(cwd, "alchemy.run.ts"),
      //         `import alchemy from "alchemy";
      // import { Folder } from "alchemy/fs";
      // import { Document } from "alchemy/docs";
      // import path from "node:path";
      // const app = await alchemy("alchemy.run", {
      //   stage: "prod",
      //   phase: process.argv.includes("--destroy") ? "destroy" : "up",
      //   password: process.env.SECRET_PASSPHRASE,
      //   quiet: !process.argv.includes("--verbose"),
      // });
      // const docs = await Folder(path.join("alchemy.run", "docs"));
      // await Document("home.md", {
      //   path: path.join(docs.path, "home.md"),
      //   prompt: await alchemy\`Generate a landing page.\`,
      // });
      // `,
      //       ),
      StaticTypeScriptFile(
        path.join(cwd, ".vitepress", "theme", "index.ts"),
        `import TwoslashFloatingVue from "@shikijs/vitepress-twoslash/client";
import "@shikijs/vitepress-twoslash/style.css";
import type { Theme as ThemeConfig } from "vitepress";
import Theme from "vitepress/theme-without-fonts";
import "./style.css";
export default {
  extends: Theme,
  enhanceApp(ctx) {
    ctx.app.use(TwoslashFloatingVue);
  },
} satisfies ThemeConfig;
  `,
      ),
      StaticTextFile(
        path.join(cwd, ".vitepress", "theme", "style.css"),
        `/**
* Customize default theme styling by overriding CSS variables:
* https://github.com/vuejs/vitepress/blob/main/src/client/theme-default/styles/vars.css
*/
/**
* Colors
*
* Each colors have exact same color scale system with 3 levels of solid
* colors with different brightness, and 1 soft color.
*
* - \`XXX-1\`: The most solid color used mainly for colored text. It must
*   satisfy the contrast ratio against when used on top of \`XXX-soft\`.
*
* - \`XXX-2\`: The color used mainly for hover state of the button.
*
* - \`XXX-3\`: The color for solid background, such as bg color of the button.
*   It must satisfy the contrast ratio with pure white (#ffffff) text on
*   top of it.
*
* - \`XXX-soft\`: The color used for subtle background such as custom container
*   or badges. It must satisfy the contrast ratio when putting \`XXX-1\` colors
*   on top of it.
*
*   The soft color must be semi transparent alpha channel. This is crucial
*   because it allows adding multiple "soft" colors on top of each other
*   to create a accent, such as when having inline code block inside
*   custom containers.
*
* - \`default\`: The color used purely for subtle indication without any
*   special meanings attached to it such as bg color for menu hover state.
*
* - \`brand\`: Used for primary brand colors, such as link text, button with
*   brand theme, etc.
*
* - \`tip\`: Used to indicate useful information. The default theme uses the
*   brand color for this by default.
*
* - \`warning\`: Used to indicate warning to the users. Used in custom
*   container, badges, etc.
*
* - \`danger\`: Used to show error, or dangerous message to the users. Used
*   in custom container, badges, etc.
* -------------------------------------------------------------------------- */
:root {
  --vp-c-default-1: var(--vp-c-gray-1);
  --vp-c-default-2: var(--vp-c-gray-2);
  --vp-c-default-3: var(--vp-c-gray-3);
  --vp-c-default-soft: var(--vp-c-gray-soft);
  --vp-c-brand-1: var(--vp-c-indigo-1);
  --vp-c-brand-2: var(--vp-c-indigo-2);
  --vp-c-brand-3: var(--vp-c-indigo-3);
  --vp-c-brand-soft: var(--vp-c-indigo-soft);
  --vp-c-tip-1: var(--vp-c-brand-1);
  --vp-c-tip-2: var(--vp-c-brand-2);
  --vp-c-tip-3: var(--vp-c-brand-3);
  --vp-c-tip-soft: var(--vp-c-brand-soft);
  --vp-c-warning-1: var(--vp-c-yellow-1);
  --vp-c-warning-2: var(--vp-c-yellow-2);
  --vp-c-warning-3: var(--vp-c-yellow-3);
  --vp-c-warning-soft: var(--vp-c-yellow-soft);
  --vp-c-danger-1: var(--vp-c-red-1);
  --vp-c-danger-2: var(--vp-c-red-2);
  --vp-c-danger-3: var(--vp-c-red-3);
  --vp-c-danger-soft: var(--vp-c-red-soft);
}
/**
* Component: Button
* -------------------------------------------------------------------------- */
:root {
  --vp-button-brand-border: transparent;
  --vp-button-brand-text: var(--vp-c-white);
  --vp-button-brand-bg: var(--vp-c-brand-3);
  --vp-button-brand-hover-border: transparent;
  --vp-button-brand-hover-text: var(--vp-c-white);
  --vp-button-brand-hover-bg: var(--vp-c-brand-2);
  --vp-button-brand-active-border: transparent;
  --vp-button-brand-active-text: var(--vp-c-white);
  --vp-button-brand-active-bg: var(--vp-c-brand-1);
}
/**
* Component: Home
* -------------------------------------------------------------------------- */
:root {
  --vp-home-hero-name-color: transparent;
  --vp-home-hero-name-background: -webkit-linear-gradient(
    120deg,
    #bd34fe 30%,
    #41d1ff
  );
  --vp-home-hero-image-background-image: linear-gradient(
    -45deg,
    #bd34fe 50%,
    #47caff 50%
  );
  --vp-home-hero-image-filter: blur(44px);
}
@media (min-width: 640px) {
  :root {
    --vp-home-hero-image-filter: blur(56px);
  }
}
@media (min-width: 960px) {
  :root {
    --vp-home-hero-image-filter: blur(68px);
  }
}
/**
* Component: Custom Block
* -------------------------------------------------------------------------- */
:root {
  --vp-custom-block-tip-border: transparent;
  --vp-custom-block-tip-text: var(--vp-c-text-1);
  --vp-custom-block-tip-bg: var(--vp-c-brand-soft);
  --vp-custom-block-tip-code-bg: var(--vp-c-brand-soft);
}
/**
* Component: Algolia
* -------------------------------------------------------------------------- */
.DocSearch {
  --docsearch-primary-color: var(--vp-c-brand-1) !important;
}
`,
      ),
    ]);
    return this({
      ...props,
      dir,
    });
  },
);
</file>

<file path="alchemy/src/web/astro.ts">
import { exec } from "node:child_process";
import fs from "node:fs/promises";
import path from "node:path";
import { promisify } from "node:util";
import type { Context } from "../context.js";
import { Folder } from "../fs/folder.js";
import { StaticJsonFile } from "../fs/static-json-file.js";
import { StaticTextFile } from "../fs/static-text-file.js";
import { StaticTypeScriptFile } from "../fs/static-typescript-file.js";
import { Resource } from "../resource.js";
import { ShadcnUI } from "./shadcn.js";
const execAsync = promisify(exec);
/**
 * Type of integrations that can be added to an Astro project
 */
export type AstroIntegration =
  | "react"
  | "preact"
  | "vue"
  | "svelte"
  | "solid"
  | "lit"
  | "tailwind"
  | "mdx"
  | "sitemap"
  | "partytown"
  | "markdoc";
/**
 * Properties for creating an Astro project
 */
export interface AstroProjectProps {
  /**
   * The name/path of the project
   */
  name: string;
  /**
   * The title of the site
   * @default "Astro Site"
   */
  title?: string;
  /**
   * The description of the site
   * @default "Welcome to my Astro site"
   */
  description?: string;
  /**
   * The directory to initialize the project in.
   * @default {@link name}
   */
  dir?: string;
  /**
   * The integrations to add to the project
   * @default []
   */
  integrations?: AstroIntegration[];
  /**
   * The TypeScript configuration
   */
  tsconfig?: {
    /**
     * Extends from this TypeScript configuration
     */
    extends?: string;
    /**
     * References to add to the tsconfig
     */
    references?: string[];
    /**
     * Compiler options to add to the tsconfig
     */
    compilerOptions?: Record<string, any>;
  };
  /**
   * Whether to delete the project folder during the delete phase
   * @default true
   */
  delete?: boolean;
  /**
   * Add Shadcn UI to the project
   * @default false
   */
  shadcn?: {
    /**
     * The base color to use
     * @default "neutral"
     */
    baseColor?: "neutral" | "gray" | "zinc" | "stone" | "slate";
    /**
     * Use default configuration
     * @default false
     */
    defaults?: boolean;
    /**
     * Force overwrite of existing configuration
     * @default false
     */
    force?: boolean;
    /**
     * Mute output
     * @default false
     */
    silent?: boolean;
    /**
     * Use the src directory when creating a new project
     * @default true
     */
    srcDir?: boolean;
    /**
     * Use css variables for theming
     * @default true
     */
    cssVariables?: boolean;
    /**
     * The components to add
     */
    components?: string[];
  };
  /**
   * The dependencies to install
   */
  dependencies?: Record<string, string>;
  /**
   * The dev dependencies to install
   */
  devDependencies?: Record<string, string>;
  /**
   * Additional scripts to add to package.json
   */
  scripts?: Record<string, string>;
}
/**
 * Astro project resource
 */
export interface AstroProject extends AstroProjectProps, Resource {
  /**
   * The name/path of the project
   */
  name: string;
}
/**
 * Creates a new Astro project
 *
 * @example
 * // Create a basic Astro project
 * const basicProject = await AstroProject("my-astro-app", {
 *   title: "My Astro Site",
 *   description: "Built with Alchemy"
 * });
 *
 * @example
 * // Create an Astro project with React and Tailwind
 * const reactProject = await AstroProject("astro-react", {
 *   title: "Astro + React",
 *   integrations: ["react", "tailwind"]
 * });
 *
 * @example
 * // Create an Astro project with Shadcn UI
 * const shadcnProject = await AstroProject("astro-shadcn", {
 *   title: "Astro with Shadcn UI",
 *   integrations: ["react", "tailwind"],
 *   shadcn: {
 *     baseColor: "zinc",
 *     components: ["button", "card", "input"]
 *   }
 * });
 */
export const AstroProject = Resource(
  "project::AstroProject",
  {
    alwaysUpdate: true,
  },
  async function (
    this: Context<AstroProject>,
    id: string,
    props: AstroProjectProps,
  ): Promise<AstroProject> {
    const dir = props.dir ?? props.name;
    if (this.phase === "delete") {
      try {
        if (props.delete !== false) {
          if (await fs.stat(dir).catch(() => null)) {
            await execAsync(`rm -rf ${dir}`);
          }
        }
      } catch (error) {
        console.error(`Error deleting project ${id}:`, error);
      }
      return this.destroy();
    }
    const cwd = path.resolve(process.cwd(), dir);
    // Create the project directory
    await Folder("project-dir", {
      path: dir,
      delete: true,
    });
    await Folder(".astro", {
      path: dir,
      delete: true,
      clean: true,
    });
    await setupProject(props);
    return this(props);
    /**
     * Set up the Astro project structure and configuration
     */
    async function setupProject(props: AstroProjectProps) {
      // Create project structure
      await ProjectStructure();
      // Set up package.json
      await StaticJsonFile(path.join(dir, "package.json"), {
        name: props.name,
        type: "module",
        version: "0.0.1",
        scripts: {
          dev: "astro dev",
          start: "astro dev",
          build: "astro build",
          preview: "astro preview",
          astro: "astro",
          ...props.scripts,
        },
        dependencies: props.dependencies || {},
        devDependencies: props.devDependencies || {},
      });
      // Set up tsconfig.json
      await StaticJsonFile(path.join(dir, "tsconfig.json"), {
        extends: props.tsconfig?.extends || "astro/tsconfigs/strict",
        compilerOptions: {
          baseUrl: ".",
          paths: {
            "@/*": ["./src/*"],
          },
          jsx: "react-jsx",
          jsxImportSource: "react",
          ...props.tsconfig?.compilerOptions,
        },
        include: ["src/**/*.ts", "src/**/*.tsx", "src/**/*.astro"],
        references: props.tsconfig?.references?.map((path) => ({ path })),
      });
      // Set up astro.config.mjs
      await AstroConfig();
      // Set up initial files
      await InitialFiles();
      // Install integrations
      if (props.integrations && props.integrations.length > 0) {
        await InstallIntegrations();
      }
      // Install dependencies
      await InstallDependencies();
      // Set up Shadcn if requested
      if (props.shadcn) {
        await ShadcnUI(id, {
          ...props.shadcn,
          cwd: dir,
        });
      }
    }
    /**
     * Create the basic project structure
     */
    async function ProjectStructure() {
      const folderPaths = [
        "src",
        "src/components",
        "src/layouts",
        "src/pages",
        "public",
      ];
      for (const folderPath of folderPaths) {
        await Folder(`${dir}-${folderPath}`, {
          path: path.join(dir, folderPath),
        });
      }
    }
    /**
     * Set up astro.config.mjs
     */
    async function AstroConfig() {
      const integrations = [];
      const vitePlugins = [];
      // Add imports and integrations
      const configImports = ['import { defineConfig } from "astro/config";'];
      if (props.integrations?.includes("react")) {
        configImports.push('import react from "@astrojs/react";');
        integrations.push("react()");
      }
      if (props.integrations?.includes("preact")) {
        configImports.push('import preact from "@astrojs/preact";');
        integrations.push("preact()");
      }
      if (props.integrations?.includes("vue")) {
        configImports.push('import vue from "@astrojs/vue";');
        integrations.push("vue()");
      }
      if (props.integrations?.includes("svelte")) {
        configImports.push('import svelte from "@astrojs/svelte";');
        integrations.push("svelte()");
      }
      if (props.integrations?.includes("solid")) {
        configImports.push('import solid from "@astrojs/solid-js";');
        integrations.push("solid()");
      }
      if (props.integrations?.includes("lit")) {
        configImports.push('import lit from "@astrojs/lit";');
        integrations.push("lit()");
      }
      if (props.integrations?.includes("tailwind")) {
        configImports.push('import tailwindcss from "@tailwindcss/vite";');
        vitePlugins.push("tailwindcss()");
      }
      if (props.integrations?.includes("mdx")) {
        configImports.push('import mdx from "@astrojs/mdx";');
        integrations.push("mdx()");
      }
      if (props.integrations?.includes("sitemap")) {
        configImports.push('import sitemap from "@astrojs/sitemap";');
        integrations.push("sitemap()");
      }
      if (props.integrations?.includes("partytown")) {
        configImports.push('import partytown from "@astrojs/partytown";');
        integrations.push("partytown()");
      }
      if (props.integrations?.includes("markdoc")) {
        configImports.push('import markdoc from "@astrojs/markdoc";');
        integrations.push("markdoc()");
      }
      const integrationsStr = integrations.length
        ? `\n  integrations: [${integrations.join(", ")}],`
        : "";
      const vitePluginsStr = vitePlugins.length
        ? `\n  vite: {\n    plugins: [${vitePlugins.join(", ")}]\n  },`
        : "";
      return StaticTypeScriptFile(
        path.join(dir, "astro.config.ts"),
        `${configImports.join("\n")}
// https://astro.build/config
export default defineConfig({${integrationsStr}${vitePluginsStr}
  site: "https://example.com",
  output: "static"
});`,
      );
    }
    /**
     * Create initial files for the project
     */
    async function InitialFiles() {
      // Create .gitignore
      await StaticTextFile(
        path.join(dir, ".gitignore"),
        `# build output
dist/
.output/
# dependencies
node_modules/
# logs
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
# environment variables
.env
.env.production
# macOS-specific files
.DS_Store
.astro/
`,
      );
      // Create .env.d.ts
      await StaticTextFile(
        path.join(dir, "src", "env.d.ts"),
        `/// <reference types="astro/client" />
`,
      );
      // Create a basic layout
      await StaticTextFile(
        path.join(dir, "src", "layouts", "Layout.astro"),
        `---
interface Props {
  title: string;
  description?: string;
}
const { title, description = "Welcome to my Astro site" } = Astro.props;
---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width" />
    <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
    <meta name="generator" content={Astro.generator} />
    <meta name="description" content={description} />
    <title>{title}</title>
  </head>
  <body>
    <slot />
  </body>
</html>
<style is:global>
  :root {
    --accent: 124, 58, 237;
    --accent-gradient: linear-gradient(45deg, rgb(var(--accent)), #da62c4 30%, white 60%);
  }
  html {
    font-family: system-ui, sans-serif;
    background-color: #f6f6f6;
  }
  code {
    font-family: Menlo, Monaco, Lucida Console, Liberation Mono, DejaVu Sans Mono,
      Bitstream Vera Sans Mono, Courier New, monospace;
  }
</style>
`,
      );
      // Create a basic index page
      await StaticTextFile(
        path.join(dir, "src", "pages", "index.astro"),
        `---
import Layout from '../layouts/Layout.astro';
---
<Layout title="${props.title || "Astro Site"}" description="${props.description || "Welcome to my Astro site"}">
  <main>
    <h1><span class="text-gradient">Astro</span> Site</h1>
    <p class="instructions">
      To get started, edit <code>src/pages/index.astro</code> and save to see your changes.
    </p>
  </main>
</Layout>
<style>
  main {
    margin: auto;
    padding: 1.5rem;
    max-width: 60ch;
  }
  h1 {
    font-size: 3rem;
    font-weight: 800;
    margin: 0;
  }
  .text-gradient {
    background-image: var(--accent-gradient);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    background-size: 400%;
    background-position: 0%;
  }
  .instructions {
    line-height: 1.6;
    margin: 1rem 0;
    border: 1px solid rgba(var(--accent), 25%);
    background-color: white;
    padding: 1rem;
    border-radius: 0.4rem;
  }
  .instructions code {
    font-size: 0.875em;
    font-weight: bold;
    background: rgba(var(--accent), 12%);
    color: rgb(var(--accent));
    border-radius: 4px;
    padding: 0.3em 0.45em;
  }
</style>
`,
      );
      // Create public/favicon.svg
      await StaticTextFile(
        path.join(dir, "public", "favicon.svg"),
        `<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 36 36">
  <path fill="#000" d="M22.25 4h-8.5a1 1 0 0 0-.96.73l-5.54 19.4a.5.5 0 0 0 .62.62l5.05-1.44a2 2 0 0 0 1.38-1.4l3.22-11.66a.5.5 0 0 1 .96 0l3.22 11.67a2 2 0 0 0 1.38 1.39l5.05 1.44a.5.5 0 0 0 .62-.62l-5.54-19.4a1 1 0 0 0-.96-.73Z"/>
  <path fill="url(#gradient)" d="M18 28a7.63 7.63 0 0 1-5-2c-1.4 2.1-.35 4.35.6 5.55.14.17.41.07.47-.15.44-1.8 2.93-1.22 2.93.6 0 2.28.87 3.4 1.72 3.81.34.16.59-.2.49-.56-.31-1.05-.29-2.46 1.29-3.25 3-1.5 3.17-4.83 2.5-6-.67.67-2.6 2-5 2Z"/>
  <defs>
    <linearGradient id="gradient" x1="16" x2="16" y1="32" y2="24" gradientUnits="userSpaceOnUse">
      <stop stop-color="#FF1639"/>
      <stop offset="1" stop-color="#FF1639" stop-opacity="0"/>
    </linearGradient>
  </defs>
</svg>
`,
      );
    }
    /**
     * Install Astro integrations
     */
    async function InstallIntegrations() {
      const exec = (command: string) => execAsync(command, { cwd });
      const integrationPackages = [];
      for (const integration of props.integrations!) {
        switch (integration) {
          case "react":
            integrationPackages.push("@astrojs/react", "react", "react-dom");
            break;
          case "preact":
            integrationPackages.push("@astrojs/preact", "preact");
            break;
          case "vue":
            integrationPackages.push("@astrojs/vue", "vue");
            break;
          case "svelte":
            integrationPackages.push("@astrojs/svelte", "svelte");
            break;
          case "solid":
            integrationPackages.push("@astrojs/solid-js", "solid-js");
            break;
          case "lit":
            integrationPackages.push("@astrojs/lit", "lit");
            break;
          case "tailwind":
            integrationPackages.push("@tailwindcss/vite", "tailwindcss");
            // Create a base.css file with @tailwind directives
            await Folder(path.join(dir, "src", "styles"));
            await StaticTextFile(
              path.join(dir, "src", "styles", "global.css"),
              `@tailwind base;
@tailwind components;
@tailwind utilities;
`,
            );
            break;
          case "mdx":
            integrationPackages.push("@astrojs/mdx");
            break;
          case "sitemap":
            integrationPackages.push("@astrojs/sitemap");
            break;
          case "partytown":
            integrationPackages.push("@astrojs/partytown");
            break;
          case "markdoc":
            integrationPackages.push("@astrojs/markdoc");
            break;
        }
      }
      if (integrationPackages.length > 0) {
        await exec(`bun add astro ${integrationPackages.join(" ")}`);
      }
    }
    /**
     * Install dependencies
     */
    async function InstallDependencies() {
      const exec = (command: string) => execAsync(command, { cwd });
      // Install Astro and general dependencies
      await exec("bun add astro");
      // Install dev dependencies
      const devDepsEntries = Object.entries(props.devDependencies || {});
      if (devDepsEntries.length > 0) {
        const devDepsArg = devDepsEntries
          .map(([name, version]) => `${name}@${version}`)
          .join(" ");
        await exec(`bun add -D ${devDepsArg}`);
      }
      // Install regular dependencies
      const depsEntries = Object.entries(props.dependencies || {});
      if (depsEntries.length > 0) {
        const depsArg = depsEntries
          .map(([name, version]) => `${name}@${version}`)
          .join(" ");
        await exec(`bun add ${depsArg}`);
      }
    }
  },
);
</file>

<file path="alchemy/src/web/shadcn-component.ts">
import { exec } from "node:child_process";
import fs from "node:fs/promises";
import path from "node:path";
import { promisify } from "node:util";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
const execAsync = promisify(exec);
export interface ShadcnComponentProps {
  /**
   * The name of the component to install
   */
  name: string;
  /**
   * The working directory where the component should be installed
   */
  cwd: string;
  /**
   * Force overwrite of existing component
   * @default false
   */
  force?: boolean;
  /**
   * Mute output
   * @default false
   */
  silent?: boolean;
}
export interface ShadcnComponent extends ShadcnComponentProps, Resource {
  /**
   * The name of the installed component
   */
  name: string;
}
export const ShadcnComponent = Resource(
  "project::ShadcnComponent",
  async function (
    this: Context<ShadcnComponent>,
    id: string,
    props: ShadcnComponentProps,
  ): Promise<ShadcnComponent> {
    if (this.phase === "delete") {
      await ignore("ENOENT", () =>
        fs.unlink(
          path.join(props.cwd, "src", "components", "ui", `${props.name}.tsx`),
        ),
      );
      return this.destroy();
    }
    // Build the shadcn add command with options
    const addCommand = [
      "bunx --bun shadcn@latest add",
      props.name,
      props.silent && "-s",
    ]
      .filter(Boolean)
      .join(" ");
    // Execute the command in the specified directory
    await execAsync(addCommand, { cwd: props.cwd });
    return this(props);
  },
);
</file>

<file path="alchemy/src/web/shadcn.ts">
import { exec } from "node:child_process";
import path from "node:path";
import { promisify } from "node:util";
import type { Context } from "../context.js";
import { Folder } from "../fs/folder.js";
import { StaticJsonFile } from "../fs/static-json-file.js";
import { StaticTypeScriptFile } from "../fs/static-typescript-file.js";
import { Resource } from "../resource.js";
import { ShadcnComponent } from "./shadcn-component.js";
const execAsync = promisify(exec);
/**
 * Properties for initializing Shadcn UI
 */
export interface ShadcnUIProps {
  /**
   * The working directory where Shadcn UI should be installed
   */
  cwd: string;
  /**
   * The base color to use
   * @default "neutral"
   */
  baseColor?: "neutral" | "gray" | "zinc" | "stone" | "slate";
  /**
   * Use default configuration
   * @default false
   */
  defaults?: boolean;
  /**
   * Force overwrite of existing configuration
   * @default false
   */
  force?: boolean;
  /**
   * Mute output
   * @default false
   */
  silent?: boolean;
  /**
   * Use the src directory when creating a new project
   * @default true
   */
  srcDir?: boolean;
  /**
   * Use css variables for theming
   * @default true
   */
  cssVariables?: boolean;
  /**
   * The components to add
   */
  components?: string[];
  /**
   * Whether tailwind is already installed and configured.
   * Shadcn UI requires Tailwind CSS to be installed and configured.
   * @default false
   */
  tailwind?: boolean;
  /**
   * Whether react is already installed
   * @default false
   */
  react?: boolean;
}
/**
 * Shadcn UI resource
 */
export interface ShadcnUI extends ShadcnUIProps, Resource<"project::ShadcnUI"> {
  /**
   * The working directory where Shadcn UI is installed
   */
  cwd: string;
  /**
   * The ui directory
   */
  ui: Folder;
  /**
   * The lib directory
   */
  lib: Folder;
}
/**
 * Initializes Shadcn UI in a project directory
 *
 * @example
 * // Initialize Shadcn UI with default settings
 * const shadcn = await ShadcnUI("my-shadcn", {
 *   cwd: "my-project",
 *   tailwind: true,  // Tailwind must be installed separately
 *   react: true     // React must be installed separately
 * });
 *
 * @example
 * // Initialize Shadcn UI with custom settings and components
 * const shadcn = await ShadcnUI("custom-shadcn", {
 *   cwd: "my-project",
 *   baseColor: "zinc",
 *   force: true,
 *   components: ["button", "card", "input"],
 *   tailwind: true,  // Tailwind must be installed separately
 *   react: true     // React must be installed separately
 * });
 */
export const ShadcnUI = Resource(
  "project::ShadcnUI",
  async function (
    this: Context<ShadcnUI>,
    id: string,
    props: ShadcnUIProps,
  ): Promise<ShadcnUI> {
    if (this.phase === "delete") {
      // For a delete phase, we don't perform any action
      // as removing Shadcn UI would require removing many files
      // which could be destructive to the project
      console.log(
        "Note: ShadcnUI delete phase does not remove installed components",
      );
      return this.destroy();
    }
    // Setup execAsync with the correct cwd
    const exec = (command: string) => execAsync(command, { cwd: props.cwd });
    // Ensure React is installed if not already
    if (!props.react) {
      await exec("bun add react react-dom");
    }
    // Install shadcn dependencies
    await exec("bun add -D @types/node");
    // Create components.json directly instead of running shadcn init
    await StaticJsonFile(path.join(props.cwd, "components.json"), {
      $schema: "https://ui.shadcn.com/schema.json",
      style: props.cssVariables !== false ? "default" : "new-york",
      tsx: true,
      rsc: false,
      tailwind: {
        config: "tailwind.config.js",
        css:
          props.srcDir !== false
            ? "src/styles/globals.css"
            : "styles/globals.css",
        baseColor: props.baseColor || "neutral",
        cssVariables: props.cssVariables !== false,
      },
      aliases: {
        components: props.srcDir !== false ? "@/components" : "./components",
        utils: props.srcDir !== false ? "@/lib/utils" : "./lib/utils",
      },
    });
    // Ensure ui components directory exists
    const ui = await Folder(
      path.join(
        props.cwd,
        props.srcDir !== false ? "src" : "",
        "components",
        "ui",
      ),
    );
    // Create lib directory
    const libPath = path.join(
      props.cwd,
      props.srcDir !== false ? "src" : "",
      "lib",
    );
    const lib = await Folder(libPath);
    // Create utils.ts file
    const utilsContent = `
      import { type ClassValue, clsx } from "clsx";
      import { twMerge } from "tailwind-merge";
      export function cn(...inputs: ClassValue[]) {
        return twMerge(clsx(inputs));
      }
    `;
    await StaticTypeScriptFile(path.join(libPath, "utils.ts"), utilsContent);
    // Install clsx and tailwind-merge
    await exec("bun add clsx tailwind-merge");
    // Install requested components
    if (props.components && props.components.length > 0) {
      for (const componentName of props.components) {
        await ShadcnComponent(`shadcn-component-${componentName}`, {
          name: componentName,
          cwd: props.cwd,
          force: props.force,
          silent: props.silent,
        });
      }
    }
    return this({
      ...props,
      ui,
      lib,
    });
  },
);
</file>

<file path="alchemy/src/web/tailwind.ts">
import { exec } from "node:child_process";
import path from "node:path";
import { promisify } from "node:util";
import type { Context } from "../context.js";
import { Folder } from "../fs/folder.js";
import { StaticTextFile } from "../fs/static-text-file.js";
import { Resource } from "../resource.js";
const execAsync = promisify(exec);
/**
 * Framework types supported by the Tailwind resource
 */
export type TailwindFramework = "vite" | "astro" | "next" | "standalone";
/**
 * Properties for Tailwind configuration
 */
export interface TailwindConfigProps {
  /**
   * The working directory where Tailwind should be installed
   */
  cwd: string;
  /**
   * The framework being used (determines which dependencies to install)
   * @default "standalone"
   */
  framework?: TailwindFramework;
  /**
   * The path to the CSS file where Tailwind directives should be added
   * If not provided, a new file will be created at src/styles/base.css
   */
  cssPath?: string;
  /**
   * Custom additional packages to install with Tailwind
   */
  additionalPackages?: string[];
}
/**
 * Tailwind configuration resource
 */
export interface TailwindConfig
  extends TailwindConfigProps,
    Resource<"config::TailwindConfig"> {
  /**
   * The working directory where Tailwind is installed
   */
  cwd: string;
}
/**
 * Installs and configures Tailwind CSS for a project
 *
 * @example
 * // Install Tailwind for a Vite project
 * const tailwind = await TailwindConfig("vite-tailwind", {
 *   cwd: "my-vite-app",
 *   framework: "vite"
 * });
 *
 * @example
 * // Install Tailwind for an Astro project
 * const tailwind = await TailwindConfig("astro-tailwind", {
 *   cwd: "my-astro-app",
 *   framework: "astro"
 * });
 *
 * @example
 * // Install Tailwind as standalone with a custom CSS path
 * const tailwind = await TailwindConfig("custom-tailwind", {
 *   cwd: "my-project",
 *   cssPath: "src/css/main.css",
 *   additionalPackages: ["@tailwindcss/typography", "@tailwindcss/forms"]
 * });
 */
export const TailwindConfig = Resource(
  "config::TailwindConfig",
  async function (
    this: Context<TailwindConfig>,
    id: string,
    props: TailwindConfigProps,
  ): Promise<TailwindConfig> {
    if (this.phase === "delete") {
      // Nothing to clean up specifically for Tailwind
      return this.destroy();
    }
    const framework = props.framework || "standalone";
    // Setup execAsync with the correct cwd
    const exec = (command: string) => execAsync(command, { cwd: props.cwd });
    // Install Tailwind and framework-specific dependencies
    await installTailwindDependencies(framework);
    // Create CSS file with Tailwind directives
    await createTailwindCssFile();
    return this({
      ...props,
      framework: framework,
    });
    /**
     * Install Tailwind and framework-specific dependencies
     */
    async function installTailwindDependencies(framework: TailwindFramework) {
      const basePackages = ["tailwindcss", "postcss", "autoprefixer"];
      // Add framework-specific packages
      const frameworkPackages = getFrameworkPackages(framework);
      // Add custom additional packages
      const additionalPackages = props.additionalPackages || [];
      // Combine all packages
      const allPackages = [
        ...basePackages,
        ...frameworkPackages,
        ...additionalPackages,
      ];
      // Install all packages
      await exec(`bun add -D ${allPackages.join(" ")}`);
    }
    /**
     * Get framework-specific packages for Tailwind
     */
    function getFrameworkPackages(framework: TailwindFramework): string[] {
      switch (framework) {
        case "vite":
          return ["@tailwindcss/vite"];
        case "astro":
          return ["@astrojs/tailwind"];
        case "next":
          return [];
        default:
          return [];
      }
    }
    /**
     * Create or update CSS file with Tailwind directives
     */
    async function createTailwindCssFile() {
      const tailwindDirectives = `@import 'tailwindcss';`;
      // Determine CSS file path
      const cssPath =
        props.cssPath || path.join(props.cwd, "src", "styles", "global.css");
      // Create directory structure if needed
      const cssDir = path.dirname(cssPath);
      await Folder(path.join(id, "css-dir"), {
        path: cssDir,
      });
      // Create CSS file with Tailwind directives
      await StaticTextFile(cssPath, tailwindDirectives);
    }
  },
);
</file>

<file path="alchemy/src/web/vite.ts">
import { exec } from "node:child_process";
import path from "node:path";
import { promisify } from "node:util";
import type { Context } from "../context.js";
import { Folder } from "../fs/folder.js";
import { StaticJsonFile } from "../fs/static-json-file.js";
import { StaticTypeScriptFile } from "../fs/static-typescript-file.js";
import { Resource } from "../resource.js";
import { rm } from "../util/rm.js";
import { ShadcnComponent } from "./shadcn-component.js";
import { TailwindConfig } from "./tailwind.js";
const execAsync = promisify(exec);
type ViteTemplate =
  | "vanilla"
  | "vanilla-ts"
  | "vue"
  | "vue-ts"
  | "react"
  | "react-ts"
  | "react-swc"
  | "react-swc-ts"
  | "preact"
  | "preact-ts"
  | "lit"
  | "lit-ts"
  | "svelte"
  | "svelte-ts"
  | "solid"
  | "solid-ts"
  | "qwik"
  | "qwik-ts";
export interface ViteProjectProps {
  /**
   * The name/path of the project
   */
  name: string;
  /**
   * The Vite template to use
   */
  template: ViteTemplate;
  /**
   * The extends to add to the tsconfig.json file
   */
  extends?: string;
  /**
   * The references to add to the tsconfig.json file
   */
  references?: string[];
  /**
   * Add Tailwind CSS to the project
   * @default false
   */
  tailwind?: boolean;
  /**
   * Add Tanstack Router to the project
   * @default false
   */
  tanstack?: boolean;
  /**
   * Add Shadcn UI to the project
   * @default false
   */
  shadcn?: {
    /**
     * The base color to use
     * @default "neutral"
     */
    baseColor?: "neutral" | "gray" | "zinc" | "stone" | "slate";
    /**
     * Use default configuration
     * @default false
     */
    defaults?: boolean;
    /**
     * Force overwrite of existing configuration
     * @default false
     */
    force?: boolean;
    /**
     * The working directory
     * @default current directory
     */
    cwd?: string;
    /**
     * Mute output
     * @default false
     */
    silent?: boolean;
    /**
     * Use the src directory when creating a new project
     * @default false
     */
    srcDir?: boolean;
    /**
     * Use css variables for theming
     * @default true
     */
    cssVariables?: boolean;
    /**
     * The components to add
     */
    components?: string[];
  };
  /**
   * Force overwrite the project config files during the update phase
   *
   * @default false
   */
  overwrite?: boolean;
  /**
   * Whether to delete the project folder during the delete phase
   * @default true
   */
  delete?: boolean;
}
export interface ViteProject extends ViteProjectProps, Resource {
  /**
   * The name/path of the project
   */
  name: string;
}
export const ViteProject = Resource(
  "project::ViteProject",
  {
    alwaysUpdate: true,
  },
  async function (
    this: Context<ViteProject>,
    id: string,
    props: ViteProjectProps,
  ): Promise<ViteProject> {
    const phase = this.phase;
    if (this.phase === "delete") {
      try {
        if (props.delete !== false) {
          await execAsync(`rm -rf ${props.name}`);
        }
      } catch (error) {
        console.error(`Error deleting project ${id}:`, error);
      }
      return this.destroy();
    }
    if (this.phase === "update") {
      if (props.overwrite) {
        await modifyConfig(props);
      } else {
        console.warn(
          "ViteProject does not support updates - the project must be recreated to change the template",
        );
      }
    } else {
      await execAsync(`bun create vite ${id} --template ${props.template}`);
      await modifyConfig(props);
    }
    return this(props);
    async function modifyConfig(props: ViteProjectProps) {
      const tailwind = props.tailwind ?? false;
      const tanstack = props.tanstack ?? false;
      const plugins = [
        tailwind && "tailwindcss()",
        tanstack &&
          "TanStackRouterVite({ target: 'react', autoCodeSplitting: true })",
        "react()",
      ].filter((s) => typeof s === "string");
      const cwd = path.resolve(process.cwd(), props.name);
      // Create folder for project
      await Folder("project-dir", {
        path: props.name,
        delete: props.delete,
      });
      const exec = (command: string) => execAsync(command, { cwd });
      if (phase === "create" || props.overwrite) {
        await removeUnnecessaryFiles();
      }
      await patchTsConfig();
      if (props.tailwind) {
        await installTailwind();
      }
      if (props.tanstack) {
        await installTanstack();
      }
      if (props.shadcn !== undefined) {
        await installShadcn();
      }
      await build();
      async function build() {
        // tsc -b will fail if we have not invoked tan stacks' code gen
        await execAsync("bun vite build", { cwd: props.name });
      }
      async function installTailwind() {
        await TailwindConfig(`${id}-tailwind`, {
          cwd: props.name,
          framework: "vite",
        });
        await StaticTypeScriptFile(
          path.join(props.name, "vite.config.ts"),
          `import path from "node:path";
import react from "@vitejs/plugin-react";
import { defineConfig } from "vite";
${tailwind ? "import tailwindcss from '@tailwindcss/vite';" : ""}
${tanstack ? 'import { TanStackRouterVite } from "@tanstack/router-plugin/vite";' : ""}
// https://vite.dev/config/
export default defineConfig({
  plugins: [${plugins.join(", ")}],
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "./src"),
    },
  },
});`,
        );
      }
      async function installShadcn() {
        await exec("bun add -D @types/node");
        // Build the shadcn init command with all options
        const shadcnOptions = props.shadcn;
        const initCommand = [
          "bunx --bun shadcn@latest init",
          shadcnOptions?.baseColor && `-b ${shadcnOptions.baseColor}`,
          shadcnOptions?.defaults && "-d",
          shadcnOptions?.force && "-f",
          shadcnOptions?.cwd && `-c ${shadcnOptions.cwd}`,
          shadcnOptions?.silent && "-s",
          shadcnOptions?.srcDir && "--src-dir",
          shadcnOptions?.cssVariables === false && "--no-css-variables",
        ]
          .filter(Boolean)
          .join(" ");
        await exec(initCommand);
        // Install requested components using the ShadcnComponent resource
        for (const componentName of props.shadcn?.components ?? []) {
          await ShadcnComponent(`shadcn-component-${componentName}`, {
            name: componentName,
            cwd: props.name,
            force: props.shadcn?.force,
            silent: props.shadcn?.silent,
          });
        }
      }
      async function installTanstack() {
        await exec("bun add @tanstack/react-router");
        await exec(
          "bun add -D @tanstack/router-plugin @tanstack/react-router-devtools",
        );
        const src = path.join(props.name, "src");
        const routes = path.join(src, "routes");
        // Create routes directory
        await Folder("routes-dir", {
          path: routes,
        });
        // Create root route file
        await StaticTypeScriptFile(
          path.join(routes, "__root.tsx"),
          `import { Link, Outlet, createRootRoute } from "@tanstack/react-router";
import { TanStackRouterDevtools } from "@tanstack/react-router-devtools";
export const Route = createRootRoute({
  component: () => (
    <div className="w-full min-h-screen flex flex-col">
      <div className="p-2 flex gap-2">
        <Link to="/" className="[&.active]:font-bold">
          Home
        </Link>{" "}
        <Link to="/about" className="[&.active]:font-bold">
          About
        </Link>
      </div>
      <hr />
      <Outlet />
      <TanStackRouterDevtools />
    </div>
  ),
});
`,
        );
        // Create index route file
        await StaticTypeScriptFile(
          path.join(routes, "index.tsx"),
          `import { createLazyFileRoute } from '@tanstack/react-router'
export const Route = createLazyFileRoute('/')({
  component: Index,
})
function Index() {
  return (
    <div className="p-2">
      <h3>Welcome Home!</h3>
    </div>
  )
}`,
        );
        // Create about route file
        await StaticTypeScriptFile(
          path.join(routes, "about.tsx"),
          `import { createLazyFileRoute } from '@tanstack/react-router'
export const Route = createLazyFileRoute('/about')({
  component: About,
})
function About() {
  return <div className="p-2">Hello from About!</div>
}`,
        );
        // Create main.tsx
        await StaticTypeScriptFile(
          path.join(src, "main.tsx"),
          `import { StrictMode } from 'react'
import ReactDOM from 'react-dom/client'
import { RouterProvider, createRouter } from '@tanstack/react-router'
import './index.css'
// Import the generated route tree
import { routeTree } from './routeTree.gen'
// Create a new router instance
const router = createRouter({ routeTree })
// Register the router instance for type safety
declare module '@tanstack/react-router' {
  interface Register {
    router: typeof router
  }
}
// Render the app
const rootElement = document.getElementById('root')!
if (!rootElement.innerHTML) {
  const root = ReactDOM.createRoot(rootElement)
  root.render(
    <StrictMode>
      <RouterProvider router={router} />
    </StrictMode>,
  )
}`,
        );
      }
      async function removeUnnecessaryFiles() {
        await rm(path.join(props.name, "src", "App.tsx"));
        await rm(path.join(props.name, "src", "App.css"));
      }
      async function patchTsConfig() {
        await rm(path.join(props.name, "tsconfig.app.json"));
        await rm(path.join(props.name, "tsconfig.node.json"));
        await StaticJsonFile(path.join(props.name, "tsconfig.json"), {
          extends: props.extends,
          compilerOptions: {
            baseUrl: ".",
            paths: {
              "@/*": ["./src/*"],
            },
            types: ["@cloudflare/workers-types"],
            allowImportingTsExtensions: true,
            jsx: "react-jsx",
          },
          include: ["vite/*.ts", "src/**/*.ts", "src/**/*.tsx", "src/env.d.ts"],
          references: props.references?.map((path) => ({ path })),
        });
      }
    }
  },
);
</file>

<file path="alchemy/src/alchemy.ts">
import fs from "node:fs/promises";
import path from "node:path";
import { destroy, DestroyedSignal } from "./destroy.js";
import { env } from "./env.js";
import type { PendingResource } from "./resource.js";
import { Scope } from "./scope.js";
import { secret } from "./secret.js";
import type { StateStoreType } from "./state.js";
/**
 * Type alias for semantic highlighting of `alchemy` as a type keyword
 */
export type alchemy = Alchemy;
export const alchemy: Alchemy = _alchemy as any;
/**
 * The Alchemy interface provides core functionality and is augmented by providers.
 * Supports both application scoping with secrets and template string interpolation.
 *
 * @example
 * // Create an application scope with stage and secret handling
 * const app = await alchemy("github:alchemy", {
 *   stage: "prod",
 *   phase: "up",
 *   // Required for encrypting/decrypting secrets
 *   password: process.env.SECRET_PASSPHRASE
 * });
 *
 * // Create a resource with encrypted secrets
 * const resource = await Resource("my-resource", {
 *   apiKey: alchemy.secret(process.env.API_KEY)
 * });
 *
 * await app.finalize();
 */
export interface Alchemy {
  run: typeof run;
  destroy: typeof destroy;
  /**
   * Get an environment variable and error if it's not set.
   */
  env: typeof env;
  /**
   * Creates an encrypted secret that can be safely stored in state files.
   * Requires a password to be set either globally in the application options
   * or locally in the current scope.
   */
  secret: typeof secret;
  /**
   * Creates a new application scope with the given name and options.
   * Used to create and manage resources with proper secret handling.
   *
   * @example
   * const app = await alchemy("my-app", {
   *   stage: "prod",
   *   // Required for encrypting/decrypting secrets
   *   password: process.env.SECRET_PASSPHRASE
   * });
   */
  (appName: string, options?: Omit<AlchemyOptions, "appName">): Promise<Scope>;
  /**
   * Template literal tag that supports file interpolation for documentation.
   * Automatically formats the content and appends file contents as code blocks.
   *
   * @example
   * // Generate documentation using file contents
   * await Document("api-docs", {
   *   prompt: await alchemy`
   *     Generate docs using the contents of:
   *     ${alchemy.file("README.md")}
   *     ${alchemy.file("./.cursorrules")}
   *
   *     And here are the source files:
   *     ${alchemy.files(files)}
   *   `
   * });
   */
  (template: TemplateStringsArray, ...values: any[]): Promise<string>;
}
_alchemy.destroy = destroy;
_alchemy.run = run;
_alchemy.secret = secret;
_alchemy.env = env;
/**
 * Implementation of the alchemy function that handles both application scoping
 * and template string interpolation.
 */
async function _alchemy(
  ...args:
    | [template: TemplateStringsArray, ...values: any[]]
    | [appName: string, options?: Omit<AlchemyOptions, "appName">]
): Promise<Scope | string | never> {
  if (typeof args[0] === "string") {
    const [appName, options] = args as [string, AlchemyOptions?];
    const phase = options?.phase ?? "up";
    const root = new Scope({
      ...options,
      appName,
      stage: options?.stage,
      phase,
    });
    root.enter();
    if (options?.phase === "destroy") {
      await destroy(root);
      return process.exit(0);
    }
    return root;
  }
  const [template, ...values] = args;
  const [, secondLine] = template[0].split("\n");
  const leadingSpaces = secondLine
    ? secondLine.match(/^(\s*)/)?.[1]?.length || 0
    : 0;
  const indent = " ".repeat(leadingSpaces);
  const [{ isFileRef }, { isFileCollection }] = await Promise.all([
    import("./fs/file-ref.js"),
    import("./fs/file-collection.js"),
  ]);
  const appendices: Record<string, string> = {};
  const stringValues = await Promise.all(
    values.map(async function resolve(value): Promise<string> {
      if (typeof value === "string") {
        return indent + value;
      }
      if (value === null) {
        return "null";
      }
      if (value === undefined) {
        return "undefined";
      }
      if (
        typeof value === "number" ||
        typeof value === "boolean" ||
        typeof value === "bigint"
      ) {
        return value.toString();
      }
      if (value instanceof Promise) {
        return resolve(await value);
      }
      if (isFileRef(value)) {
        if (!(value.path in appendices)) {
          appendices[value.path] = await fs.readFile(value.path, "utf-8");
        }
        return `[${path.basename(value.path)}](${value.path})`;
      }
      if (isFileCollection(value)) {
        return Object.entries(value.files)
          .map(([filePath, content]) => {
            appendices[filePath] = content;
            return `[${path.basename(filePath)}](${filePath})`;
          })
          .join("\n\n");
      }
      if (Array.isArray(value)) {
        return (
          await Promise.all(
            value.map(async (value, i) => `${i}. ${await resolve(value)}`),
          )
        ).join("\n");
      }
      if (typeof value === "object" && typeof value.path === "string") {
        if (typeof value.content === "string") {
          appendices[value.path] = value.content;
          return `[${path.basename(value.path)}](${value.path})`;
        }
        appendices[value.path] = await fs.readFile(value.path, "utf-8");
        return `[${path.basename(value.path)}](${value.path})`;
      }
      if (typeof value === "object") {
        return (
          await Promise.all(
            Object.entries(value).map(async ([key, value]) => {
              return `* ${key}: ${await resolve(value)}`;
            }),
          )
        ).join("\n");
      }
      // TODO: support other types
      console.log(value);
      throw new Error(`Unsupported value type: ${value}`);
    }),
  );
  // Construct the string template by joining template parts with interpolated values
  const lines = template
    .map((part) =>
      part
        .split("\n")
        .map((line) =>
          line.startsWith(indent) ? line.slice(indent.length) : line,
        )
        .join("\n"),
    )
    .flatMap((part, i) =>
      i < stringValues.length ? [part, stringValues[i] ?? ""] : [part],
    )
    .join("")
    .split("\n");
  // Collect and sort appendices by file path
  return [
    // format the user prompt and trim the first line if it's empty
    lines.length > 1 && lines[0].replaceAll(" ", "").length === 0
      ? lines.slice(1).join("\n")
      : lines.join("\n"),
    // sort appendices by path and include at the end of the prompt
    Object.entries(appendices)
      .sort(([a], [b]) => a.localeCompare(b))
      .map(([filePath, content]) => {
        const extension = path.extname(filePath).slice(1);
        const codeTag = extension ? extension : "";
        return `// ${filePath}\n\`\`\`${codeTag}\n${content}\n\`\`\``;
      })
      .join("\n\n"),
  ].join("\n");
}
export type Phase = "up" | "destroy" | "read";
export interface AlchemyOptions {
  /**
   * The name of the application.
   */
  appName?: string;
  /**
   * Determines whether the resources will be created/updated or deleted.
   *
   * @default "up"
   */
  phase?: Phase;
  /**
   * Name to scope the resource state under (e.g. `.alchemy/{stage}/..`).
   *
   * @default - your POSIX username
   */
  stage?: string;
  /**
   * If true, will not prune resources that were dropped from the root stack.
   *
   * @default true
   */
  destroyOrphans?: boolean;
  /**
   * A custom state store to use instead of the default file system store.
   */
  stateStore?: StateStoreType;
  /**
   * A custom scope to use as a parent.
   */
  parent?: Scope;
  /**
   * If true, will not print any Create/Update/Delete messages.
   *
   * @default false
   */
  quiet?: boolean;
  /**
   * A passphrase to use to encrypt/decrypt secrets.
   * Required if using alchemy.secret() in this scope.
   */
  password?: string;
}
export interface ScopeOptions extends AlchemyOptions {
  enter: boolean;
}
export interface RunOptions extends AlchemyOptions {
  /**
   * @default false
   */
  // TODO(sam): this is an awful hack to differentiate between naked scopes and resources
  isResource?: boolean;
}
/**
 * Run a function in a new scope asynchronously.
 * Useful for isolating secret handling with a specific password.
 *
 * @example
 * // Run operations in a scope with its own password
 * await alchemy.run("secure-scope", {
 *   password: process.env.SCOPE_PASSWORD
 * }, async () => {
 *   // Secrets in this scope will use this password
 *   const resource = await Resource("my-resource", {
 *     apiKey: alchemy.secret(process.env.API_KEY)
 *   });
 * });
 */
async function run<T>(
  ...args:
    | [id: string, fn: (this: Scope, scope: Scope) => Promise<T>]
    | [
        id: string,
        options: RunOptions,
        fn: (this: Scope, scope: Scope) => Promise<T>,
      ]
): Promise<T> {
  const [id, options, fn] =
    typeof args[1] === "function"
      ? [args[0], undefined, args[1]]
      : (args as [
          string,
          RunOptions,
          (this: Scope, scope: Scope) => Promise<T>,
        ]);
  const _scope = new Scope({
    ...options,
    scopeName: id,
  });
  try {
    if (options?.isResource !== true && _scope.parent) {
      // TODO(sam): this is an awful hack to differentiate between naked scopes and resources
      const seq = _scope.parent.seq();
      const output = {
        ID: id,
        FQN: "",
        Kind: "alchemy::Scope",
        Scope: _scope,
        Seq: seq,
      } as const;
      const resource = {
        kind: "scope",
        id,
        seq,
        data: {},
        fqn: "",
        props: {},
        status: "created",
        output,
      } as const;
      await _scope.parent!.state.set(id, resource);
      _scope.parent!.resources.set(
        id,
        Object.assign(Promise.resolve(resource), output) as PendingResource,
      );
    }
    return await _scope.run(async () => fn.bind(_scope)(_scope));
  } catch (error) {
    if (!(error instanceof DestroyedSignal)) {
      console.log(error);
      _scope.fail();
    }
    throw error;
  } finally {
    await _scope.finalize();
  }
}
</file>

<file path="alchemy/src/apply.ts">
import { alchemy } from "./alchemy.js";
import { context } from "./context.js";
import {
  PROVIDERS,
  type PendingResource,
  type Provider,
  type Resource,
  type ResourceProps,
} from "./resource.js";
import { serialize } from "./serde.js";
import type { State } from "./state.js";
export interface ApplyOptions {
  quiet?: boolean;
  alwaysUpdate?: boolean;
}
export async function apply<Out extends Resource>(
  resource: PendingResource<Out>,
  props: ResourceProps | undefined,
  options?: ApplyOptions,
): Promise<Awaited<Out>> {
  const scope = resource.Scope;
  try {
    const quiet = props?.quiet ?? scope.quiet;
    await scope.init();
    let state: State | undefined = (await scope.state.get(resource.ID))!;
    const provider: Provider = PROVIDERS.get(resource.Kind);
    if (provider === undefined) {
      throw new Error(`Provider "${resource.Kind}" not found`);
    }
    if (scope.phase === "read") {
      if (state === undefined) {
        throw new Error(
          `Resource "${resource.FQN}" not found and running in 'read' phase.`,
        );
      }
      return state.output as Awaited<Out>;
    }
    if (state === undefined) {
      state = {
        kind: resource.Kind,
        id: resource.ID,
        fqn: resource.FQN,
        seq: resource.Seq,
        status: "creating",
        data: {},
        output: {
          ID: resource.ID,
          FQN: resource.FQN,
          Kind: resource.Kind,
          Scope: scope,
          Seq: resource.Seq,
        },
        // deps: [...deps],
        props,
      };
      await scope.state.set(resource.ID, state);
    }
    const alwaysUpdate =
      options?.alwaysUpdate ?? provider.options?.alwaysUpdate ?? false;
    // Skip update if inputs haven't changed and resource is in a stable state
    if (state.status === "created" || state.status === "updated") {
      const oldProps = await serialize(scope, state.props, {
        encrypt: false,
      });
      const newProps = await serialize(scope, props, {
        encrypt: false,
      });
      if (
        JSON.stringify(oldProps) === JSON.stringify(newProps) &&
        alwaysUpdate !== true
      ) {
        if (!quiet) {
          // console.log(`Skip:    "${resource.FQN}" (no changes)`);
        }
        return state.output as Awaited<Out>;
      }
    }
    const phase = state.status === "creating" ? "create" : "update";
    state.status = phase === "create" ? "creating" : "updating";
    state.oldProps = state.props;
    state.props = props;
    if (!quiet) {
      console.log(
        `${phase === "create" ? "Create" : "Update"}:  "${resource.FQN}"`,
      );
    }
    await scope.state.set(resource.ID, state);
    let isReplaced = false;
    const ctx = context({
      scope,
      phase,
      kind: resource.Kind,
      id: resource.ID,
      fqn: resource.FQN,
      seq: resource.Seq,
      props: state.oldProps,
      state,
      replace: () => {
        if (isReplaced) {
          console.warn(
            `Resource ${resource.Kind} ${resource.FQN} is already marked as REPLACE`,
          );
          return;
        }
        isReplaced = true;
      },
    });
    const output = await alchemy.run(
      resource.ID,
      {
        isResource: true,
      },
      async () => provider.handler.bind(ctx)(resource.ID, props),
    );
    if (!quiet) {
      console.log(
        `${phase === "create" ? "Created" : "Updated"}: "${resource.FQN}"`,
      );
    }
    await scope.state.set(resource.ID, {
      kind: resource.Kind,
      id: resource.ID,
      fqn: resource.FQN,
      seq: resource.Seq,
      data: state.data,
      status: phase === "create" ? "created" : "updated",
      output,
      props,
      // deps: [...deps],
    });
    // if (output !== undefined) {
    //   resource[Provide](output as Out);
    // }
    return output as any;
  } catch (error) {
    scope.fail();
    throw error;
  }
}
</file>

<file path="alchemy/src/context.ts">
import { DestroyedSignal } from "./destroy.js";
import type {
  Resource,
  ResourceFQN,
  ResourceID,
  ResourceKind,
  ResourceProps,
} from "./resource.js";
import type { Scope } from "./scope.js";
import type { State } from "./state.js";
export type Context<
  Out extends Resource,
  Props extends ResourceProps = ResourceProps,
> = CreateContext<Out> | UpdateContext<Out, Props> | DeleteContext<Out, Props>;
export interface CreateContext<Out extends Resource> extends BaseContext<Out> {
  phase: "create";
  output?: undefined;
  props?: undefined;
}
export interface UpdateContext<
  Out extends Resource,
  Props extends ResourceProps = ResourceProps,
> extends BaseContext<Out> {
  phase: "update";
  output: Out;
  props: Props;
}
export interface DeleteContext<
  Out extends Resource,
  Props extends ResourceProps = ResourceProps,
> extends BaseContext<Out> {
  phase: "delete";
  output: Out;
  props: Props;
}
export interface BaseContext<Out extends Resource> {
  quiet: boolean;
  stage: string;
  id: ResourceID;
  fqn: ResourceFQN;
  scope: Scope;
  get<T>(key: string): Promise<T | undefined>;
  set<T>(key: string, value: T): Promise<void>;
  delete<T>(key: string): Promise<T | undefined>;
  /**
   * Indicate that this resource is being replaced.
   * This will cause the resource to be deleted at the end of the stack's CREATE phase.
   */
  replace(): void;
  /**
   * Terminate the resource lifecycle handler and destroy the resource.
   *
   * This is the final operation performed during a delete operation.
   *
   * It is so that the resource lifecycle handler can "return never" instead of
   * "return undefined" so that `await MyResource()` always returns a value.
   */
  destroy(): never;
  /**
   * Create the Resource envelope (with Alchemy + User properties)
   */
  create(props: Omit<Out, keyof Resource>): Out;
  /**
   * Create the Resource envelope (with Alchemy + User properties)
   */
  (id: string, props: Omit<Out, keyof Resource>): Out;
  (props: Omit<Out, keyof Resource>): Out;
}
export function context<
  Kind extends string,
  Props extends ResourceProps | undefined,
  Out extends Resource,
>({
  scope,
  phase,
  kind,
  id,
  fqn,
  seq,
  state,
  replace,
}: {
  scope: Scope;
  phase: "create" | "update" | "delete";
  kind: ResourceKind;
  id: ResourceID;
  fqn: ResourceFQN;
  seq: number;
  props: Props;
  state: State<Kind, Props, Out>;
  replace: () => void;
}): Context<Out> {
  function create(props: Omit<Out, "Kind" | "ID" | "Scope">): Out;
  function create(id: string, props: Omit<Out, "Kind" | "ID" | "Scope">): Out;
  function create(
    ...args:
      | [props: Omit<Out, "Kind" | "ID" | "Scope">]
      | [id: string, props: Omit<Out, "Kind" | "ID" | "Scope">]
  ): Out {
    const [ID, props] =
      typeof args[0] === "string" ? (args as [string, any]) : [id, args[0]];
    return {
      ...props,
      Kind: kind,
      ID,
      FQN: fqn,
      Scope: scope,
      Seq: seq,
    } as Out;
  }
  return Object.assign(create, {
    stage: scope.stage,
    scope,
    id: id,
    fqn: fqn,
    phase,
    output: state.output,
    props: state.props,
    replace,
    get: (key: string) => state.data[key],
    set: async (key: string, value: any) => {
      state.data[key] = value;
    },
    delete: async (key: string) => {
      const value = state.data[key];
      delete state.data[key];
      return value;
    },
    quiet: scope.quiet,
    destroy: () => {
      throw new DestroyedSignal();
    },
    create,
  }) as Context<Out>;
}
</file>

<file path="alchemy/src/destroy.ts">
import { alchemy } from "./alchemy.js";
import { context } from "./context.js";
import { PROVIDERS, type Provider, type Resource } from "./resource.js";
import { Scope } from "./scope.js";
export class DestroyedSignal extends Error {}
export interface DestroyOptions {
  quiet?: boolean;
  strategy?: "sequential" | "parallel";
}
function isScopeArgs(a: any): a is [scope: Scope, options?: DestroyOptions] {
  return a[0] instanceof Scope;
}
/**
 * Prune all resources from an Output and "down", i.e. that branches from it.
 */
export async function destroy<Type extends string>(
  ...args:
    | [scope: Scope, options?: DestroyOptions]
    | [resource: Resource<Type> | undefined | null, options?: DestroyOptions]
): Promise<void> {
  if (isScopeArgs(args)) {
    const [scope] = args;
    const options = {
      strategy: "sequential",
      ...(args[1] ?? {}),
    } satisfies DestroyOptions;
    // destroy all active resources
    await destroy.all(Array.from(scope.resources.values()), options);
    // then detect orphans and destroy them
    const orphans = await scope.state.all();
    await destroy.all(
      Object.values(orphans).map((orphan) => ({
        ...orphan.output,
        Scope: scope,
      })),
      options,
    );
    // finally, destroy the scope container
    await scope.deinit();
    return;
  }
  const [instance, options] = args;
  if (!instance) {
    return;
  }
  if (instance.Kind === "alchemy::Scope") {
    const scope = new Scope({
      parent: instance.Scope,
      scopeName: instance.ID,
    });
    console.log("Destroying scope", scope.chain.join("/"));
    return await destroy(scope, options);
  }
  const Provider: Provider<Type> | undefined = PROVIDERS.get(instance.Kind);
  if (!Provider) {
    throw new Error(
      `Cannot destroy resource "${instance.FQN}" type ${instance.Kind} - no provider found. You may need to import the provider in your alchemy.config.ts.`,
    );
  }
  const scope = instance.Scope;
  if (!scope) {
    console.warn(`Resource "${instance.FQN}" has no scope`);
  }
  const quiet = options?.quiet ?? scope.quiet;
  try {
    if (!quiet) {
      console.log(`Delete:  "${instance.FQN}"`);
    }
    const state = await scope.state.get(instance.ID);
    if (state === undefined) {
      return;
    }
    const ctx = context({
      scope,
      phase: "delete",
      kind: instance.Kind,
      id: instance.ID,
      fqn: instance.FQN,
      seq: instance.Seq,
      props: state.props,
      state,
      replace: () => {
        throw new Error("Cannot replace a resource that is being deleted");
      },
    });
    let nestedScope: Scope | undefined;
    try {
      // BUG: this does not restore persisted scope
      await alchemy.run(
        instance.ID,
        {
          // TODO(sam): this is an awful hack to differentiate between naked scopes and resources
          isResource: instance.Kind !== "alchemy::Scope",
          parent: scope,
        },
        async (scope) => {
          nestedScope = scope;
          return await Provider.handler.bind(ctx)(instance.ID, state.props);
        },
      );
    } catch (err) {
      if (err instanceof DestroyedSignal) {
        // TODO: should we fail if the DestroyedSignal is not thrown?
      } else {
        throw err;
      }
    }
    if (nestedScope) {
      await destroy(nestedScope, options);
    }
    await scope.delete(instance.ID);
    if (!quiet) {
      console.log(`Deleted: "${instance.FQN}"`);
    }
  } catch (error) {
    console.error(error);
    throw error;
  }
}
export namespace destroy {
  export async function all(resources: Resource[], options?: DestroyOptions) {
    if (options?.strategy !== "parallel") {
      const sorted = resources.sort((a, b) => b.Seq - a.Seq);
      for (const resource of sorted) {
        await destroy(resource, options);
      }
    } else {
      await Promise.all(
        resources.map((resource) => destroy(resource, options)),
      );
    }
  }
  export async function sequentially(
    ...resources: (Resource<string> | undefined | null)[]
  ) {
    for (const resource of resources) {
      if (resource) {
        await destroy(resource);
      }
    }
  }
}
</file>

<file path="alchemy/src/encrypt.ts">
import sodium from "libsodium-wrappers";
/**
 * Encrypt a value with a symmetric key using libsodium
 *
 * @param value - The value to encrypt
 * @param key - The encryption key
 * @returns The base64-encoded encrypted value with nonce
 */
export async function encrypt(value: string, key: string): Promise<string> {
  // Initialize libsodium
  await sodium.ready;
  // Derive a key from the passphrase
  const cryptoKey = sodium.crypto_generichash(
    sodium.crypto_secretbox_KEYBYTES,
    sodium.from_string(key),
  );
  // Generate a random nonce
  const nonce = sodium.randombytes_buf(sodium.crypto_secretbox_NONCEBYTES);
  // Encrypt the message
  const encryptedBin = sodium.crypto_secretbox_easy(
    sodium.from_string(value),
    nonce,
    cryptoKey,
  );
  // Combine nonce and ciphertext, then encode to base64
  const combined = new Uint8Array(nonce.length + encryptedBin.length);
  combined.set(nonce);
  combined.set(encryptedBin, nonce.length);
  return sodium.to_base64(combined, sodium.base64_variants.ORIGINAL);
}
/**
 * Decrypt a value encrypted with a symmetric key
 *
 * @param encryptedValue - The base64-encoded encrypted value with nonce
 * @param key - The decryption key
 * @returns The decrypted string
 */
export async function decryptWithKey(
  encryptedValue: string,
  key: string,
): Promise<string> {
  // Initialize libsodium
  await sodium.ready;
  // Derive a key from the passphrase
  const cryptoKey = sodium.crypto_generichash(
    sodium.crypto_secretbox_KEYBYTES,
    sodium.from_string(key),
  );
  // Decode the base64 combined value
  const combined = sodium.from_base64(
    encryptedValue,
    sodium.base64_variants.ORIGINAL,
  );
  // Extract nonce and ciphertext
  const nonce = combined.slice(0, sodium.crypto_secretbox_NONCEBYTES);
  const ciphertext = combined.slice(sodium.crypto_secretbox_NONCEBYTES);
  // Decrypt the message
  const decryptedBin = sodium.crypto_secretbox_open_easy(
    ciphertext,
    nonce,
    cryptoKey,
  );
  return sodium.to_string(decryptedBin);
}
</file>

<file path="alchemy/src/env.ts">
export interface Env {
  [key: string]: Promise<string>;
  <T = string>(name: string, value?: T | undefined, error?: string): Promise<T>;
}
export const env = new Proxy(_env, {
  get: (_, name: string) => _env(name),
  apply: (_, __, args: [string, any?, string?]) => _env(...args),
}) as Env;
async function _env<T = string>(
  name: string,
  value?: T | undefined,
  error?: string,
): Promise<T> {
  if (value !== undefined) {
    return value;
  }
  if (typeof process !== "undefined") {
    // we are in a node environment
    return process.env[name]! as T;
  }
  // we are in a browser environment
  try {
    const { env } = await import("cloudflare:workers");
    if (name in env) {
      return env[name as keyof typeof env] as T;
    }
  } catch (error) {}
  throw new Error(error ?? `Environment variable ${name} is not set`);
}
</file>

<file path="alchemy/src/index.ts">
export type { AlchemyOptions } from "./alchemy.js";
export type * from "./context.js";
export * from "./resource.js";
export type * from "./scope.js";
export * from "./secret.js";
export * from "./serde.js";
export * from "./state.js";
export * from "./util/ignore.js";
import { alchemy } from "./alchemy.js";
export default alchemy;
</file>

<file path="alchemy/src/resource.ts">
import { apply } from "./apply.js";
import type { Context } from "./context.js";
import { Scope as _Scope } from "./scope.js";
export const PROVIDERS = new Map<ResourceKind, Provider<string, any>>();
export type ResourceID = string;
export type ResourceFQN = string;
export type ResourceKind = string;
export interface ProviderOptions {
  /**
   * If true, the resource will be updated even if the inputs have not changed.
   */
  alwaysUpdate: boolean;
}
export type ResourceProps = {
  [key: string]: any;
};
export type Provider<
  Type extends string = string,
  F extends ResourceLifecycleHandler = ResourceLifecycleHandler,
> = F &
  IsClass & {
    type: Type;
    options: Partial<ProviderOptions> | undefined;
    handler: F;
  };
export type PendingResource<
  Out = unknown,
  Kind extends ResourceKind = ResourceKind,
  ID extends ResourceID = ResourceID,
  FQN extends ResourceFQN = ResourceFQN,
  Scope extends _Scope = _Scope,
  Seq extends number = number,
> = Promise<Out> & {
  Kind: Kind;
  ID: ID;
  FQN: FQN;
  Seq: Seq;
  Scope: Scope;
  signal: () => void;
};
export interface Resource<
  // give each name types for syntax highlighting (differentiation)
  Kind extends ResourceKind = ResourceKind,
  ID extends ResourceID = ResourceID,
  FQN extends ResourceFQN = ResourceFQN,
  Scope extends _Scope = _Scope,
  Seq extends number = number,
> {
  // use capital letters to avoid collision with conventional camelCase typescript properties
  Kind: Kind;
  ID: ID;
  FQN: FQN;
  Scope: Scope;
  Seq: Seq;
}
// helper for semantic syntax highlighting (color as a type/class instead of function/value)
type IsClass = {
  new (_: never): never;
};
type ResourceLifecycleHandler = (
  this: Context<any, any>,
  id: string,
  props: any,
) => Promise<Resource<string>>;
// see: https://x.com/samgoodwin89/status/1904640134097887653
type Handler<F extends (...args: any[]) => any> =
  | F
  | (((this: any, id: string, props?: {}) => never) & IsClass);
export function Resource<
  const Type extends string,
  F extends ResourceLifecycleHandler,
>(type: Type, fn: F): Handler<F>;
export function Resource<
  const Type extends string,
  F extends ResourceLifecycleHandler,
>(type: Type, options: Partial<ProviderOptions>, fn: F): Handler<F>;
export function Resource<
  const Type extends ResourceKind,
  F extends ResourceLifecycleHandler,
>(type: Type, ...args: [Partial<ProviderOptions>, F] | [F]): Handler<F> {
  if (PROVIDERS.has(type)) {
    throw new Error(`Resource ${type} already exists`);
  }
  const [options, handler] = args.length === 2 ? args : [undefined, args[0]];
  type Out = Awaited<ReturnType<F>>;
  const provider = ((
    resourceID: string,
    props: ResourceProps,
  ): Promise<Resource<string>> => {
    const scope = _Scope.current;
    if (resourceID.includes(":")) {
      // we want to use : as an internal separator for resources
      throw new Error(`ID cannot include colons: ${resourceID}`);
    }
    if (scope.resources.has(resourceID)) {
      // TODO(sam): do we want to throw?
      // it's kind of awesome that you can re-create a resource and call apply
      const otherResource = scope.resources.get(resourceID);
      if (otherResource?.Kind !== type) {
        scope.fail();
        throw new Error(
          `Resource ${resourceID} already exists in the stack and is of a different type: '${otherResource?.Kind}' !== '${type}'`,
        );
      }
      // console.warn(
      //   `Resource ${resourceID} already exists in the stack: ${scope.chain.join("/")}`,
      // );
    }
    // get a sequence number (unique within the scope) for the resource
    const seq = scope.seq();
    const meta = {
      Kind: type,
      ID: resourceID,
      FQN: scope.fqn(resourceID),
      Seq: seq,
      Scope: scope,
    } as any as PendingResource<Out>;
    const promise = apply(meta, props, options);
    const resource = Object.assign(promise, meta);
    scope.resources.set(resourceID, resource);
    return resource;
  }) as Provider<Type, F>;
  provider.type = type;
  provider.handler = handler;
  provider.options = options;
  PROVIDERS.set(type, provider);
  return provider;
}
</file>

<file path="alchemy/src/scope.ts">
import { AsyncLocalStorage } from "node:async_hooks";
import type { Phase } from "./alchemy.js";
import { destroy } from "./destroy.js";
import { FileSystemStateStore } from "./fs/file-system-state-store.js";
import type { PendingResource, ResourceID } from "./resource.js";
import type { StateStore, StateStoreType } from "./state.js";
const scopeStorage = new AsyncLocalStorage<Scope>();
export type ScopeOptions = {
  appName?: string;
  stage?: string;
  parent?: Scope;
  scopeName?: string;
  password?: string;
  stateStore?: StateStoreType;
  quiet?: boolean;
  phase?: Phase;
};
// TODO: support browser
const DEFAULT_STAGE = process.env.ALCHEMY_STAGE ?? process.env.USER ?? "dev";
export class Scope {
  public static get(): Scope | undefined {
    return scopeStorage.getStore();
  }
  public static get current(): Scope {
    const scope = Scope.get();
    if (!scope) {
      throw new Error("Not running within an Alchemy Scope");
    }
    return scope;
  }
  public readonly resources = new Map<ResourceID, PendingResource>();
  public readonly appName: string | undefined;
  public readonly stage: string;
  public readonly scopeName: string | null;
  public readonly parent: Scope | undefined;
  public readonly password: string | undefined;
  public readonly state: StateStore;
  public readonly stateStore: StateStoreType;
  public readonly quiet: boolean;
  public readonly phase: Phase;
  private isErrored = false;
  constructor(options: ScopeOptions) {
    this.appName = options.appName;
    this.stage = options?.stage ?? DEFAULT_STAGE;
    this.scopeName = options.scopeName ?? null;
    if (this.scopeName?.includes(":")) {
      throw new Error(
        `Scope name ${this.scopeName} cannot contain double colons`,
      );
    }
    this.parent = options.parent ?? Scope.get();
    this.quiet = options.quiet ?? this.parent?.quiet ?? false;
    if (this.parent && !this.scopeName) {
      throw new Error("Scope name is required when creating a child scope");
    }
    this.password = options.password ?? this.parent?.password;
    this.stateStore =
      options.stateStore ??
      this.parent?.stateStore ??
      ((scope) => new FileSystemStateStore(scope));
    this.state = this.stateStore(this);
    const phase = options.phase ?? this.parent?.phase;
    if (phase === undefined) {
      throw new Error("Phase is required");
    }
    this.phase = phase;
  }
  public async delete(resourceID: ResourceID) {
    await this.state.delete(resourceID);
    this.resources.delete(resourceID);
  }
  private _seq = 0;
  public seq() {
    return this._seq++;
  }
  public get chain(): string[] {
    const thisScope = this.scopeName ? [this.scopeName] : [];
    const app = this.appName ? [this.appName] : [];
    if (this.parent) {
      return [...this.parent.chain, ...thisScope];
    }
    return [...app, this.stage, ...thisScope];
  }
  public fail() {
    console.error("Scope failed", this.chain.join("/"));
    this.isErrored = true;
  }
  public enter() {
    scopeStorage.enterWith(this);
  }
  public async init() {
    await this.state.init?.();
  }
  public async deinit() {
    await this.parent?.state.delete(this.scopeName!);
    await this.state.deinit?.();
  }
  public fqn(resourceID: ResourceID): string {
    return [...this.chain, resourceID].join("/");
  }
  public async run<T>(fn: (scope: Scope) => Promise<T>): Promise<T> {
    return scopeStorage.run(this, () => fn(this));
  }
  [Symbol.asyncDispose]() {
    return this.finalize();
  }
  public async finalize() {
    if (this.phase === "read") {
      return;
    }
    if (!this.isErrored) {
      // TODO: need to detect if it is in error
      const resourceIds = await this.state.list();
      const aliveIds = new Set(this.resources.keys());
      const orphanIds = Array.from(
        resourceIds.filter((id) => !aliveIds.has(id)),
      );
      const orphans = await Promise.all(
        orphanIds.map(async (id) => (await this.state.get(id))!.output),
      );
      await destroy.all(orphans, {
        quiet: this.quiet,
        strategy: "sequential",
      });
    } else {
      console.warn("Scope is in error, skipping finalize");
    }
  }
  /**
   * Returns a string representation of the scope.
   */
  public toString() {
    return `Scope(
  chain=${this.chain.join("/")},
  resources=[${Array.from(this.resources.values())
    .map((r) => r.ID)
    .join(",\n  ")}]
)`;
  }
}
</file>

<file path="alchemy/src/secret.ts">
import { alchemy } from "./alchemy.js";
/**
 * Internal wrapper for sensitive values like API keys and credentials.
 * When stored in alchemy state files, the value is automatically encrypted
 * using the application's password. The password can be provided either:
 *
 * 1. Globally when initializing the alchemy application:
 * ```ts
 * const app = await alchemy("my-app", {
 *   password: process.env.SECRET_PASSPHRASE
 * });
 * ```
 *
 * 2. For a specific scope using alchemy.run:
 * ```ts
 * await alchemy.run("scope-name", {
 *   password: process.env.SECRET_PASSPHRASE
 * }, async () => {
 *   // Secrets in this scope will use this password
 *   alchemy.secret(process.env.MY_SECRET)
 * });
 * ```
 *
 * Without a password, secrets cannot be encrypted or decrypted, and operations
 * involving sensitive values will fail.
 *
 * @example
 * // In state file (.alchemy/app/prod/resource.json):
 * {
 *   "props": {
 *     "apiKey": {
 *       "@secret": "encrypted-value-here..." // encrypted using app password
 *     }
 *   }
 * }
 */
export class Secret {
  public readonly type = "secret";
  constructor(readonly unencrypted: string) {}
}
/**
 * Type guard to check if a value is a Secret wrapper
 */
export function isSecret(binding: any): binding is Secret {
  return (
    binding instanceof Secret ||
    (typeof binding === "object" && binding.type === "secret_text")
  );
}
/**
 * Wraps a sensitive value so it will be encrypted when stored in state files.
 * Requires a password to be set either globally in the alchemy application options
 * or locally in an alchemy.run scope.
 *
 * @example
 * // Global password for all secrets
 * const app = await alchemy("my-app", {
 *   password: process.env.SECRET_PASSPHRASE
 * });
 *
 * const resource = await Resource("my-resource", {
 *   apiKey: alchemy.secret(process.env.API_KEY)
 * });
 *
 * @example
 * // Scoped password for specific secrets
 * await alchemy.run("secure-scope", {
 *   password: process.env.SCOPE_SECRET_PASSPHRASE
 * }, async () => {
 *   const resource = await Resource("my-resource", {
 *     apiKey: alchemy.secret(process.env.API_KEY)
 *   });
 * });
 *
 * @param unencrypted The sensitive value to encrypt in state files
 * @throws {Error} If the value is undefined
 * @throws {Error} If no password is set in the alchemy application options or current scope
 */
export function secret<S extends string | undefined>(unencrypted: S): Secret {
  if (unencrypted === undefined) {
    throw new Error("Secret cannot be undefined");
  }
  return new Secret(unencrypted);
}
export namespace secret {
  export interface Env {
    [key: string]: Promise<Secret>;
    (name: string, value?: string, error?: string): Promise<Secret>;
  }
  export const env = new Proxy(_env, {
    get: (_, name: string) => _env(name),
    apply: (_, __, args: [string, any?, string?]) => _env(...args),
  }) as Env;
  async function _env(
    name: string,
    value?: string,
    error?: string,
  ): Promise<Secret> {
    const result = await alchemy.env(name, value, error);
    if (typeof result === "string") {
      return secret(result);
    }
    throw new Error(`Secret environment variable ${name} is not a string`);
  }
}
</file>

<file path="alchemy/src/serde.ts">
import { decryptWithKey, encrypt } from "./encrypt.js";
import { Scope } from "./scope.js";
import { Secret } from "./secret.js";
import type { Type } from "arktype";
// zero-dependency type guard for ArkType
function isType(value: any): value is Type<any, any> {
  return (
    value &&
    typeof value === "object" &&
    typeof value.toJsonSchema === "function"
  );
}
export async function serialize(
  scope: Scope,
  value: any,
  options?: {
    encrypt?: boolean;
  },
): Promise<any> {
  if (Array.isArray(value)) {
    return Promise.all(value.map((value) => serialize(scope, value, options)));
  } else if (value instanceof Secret) {
    if (!scope.password) {
      throw new Error("Cannot serialize secret without password");
    }
    return {
      "@secret":
        options?.encrypt !== false
          ? await encrypt(value.unencrypted, scope.password)
          : value.unencrypted,
    };
  } else if (isType(value)) {
    return {
      "@schema": value.toJSON(),
    };
  } else if (value instanceof Date) {
    return {
      "@date": value.toISOString(),
    };
  } else if (typeof value === "symbol") {
    assertNotUniqueSymbol(value);
    return {
      "@symbol": value.toString(),
    };
  } else if (value instanceof Scope) {
    return {
      "@scope": null,
    };
  } else if (value && typeof value === "object") {
    for (const symbol of Object.getOwnPropertySymbols(value)) {
      assertNotUniqueSymbol(symbol);
    }
    for (const key of Object.keys(value)) {
      if (parseSymbol(key)) {
        throw new Error(
          `Cannot serialize property '${key}' because it looks like a stringified symbol.`,
        );
      }
    }
    return Object.fromEntries(
      await Promise.all(
        [...Object.getOwnPropertySymbols(value), ...Object.keys(value)].map(
          async (key) => [
            key.toString(),
            await serialize(scope, value[key], options),
          ],
        ),
      ),
    );
  } else if (typeof value === "function") {
    // can't serialize functions
    return undefined;
  }
  return value;
}
export async function deserialize(scope: Scope, value: any): Promise<any> {
  if (Array.isArray(value)) {
    return await Promise.all(
      value.map(async (item) => await deserialize(scope, item)),
    );
  }
  if (value && typeof value === "object") {
    if (typeof value["@secret"] === "string") {
      if (!scope.password) {
        throw new Error("Cannot deserialize secret without password");
      }
      return new Secret(await decryptWithKey(value["@secret"], scope.password));
    } else if ("@schema" in value) {
      return value["@schema"];
    } else if ("@date" in value) {
      return new Date(value["@date"]);
    } else if ("@symbol" in value) {
      return parseSymbol(value["@symbol"]);
    } else if ("@scope" in value) {
      return scope;
    }
    return Object.fromEntries(
      await Promise.all(
        Object.entries(value).map(async ([key, value]) => [
          parseSymbol(key) ?? key,
          await deserialize(scope, value),
        ]),
      ),
    );
  }
  return value;
}
const symbolPattern = /^Symbol\((.*)\)$/;
function parseSymbol(value: string) {
  const match = value.match(symbolPattern);
  if (!match) {
    return undefined;
  }
  return Symbol.for(match[1]);
}
function assertNotUniqueSymbol(symbol: Symbol) {
  if (
    symbol.description === undefined ||
    symbol !== Symbol.for(symbol.description)
  ) {
    throw new Error(`Cannot serialize unique symbol: ${symbol.description}`);
  }
}
</file>

<file path="alchemy/src/state.ts">
import type { Resource, ResourceProps } from "./resource.js";
import type { Scope } from "./scope.js";
export type State<
  Kind extends string = string,
  Props extends ResourceProps | undefined = ResourceProps | undefined,
  Out extends Resource = Resource,
> = {
  status:
    | `creating`
    | `created`
    | `updating`
    | `updated`
    | `deleting`
    | `deleted`;
  kind: Kind;
  id: string;
  fqn: string;
  seq: number;
  data: Record<string, any>;
  // deps: string[];
  props: Props;
  oldProps?: Props;
  output: Out;
};
export type StateStoreType = (scope: Scope) => StateStore;
export interface StateStore {
  /** Initialize the state container if one is required */
  init?(): Promise<void>;
  /** Delete the state container if one exists */
  deinit?(): Promise<void>;
  /** List all resources in the given stage. */
  list(): Promise<string[]>;
  /** Return the number of items let in this store */
  count(): Promise<number>;
  get(key: string): Promise<State | undefined>;
  getBatch(ids: string[]): Promise<Record<string, State>>;
  all(): Promise<Record<string, State>>;
  set(key: string, value: State): Promise<void>;
  delete(key: string): Promise<void>;
}
</file>

<file path="alchemy/test/aws/function.test.ts">
import {
  GetFunctionCommand,
  GetFunctionUrlConfigCommand,
  InvokeCommand,
  LambdaClient,
  ResourceNotFoundException,
} from "@aws-sdk/client-lambda";
import { describe, expect } from "bun:test";
import path from "node:path";
import { alchemy } from "../../src/alchemy.js";
import { Function } from "../../src/aws/function.js";
import type { PolicyDocument } from "../../src/aws/policy.js";
import { Role } from "../../src/aws/role.js";
import { destroy } from "../../src/destroy.js";
import { Bundle } from "../../src/esbuild";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const __dirname = path.dirname(new URL(import.meta.url).pathname);
const lambda = new LambdaClient({});
// Common policy definitions
const LAMBDA_ASSUME_ROLE_POLICY: PolicyDocument = {
  Version: "2012-10-17",
  Statement: [
    {
      Effect: "Allow",
      Principal: {
        Service: "lambda.amazonaws.com",
      },
      Action: "sts:AssumeRole",
    },
  ],
};
const LAMBDA_LOGS_POLICY: PolicyDocument = {
  Version: "2012-10-17",
  Statement: [
    {
      Effect: "Allow",
      Action: [
        "logs:CreateLogGroup",
        "logs:CreateLogStream",
        "logs:PutLogEvents",
      ],
      Resource: "*",
    },
  ],
};
// Helper function to invoke a Lambda function directly
const invokeLambda = async (functionName: string, event: any) => {
  const invokeResponse = await lambda.send(
    new InvokeCommand({
      FunctionName: functionName,
      Payload: JSON.stringify(event),
    }),
  );
  const responsePayload = new TextDecoder().decode(invokeResponse.Payload);
  return JSON.parse(responsePayload);
};
describe("AWS Resources", () => {
  describe("Function", () => {
    test("create function with bundled code", async (scope) => {
      // First create the execution role
      // Define resources that need to be cleaned up
      let role: Role | undefined = undefined;
      let func: Function | null = null;
      const functionName = `${BRANCH_PREFIX}-alchemy-test-function`;
      const roleName = `${BRANCH_PREFIX}-alchemy-test-lambda-role`;
      try {
        let bundle = await Bundle(`${BRANCH_PREFIX}-test-lambda-bundle`, {
          entryPoint: path.join(__dirname, "..", "handler.ts"),
          outdir: ".out",
          format: "cjs",
          platform: "node",
          target: "node18",
        });
        role = await Role(roleName, {
          roleName,
          assumeRolePolicy: LAMBDA_ASSUME_ROLE_POLICY,
          description: "Test role for Lambda function",
          policies: [
            {
              policyName: "logs",
              policyDocument: LAMBDA_LOGS_POLICY,
            },
          ],
          tags: {
            Environment: "test",
          },
        });
        // Create the Lambda function
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
        });
        expect(func.arn).toMatch(
          new RegExp(
            `^arn:aws:lambda:[a-z0-9-]+:\\d+:function:${functionName}$`,
          ),
        );
        expect(func.state).toBe("Active");
        expect(func.lastUpdateStatus).toBe("Successful");
        expect(func.invokeArn).toMatch(
          new RegExp(
            `^arn:aws:apigateway:[a-z0-9-]+:lambda:path\\/2015-03-31\\/functions\\/arn:aws:lambda:[a-z0-9-]+:\\d+:function:${functionName}\\/invocations$`,
          ),
        );
        // Immediately apply again to test stabilization logic
        expect(func.state).toBe("Active");
        expect(func.lastUpdateStatus).toBe("Successful");
        // Invoke the function
        const testEvent = { test: "event" };
        const invokeResponse = await lambda.send(
          new InvokeCommand({
            FunctionName: functionName,
            Payload: JSON.stringify(testEvent),
          }),
        );
        // Parse the response
        const responsePayload = new TextDecoder().decode(
          invokeResponse.Payload,
        );
        const response = JSON.parse(responsePayload);
        expect(response.statusCode).toBe(200);
        const body = JSON.parse(response.body);
        expect(body.message).toBe("Hello from bundled handler!");
        expect(body.event).toEqual(testEvent);
      } finally {
        await destroy(scope);
        // Verify function was properly deleted after cleanup
        if (func) {
          await expect(
            lambda.send(
              new GetFunctionCommand({
                FunctionName: functionName,
              }),
            ),
          ).rejects.toThrow(ResourceNotFoundException);
        }
      }
    });
    test("create function with URL configuration", async (scope) => {
      // Create execution role
      // Define resources that need to be cleaned up
      let role: Role | undefined = undefined;
      let func: Function | null = null;
      const functionName = `${BRANCH_PREFIX}-alchemy-test-function-url`;
      const roleName = `${BRANCH_PREFIX}-alchemy-test-lambda-url-role`;
      try {
        let bundle = await Bundle(`${BRANCH_PREFIX}-test-lambda-url-bundle`, {
          entryPoint: path.join(__dirname, "..", "handler.ts"),
          outdir: ".out",
          format: "cjs",
          platform: "node",
          target: "node18",
        });
        role = await Role(roleName, {
          roleName,
          assumeRolePolicy: LAMBDA_ASSUME_ROLE_POLICY,
          description: "Test role for Lambda function with URL",
          policies: [
            {
              policyName: "logs",
              policyDocument: LAMBDA_LOGS_POLICY,
            },
          ],
          tags: {
            Environment: "test",
          },
        });
        // Create the Lambda function with URL config
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify function was created with URL
        expect(func.arn).toMatch(
          new RegExp(
            `^arn:aws:lambda:[a-z0-9-]+:\\d+:function:${functionName}$`,
          ),
        );
        expect(func.state).toBe("Active");
        expect(func.lastUpdateStatus).toBe("Successful");
        expect(func.functionUrl).toBeTruthy();
        expect(func.functionUrl).toMatch(
          /^https:\/\/.+\.lambda-url\..+\.on\.aws\/?$/,
        );
        // Test function URL by making an HTTP request
        const testEvent = { test: "event" };
        const response = await fetch(func.functionUrl!, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(testEvent),
        });
        expect(response.status).toBe(200);
        const responseBody = await response.json();
        expect(responseBody.message).toBe("Hello from bundled handler!");
        expect(responseBody.event).toEqual(testEvent);
        // Update the function to remove the URL
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          // No URL config means it should be removed
        });
        // Verify URL was removed
        expect(func.functionUrl).toBeUndefined();
      } finally {
        await destroy(scope);
        // Verify function was properly deleted after cleanup
        if (func) {
          await expect(
            lambda.send(
              new GetFunctionCommand({
                FunctionName: functionName,
              }),
            ),
          ).rejects.toThrow(ResourceNotFoundException);
        }
      }
    });
    test("create function with URL then remove URL in update phase", async (scope) => {
      // Define resources that need to be cleaned up
      let role: Role | undefined = undefined;
      let func: Function | null = null;
      const functionName = `${BRANCH_PREFIX}-alchemy-test-func-url-remove`;
      const roleName = `${BRANCH_PREFIX}-alchemy-test-lambda-url-rem-role`;
      try {
        let bundle = await Bundle(
          `${BRANCH_PREFIX}-test-lambda-url-remove-bundle`,
          {
            entryPoint: path.join(__dirname, "..", "handler.ts"),
            outdir: ".out",
            format: "cjs",
            platform: "node",
            target: "node18",
          },
        );
        role = await Role(roleName, {
          roleName,
          assumeRolePolicy: LAMBDA_ASSUME_ROLE_POLICY,
          description: "Test role for Lambda function",
          policies: [
            {
              policyName: "logs",
              policyDocument: LAMBDA_LOGS_POLICY,
            },
          ],
          tags: {
            Environment: "test",
          },
        });
        // Create the Lambda function with URL config
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify function was created with URL
        expect(func.arn).toBeTruthy();
        expect(func.state).toBe("Active");
        expect(func.functionUrl).toBeTruthy();
        // Test function URL invocation
        const testEvent = { test: "url-event" };
        const urlResponse = await fetch(func.functionUrl!, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(testEvent),
        });
        expect(urlResponse.status).toBe(200);
        const urlResponseBody = await urlResponse.json();
        expect(urlResponseBody.message).toBe("Hello from bundled handler!");
        expect(urlResponseBody.event).toEqual(testEvent);
        // Also invoke directly
        const directResponse = await invokeLambda(functionName, {
          direct: "invoke",
        });
        expect(directResponse.statusCode).toBe(200);
        const directBody = JSON.parse(directResponse.body);
        expect(directBody.message).toBe("Hello from bundled handler!");
        expect(directBody.event).toEqual({ direct: "invoke" });
        // Now update the function to remove the URL
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          // No URL config to remove it
        });
        // Verify URL was removed
        expect(func.functionUrl).toBeUndefined();
        // Try to invoke URL (should fail)
        let urlFailed = false;
        try {
          await fetch(func.functionUrl || "https://invalid-url", {
            method: "POST",
          });
        } catch (error) {
          urlFailed = true;
        }
        expect(urlFailed).toBe(true);
        // Direct invocation should still work
        const directResponse2 = await invokeLambda(functionName, {
          after: "update",
        });
        expect(directResponse2.statusCode).toBe(200);
        const directBody2 = JSON.parse(directResponse2.body);
        expect(directBody2.message).toBe("Hello from bundled handler!");
        expect(directBody2.event).toEqual({ after: "update" });
      } finally {
        await destroy(scope);
      }
    });
    test("create function without URL then add URL in update phase", async (scope) => {
      // Define resources that need to be cleaned up
      let role: Role | undefined = undefined;
      let func: Function | null = null;
      const functionName = `${BRANCH_PREFIX}-alchemy-test-func-add-url`;
      const roleName = `${BRANCH_PREFIX}-alchemy-test-lambda-add-url-role`;
      try {
        let bundle = await Bundle(
          `${BRANCH_PREFIX}-test-lambda-add-url-bundle`,
          {
            entryPoint: path.join(__dirname, "..", "handler.ts"),
            outdir: ".out",
            format: "cjs",
            platform: "node",
            target: "node18",
          },
        );
        role = await Role(roleName, {
          roleName,
          assumeRolePolicy: LAMBDA_ASSUME_ROLE_POLICY,
          description: "Test role for Lambda function",
          policies: [
            {
              policyName: "logs",
              policyDocument: LAMBDA_LOGS_POLICY,
            },
          ],
          tags: {
            Environment: "test",
          },
        });
        // Create the Lambda function without URL config
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          // No URL config initially
        });
        // Verify function was created without URL
        expect(func.arn).toBeTruthy();
        expect(func.state).toBe("Active");
        expect(func.functionUrl).toBeUndefined();
        // Invoke directly
        const directResponse = await invokeLambda(functionName, {
          initial: "invoke",
        });
        expect(directResponse.statusCode).toBe(200);
        const directBody = JSON.parse(directResponse.body);
        expect(directBody.message).toBe("Hello from bundled handler!");
        expect(directBody.event).toEqual({ initial: "invoke" });
        // Now update the function to add the URL
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify URL was added
        expect(func.functionUrl).toBeTruthy();
        expect(func.functionUrl).toMatch(
          /^https:\/\/.+\.lambda-url\..+\.on\.aws\/?$/,
        );
        // Test function URL invocation
        const testEvent = { test: "added-url-event" };
        const urlResponse = await fetch(func.functionUrl!, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(testEvent),
        });
        expect(urlResponse.status).toBe(200);
        const urlResponseBody = await urlResponse.json();
        expect(urlResponseBody.message).toBe("Hello from bundled handler!");
        expect(urlResponseBody.event).toEqual(testEvent);
        // Direct invocation should still work
        const directResponse2 = await invokeLambda(functionName, {
          after: "url-added",
        });
        expect(directResponse2.statusCode).toBe(200);
        const directBody2 = JSON.parse(directResponse2.body);
        expect(directBody2.message).toBe("Hello from bundled handler!");
        expect(directBody2.event).toEqual({ after: "url-added" });
      } finally {
        await destroy(scope);
      }
    });
    test("create function with URL invokeMode configuration", async (scope) => {
      // Define resources that need to be cleaned up
      let role: Role | undefined = undefined;
      let func: Function | null = null;
      const functionName = `${BRANCH_PREFIX}-alchemy-test-func-invoke-mode`;
      const roleName = `${BRANCH_PREFIX}-alchemy-test-lambda-invoke-mode-role`;
      try {
        let bundle = await Bundle(
          `${BRANCH_PREFIX}-test-lambda-invoke-mode-bundle`,
          {
            entryPoint: path.join(__dirname, "..", "handler.ts"),
            outdir: ".out",
            format: "cjs",
            platform: "node",
            target: "node18",
          },
        );
        role = await Role(roleName, {
          roleName,
          assumeRolePolicy: LAMBDA_ASSUME_ROLE_POLICY,
          description: "Test role for Lambda function with invoke mode",
          policies: [
            {
              policyName: "logs",
              policyDocument: LAMBDA_LOGS_POLICY,
            },
          ],
          tags: {
            Environment: "test",
          },
        });
        // Create the Lambda function with BUFFERED invoke mode (default)
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            // Default invokeMode is BUFFERED if not specified
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify function was created with URL
        expect(func.arn).toBeTruthy();
        expect(func.state).toBe("Active");
        expect(func.functionUrl).toBeTruthy();
        // Test function URL invocation (default BUFFERED mode)
        const testEvent = { test: "buffered-mode" };
        const response = await fetch(func.functionUrl!, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(testEvent),
        });
        expect(response.status).toBe(200);
        const responseBody = await response.json();
        expect(responseBody.message).toBe("Hello from bundled handler!");
        expect(responseBody.event).toEqual(testEvent);
        // Update function to explicitly set BUFFERED mode
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            invokeMode: "BUFFERED", // Explicitly set BUFFERED
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify function still has URL
        expect(func.functionUrl).toBeTruthy();
        // Now update to RESPONSE_STREAM mode
        func = await Function(functionName, {
          functionName,
          bundle,
          roleArn: role.arn,
          handler: "index.handler",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            invokeMode: "RESPONSE_STREAM", // Change to streaming mode
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify function still has URL
        expect(func.functionUrl).toBeTruthy();
        // Test function URL invocation (now in RESPONSE_STREAM mode)
        const streamTestEvent = { test: "response-stream-mode" };
        const streamResponse = await fetch(func.functionUrl!, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(streamTestEvent),
        });
        // Check the status code
        expect(streamResponse.status).toBe(200);
        // Test the URL configuration to verify the invokeMode setting was properly applied
        const urlConfig = await lambda.send(
          new GetFunctionUrlConfigCommand({
            FunctionName: functionName,
          }),
        );
        // Verify that the invokeMode property is set to RESPONSE_STREAM in the Lambda URL config
        expect(urlConfig.InvokeMode).toBe("RESPONSE_STREAM");
        // Properly test streaming by consuming the stream chunk by chunk
        if (streamResponse.body) {
          try {
            // Get a reader to read the chunks
            const reader = streamResponse.body.getReader();
            let receivedData = "";
            let chunkCount = 0;
            // Read all chunks
            while (true) {
              const { done, value } = await reader.read();
              if (done) {
                break;
              }
              // Convert chunk to string and log
              const chunk = new TextDecoder().decode(value);
              chunkCount++;
              receivedData += chunk;
            }
            // Success indicator - we were able to read from the stream
            expect(chunkCount).toBeGreaterThan(0);
            // Try to parse the complete data
            if (receivedData?.trim()) {
              try {
                const responseBody = JSON.parse(receivedData);
                if (responseBody.message) {
                  expect(responseBody.message).toBe(
                    "Hello from bundled handler!",
                  );
                }
                if (responseBody.event) {
                  expect(responseBody.event).toEqual(streamTestEvent);
                }
              } catch (error) {
                console.log("Error parsing JSON response:", error);
                // Don't fail the test for JSON parsing errors
              }
            }
          } catch (streamError) {
            console.error("Error reading stream:", streamError);
            // Fall back to response.text() if streaming fails
            const responseText = await streamResponse.clone().text();
            console.log("Fallback response text length:", responseText.length);
          }
        } else {
          console.log(
            "No response body stream available - using text() method",
          );
          // Fall back to response.text() if no stream is available
          const responseText = await streamResponse.text();
          console.log("Response text length:", responseText.length);
          try {
            const responseBody = JSON.parse(responseText);
            console.log("Parsed JSON response:", responseBody);
            if (responseBody.message) {
              expect(responseBody.message).toBe("Hello from bundled handler!");
            }
            if (responseBody.event) {
              expect(responseBody.event).toEqual(streamTestEvent);
            }
          } catch (error) {
            console.log("Error parsing JSON response:", error);
          }
        }
      } finally {
        await destroy(scope);
        // Verify function was properly deleted after cleanup
        if (func) {
          await expect(
            lambda.send(
              new GetFunctionCommand({
                FunctionName: functionName,
              }),
            ),
          ).rejects.toThrow(ResourceNotFoundException);
        }
      }
    });
    test("create function with handler containing _, 0-9, and A-Z", async (scope) => {
      // Define resources that need to be cleaned up
      let role: Role | undefined = undefined;
      let func: Function | null = null;
      try {
        let bundle = await Bundle("bundle", {
          entryPoint: path.join(__dirname, "..", "handler.ts"),
          outdir: ".out",
          format: "cjs",
          platform: "node",
          target: "node18",
        });
        role = await Role("role", {
          roleName: `${BRANCH_PREFIX}-alchemy-test-lambda-handler-special-chars-role`,
          assumeRolePolicy: LAMBDA_ASSUME_ROLE_POLICY,
          policies: [
            {
              policyName: "logs",
              policyDocument: LAMBDA_LOGS_POLICY,
            },
          ],
          tags: {
            Environment: "test",
          },
        });
        // Create the Lambda function with BUFFERED invoke mode (default)
        func = await Function("function", {
          functionName: `${BRANCH_PREFIX}-alchemy-test-func-handler-special-chars`,
          bundle,
          roleArn: role.arn,
          handler: "index._myHandler012",
          runtime: "nodejs20.x",
          tags: {
            Environment: "test",
          },
          url: {
            authType: "NONE",
            // Default invokeMode is BUFFERED if not specified
            cors: {
              allowOrigins: ["*"],
              allowMethods: ["GET", "POST"],
              allowHeaders: ["Content-Type"],
            },
          },
        });
        // Verify function was created successfully
        expect(func.arn).toBeTruthy();
        expect(func.state).toBe("Active");
        expect(func.functionUrl).toMatch(
          /^https:\/\/.+\.lambda-url\..+\.on\.aws\/?$/,
        );
        // Test function invocation via URL
        const response = await fetch(func.functionUrl!, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ test: "special-handler" }),
        });
        expect(response.status).toBe(200);
        const body = await response.json();
        expect(body.message).toBe("Hello from bundled handler!");
      } finally {
        await destroy(scope);
      }
    });
  });
});
</file>

<file path="alchemy/test/aws/queue.test.ts">
import {
  GetQueueAttributesCommand,
  GetQueueUrlCommand,
  SQSClient,
  SendMessageCommand,
} from "@aws-sdk/client-sqs";
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { Queue } from "../../src/aws/queue.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const sqs = new SQSClient({});
describe("AWS Resources", () => {
  describe("Queue", () => {
    test("create queue", async (scope) => {
      const queueName = `${BRANCH_PREFIX}-alchemy-test-queue`;
      try {
        const queue = await Queue(queueName, {
          queueName,
          fifo: false,
          visibilityTimeout: 30,
          tags: {
            Environment: "test",
          },
        });
        expect(queue.url).toMatch(
          new RegExp(
            `https:\\/\\/sqs\\.[a-z0-9-]+\\.amazonaws\\.com\\/\\d+\\/${queueName}$`,
          ),
        );
        expect(queue.arn).toMatch(
          new RegExp(`^arn:aws:sqs:[a-z0-9-]+:\\d+:${queueName}$`),
        );
        expect(queue.tags).toEqual({
          Environment: "test",
        });
        // Verify queue exists with proper attributes
        const getQueueUrlResponse = await sqs.send(
          new GetQueueUrlCommand({
            QueueName: queueName,
          }),
        );
        const getQueueAttributesResponse = await sqs.send(
          new GetQueueAttributesCommand({
            QueueUrl: getQueueUrlResponse.QueueUrl,
            AttributeNames: ["All"],
          }),
        );
        expect(getQueueAttributesResponse.Attributes?.VisibilityTimeout).toBe(
          "30",
        );
      } finally {
        // Always clean up, even if test assertions fail
        await destroy(scope);
        // Verify queue is gone (this will throw if queue doesn't exist)
        await expect(
          sqs.send(
            new GetQueueUrlCommand({
              QueueName: queueName,
            }),
          ),
        ).rejects.toThrow("The specified queue does not exist");
      }
    });
    test("create fifo queue", async (scope) => {
      // For FIFO queues, the name must end with .fifo suffix
      const queueName = `${BRANCH_PREFIX}-alchemy-test-fifo-queue.fifo`;
      try {
        const queue = await Queue(queueName, {
          queueName,
          fifo: true,
          visibilityTimeout: 30,
          contentBasedDeduplication: true,
          tags: {
            Environment: "test",
          },
        });
        expect(queue.url).toMatch(
          new RegExp(
            `https:\\/\\/sqs\\.[a-z0-9-]+\\.amazonaws\\.com\\/\\d+\\/${queueName.replace(/\./g, "\\.")}$`,
          ),
        );
        expect(queue.fifo).toBe(true);
        expect(queue.contentBasedDeduplication).toBe(true);
        // Verify queue exists with proper attributes
        const getQueueUrlResponse = await sqs.send(
          new GetQueueUrlCommand({
            QueueName: queueName,
          }),
        );
        const getQueueAttributesResponse = await sqs.send(
          new GetQueueAttributesCommand({
            QueueUrl: getQueueUrlResponse.QueueUrl,
            AttributeNames: ["All"],
          }),
        );
        expect(getQueueAttributesResponse.Attributes?.FifoQueue).toBe("true");
        expect(
          getQueueAttributesResponse.Attributes?.ContentBasedDeduplication,
        ).toBe("true");
      } finally {
        // Always clean up, even if test assertions fail
        await destroy(scope);
      }
    });
    test("create queue, send message, delete, and recreate", async (scope) => {
      // Create initial queue
      const queueName = `${BRANCH_PREFIX}-alchemy-test-queue-recreate`;
      try {
        const queue = await Queue(queueName, {
          queueName,
          fifo: false,
          visibilityTimeout: 30,
        });
        expect(queue.arn).toMatch(
          new RegExp(`^arn:aws:sqs:[a-z0-9-]+:\\d+:${queueName}$`),
        );
        expect(queue.url).toMatch(
          new RegExp(
            `^https:\\/\\/sqs\\.[a-z0-9-]+\\.amazonaws\\.com\\/\\d+\\/${queueName}$`,
          ),
        );
        // Send a test message
        const messageResponse = await sqs.send(
          new SendMessageCommand({
            QueueUrl: queue.url,
            MessageBody: "Hello from test!",
          }),
        );
        expect(messageResponse.MessageId).toBeTruthy();
        // Delete the queue
        await destroy(queue);
        // Verify queue is fully deleted by checking if GetQueueUrl throws
        await expect(
          sqs.send(
            new GetQueueUrlCommand({
              QueueName: queueName,
            }),
          ),
        ).rejects.toThrow("The specified queue does not exist");
        // Immediately try to recreate the queue - this should handle the QueueDeletedRecently error
        const recreatedQueue = await Queue(queueName, {
          queueName,
          visibilityTimeout: 30,
          messageRetentionPeriod: 345600,
          tags: {
            Environment: "test",
          },
        });
        expect(recreatedQueue.arn).toMatch(
          new RegExp(`^arn:aws:sqs:[a-z0-9-]+:\\d+:${queueName}$`),
        );
        expect(recreatedQueue.url).toMatch(
          new RegExp(
            `^https:\\/\\/sqs\\.[a-z0-9-]+\\.amazonaws\\.com\\/\\d+\\/${queueName}$`,
          ),
        );
      } finally {
        // In case the initial queue creation or tests fail
        await destroy(scope); // Ignore errors on cleanup
      }
    });
  });
});
</file>

<file path="alchemy/test/aws/role.test.ts">
import {
  GetRoleCommand,
  IAMClient,
  ListAttachedRolePoliciesCommand,
  NoSuchEntityException,
} from "@aws-sdk/client-iam";
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import type { PolicyDocument } from "../../src/aws/policy.js";
import { Role, type RoleProps } from "../../src/aws/role.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
// Verify role was deleted
const iam = new IAMClient({});
describe("AWS Resources", () => {
  describe("Role", () => {
    const assumeRolePolicy: PolicyDocument = {
      Version: "2012-10-17",
      Statement: [
        {
          Effect: "Allow",
          Principal: {
            Service: "lambda.amazonaws.com",
          },
          Action: "sts:AssumeRole",
        },
      ],
    };
    const inlinePolicy: PolicyDocument = {
      Version: "2012-10-17",
      Statement: [
        {
          Effect: "Allow",
          Action: [
            "logs:CreateLogGroup",
            "logs:CreateLogStream",
            "logs:PutLogEvents",
          ],
          Resource: "*",
        },
      ],
    };
    test("create role simple", async (scope) => {
      const role = await Role(`${BRANCH_PREFIX}-test-create-role`, {
        roleName: `${BRANCH_PREFIX}-test-create-role`,
        assumeRolePolicy,
        description: "Test role for IAC",
        tags: {
          Environment: "test",
        },
        policies: [
          {
            policyName: "logs",
            policyDocument: inlinePolicy,
          },
        ],
      });
      try {
        expect(role.roleName).toBe(`${BRANCH_PREFIX}-test-create-role`);
        expect(role.arn).toMatch(
          new RegExp(
            `^arn:aws:iam::\\d+:role/${BRANCH_PREFIX.replace(/\//g, "\\/")}-test-create-role$`,
          ),
        );
        expect(role.uniqueId).toBeTruthy();
        expect(role.roleId).toBeTruthy();
        expect(role.createDate).toBeInstanceOf(Date);
      } finally {
        await destroy(scope);
        await assertRoleNotExists(`${BRANCH_PREFIX}-test-create-role`);
      }
    });
    test("update role", async (scope) => {
      const roleProps: RoleProps = {
        roleName: `${BRANCH_PREFIX}-test-update-role`,
        assumeRolePolicy,
        description: "Updated test role for IAC",
        maxSessionDuration: 7200,
        tags: {
          Environment: "test",
          Updated: "true",
        },
        policies: [
          {
            policyName: "logs",
            policyDocument: inlinePolicy,
          },
          {
            policyName: "extra",
            policyDocument: {
              Version: "2012-10-17",
              Statement: [
                {
                  Effect: "Allow",
                  Action: "s3:ListBucket",
                  Resource: "*",
                },
              ],
            },
          },
        ],
      };
      let role = await Role(`${BRANCH_PREFIX}-test-update-role`, roleProps);
      try {
        expect(role.roleName).toBe(`${BRANCH_PREFIX}-test-update-role`);
        expect(role.description).toBe("Updated test role for IAC");
        expect(role.maxSessionDuration).toBe(7200);
        expect(role.tags).toEqual({
          Environment: "test",
          Updated: "true",
        });
        role = await Role(`${BRANCH_PREFIX}-test-update-role`, {
          ...roleProps,
          description: "Updated test role for IAC",
          policies: [
            {
              policyName: "logs",
              policyDocument: inlinePolicy,
            },
            // 1 policy removed
          ],
        });
        expect(role.description).toBe("Updated test role for IAC");
        expect(role.policies).toEqual([
          {
            policyName: "logs",
            policyDocument: inlinePolicy,
          },
        ]);
      } finally {
        await destroy(scope);
        await assertRoleNotExists(`${BRANCH_PREFIX}-test-update-role`);
      }
    });
    test("create role with managed policies", async (scope) => {
      const managedPolicyArn = "arn:aws:iam::aws:policy/ReadOnlyAccess";
      const roleId = `${BRANCH_PREFIX}-test-managed-policy-role`;
      const roleName = `${BRANCH_PREFIX}-test-managed-policy-role`;
      // Create an initial role
      let role;
      try {
        role = await Role(roleId, {
          roleName,
          assumeRolePolicy,
          description: "Test role with managed policies",
          tags: {
            Environment: "test",
          },
          managedPolicyArns: [managedPolicyArn],
        });
        expect(role.roleName).toBe(roleName);
        expect(role.arn).toMatch(
          new RegExp(
            `^arn:aws:iam::\\d+:role/${BRANCH_PREFIX.replace(/\//g, "\\/")}-test-managed-policy-role$`,
          ),
        );
        // Verify managed policy is attached
        const attachedPoliciesResponse = await iam.send(
          new ListAttachedRolePoliciesCommand({
            RoleName: roleName,
          }),
        );
        expect(attachedPoliciesResponse.AttachedPolicies).toBeTruthy();
        expect(attachedPoliciesResponse.AttachedPolicies?.length).toBe(1);
        expect(attachedPoliciesResponse.AttachedPolicies?.[0].PolicyArn).toBe(
          managedPolicyArn,
        );
      } finally {
        await destroy(scope);
        // Wait for the role to be deleted before continuing
        await new Promise((resolve) => setTimeout(resolve, 2000));
      }
      // Now test updating with a different policy
      const updatedPolicyArn = "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess";
      try {
        role = await Role(roleId, {
          roleName,
          assumeRolePolicy,
          description: "Test role with updated managed policies",
          tags: {
            Environment: "test",
          },
          managedPolicyArns: [updatedPolicyArn],
        });
        // Verify the updated managed policy is attached
        const updatedPolicies = await iam.send(
          new ListAttachedRolePoliciesCommand({
            RoleName: roleName,
          }),
        );
        expect(updatedPolicies.AttachedPolicies).toBeTruthy();
        expect(updatedPolicies.AttachedPolicies?.length).toBe(1);
        expect(updatedPolicies.AttachedPolicies?.[0].PolicyArn).toBe(
          updatedPolicyArn,
        );
      } finally {
        await destroy(scope);
        // Wait for the role to be deleted before asserting
        await new Promise((resolve) => setTimeout(resolve, 2000));
        await assertRoleNotExists(roleName);
      }
    });
    test("remove managed policies when not specified in update", async (scope) => {
      const managedPolicyArn = "arn:aws:iam::aws:policy/ReadOnlyAccess";
      const roleName = `${BRANCH_PREFIX}-test-remove-policies-role`;
      let role;
      // Create role with managed policy
      try {
        role = await Role(`${BRANCH_PREFIX}-test-remove-policies`, {
          roleName,
          assumeRolePolicy,
          description: "Test role with managed policies",
          tags: {
            Environment: "test",
          },
          managedPolicyArns: [managedPolicyArn],
        });
        expect(role.roleName).toBe(roleName);
        // Verify managed policy is attached
        let attachedPolicies = await iam.send(
          new ListAttachedRolePoliciesCommand({
            RoleName: roleName,
          }),
        );
        expect(attachedPolicies.AttachedPolicies).toBeTruthy();
        expect(attachedPolicies.AttachedPolicies?.length).toBe(1);
        expect(attachedPolicies.AttachedPolicies?.[0].PolicyArn).toBe(
          managedPolicyArn,
        );
        // Update role WITHOUT specifying managedPolicyArns (undefined)
        role = await Role(`${BRANCH_PREFIX}-test-remove-policies`, {
          roleName,
          assumeRolePolicy,
          description: "Test role with managed policies removed",
          tags: {
            Environment: "test",
          },
          // No managedPolicyArns specified
        });
        // Verify managed policies have been removed
        attachedPolicies = await iam.send(
          new ListAttachedRolePoliciesCommand({
            RoleName: roleName,
          }),
        );
        expect(attachedPolicies.AttachedPolicies).toBeTruthy();
        expect(attachedPolicies.AttachedPolicies?.length).toBe(0);
      } finally {
        await destroy(scope);
      }
      await assertRoleNotExists(roleName);
    });
  });
});
async function assertRoleNotExists(roleName: string) {
  await expect(
    iam.send(
      new GetRoleCommand({
        RoleName: roleName,
      }),
    ),
  ).rejects.toThrow(NoSuchEntityException);
}
</file>

<file path="alchemy/test/aws/ses.test.ts">
import {
  GetConfigurationSetCommand,
  GetEmailIdentityCommand,
  NotFoundException,
  SESv2Client,
} from "@aws-sdk/client-sesv2";
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { SES } from "../../src/aws/ses.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("SES Resource", () => {
  const testId = `${BRANCH_PREFIX}-test-ses`;
  test("create, update, and delete configuration set", async (scope) => {
    // Create a test configuration set
    const configurationSetName = `${testId}-config-set`;
    let ses;
    try {
      ses = await SES(testId, {
        configurationSetName,
        sendingOptions: {
          SendingEnabled: true,
        },
        tags: {
          Environment: "test",
          Project: "alchemy",
        },
      });
      // Apply to create the configuration set
      expect(ses.configurationSetName).toBe(configurationSetName);
      expect(ses.configurationSetArn).toBeTruthy();
      // Verify configuration set was created by querying the API directly
      const client = new SESv2Client({});
      const getResponse = await client.send(
        new GetConfigurationSetCommand({
          ConfigurationSetName: configurationSetName,
        }),
      );
      // In SESv2, check the sending options specifically
      expect(getResponse).toBeTruthy();
      expect(getResponse.SendingOptions?.SendingEnabled).toBe(true);
      // Update the configuration set
      ses = await SES(testId, {
        configurationSetName,
        sendingOptions: {
          SendingEnabled: false,
        },
        tags: {
          Environment: "test",
          Project: "alchemy",
          Updated: "true",
        },
      });
      // Check if ARNs match when they exist
      if (ses.configurationSetArn) {
        expect(ses.configurationSetArn).toBe(ses.configurationSetArn);
      }
      // Verify configuration set was updated
      const getUpdatedResponse = await client.send(
        new GetConfigurationSetCommand({
          ConfigurationSetName: configurationSetName,
        }),
      );
      // In SESv2, check the sending options specifically
      expect(getUpdatedResponse.SendingOptions?.SendingEnabled).toBe(false);
    } finally {
      // Clean up
      await destroy(scope);
      await assertSESDoesNotExist(configurationSetName);
    }
  });
  test("create, update, and delete email identity", async (scope) => {
    // Using a domain for testing is better than an email address
    // since email addresses require actual verification
    const testDomain = `${testId.toLowerCase()}.example.com`;
    let ses: SES | undefined;
    try {
      ses = await SES(`${testId}-domain`, {
        emailIdentity: testDomain,
        enableDkim: true,
        tags: {
          Environment: "test",
          Project: "alchemy",
        },
      });
      // Apply to create the email identity
      expect(ses.configurationSetArn).toBeUndefined();
      expect(ses.emailIdentity).toBe(testDomain);
      expect(ses.emailIdentityArn).toBeTruthy();
      // Verification status may be PENDING or VERIFIED depending on the domain
      expect(ses.emailIdentityVerificationStatus).toBeDefined();
      // DKIM status may not be immediately available
      if (ses.dkimVerificationStatus) {
        expect([
          "PENDING",
          "SUCCESS",
          "FAILED",
          "TEMPORARY_FAILURE",
          "NOT_STARTED",
        ]).toContain(ses.dkimVerificationStatus);
      }
      // Verify email identity was created by querying the API directly
      const client = new SESv2Client({});
      const getResponse = await client.send(
        new GetEmailIdentityCommand({
          EmailIdentity: testDomain,
        }),
      );
      // Check that the identity exists (it should have DkimAttributes)
      expect(getResponse).toBeTruthy();
      expect(getResponse.DkimAttributes).toBeDefined();
    } finally {
      // Clean up
      await destroy(scope);
      if (ses?.configurationSetName) {
        await assertSESDoesNotExist(ses.configurationSetName);
      }
    }
  });
});
async function assertSESDoesNotExist(configurationSetName: string) {
  // Verify configuration set was deleted
  const client = new SESv2Client({});
  try {
    await client.send(
      new GetConfigurationSetCommand({
        ConfigurationSetName: configurationSetName,
      }),
    );
    // Should not reach here
    expect(true).toBe(false);
  } catch (error) {
    expect(error instanceof NotFoundException).toBe(true);
  }
}
</file>

<file path="alchemy/test/aws/table.test.ts">
import {
  DescribeTableCommand,
  DynamoDBClient,
  ResourceNotFoundException,
} from "@aws-sdk/client-dynamodb";
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { Table } from "../../src/aws/table.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta);
const dynamo = new DynamoDBClient({});
describe("AWS Resources", () => {
  describe("Table", () => {
    test("create table", async (scope) => {
      const tableName = `${BRANCH_PREFIX}-alchemy-test-create-table`;
      const table = await Table(tableName, {
        tableName,
        partitionKey: {
          name: "id",
          type: "S",
        },
        sortKey: {
          name: "timestamp",
          type: "N",
        },
        tags: {
          Environment: "test",
        },
      });
      try {
        expect(table.tableName).toBe(tableName);
        expect(table.arn).toMatch(
          new RegExp(`^arn:aws:dynamodb:[a-z0-9-]+:\\d+:table\\/${tableName}$`),
        );
        expect(table.tableId).toBeTruthy();
        expect(table.partitionKey).toEqual({
          name: "id",
          type: "S",
        });
        expect(table.sortKey).toEqual({
          name: "timestamp",
          type: "N",
        });
        expect(table.tags).toEqual({
          Environment: "test",
        });
        // Verify table exists and is active
        const describeResponse = await dynamo.send(
          new DescribeTableCommand({
            TableName: tableName,
          }),
        );
        expect(describeResponse.Table?.TableStatus).toBe("ACTIVE");
      } finally {
        // Always clean up, even if test assertions fail
        await destroy(scope);
        // Verify table is fully deleted
        await assertTableNotExists(tableName);
      }
    });
  });
});
async function assertTableNotExists(tableName: string) {
  await expect(
    dynamo.send(
      new DescribeTableCommand({
        TableName: tableName,
      }),
    ),
  ).rejects.toThrow(ResourceNotFoundException);
}
</file>

<file path="alchemy/test/cloudflare/migrations/001_create_table.sql">
CREATE TABLE test_migrations_table (
  id INTEGER PRIMARY KEY,
  name TEXT
);
</file>

<file path="alchemy/test/cloudflare/account-api-token.test.ts">
import { beforeAll, describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { AccountApiToken } from "../../src/cloudflare/account-api-token.js";
import {
  type CloudflareApi,
  createCloudflareApi,
} from "../../src/cloudflare/api.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
// Create API client for verification
let api: CloudflareApi;
const test = alchemy.test(import.meta);
describe("AccountApiToken Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-token`;
  // Set up API client before tests
  beforeAll(async () => {
    api = await createCloudflareApi();
  });
  test("create, update, and delete token", async (scope) => {
    let token: AccountApiToken | undefined;
    try {
      // Create a test token with minimal permissions
      token = await AccountApiToken(testId, {
        name: `Test Token ${testId}`,
        policies: [
          {
            effect: "allow",
            permissionGroups: [
              // Use a read-only permission group to minimize risk in test
              { id: "c8fed203ed3043cba015a93ad1616f1f" }, // Zone Read permission
            ],
            resources: {
              [`com.cloudflare.api.account.${api.accountId}`]: "*",
            },
          },
        ],
        // Short expiration for test tokens
        expiresOn: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(), // 1 day from now
      });
      // Verify token was created
      expect(token.id).toBeTruthy();
      expect(token.name).toEqual(`Test Token ${testId}`);
      expect(token.status).toEqual("active");
      expect(token.value).toBeTruthy(); // Should have a token value on creation
      // Keep token ID for verification
      const tokenId = token.id;
      // Verify token was created by querying the API directly
      const getResponse = await api.get(
        `/accounts/${api.accountId}/tokens/${tokenId}`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.name).toEqual(`Test Token ${testId}`);
      // Update the token
      token = await AccountApiToken(testId, {
        name: `Updated Token ${testId}`,
        policies: [
          {
            effect: "allow",
            permissionGroups: [
              { id: "c8fed203ed3043cba015a93ad1616f1f" }, // Zone Read permission
            ],
            resources: {
              [`com.cloudflare.api.account.${api.accountId}`]: "*",
            },
          },
        ],
        expiresOn: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString(), // 1 day from now
      });
      expect(token.id).toEqual(tokenId);
      expect(token.name).toEqual(`Updated Token ${testId}`);
      // Verify token was updated
      const getUpdatedResponse = await api.get(
        `/accounts/${api.accountId}/tokens/${tokenId}`,
      );
      const updatedData = await getUpdatedResponse.json();
      expect(updatedData.result.name).toEqual(`Updated Token ${testId}`);
    } catch (err) {
      // Log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify token was deleted if it was created
      if (token?.id) {
        const getDeletedResponse = await api.get(
          `/accounts/${api.accountId}/tokens/${token.id}`,
        );
        expect(getDeletedResponse.status).toEqual(404);
      }
    }
  });
});
</file>

<file path="alchemy/test/cloudflare/ai-gateway.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { AiGateway } from "../../src/cloudflare/ai-gateway.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
// must import this or else alchemy.test won't exist
import "../../src/test/bun.js";
// Create API client for verification
const api = await createCloudflareApi();
const test = alchemy.test(import.meta);
describe("AiGateway Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-ai-gateway`;
  test("create, update, and delete ai gateway", async (scope) => {
    let gateway: AiGateway | undefined;
    try {
      // Create a test AI Gateway with basic settings
      gateway = await AiGateway(testId, {
        collectLogs: true,
        cacheTtl: 0,
        rateLimitingTechnique: "fixed",
      });
      expect(gateway.id).toEqual(testId);
      expect(gateway.collectLogs).toEqual(true);
      expect(gateway.cacheTtl).toEqual(0);
      expect(gateway.rateLimitingTechnique).toEqual("fixed");
      // Verify gateway was created by querying the API directly
      const getResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.id).toEqual(testId);
      expect(responseData.result.collect_logs).toEqual(true);
      // Update the gateway
      gateway = await AiGateway(testId, {
        collectLogs: true,
        cacheTtl: 60,
        rateLimitingTechnique: "sliding",
        rateLimitingInterval: 60,
        rateLimitingLimit: 100,
      });
      expect(gateway.id).toEqual(testId);
      expect(gateway.cacheTtl).toEqual(60);
      expect(gateway.rateLimitingTechnique).toEqual("sliding");
      expect(gateway.rateLimitingInterval).toEqual(60);
      expect(gateway.rateLimitingLimit).toEqual(100);
      // Verify gateway was updated
      const getUpdatedResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}`,
      );
      const updatedData = await getUpdatedResponse.json();
      expect(updatedData.result.id).toEqual(testId);
      expect(updatedData.result.cache_ttl).toEqual(60);
      expect(updatedData.result.rate_limiting_technique).toEqual("sliding");
      expect(updatedData.result.rate_limiting_interval).toEqual(60);
      expect(updatedData.result.rate_limiting_limit).toEqual(100);
    } catch (err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify gateway was deleted
      const getDeletedResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}`,
      );
      expect(getDeletedResponse.status).toEqual(404);
    }
  });
  test("create ai gateway with authentication and logging", async (scope) => {
    let gateway: AiGateway | undefined;
    try {
      // Create a test AI Gateway with authentication and logging
      gateway = await AiGateway(`${testId}-auth`, {
        collectLogs: true,
        authentication: true,
        logManagement: 10000,
        logManagementStrategy: "DELETE_OLDEST",
      });
      expect(gateway.id).toEqual(`${testId}-auth`);
      expect(gateway.authentication).toEqual(true);
      expect(gateway.logManagement).toEqual(10000);
      expect(gateway.logManagementStrategy).toEqual("DELETE_OLDEST");
      // Verify gateway was created with correct settings
      const getResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}-auth`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.authentication).toEqual(true);
      expect(responseData.result.log_management).toEqual(10000);
      expect(responseData.result.log_management_strategy).toEqual(
        "DELETE_OLDEST",
      );
    } finally {
      // Always clean up
      await destroy(scope);
      // Verify gateway was deleted
      const getDeletedResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}-auth`,
      );
      expect(getDeletedResponse.status).toEqual(404);
    }
  });
  test("create ai gateway with rate limiting", async (scope) => {
    let gateway: AiGateway | undefined;
    try {
      // Create a test AI Gateway with rate limiting
      gateway = await AiGateway(`${testId}-ratelimit`, {
        rateLimitingInterval: 30,
        rateLimitingLimit: 50,
        rateLimitingTechnique: "sliding",
        cacheInvalidateOnUpdate: true,
      });
      expect(gateway.id).toEqual(`${testId}-ratelimit`);
      expect(gateway.rateLimitingInterval).toEqual(30);
      expect(gateway.rateLimitingLimit).toEqual(50);
      expect(gateway.rateLimitingTechnique).toEqual("sliding");
      expect(gateway.cacheInvalidateOnUpdate).toEqual(true);
      // Verify gateway was created with correct rate limiting settings
      const getResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}-ratelimit`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.rate_limiting_interval).toEqual(30);
      expect(responseData.result.rate_limiting_limit).toEqual(50);
      expect(responseData.result.rate_limiting_technique).toEqual("sliding");
    } finally {
      // Always clean up
      await destroy(scope);
      // Verify gateway was deleted
      const getDeletedResponse = await api.get(
        `/accounts/${api.accountId}/ai-gateway/gateways/${testId}-ratelimit`,
      );
      expect(getDeletedResponse.status).toEqual(404);
    }
  });
});
</file>

<file path="alchemy/test/cloudflare/ai.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { Ai } from "../../src/cloudflare/ai.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("AI Resource Binding", () => {
  test("create worker with AI binding and make a prompt call", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-ai-worker`;
    let worker: Worker | undefined = undefined;
    try {
      // Create a worker with an AI binding
      worker = await Worker(workerName, {
        name: workerName,
        script: `
          export default {
            async fetch(request, env) {
              // Process a simple AI prompt using the AI binding
              const response = await env.MYAI.run("@cf/meta/llama-3.1-8b-instruct", {
                prompt: "What is the capital of France?",
              });
              // Return the AI response as JSON
              return new Response(JSON.stringify(response), {
                headers: { "Content-Type": "application/json" },
              });
            },
          };
        `,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          MYAI: new Ai(),
        },
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.bindings?.MYAI).toBeDefined();
      expect(worker.url).toBeTruthy();
      // Test the AI prompt by calling the worker endpoint
      const response = await fetch(worker.url!);
      expect(response.status).toEqual(200);
      expect(response.headers.get("content-type")).toContain(
        "application/json",
      );
      // Parse the response and verify it contains the expected AI model output
      const result = await response.json();
      expect(result).toBeDefined();
      // For the specific question, we expect the response to contain "Paris"
      // But since AI responses can vary, we'll check for a minimum of structure instead
      expect(typeof result.response).toBe("string");
      expect(result.response.length).toBeGreaterThan(0);
    } finally {
      await destroy(scope);
    }
  }, 60000); // Longer timeout for AI operations
});
</file>

<file path="alchemy/test/cloudflare/browser-handler.ts">
import puppeteer from "@cloudflare/puppeteer";
export default {
  async fetch(request, env) {
    const { searchParams } = new URL(request.url);
    let url = searchParams.get("url");
    let img;
    if (url) {
      url = new URL(url).toString(); // normalize
      img = await env.BROWSER_KV_DEMO.get(url, { type: "arrayBuffer" });
      if (img === null) {
        const browser = await puppeteer.launch(env.MYBROWSER);
        const page = await browser.newPage();
        await page.goto(url);
        img = await page.screenshot();
        await env.BROWSER_KV_DEMO.put(url, img, {
          expirationTtl: 60 * 60 * 24,
        });
        await browser.close();
      }
      return new Response(img, {
        headers: {
          "content-type": "image/jpeg",
        },
      });
    } else {
      return new Response("Please add an ?url=https://example.com/ parameter");
    }
  },
};
</file>

<file path="alchemy/test/cloudflare/browser-rendering.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { BrowserRendering } from "../../src/cloudflare/browser-rendering.js";
import { KVNamespace } from "../../src/cloudflare/kv-namespace.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import path from "node:path";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Browser Rendering Resource", () => {
  test("create worker with browser rendering binding and take screenshot", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-browser-renderer`;
    const kvNamespaceName = `${BRANCH_PREFIX}-browser-kv-demo`;
    let worker: Worker | undefined = undefined;
    let kvNamespace: KVNamespace | undefined = undefined;
    try {
      // Create a KV namespace for caching screenshots
      kvNamespace = await KVNamespace(kvNamespaceName, {
        title: `${BRANCH_PREFIX} Browser KV Demo`,
      });
      expect(kvNamespace.title).toEqual(`${BRANCH_PREFIX} Browser KV Demo`);
      // Create a worker with browser rendering binding
      worker = await Worker(workerName, {
        name: workerName,
        entrypoint: path.join(import.meta.dirname, "browser-handler.ts"),
        format: "esm",
        compatibilityFlags: ["nodejs_compat"], // Required for puppeteer
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          MYBROWSER: new BrowserRendering(),
          BROWSER_KV_DEMO: kvNamespace,
        },
        bundle: {
          platform: "node",
        },
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.url).toBeTruthy();
      // Test taking a screenshot of Google
      const response = await fetch(`${worker.url}?url=https://google.com`);
      expect(response.status).toEqual(200);
      expect(response.headers.get("content-type")).toEqual("image/jpeg");
      // Verify we got an actual image by checking content length
      const imageBuffer = await response.arrayBuffer();
      expect(imageBuffer.byteLength).toBeGreaterThan(1000); // A valid screenshot should be at least 1KB
      // Test fetching from cache
      console.log("Testing cached screenshot...");
      const cachedResponse = await fetch(
        `${worker.url}?url=https://google.com`,
      );
      expect(cachedResponse.status).toEqual(200);
      // Take a screenshot of a different URL
      console.log("Testing screenshot of a different URL...");
      const anotherResponse = await fetch(
        `${worker.url}?url=https://example.com`,
      );
      expect(anotherResponse.status).toEqual(200);
      // Test error case - missing URL parameter
      console.log("Testing error case - missing URL parameter...");
      const errorResponse = await fetch(worker.url!);
      expect(errorResponse.status).toEqual(200); // The worker returns 200 even for the error case
      const errorText = await errorResponse.text();
      expect(errorText).toEqual(
        "Please add an ?url=https://example.com/ parameter",
      );
    } finally {
      await destroy(scope);
    }
  }, 120000); // Longer timeout for browser rendering operations
});
</file>

<file path="alchemy/test/cloudflare/bucket.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import {
  createR2Client,
  getBucket,
  listBuckets,
  listObjects,
  R2Bucket,
  withJurisdiction,
} from "../../src/cloudflare/bucket.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("R2 Bucket Resource", async () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  // Bucket names must be lowercase, so transform the prefix
  const testId = `${BRANCH_PREFIX.toLowerCase()}-test-bucket`;
  // For public access, we still need to use the Cloudflare API
  // This is one feature not available through the S3 API
  const api = await createCloudflareApi();
  test("create, update, and delete bucket", async (scope) => {
    // Create a test bucket
    let bucket: R2Bucket | undefined = undefined;
    try {
      bucket = await R2Bucket(testId, {
        name: testId,
        locationHint: "wnam", // West North America
      });
      expect(bucket.name).toEqual(testId);
      // Check if bucket exists by getting it explicitly
      const gotBucket = await getBucket(api, testId);
      expect(gotBucket.result.name).toEqual(testId);
      // Check if bucket exists by listing buckets
      const buckets = await listBuckets(api);
      const foundBucket = buckets.find((b) => b.Name === testId);
      expect(foundBucket).toBeTruthy();
      // Update the bucket to enable public access
      bucket = await R2Bucket(testId, {
        name: testId,
        allowPublicAccess: true,
      });
      const publicAccessResponse = await api.get(
        `/accounts/${api.accountId}/r2/buckets/${testId}/domains/managed`,
      );
      const publicAccessData = await publicAccessResponse.json();
      expect(publicAccessData.result.enabled).toEqual(true);
    } finally {
      await alchemy.destroy(scope);
      // Verify bucket was deleted
      if (bucket) {
        await assertBucketDeleted(bucket);
      }
    }
  });
  test("bucket with jurisdiction", async (scope) => {
    const api = await createCloudflareApi();
    const euBucketName = `${testId}-eu`;
    const euBucket = await R2Bucket(euBucketName, {
      name: euBucketName,
      jurisdiction: "eu",
    });
    try {
      // Create a bucket with EU jurisdiction
      expect(euBucket.name).toEqual(euBucketName);
      expect(euBucket.jurisdiction).toEqual("eu");
      // Check if bucket exists by listing buckets
      const buckets = await listBuckets(api, {
        jurisdiction: "eu",
      });
      const foundBucket = buckets.find((b) => b.Name === euBucketName);
      expect(foundBucket).toBeTruthy();
      // Note: S3 API doesn't expose jurisdiction info, so we can't verify that aspect
    } finally {
      await alchemy.destroy(scope);
      await assertBucketDeleted(euBucket);
    }
  });
  test("bucket with file is properly emptied and deleted", async (scope) => {
    // Create a test bucket
    let bucket: R2Bucket | undefined = undefined;
    try {
      const bucketName = `${testId}-with-files`;
      bucket = await R2Bucket(bucketName, {
        name: bucketName,
        empty: true,
      });
      expect(bucket.name).toEqual(bucketName);
      // Get R2 client
      const r2Client = await createR2Client();
      // Upload a test file to the bucket
      const testContent = "This is test file content";
      const testKey = "test-file.txt";
      // Put object with jurisdiction header
      const putUrl = new URL(
        `https://${r2Client.accountId}.r2.cloudflarestorage.com/${bucketName}/${testKey}`,
      );
      const putHeaders = withJurisdiction(
        { "Content-Type": "text/plain" },
        bucket.jurisdiction,
      );
      const putResponse = await r2Client.fetch(putUrl.toString(), {
        method: "PUT",
        body: testContent,
        headers: putHeaders,
      });
      expect(putResponse.status).toEqual(200);
      // Verify the file exists in the bucket
      const { objects } = await listObjects(
        r2Client,
        bucketName,
        undefined,
        bucket.jurisdiction,
      );
      expect(objects.length).toBeGreaterThan(0);
      expect(objects.some((obj) => obj.Key === testKey)).toBe(true);
      // For extra verification, directly fetch the file content
      const getUrl = new URL(
        `https://${r2Client.accountId}.r2.cloudflarestorage.com/${bucketName}/${testKey}`,
      );
      const getHeaders = withJurisdiction({}, bucket.jurisdiction);
      const getResponse = await r2Client.fetch(getUrl.toString(), {
        headers: getHeaders,
      });
      expect(getResponse.status).toEqual(200);
      // Get content
      const content = await getResponse.text();
      expect(content).toEqual(testContent);
      // NOTE: Skipping test cleanup due to Cloudflare R2 API limitation
      // Even after emptying the bucket, the API sometimes reports it's not empty
      // This is a known issue with R2 buckets containing certain object types
      console.log(
        "Skipping bucket deletion test due to Cloudflare R2 API limitation",
      );
    } finally {
      // Destroy the bucket which should empty it first
      await alchemy.destroy(scope);
      console.log(
        "Note: Manual cleanup may be needed for bucket:",
        bucket?.name,
      );
      console.log("Visit the Cloudflare dashboard to verify bucket deletion");
    }
  });
});
async function assertBucketDeleted(bucket: R2Bucket) {
  const api = await createCloudflareApi();
  try {
    if (!bucket.name) {
      throw new Error("Bucket name is undefined");
    }
    // Try to list buckets and check if our bucket is still there
    const buckets = await listBuckets(api, {
      jurisdiction: bucket.jurisdiction,
    });
    const foundBucket = buckets.find((b) => b.Name === bucket.name);
    if (foundBucket) {
      throw new Error(`Bucket ${bucket.name} was not deleted as expected`);
    }
  } catch (error: any) {
    // If we get a 404 or NoSuchBucket error, the bucket was deleted
    if (error.status === 404 || error.message.includes("NoSuchBucket")) {
      return; // This is expected
    } else {
      throw new Error(`Unexpected error type: ${error}`);
    }
  }
}
</file>

<file path="alchemy/test/cloudflare/bundle-handler-als.ts">
import hooks from "node:async_hooks";
export default {
  async fetch(): Promise<Response> {
    return new Response(typeof hooks.AsyncLocalStorage);
  },
};
</file>

<file path="alchemy/test/cloudflare/bundle-handler.ts">
import { initLogger } from "braintrust";
// biome-ignore lint/style/useNodejsImportProtocol: we are testing `crypto` and `node:crypto`
import crypto from "crypto";
import crypto2 from "node:crypto";
export default {
  async fetch(request, env, ctx): Promise<Response> {
    const logger = initLogger({
      projectName: "My Project",
      apiKey: env.BRAINTRUST_API_KEY,
      asyncFlush: false,
    });
    console.log(crypto.randomBytes(10));
    console.log(crypto2.randomBytes(10));
    console.log(logger);
    return new Response("Hello World!");
  },
};
</file>

<file path="alchemy/test/cloudflare/bundle.test.ts">
import { describe, expect } from "bun:test";
import * as path from "node:path";
import { alchemy } from "../../src/alchemy.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
// Import bun test utilities
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const entrypoint = path.resolve(__dirname, "bundle-handler.ts");
const entrypoint_als = path.resolve(__dirname, "bundle-handler-als.ts");
describe("Bundle Worker Test", () => {
  test("create, test, and delete worker from bundle", async (scope) => {
    try {
      // Create a worker using the entrypoint file
      const worker = await Worker(`${BRANCH_PREFIX}-test-bundle-worker`, {
        entrypoint,
        format: "esm", // Assuming bundle-handler.ts is ESM
        url: true, // Enable workers.dev URL to test the worker
        compatibilityFlags: ["nodejs_compat"],
      });
      const response = await fetch(worker.url!);
      expect(response.status).toEqual(200);
      const text = await response.text();
      // Check against the expected response from bundle-handler.ts
      expect(text).toEqual("Hello World!");
    } finally {
      // Clean up the worker
      await destroy(scope);
    }
  }, 120000); // Increased timeout for bundling and deployment
  test("create, test and delete a worker with 'nodejs_als' compatibility flag", async (scope) => {
    try {
      console.log(entrypoint_als);
      // Create a worker using the entrypoint file
      const worker = await Worker(`${BRANCH_PREFIX}-test-bundle-worker-als`, {
        entrypoint: entrypoint_als,
        format: "esm", // Assuming bundle-handler.ts is ESM
        url: true, // Enable workers.dev URL to test the worker
        compatibilityFlags: ["nodejs_als"],
      });
      const response = await fetch(worker.url!);
      expect(response.status).toEqual(200);
      const text = await response.text();
      // Check against the expected response from bundle-handler.ts
      expect(text).toEqual("function");
    } finally {
      // Clean up the worker
      await destroy(scope);
    }
  }, 120000); // Increased timeout for bundling and deployment
  test("error when using 'nodejs_compat' compatibility flag with a compatibility date before Sept 23rd 2024", async (scope) => {
    try {
      // Create a worker using the entrypoint file
      expect(
        Worker(`${BRANCH_PREFIX}-test-bundle-worker-legacy`, {
          entrypoint,
          format: "esm",
          url: true,
          compatibilityDate: "2024-09-22", // v1 mode (before Sept 23rd 2024)
          compatibilityFlags: ["nodejs_compat"],
        }),
      ).rejects.toThrow(
        "You must set your compatibilty date >= 2024-09-23 when using 'nodejs_compat' compatibility flag",
      );
    } finally {
      // Clean up the worker
      await destroy(scope);
    }
  }, 120000); // Increased timeout for bundling and deployment
});
</file>

<file path="alchemy/test/cloudflare/d1-database.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { D1Database, listDatabases } from "../../src/cloudflare/d1-database.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("D1 Database Resource", async () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-db`;
  // Create Cloudflare API client for direct verification
  const api = await createCloudflareApi();
  test("create and delete database", async (scope) => {
    // Create a test database
    let database: D1Database | undefined = undefined;
    try {
      database = await D1Database(testId, {
        name: testId,
        primaryLocationHint: "wnam", // West North America
        adopt: true,
      });
      expect(database.name).toEqual(testId);
      expect(database.id).toBeTruthy();
      expect(database.fileSize).toBeNumber();
      expect(database.numTables).toBeNumber();
      expect(database.version).toBeTruthy();
      // Check if database exists by listing databases
      const databases = await listDatabases(api);
      const foundDatabase = databases.find((db) => db.name === testId);
      expect(foundDatabase).toBeTruthy();
      expect(foundDatabase?.id).toEqual(database.id);
    } finally {
      await alchemy.destroy(scope);
      // Verify database was deleted
      if (database) {
        await assertDatabaseDeleted(database);
      }
    }
  });
  test("primary location hint", async (scope) => {
    const locationDb = `${testId}-location`;
    try {
      // Create a database with West North America location hint
      const database = await D1Database(locationDb, {
        name: locationDb,
        primaryLocationHint: "wnam", // West North America
        adopt: true,
      });
      expect(database.name).toEqual(locationDb);
      expect(database.id).toBeTruthy();
      expect(database.primaryLocationHint).toEqual("wnam");
      // Check if database exists
      const databases = await listDatabases(api);
      const foundDatabase = databases.find((db) => db.name === locationDb);
      expect(foundDatabase).toBeTruthy();
    } finally {
      await alchemy.destroy(scope);
    }
  });
  test("update read replication mode", async (scope) => {
    const replicationDb = `${testId}-replication`;
    try {
      // Create a database with default settings
      let database = await D1Database(replicationDb, {
        name: replicationDb,
        adopt: true,
      });
      expect(database.name).toEqual(replicationDb);
      expect(database.id).toBeTruthy();
      // Update the database with disabled read replication
      database = await D1Database(replicationDb, {
        name: replicationDb,
        readReplication: {
          mode: "disabled",
        },
        adopt: true,
      });
      // Verify the update
      expect(database.readReplication?.mode).toEqual("disabled");
    } finally {
      await alchemy.destroy(scope);
    }
  });
  test("throws error on invalid update", async (scope) => {
    const invalidUpdateDb = `${testId}-invalid-update`;
    try {
      // Create a database with West North America location hint
      const database = await D1Database(invalidUpdateDb, {
        name: invalidUpdateDb,
        primaryLocationHint: "wnam", // West North America
        adopt: true,
      });
      expect(database.name).toEqual(invalidUpdateDb);
      expect(database.id).toBeTruthy();
      expect(database.primaryLocationHint).toEqual("wnam");
      // Attempt to update with a different location hint, which should throw an error
      await expect(
        D1Database(invalidUpdateDb, {
          name: invalidUpdateDb,
          primaryLocationHint: "eeur", // East Europe - different from original
          adopt: true,
        }),
      ).rejects.toThrow("Cannot update primaryLocationHint");
    } finally {
      await alchemy.destroy(scope);
    }
  });
  test("create database with migrationsDir applies migrations", async (scope) => {
    const migrationsDb = `${testId}-with-migrations`;
    let database: D1Database | undefined = undefined;
    try {
      database = await D1Database(migrationsDb, {
        name: migrationsDb,
        migrationsDir: `${__dirname}/migrations`,
        adopt: true,
      });
      expect(database.name).toEqual(migrationsDb);
      expect(database.id).toBeTruthy();
      // Now check if the test_migrations_table exists by querying the schema
      const resp = await api.post(
        `/accounts/${api.accountId}/d1/database/${database.id}/query`,
        {
          sql: "SELECT name FROM sqlite_master WHERE type='table' AND name='test_migrations_table';",
        },
      );
      const data = await resp.json();
      const tables = data.result?.results || data.result?.[0]?.results || [];
      expect(tables.length).toBeGreaterThan(0);
      expect(tables[0]?.name).toEqual("test_migrations_table");
    } finally {
      await alchemy.destroy(scope);
      if (database) {
        await assertDatabaseDeleted(database);
      }
    }
  });
});
async function assertDatabaseDeleted(database: D1Database) {
  const api = await createCloudflareApi();
  try {
    if (!database.id) {
      throw new Error("Database ID is undefined");
    }
    // Try to list databases and check if our database is still there
    const databases = await listDatabases(api);
    const foundDatabase = databases.find((db) => db.id === database.id);
    if (foundDatabase) {
      throw new Error(`Database ${database.name} was not deleted as expected`);
    }
  } catch (error: any) {
    // If we get a 404, the database was deleted
    if (error.status === 404) {
      return; // This is expected
    } else {
      throw new Error(`Unexpected error type: ${error}`);
    }
  }
}
</file>

<file path="alchemy/test/cloudflare/dns-records.test.ts">
import { afterAll, describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { DnsRecords } from "../../src/cloudflare/dns-records.js";
import { Zone } from "../../src/cloudflare/zone.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import type { Scope } from "../../src/scope.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const testDomain = `${BRANCH_PREFIX}-test-2.com`;
let zone: Zone;
let scope: Scope | undefined;
test.beforeAll(async (_scope) => {
  zone = await Zone(`${BRANCH_PREFIX}-zone`, {
    name: testDomain,
  });
  scope = _scope;
});
afterAll(async () => {
  if (scope) {
    await destroy(scope);
  }
});
describe("DnsRecords Resource", async () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const api = await createCloudflareApi();
  test("create, update, and delete DNS records", async (scope) => {
    let dnsRecords;
    try {
      // Create test DNS records
      dnsRecords = await DnsRecords(`${testDomain}-dns`, {
        zoneId: zone.id,
        records: [
          {
            name: `www.${testDomain}`,
            type: "A",
            content: "192.0.2.1",
            proxied: true,
            comment: "Web server",
          },
          {
            name: `api.${testDomain}`,
            type: "A",
            content: "192.0.2.2",
            proxied: true,
            comment: "API server",
          },
          {
            name: `mail.${testDomain}`,
            type: "MX",
            content: "mail.example.com",
            priority: 10,
            proxied: false,
            comment: "Mail server",
          },
        ],
      });
      expect(dnsRecords.records).toHaveLength(3);
      // Verify records were created by querying the API directly
      for (const record of dnsRecords.records) {
        const response = await api.get(
          `/zones/${dnsRecords.zoneId}/dns_records/${record.id}`,
        );
        expect(response.ok).toBe(true);
        const data = await response.json();
        expect(data.result.name).toBe(record.name);
        expect(data.result.type).toBe(record.type);
        expect(data.result.content).toBe(record.content);
        expect(data.result.proxied).toBe(record.proxied);
        expect(data.result.comment).toBe(record.comment);
        if (record.priority) {
          expect(data.result.priority).toBe(record.priority);
        }
      }
      // Update records - modify one record, add one record, remove one record
      dnsRecords = await DnsRecords(`${testDomain}-dns`, {
        zoneId: zone.id,
        records: [
          // Modify existing record
          {
            name: `www.${testDomain}`,
            type: "A",
            content: "192.0.2.3", // Changed IP
            proxied: true,
            comment: "Updated web server",
          },
          // Keep existing record unchanged
          {
            name: `api.${testDomain}`,
            type: "A",
            content: "192.0.2.2",
            proxied: true,
            comment: "API server",
          },
          // Add new record
          {
            name: `cdn.${testDomain}`,
            type: "CNAME",
            content: "cdn.cloudflare.com.",
            proxied: true,
            comment: "CDN endpoint",
          },
          // Removed mail.example.com record
        ],
      });
      expect(dnsRecords.records).toHaveLength(3);
      // Verify updated records
      const updatedWww = dnsRecords.records.find(
        (r) => r.name === `www.${testDomain}`,
      );
      expect(updatedWww?.content).toBe("192.0.2.3");
      expect(updatedWww?.comment).toBe("Updated web server");
      // Verify new record
      const newCdn = dnsRecords.records.find(
        (r) => r.name === `cdn.${testDomain}`,
      );
      expect(newCdn?.type).toBe("CNAME");
      expect(newCdn?.content).toBe("cdn.cloudflare.com");
      // Verify deleted record is gone
      const mailRecord = dnsRecords.records.find(
        (r) => r.name === `mail.${testDomain}`,
      );
      expect(mailRecord).toBeUndefined();
      // Verify directly with API
      const listResponse = await api.get(
        `/zones/${dnsRecords.zoneId}/dns_records`,
      );
      expect(listResponse.ok).toBe(true);
      const listData = await listResponse.json();
      const apiRecords = listData.result;
      // Should find our 3 records
      const testRecords = apiRecords.filter((r: any) =>
        r.name.includes(testDomain),
      );
      expect(testRecords).toHaveLength(3);
    } catch (err) {
      console.error("Test failed:", err);
      throw err;
    } finally {
      // Clean up all resources
      await destroy(scope);
      // Verify records were deleted
      if (dnsRecords?.records) {
        for (const record of dnsRecords.records) {
          const response = await api.get(
            `/zones/${dnsRecords.zoneId}/dns_records/${record.id}`,
          );
          expect(response.status).toBe(404);
        }
      }
    }
  });
  test("handles empty records array", async (scope) => {
    try {
      const dnsRecords = await DnsRecords(`${testDomain}-empty-dns`, {
        zoneId: zone.id,
        records: [],
      });
      expect(dnsRecords.records).toHaveLength(0);
    } finally {
      await destroy(scope);
    }
  });
  test("handles duplicate records gracefully", async (scope) => {
    try {
      const dnsRecords = await DnsRecords(`${testDomain}-duplicate-dns`, {
        zoneId: zone.id,
        records: [
          {
            name: `www.${testDomain}`,
            type: "A",
            content: "192.0.2.1",
          },
          // Duplicate record with same name and type but different content
          {
            name: `www.${testDomain}`,
            type: "A",
            content: "192.0.2.2",
          },
        ],
      });
      // Should only create one record (the last one)
      expect(dnsRecords.records).toHaveLength(1);
      expect(dnsRecords.records[0].content).toBe("192.0.2.2");
    } finally {
      await destroy(scope);
    }
  });
});
</file>

<file path="alchemy/test/cloudflare/hyperdrive.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { Hyperdrive } from "../../src/cloudflare/hyperdrive.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { NeonProject } from "../../src/neon/project.js";
import { BRANCH_PREFIX } from "../util.js";
// must import this or else alchemy.test won't exist
import "../../src/test/bun.js";
// Create API client for verification
const api = await createCloudflareApi();
const test = alchemy.test(import.meta);
describe("Hyperdrive Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-hyperdrive`;
  test("create, update, and delete hyperdrive with Neon project", async (scope) => {
    let hyperdrive: Hyperdrive | undefined;
    let project: NeonProject | undefined;
    let worker: Worker | undefined;
    try {
      // First create a Neon PostgreSQL project
      project = await NeonProject(`${testId}-db`, {
        name: `Hyperdrive Test DB ${BRANCH_PREFIX}`,
      });
      expect(project.id).toBeTruthy();
      expect(project.connection_uris.length).toBeGreaterThan(0);
      console.log(project.connection_uris[0].connection_parameters);
      // Create a test Hyperdrive using the Neon project's connection parameters
      hyperdrive = await Hyperdrive(testId, {
        name: `test-hyperdrive-${BRANCH_PREFIX}`,
        origin: project.connection_uris[0].connection_parameters,
      });
      expect(hyperdrive.id).toEqual(testId);
      expect(hyperdrive.name).toEqual(`test-hyperdrive-${BRANCH_PREFIX}`);
      expect(hyperdrive.origin.host).toEqual(
        project.connection_uris[0].connection_parameters.host,
      );
      expect(hyperdrive.origin.database).toEqual(
        project.connection_uris[0].connection_parameters.database,
      );
      expect(hyperdrive.hyperdriveId).toBeTruthy(); // Check that we got a hyperdriveId
      // Verify hyperdrive was created by querying the API directly
      const getResponse = await api.get(
        `/accounts/${api.accountId}/hyperdrive/configs/${hyperdrive.hyperdriveId}`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.name).toEqual(
        `test-hyperdrive-${BRANCH_PREFIX}`,
      );
      expect(responseData.result.origin.host).toEqual(
        project.connection_uris[0].connection_parameters.host,
      );
      // Create a simple worker script to test the connection
      // Deploy a worker that uses the hyperdrive
      const workerName = `${BRANCH_PREFIX}-hyperdrive-test-worker`;
      worker = await Worker(workerName, {
        name: workerName,
        script: `
          export default {
            async fetch(request, env, ctx) {
              if (typeof env.DB?.connect === "function") {
                return new Response("OK", { status: 200 });
              } else {
                return new Response("DB not found", { status: 500 });
              }
            }
          };
        `,
        format: "esm",
        url: true,
        bindings: {
          DB: hyperdrive,
        },
      });
      expect(worker.url).toBeTruthy();
      // Test the connection works
      const response = await fetch(worker.url!);
      expect(response.status).toEqual(200);
      // Update the hyperdrive
      hyperdrive = await Hyperdrive(testId, {
        name: `updated-hyperdrive-${BRANCH_PREFIX}`,
        hyperdriveId: hyperdrive.hyperdriveId, // Pass the hyperdriveId
        origin: project.connection_uris[0].connection_parameters,
        caching: {
          disabled: true,
        },
      });
      expect(hyperdrive.id).toEqual(testId);
      expect(hyperdrive.name).toEqual(`updated-hyperdrive-${BRANCH_PREFIX}`);
      expect(hyperdrive.caching?.disabled).toEqual(true);
      // Verify hyperdrive was updated
      const getUpdatedResponse = await api.get(
        `/accounts/${api.accountId}/hyperdrive/configs/${hyperdrive.hyperdriveId}`,
      );
      const updatedData = await getUpdatedResponse.json();
      expect(updatedData.result.name).toEqual(
        `updated-hyperdrive-${BRANCH_PREFIX}`,
      );
      expect(updatedData.result.caching.disabled).toEqual(true);
    } catch (err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify hyperdrive was deleted
      if (hyperdrive?.hyperdriveId) {
        const getDeletedResponse = await api.get(
          `/accounts/${api.accountId}/hyperdrive/configs/${hyperdrive.hyperdriveId}`,
        );
        expect(getDeletedResponse.status).toEqual(404);
      }
    }
  });
});
</file>

<file path="alchemy/test/cloudflare/kv-namespace.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { KVNamespace } from "../../src/cloudflare/kv-namespace.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("KV Namespace Resource", () => {
  const testId = `${BRANCH_PREFIX}-test-kv`;
  test("create, update, and delete KV namespace", async (scope) => {
    let kvNamespace: KVNamespace | undefined;
    try {
      kvNamespace = await KVNamespace(testId, {
        title: `${BRANCH_PREFIX}-Test Namespace ${testId}`,
        values: [
          {
            key: "test-key-1",
            value: "test-value-1",
          },
          {
            key: "test-key-2",
            value: { hello: "world" },
          },
        ],
      });
      expect(kvNamespace.namespaceId).toBeTruthy();
      expect(kvNamespace.title).toEqual(
        `${BRANCH_PREFIX}-Test Namespace ${testId}`,
      );
      // Verify KV values were set by reading them back
      await verifyKVValue(
        kvNamespace.namespaceId,
        "test-key-1",
        "test-value-1",
      );
      const key2Value = await getKVValue(kvNamespace.namespaceId, "test-key-2");
      expect(JSON.parse(key2Value)).toEqual({ hello: "world" });
      // Update the KV namespace with new values
      kvNamespace = await KVNamespace(testId, {
        title: `${BRANCH_PREFIX}-Test Namespace ${testId}`,
        values: [
          {
            key: "test-key-1",
            value: "updated-value-1",
          },
          {
            key: "test-key-3",
            value: "new-value-3",
          },
        ],
      });
      expect(kvNamespace.namespaceId).toEqual(kvNamespace.namespaceId);
      // for some reason 1s was not enough ... eventual consistency?
      // TODO(sam): can we read strongly consistent?
      await new Promise((resolve) => setTimeout(resolve, 3000));
      // Verify updated values
      await verifyKVValue(
        kvNamespace.namespaceId,
        "test-key-1",
        "updated-value-1",
      );
      await verifyKVValue(kvNamespace.namespaceId, "test-key-3", "new-value-3");
    } finally {
      await alchemy.destroy(scope);
      if (kvNamespace) {
        // Verify namespace was deleted
        await assertKvNamespaceNotExists(kvNamespace.namespaceId);
      }
    }
  });
  test("adopt existing namespace", async (scope) => {
    let kvNamespace: KVNamespace | undefined;
    try {
      kvNamespace = await KVNamespace("kv", {
        title: `${testId}-adopt`,
      });
      await alchemy.run("nested", async () => {
        const adoptedNamespace = await KVNamespace("kv", {
          title: `${testId}-adopt`,
          adopt: true,
        });
        expect(adoptedNamespace.namespaceId).toEqual(kvNamespace!.namespaceId);
      });
    } finally {
      await alchemy.destroy(scope);
      await assertKvNamespaceNotExists(kvNamespace!.namespaceId);
    }
  });
  test("adopt existing namespace with delete false", async (scope) => {
    let kvNamespace: KVNamespace | undefined;
    try {
      kvNamespace = await KVNamespace("kv", {
        title: `${testId}-adopt`,
      });
      await alchemy.run("nested", async (scope) => {
        const adoptedNamespace = await KVNamespace("kv", {
          title: `${testId}-adopt`,
          adopt: true,
          delete: false,
        });
        expect(adoptedNamespace.namespaceId).toEqual(kvNamespace!.namespaceId);
        await alchemy.destroy(scope);
        await assertKvNamespaceExists(adoptedNamespace.namespaceId);
      });
    } finally {
      await alchemy.destroy(scope);
      await assertKvNamespaceNotExists(kvNamespace!.namespaceId);
    }
  });
  async function getKVValue(namespaceId: string, key: string): Promise<string> {
    const api = await createCloudflareApi();
    const response = await api.get(
      `/accounts/${api.accountId}/storage/kv/namespaces/${namespaceId}/values/${key}`,
    );
    expect(response.ok).toBe(true);
    return await response.text();
  }
  async function assertKvNamespaceExists(namespaceId: string): Promise<void> {
    const api = await createCloudflareApi();
    const response = await api.get(
      `/accounts/${api.accountId}/storage/kv/namespaces/${namespaceId}`,
    );
    expect(response.ok).toBe(true);
    const data = await response.json();
    expect(data.result.id).toEqual(namespaceId);
  }
  async function assertKvNamespaceNotExists(
    namespaceId: string,
  ): Promise<void> {
    const api = await createCloudflareApi();
    const response = await api.get(
      `/accounts/${api.accountId}/storage/kv/namespaces/${namespaceId}`,
    );
    expect(response.status).toEqual(404);
  }
  async function verifyKVValue(
    namespaceId: string,
    key: string,
    expectedValue: string,
  ): Promise<void> {
    const maxAttempts = 20; // Total attempts: 1 initial + 5 retries
    const maxWaitTime = 120000; // 2 minutes
    let attempt = 0;
    let lastError;
    while (attempt < maxAttempts) {
      try {
        const value = await getKVValue(namespaceId, key);
        expect(value).toEqual(expectedValue);
        return; // Success, exit the function
      } catch (error) {
        lastError = error;
        attempt++;
        if (attempt >= maxAttempts) break;
        // Calculate exponential backoff time (2^attempt * 1000ms), but cap at maxWaitTime
        const backoffTime = Math.min(
          2 ** attempt * 1000,
          maxWaitTime / maxAttempts,
        );
        console.log(
          `KV value verification failed, retrying in ${backoffTime}ms (attempt ${attempt}/${maxAttempts - 1})...`,
        );
        await new Promise((resolve) => setTimeout(resolve, backoffTime));
      }
    }
    // If we've exhausted all attempts, throw the last error
    throw lastError;
  }
});
</file>

<file path="alchemy/test/cloudflare/permission-groups.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { PermissionGroups } from "../../src/cloudflare/permission-groups.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta);
describe("PermissionGroups Resource", () => {
  const testId = `${BRANCH_PREFIX}-permission-groups`;
  test("fetch and verify well-known permission groups", async (scope) => {
    try {
      // Fetch all permission groups
      const permissionGroups = await PermissionGroups(testId);
      // Verify the resource has expected properties
      expect(permissionGroups).toBeTruthy();
      // Verify R2 related permission groups exist
      expect(permissionGroups["Workers R2 Storage Write"]).toBeTruthy();
      expect(permissionGroups["Workers R2 Storage Read"]).toBeTruthy();
      expect(
        permissionGroups["Workers R2 Storage Bucket Item Write"],
      ).toBeTruthy();
      expect(
        permissionGroups["Workers R2 Storage Bucket Item Read"],
      ).toBeTruthy();
      // Verify the structure of one of the permission groups
      const r2ReadGroup = permissionGroups["Workers R2 Storage Read"];
      expect(r2ReadGroup.id).toBeTruthy();
      expect(r2ReadGroup.name).toEqual("Workers R2 Storage Read");
      expect(Array.isArray(r2ReadGroup.scopes)).toBe(true);
      expect(r2ReadGroup.scopes.length).toBeGreaterThan(0);
      // Verify some other common permission groups
      expect(permissionGroups["Account Settings Read"]).toBeTruthy();
      expect(permissionGroups["DNS Read"]).toBeTruthy();
      expect(permissionGroups["Workers Scripts Write"]).toBeTruthy();
    } finally {
      // Clean up - this should just destroy the reference to the permission groups
      // since it's a read-only resource
      await alchemy.destroy(scope);
    }
  });
});
</file>

<file path="alchemy/test/cloudflare/pipeline.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { R2Bucket } from "../../src/cloudflare/bucket.js";
import {
  Pipeline,
  type PipelineRecord,
} from "../../src/cloudflare/pipeline.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
// Create a Cloudflare API client for verification
const api = await createCloudflareApi();
// Helper function to check if a pipeline exists
async function assertPipelineExists(pipelineName: string): Promise<boolean> {
  try {
    const response = await api.get(
      `/accounts/${api.accountId}/pipelines/${pipelineName}`,
    );
    return response.status === 200;
  } catch (error) {
    return false;
  }
}
// Helper function to check if a worker exists
async function assertWorkerDoesNotExist(workerName: string) {
  try {
    const response = await api.get(
      `/accounts/${api.accountId}/workers/scripts/${workerName}`,
    );
    expect(response.status).toEqual(404);
  } catch (error) {
    // 404 is expected, so we can ignore it
    return;
  }
}
const accessKeyId = await alchemy.secret.env("R2_ACCESS_KEY_ID");
const secretAccessKey = await alchemy.secret.env("R2_SECRET_ACCESS_KEY");
describe("Pipeline Resource", () => {
  // Create mock secrets for testing - reuse these across tests
  test("create and delete basic pipeline", async (scope) => {
    const pipelineName = `${BRANCH_PREFIX}-test-pipeline`;
    const bucketName = `${BRANCH_PREFIX.toLowerCase()}-basic-bucket`;
    let pipeline: Pipeline | undefined = undefined;
    let bucket: R2Bucket | undefined = undefined;
    try {
      // Create an R2 bucket
      bucket = await R2Bucket("basic-bucket", {
        name: bucketName,
      });
      expect(bucket.name).toEqual(bucketName);
      // Create a basic pipeline with R2 destination
      pipeline = await Pipeline(pipelineName, {
        name: pipelineName,
        source: [
          {
            type: "http",
            format: "json",
            authentication: true,
            cors: { origins: ["*"] },
          },
        ],
        destination: {
          type: "r2",
          format: "json",
          path: {
            bucket: bucket.name,
          },
          credentials: {
            accessKeyId,
            secretAccessKey,
          },
        },
      });
      // Verify the pipeline was created
      expect(pipeline.id).toBeTruthy();
      expect(pipeline.name).toEqual(pipelineName);
      expect(pipeline.endpoint).toBeTruthy();
      expect(pipeline.version).toBeNumber();
      expect(pipeline.type).toEqual("pipeline");
      expect(pipeline.destination).toBeDefined();
      expect(pipeline.destination.type).toEqual("r2");
      expect(pipeline.destination.path.bucket).toEqual(bucketName);
      // Verify the pipeline exists via the API
      const exists = await assertPipelineExists(pipelineName);
      expect(exists).toEqual(true);
    } finally {
      await destroy(scope);
      // Verify the pipeline was deleted
      const exists = await assertPipelineExists(pipelineName);
      expect(exists).toEqual(false);
    }
  }, 60000); // Increase timeout for pipeline operations
  test("create pipeline with R2 bucket destination and custom settings", async (scope) => {
    const pipelineName = `${BRANCH_PREFIX}-r2-pipeline`;
    const bucketName = `${BRANCH_PREFIX.toLowerCase()}-pipeline-bucket`;
    const prefix = "test-logs";
    let pipeline: Pipeline | undefined = undefined;
    let bucket: R2Bucket | undefined = undefined;
    try {
      // Create an R2 bucket
      bucket = await R2Bucket("pipeline-bucket", {
        name: bucketName,
      });
      expect(bucket.name).toEqual(bucketName);
      // Create a pipeline with the R2 bucket as destination and custom settings
      pipeline = await Pipeline(pipelineName, {
        name: pipelineName,
        source: [
          {
            type: "http",
            format: "json",
            authentication: true,
            cors: { origins: ["*"] },
          },
        ],
        destination: {
          type: "r2",
          format: "json",
          path: {
            bucket: bucket.name,
            prefix: prefix,
          },
          credentials: {
            accessKeyId,
            secretAccessKey,
          },
          batch: {
            maxMb: 10, // 10 MB
            maxSeconds: 60, // 1 minute
            maxRows: 1000, // 1000 rows
          },
          compression: {
            type: "gzip",
          },
        },
      });
      // Verify the pipeline was created
      expect(pipeline.id).toBeTruthy();
      expect(pipeline.name).toEqual(pipelineName);
      expect(pipeline.endpoint).toBeTruthy();
      expect(pipeline.destination).toBeDefined();
      expect(pipeline.destination.type).toEqual("r2");
      expect(pipeline.destination.path.bucket).toEqual(bucketName);
      expect(pipeline.destination.path.prefix).toEqual(prefix);
      expect(pipeline.destination.batch).toBeDefined();
      expect(pipeline.destination.batch?.maxMb).toEqual(10);
      expect(pipeline.destination.batch?.maxSeconds).toEqual(60);
      expect(pipeline.destination.batch?.maxRows).toEqual(1000);
      // Verify the pipeline exists via the API
      const exists = await assertPipelineExists(pipelineName);
      expect(exists).toEqual(true);
    } finally {
      await destroy(scope);
    }
  }, 60000); // Increase timeout for pipeline operations
  test("update pipeline settings", async (scope) => {
    const pipelineName = `${BRANCH_PREFIX}-update-pipeline`;
    const bucketName = `${BRANCH_PREFIX.toLowerCase()}-update-bucket`;
    let pipeline: Pipeline | undefined = undefined;
    let bucket: R2Bucket | undefined = undefined;
    try {
      // Create an R2 bucket
      bucket = await R2Bucket("update-bucket", {
        name: bucketName,
      });
      // Create a pipeline with initial settings
      pipeline = await Pipeline(pipelineName, {
        name: pipelineName,
        source: [
          {
            type: "http",
            format: "json",
            authentication: true,
            cors: { origins: ["*"] },
          },
        ],
        destination: {
          type: "r2",
          format: "json",
          path: {
            bucket: bucket.name,
          },
          credentials: {
            accessKeyId,
            secretAccessKey,
          },
          batch: {
            maxMb: 10,
            maxSeconds: 60,
          },
        },
      });
      expect(pipeline.id).toBeTruthy();
      expect(pipeline.name).toEqual(pipelineName);
      expect(pipeline.destination.batch?.maxMb).toEqual(10);
      expect(pipeline.destination.batch?.maxSeconds).toEqual(60);
      // Update the pipeline with new settings
      pipeline = await Pipeline(pipelineName, {
        name: pipelineName,
        source: [
          {
            type: "http",
            format: "json",
            authentication: true,
            cors: { origins: ["*"] },
          },
        ],
        destination: {
          type: "r2",
          format: "json",
          path: {
            bucket: bucket.name,
            prefix: "updated-prefix",
          },
          credentials: {
            accessKeyId,
            secretAccessKey,
          },
          batch: {
            maxMb: 20,
            maxSeconds: 120,
            maxRows: 2000,
          },
        },
        compression: {
          type: "gzip",
        },
      });
      // Verify the update
      expect(pipeline.id).toBeTruthy();
      expect(pipeline.name).toEqual(pipelineName);
      expect(pipeline.destination.path.prefix).toEqual("updated-prefix");
      expect(pipeline.destination.batch?.maxMb).toEqual(20);
      expect(pipeline.destination.batch?.maxSeconds).toEqual(120);
      expect(pipeline.destination.batch?.maxRows).toEqual(2000);
      expect(pipeline.compression?.type).toEqual("gzip");
    } finally {
      await destroy(scope);
    }
  }, 60000); // Increase timeout for pipeline operations
  test("create worker with pipeline binding and send records", async (scope) => {
    const pipelineName = `${BRANCH_PREFIX}-worker-pipeline`;
    const workerName = `${BRANCH_PREFIX}-pipeline-worker`;
    const bucketName = `${BRANCH_PREFIX.toLowerCase()}-worker-bucket`;
    // Define a TypeScript interface for our test records
    interface TestRecord extends PipelineRecord {
      id: string;
      event: string;
      timestamp: number;
      data: {
        value: number;
        tags: string[];
      };
    }
    // Sample worker script that uses a pipeline binding
    const pipelineWorkerScript = `
      export default {
        async fetch(request, env, ctx) {
          const url = new URL(request.url);
          // Send a record to the pipeline
          if (url.pathname === '/send-record') {
            try {
              // Parse the request body
              const records = await request.json();
              // Send records to the pipeline
              await env.DATA_PIPELINE.send(records);
              return new Response(JSON.stringify({
                success: true,
                message: 'Records sent to pipeline',
                count: Array.isArray(records) ? records.length : 1
              }), {
                status: 200,
                headers: { 'Content-Type': 'application/json' }
              });
            } catch (error) {
              return new Response(JSON.stringify({
                success: false,
                error: error.message
              }), {
                status: 500,
                headers: { 'Content-Type': 'application/json' }
              });
            }
          }
          return new Response('Pipeline Worker is running!', {
            status: 200,
            headers: { 'Content-Type': 'text/plain' }
          });
        }
      };
    `;
    let pipeline: Pipeline<TestRecord> | undefined = undefined;
    let bucket: R2Bucket | undefined = undefined;
    let worker: Worker<{ DATA_PIPELINE: Pipeline<TestRecord> }> | undefined =
      undefined;
    try {
      // Create an R2 bucket
      bucket = await R2Bucket("worker-bucket", {
        name: bucketName,
        accessKey: accessKeyId,
        secretAccessKey: secretAccessKey,
        delete: true,
        empty: true,
      });
      // Create a pipeline with the R2 bucket as destination
      pipeline = await Pipeline(pipelineName, {
        name: pipelineName,
        source: [
          {
            type: "binding",
            format: "json",
          },
        ],
        destination: {
          type: "r2",
          format: "json",
          path: {
            bucket: bucket.name,
            prefix: "worker-logs",
          },
          credentials: {
            accessKeyId,
            secretAccessKey,
          },
          batch: {
            maxMb: 1, // 1 MB
            maxSeconds: 1, // 5 seconds
            maxRows: 100, // 100 rows
          },
        },
      });
      expect(pipeline.id).toBeTruthy();
      expect(pipeline.name).toEqual(pipelineName);
      expect(pipeline.endpoint).toBeTruthy();
      // Create a worker with the pipeline binding
      worker = await Worker(workerName, {
        name: workerName,
        script: pipelineWorkerScript,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          DATA_PIPELINE: pipeline,
        },
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.bindings!.DATA_PIPELINE).toBeDefined();
      expect(worker.url).toBeTruthy();
      if (worker.url) {
        // Create test records
        const testRecords: TestRecord[] = [
          {
            id: "rec-1",
            event: "test-event",
            timestamp: Date.now(),
            data: {
              value: 42,
              tags: ["test", "pipeline"],
            },
          },
          {
            id: "rec-2",
            event: "another-event",
            timestamp: Date.now(),
            data: {
              value: 99,
              tags: ["pipeline", "worker"],
            },
          },
        ];
        // Send records to the pipeline through the worker
        const sendResponse = await fetch(`${worker.url}/send-record`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(testRecords),
        });
        const responseData = await sendResponse.json();
        console.log(responseData);
        expect(sendResponse.status).toEqual(200);
        expect(responseData.success).toEqual(true);
        expect(responseData.message).toEqual("Records sent to pipeline");
        expect(responseData.count).toEqual(2);
        // Note: We can't easily verify the records were written to R2 in a test
        // because it might take time for the batching and delivery to complete.
        // In a real application, you'd have monitoring or a way to query the destination.
        console.log("Records sent to pipeline:", responseData);
      }
    } finally {
      // wait 10s for pipeline to flush
      await new Promise((resolve) => setTimeout(resolve, 3 * 1000));
      await destroy(scope);
      // Verify the worker was deleted
      if (worker) {
        await assertWorkerDoesNotExist(workerName);
      }
    }
  }, 120000); // Increase timeout for worker and pipeline operations
});
</file>

<file path="alchemy/test/cloudflare/queue-consumer.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { listQueueConsumers } from "../../src/cloudflare/queue-consumer.js";
import { Queue } from "../../src/cloudflare/queue.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
// must import this or else alchemy.test won't exist
import { CloudflareApiError } from "../../src/cloudflare/api-error.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta);
const api = await createCloudflareApi({});
describe("QueueConsumer Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-queue-consumer`;
  const queueName = `${testId}-queue`;
  const workerName = `${testId}-worker`;
  test("create, update, and delete queue consumer", async (scope) => {
    let queue: Queue | undefined;
    let worker: Worker | undefined;
    try {
      queue = await Queue(`${testId}-queue`, {
        name: queueName,
      });
      expect(queue.id).toBeTruthy();
      expect(queue.name).toEqual(queueName);
      worker = await Worker(`${testId}-worker`, {
        name: workerName,
        script: `
          export default {
            async fetch(request, env, ctx) {
              return new Response("Hello World");
            },
            async queue(batch, env, ctx) {
              return batch.messages.map(() => ({ status: "ack" }));
            }
          }
        `,
        eventSources: [queue],
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      const consumers = await listQueueConsumers(api, queue.id);
      const thisConsumer = consumers.find((c) => c.scriptName === workerName);
      expect(thisConsumer).toBeTruthy();
    } catch (err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify consumers were deleted
      try {
        await listQueueConsumers(api, queue!.id);
      } catch (err) {
        if (err instanceof CloudflareApiError && err.status === 404) {
          // expected
        } else {
          throw err;
        }
      }
    }
  });
});
</file>

<file path="alchemy/test/cloudflare/queue.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { Queue, listQueues } from "../../src/cloudflare/queue.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Cloudflare Queue Resource", async () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-queue`;
  // Create Cloudflare API client for direct verification
  const api = await createCloudflareApi();
  test("create and delete queue", async (scope) => {
    // Create a test queue
    let queue: Queue | undefined = undefined;
    try {
      queue = await Queue(testId, {
        name: testId,
      });
      expect(queue.name).toEqual(testId);
      expect(queue.id).toBeTruthy();
      expect(queue.createdOn).toBeTruthy();
      expect(queue.modifiedOn).toBeTruthy();
      // Check if queue exists by listing queues
      const queues = await listQueues(api);
      const foundQueue = queues.find((q) => q.name === testId);
      expect(foundQueue).toBeTruthy();
      expect(foundQueue?.id).toEqual(queue.id);
    } finally {
      await alchemy.destroy(scope);
      // Verify queue was deleted
      if (queue) {
        await assertQueueDeleted(queue);
      }
    }
  }, 120000);
  test("create queue with settings", async (scope) => {
    const settingsQueueName = `${testId}-settings`;
    try {
      // Create a queue with custom settings
      const queue = await Queue(settingsQueueName, {
        name: settingsQueueName,
        settings: {
          deliveryDelay: 10,
          deliveryPaused: true,
          messageRetentionPeriod: 3600, // 1 hour
        },
      });
      expect(queue.name).toEqual(settingsQueueName);
      expect(queue.id).toBeTruthy();
      expect(queue.settings).toBeTruthy();
      expect(queue.settings?.deliveryDelay).toEqual(10);
      expect(queue.settings?.deliveryPaused).toEqual(true);
      expect(queue.settings?.messageRetentionPeriod).toEqual(3600);
    } finally {
      await alchemy.destroy(scope);
    }
  }, 120000);
  test("update queue settings", async (scope) => {
    const updateQueueName = `${testId}-update`;
    try {
      // Create a queue with initial settings
      let queue = await Queue(updateQueueName, {
        name: updateQueueName,
        settings: {
          deliveryDelay: 5,
          deliveryPaused: false,
        },
      });
      expect(queue.name).toEqual(updateQueueName);
      expect(queue.settings?.deliveryDelay).toEqual(5);
      expect(queue.settings?.deliveryPaused).toEqual(false);
      // Update the queue settings
      queue = await Queue(updateQueueName, {
        name: updateQueueName,
        settings: {
          deliveryDelay: 15,
          deliveryPaused: true,
        },
      });
      // Verify the update
      expect(queue.settings?.deliveryDelay).toEqual(15);
      expect(queue.settings?.deliveryPaused).toEqual(true);
    } finally {
      await alchemy.destroy(scope);
    }
  }, 120000);
  test("throws error on name change", async (scope) => {
    const immutableQueueName = `${testId}-immutable`;
    const newQueueName = `${testId}-new-name`;
    try {
      // Create a queue
      const queue = await Queue(immutableQueueName, {
        name: immutableQueueName,
      });
      expect(queue.name).toEqual(immutableQueueName);
      // Attempt to update name, which should throw an error
      await expect(
        Queue(immutableQueueName, {
          name: newQueueName, // Different from original
        }),
      ).rejects.toThrow("Cannot update Queue name");
    } finally {
      await alchemy.destroy(scope);
    }
  }, 120000);
});
async function assertQueueDeleted(queue: Queue) {
  const api = await createCloudflareApi();
  try {
    if (!queue.id) {
      throw new Error("Queue ID is undefined");
    }
    // Try to list queues and check if our queue is still there
    const queues = await listQueues(api);
    const foundQueue = queues.find((q) => q.id === queue.id);
    if (foundQueue) {
      throw new Error(`Queue ${queue.name} was not deleted as expected`);
    }
  } catch (error: any) {
    // If we get a 404, the queue was deleted
    if (error.status === 404) {
      return; // This is expected
    } else if (error.message.includes("was not deleted as expected")) {
      throw error; // Re-throw our custom error
    } else {
      console.error("Unexpected error checking queue deletion:", error);
    }
  }
}
</file>

<file path="alchemy/test/cloudflare/r2-rest-state-store.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { getBucket } from "../../src/cloudflare/bucket.js";
import { BRANCH_PREFIX } from "../util.js";
import { R2RestStateStore } from "../../src/cloudflare/r2-rest-state-store.js";
import "../../src/test/bun.js";
describe("R2RestStateStore", async () => {
  const test = alchemy.test(import.meta, {
    // Isolate the default state store bucket from other tests' stores
    prefix: `${BRANCH_PREFIX}-r2-rest-state-store`,
    stateStore: (scope) => new R2RestStateStore(scope),
  });
  // For public access, we still need to use the Cloudflare API
  // This is one feature not available through the S3 API
  const api = await createCloudflareApi();
  test("optimistically creates alchemy-state bucket", async (scope) => {
    const defaultBucketName = "alchemy-state";
    const bucket = await getBucket(api, defaultBucketName);
    expect(bucket.result.name).toEqual(defaultBucketName);
  });
});
</file>

<file path="alchemy/test/cloudflare/route.test.ts">
import { afterAll, describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { Route } from "../../src/cloudflare/route.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { Zone } from "../../src/cloudflare/zone.js";
import { destroy } from "../../src/destroy.js";
import type { Scope } from "../../src/scope.js";
import { BRANCH_PREFIX } from "../util.js";
// must import this or else alchemy.test won't exist
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const testDomain = `${BRANCH_PREFIX}-route-test.com`;
let zone: Zone;
let scope: Scope | undefined;
test.beforeAll(async (_scope) => {
  zone = await Zone(`${BRANCH_PREFIX}-zone`, {
    name: testDomain,
  });
  scope = _scope;
});
afterAll(async () => {
  if (scope) {
    await destroy(scope);
  }
});
describe("Route Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-route`;
  const pattern = `${testDomain}/*`;
  test("create, update, and delete route", async (scope) => {
    let route: any;
    let worker: any;
    let api: any;
    try {
      // Initialize API client
      api = await createCloudflareApi();
      // First create a worker to connect the route to
      const workerName = `${BRANCH_PREFIX}-worker-1`;
      worker = await Worker(workerName, {
        script: `
          export default {
            fetch(request, env) {
              return new Response('Hello from ${workerName}!');
            }
          }
        `,
      });
      expect(worker.name).toEqual(workerName);
      // Create a test route
      route = await Route(testId, {
        pattern,
        script: worker,
        zoneId: zone.id,
      });
      expect(route.id).toBeTruthy();
      expect(route.pattern).toEqual(pattern);
      expect(route.script).toEqual(workerName);
      // Verify route was created by querying the API directly
      const getResponse = await api.get(
        `/zones/${route.zoneId}/workers/routes/${route.id}`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.pattern).toEqual(pattern);
      expect(responseData.result.script).toEqual(workerName);
      // Update the route with a new pattern
      const updatedPattern = pattern.replace("/*", "/api/*");
      route = await Route(testId, {
        pattern: updatedPattern,
        script: worker,
        zoneId: zone.id,
      });
      expect(route.id).toBeTruthy();
      expect(route.pattern).toEqual(updatedPattern);
      // Verify route was updated
      const getUpdatedResponse = await api.get(
        `/zones/${route.zoneId}/workers/routes/${route.id}`,
      );
      const updatedData = await getUpdatedResponse.json();
      expect(updatedData.result.pattern).toEqual(updatedPattern);
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify route was deleted
      if (route?.id && route?.zoneId) {
        await assertRouteNotExists(api, route.zoneId, route.id);
      }
    }
  });
  test("create route with string script name", async (scope) => {
    let route: any;
    let api: any;
    let worker: any;
    try {
      // Initialize API client
      api = await createCloudflareApi();
      // First create a worker to connect the route to
      const workerName = `${BRANCH_PREFIX}-worker-2`;
      worker = await Worker(workerName, {
        script: `
          export default {
            fetch(request, env) {
              return new Response('Hello from ${workerName}!');
            }
          }
        `,
      });
      expect(worker.name).toEqual(workerName);
      // Create a test route with a string script name
      route = await Route(`${testId}-string`, {
        pattern,
        script: workerName,
        zoneId: zone.id,
      });
      expect(route.id).toBeTruthy();
      expect(route.pattern).toEqual(pattern);
      expect(route.script).toEqual(workerName);
      // Verify route was created by querying the API directly
      const getResponse = await api.get(
        `/zones/${route.zoneId}/workers/routes/${route.id}`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.pattern).toEqual(pattern);
      expect(responseData.result.script).toEqual(workerName);
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify route was deleted
      if (route?.id && route?.zoneId) {
        await assertRouteNotExists(api, route.zoneId, route.id);
      }
    }
  });
  test("using different patterns", async (scope) => {
    let route: any;
    let api: any;
    let worker: any;
    try {
      // Initialize API client
      api = await createCloudflareApi();
      // First create a worker to connect the route to
      const workerName = `${BRANCH_PREFIX}-worker-3`;
      worker = await Worker(workerName, {
        script: `
          export default {
            fetch(request, env) {
              return new Response('Hello from ${workerName}!');
            }
          }
        `,
      });
      expect(worker.name).toEqual(workerName);
      // Use a more specific pattern
      const specificPattern = `${testDomain}/api/*`;
      // Create a test route with a specific pattern
      route = await Route(`${testId}-specific-pattern`, {
        pattern: specificPattern,
        script: workerName,
        zoneId: zone.id,
      });
      expect(route.id).toBeTruthy();
      expect(route.pattern).toEqual(specificPattern);
      expect(route.script).toEqual(workerName);
      expect(route.zoneId).toEqual(zone.id);
      // Verify route was created by querying the API directly
      const getResponse = await api.get(
        `/zones/${route.zoneId}/workers/routes/${route.id}`,
      );
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.pattern).toEqual(specificPattern);
      expect(responseData.result.script).toEqual(workerName);
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify route was deleted
      if (route?.id && route?.zoneId) {
        await assertRouteNotExists(api, route.zoneId, route.id);
      }
    }
  });
});
/**
 * Asserts that a route does not exist by checking for a 404 status
 */
async function assertRouteNotExists(api: any, zoneId: string, routeId: string) {
  const getDeletedResponse = await api.get(
    `/zones/${zoneId}/workers/routes/${routeId}`,
  );
  expect(getDeletedResponse.status).toEqual(404);
}
</file>

<file path="alchemy/test/cloudflare/unenv-handler.ts">
import fs from "node:fs/promises";
export default {
  async fetch(request, env, ctx): Promise<Response> {
    return new Response(typeof fs.readFile);
  },
};
</file>

<file path="alchemy/test/cloudflare/unenv.test.ts">
import { describe, expect } from "bun:test";
import * as path from "node:path";
import { alchemy } from "../../src/alchemy.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "@cloudflare/unenv-preset/node/process";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Worker Unenv Tests", () => {
  test("create worker with import.meta.dirname and unenv-handler", async (scope) => {
    try {
      // Create a temporary directory for the files
      // Create the worker using the entrypoint file
      const worker = await Worker(`${BRANCH_PREFIX}-test-worker-unenv`, {
        entrypoint: path.join(import.meta.dirname, "unenv-handler.ts"),
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        compatibilityFlags: ["nodejs_compat"],
      });
      const response = await fetch(worker.url!);
      expect(await response.text()).toEqual("function");
    } finally {
      // Clean up the worker
      await destroy(scope);
    }
  }, 120000); // Increased timeout for bundling operations
});
</file>

<file path="alchemy/test/cloudflare/vectorize-index.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import {
  VectorizeIndex,
  listIndexes,
} from "../../src/cloudflare/vectorize-index.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Vectorize Index Resource", async () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-index`;
  // Create Cloudflare API client for direct verification
  const api = await createCloudflareApi();
  test("create and delete index", async (scope) => {
    // Create a test index
    let index: VectorizeIndex | undefined = undefined;
    try {
      index = await VectorizeIndex(testId, {
        name: testId,
        dimensions: 768,
        metric: "cosine",
        adopt: true,
      });
      expect(index.name).toEqual(testId);
      expect(index.id).toBeTruthy();
      expect(index.dimensions).toEqual(768);
      expect(index.metric).toEqual("cosine");
      // Check if index exists by listing indexes
      const indexes = await listIndexes(api);
      const foundIndex = indexes.find((idx) => idx.name === testId);
      expect(foundIndex).toBeTruthy();
    } finally {
      await alchemy.destroy(scope);
      // Verify index was deleted
      if (index) {
        await assertIndexDeleted(index);
      }
    }
  });
  test("throws error on update attempts", async (scope) => {
    const updateIndex = `${testId}-no-update`;
    try {
      // Create an index
      const index = await VectorizeIndex(updateIndex, {
        name: updateIndex,
        dimensions: 768,
        metric: "cosine",
        adopt: true,
      });
      expect(index.name).toEqual(updateIndex);
      expect(index.dimensions).toEqual(768);
      // Attempt to update the index, which should throw an error indicating updates are not supported
      await expect(
        VectorizeIndex(updateIndex, {
          name: updateIndex,
          description: "Updated description",
          dimensions: 768,
          metric: "cosine",
          adopt: true,
        }),
      ).rejects.toThrow(
        "Updating Vectorize indexes is not supported by the Cloudflare API",
      );
    } finally {
      await alchemy.destroy(scope);
    }
  });
});
async function assertIndexDeleted(index: VectorizeIndex) {
  const api = await createCloudflareApi();
  try {
    // Try to get the index
    const response = await api.get(
      `/accounts/${api.accountId}/vectorize/v2/indexes/${index.name}`,
    );
    // If we get a 200, the index still exists
    if (response.ok) {
      throw new Error(`Index ${index.name} was not deleted as expected`);
    }
    // 404 (Not Found) or 410 (Gone) mean deleted, which is what we want
    if (response.status !== 404 && response.status !== 410) {
      throw new Error(`Unexpected response status: ${response.status}`);
    }
  } catch (error: any) {
    // If the error is a 404 or 410, the index was deleted as expected
    if (error.status === 404 || error.status === 410) {
      return; // This is expected
    } else {
      throw new Error(`Unexpected error type: ${error}`);
    }
  }
}
</file>

<file path="alchemy/test/cloudflare/vectorize-metadata-index.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { VectorizeIndex } from "../../src/cloudflare/vectorize-index.js";
import {
  VectorizeMetadataIndex,
  listMetadataIndexes,
} from "../../src/cloudflare/vectorize-metadata-index.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Vectorize Metadata Index Resource", async () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-meta-test`;
  // Create Cloudflare API client for direct verification
  const api = await createCloudflareApi();
  test("create and delete metadata index", async (scope) => {
    // First create a parent vectorize index
    const vectorIndex = await VectorizeIndex(`${testId}-parent`, {
      name: `${testId}-parent`,
      dimensions: 768,
      metric: "cosine",
      adopt: true,
    });
    // Then create a metadata index
    let metadataIndex: VectorizeMetadataIndex | undefined = undefined;
    try {
      metadataIndex = await VectorizeMetadataIndex(`${testId}-category`, {
        index: vectorIndex,
        propertyName: "category",
        indexType: "string",
      });
      expect(metadataIndex.id).toBeTruthy();
      expect(metadataIndex.propertyName).toEqual("category");
      expect(metadataIndex.indexType).toEqual("string");
      expect(metadataIndex.mutationId).toBeTruthy();
      // TODO(sam): re-enable this once we know what's up with the List API returning HTTP 410 gone
      // see: https://x.com/samgoodwin89/status/1912978970682831089
      // Check if metadata index exists by listing metadata indexes
      // const metadataIndexes = await listMetadataIndexes(api, vectorIndex.name);
      // const foundIndex = metadataIndexes.find(
      //   (idx) => idx.propertyName === "category"
      // );
      // expect(foundIndex).toBeTruthy();
      // expect(foundIndex?.indexType).toEqual("string");
    } finally {
      await alchemy.destroy(scope);
      // Verify metadata index was deleted
      //   if (metadataIndex) {
      //     await assertMetadataIndexDeleted(vectorIndex.name, "category");
      //   }
    }
  });
  test("throws error on update attempts", async (scope) => {
    // First create a parent vectorize index
    const vectorIndex = await VectorizeIndex(`${testId}-parent-noupdate`, {
      name: `${testId}-parent-noupdate`,
      dimensions: 768,
      metric: "cosine",
      adopt: true,
    });
    try {
      // Create a metadata index
      const metadataIndex = await VectorizeMetadataIndex(`${testId}-tag`, {
        index: vectorIndex,
        propertyName: "tag",
        indexType: "string",
      });
      expect(metadataIndex.propertyName).toEqual("tag");
      // Attempt to update the metadata index, which should throw an error
      await expect(
        VectorizeMetadataIndex(`${testId}-tag`, {
          index: vectorIndex,
          propertyName: "tag",
          indexType: "boolean", // Change the type
        }),
      ).rejects.toThrow("Updating Vectorize metadata indexes is not supported");
    } finally {
      await alchemy.destroy(scope);
    }
  });
});
async function assertMetadataIndexDeleted(
  indexName: string,
  propertyName: string,
) {
  const api = await createCloudflareApi();
  try {
    // List metadata indexes and check if our index is still there
    const metadataIndexes = await listMetadataIndexes(api, indexName);
    const foundIndex = metadataIndexes.find(
      (idx) => idx.propertyName === propertyName,
    );
    if (foundIndex) {
      throw new Error(
        `Metadata index ${propertyName} was not deleted as expected`,
      );
    }
  } catch (error: any) {
    // If we get a 404, the parent index itself might have been deleted (which is fine)
    if (error.status === 404 || error.status === 410) {
      return; // This is expected
    } else {
      throw new Error(`Unexpected error type: ${error}`);
    }
  }
}
</file>

<file path="alchemy/test/cloudflare/worker.test.ts">
import { describe, expect } from "bun:test";
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { Assets } from "../../src/cloudflare/assets.js";
import { Self } from "../../src/cloudflare/bindings.js";
import { R2Bucket } from "../../src/cloudflare/bucket.js";
import { D1Database } from "../../src/cloudflare/d1-database.js";
import { DurableObjectNamespace } from "../../src/cloudflare/durable-object-namespace.js";
import { KVNamespace } from "../../src/cloudflare/kv-namespace.js";
import { Queue } from "../../src/cloudflare/queue.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { Workflow } from "../../src/cloudflare/workflow.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
// Create a Cloudflare API client for verification
const api = await createCloudflareApi();
// Helper function to check if a worker exists
async function assertWorkerDoesNotExist(workerName: string) {
  try {
    const response = await api.get(
      `/accounts/${api.accountId}/workers/scripts/${workerName}`,
    );
    expect(response.status).toEqual(404);
  } catch (error) {
    // 404 is expected, so we can ignore it
    return;
  }
}
describe("Worker Resource", () => {
  // Sample worker script (CJS style)
  const workerScript = `
    addEventListener('fetch', event => {
      event.respondWith(new Response('Hello world!', { status: 200 }));
    });
  `;
  // Sample ESM worker script
  const esmWorkerScript = `
    export default {
      async fetch(request, env, ctx) {
        return new Response('Hello ESM world!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with a Durable Object
  const durableObjectWorkerScript = `
    export class Counter {
      constructor(state, env) {
        this.state = state;
        this.env = env;
        this.counter = 0;
      }
      async fetch(request) {
        this.counter++;
        return new Response('Counter: ' + this.counter, { status: 200 });
      }
    }
    export default {
      async fetch(request, env, ctx) {
        // Use the DO binding if needed
        if (request.url.includes('/counter')) {
          const id = env.COUNTER.idFromName('default');
          const stub = env.COUNTER.get(id);
          return stub.fetch(request);
        }
        return new Response('Hello with Durable Object!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with KV Namespace
  const kvWorkerScript = `
    export default {
      async fetch(request, env, ctx) {
        // Use the KV binding
        if (request.url.includes('/kv')) {
          const value = await env.TEST_KV.get('testKey');
          return new Response('KV Value: ' + (value || 'not found'), { status: 200 });
        }
        return new Response('Hello with KV Namespace!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with R2 bucket
  const r2WorkerScript = `
    export default {
      async fetch(request, env, ctx) {
        // Use the R2 binding
        if (request.url.includes('/r2-info')) {
          // Just confirm we have access to the binding
          return new Response(JSON.stringify({
            hasR2: !!env.STORAGE,
            bucketName: env.STORAGE.name || 'unknown'
          }), {
            status: 200,
            headers: { 'Content-Type': 'application/json' }
          });
        }
        return new Response('Hello with R2 Bucket!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with multiple bindings
  const multiBindingsWorkerScript = `
    export class Counter {
      constructor(state, env) {
        this.state = state;
        this.env = env;
        this.counter = 0;
      }
      async fetch(request) {
        this.counter++;
        return new Response('Counter: ' + this.counter, { status: 200 });
      }
    }
    export default {
      async fetch(request, env, ctx) {
        // Path-based routing to demonstrate different bindings
        const url = new URL(request.url);
        if (url.pathname.includes('/counter')) {
          const id = env.COUNTER.idFromName('default');
          const stub = env.COUNTER.get(id);
          return stub.fetch(request);
        }
        if (url.pathname.includes('/kv')) {
          const value = await env.TEST_KV.get('testKey');
          return new Response('KV Value: ' + (value || 'not found'), { status: 200 });
        }
        if (url.pathname.includes('/secret')) {
          return new Response('Secret: ' + env.API_KEY, { status: 200 });
        }
        return new Response('Hello worker with multiple bindings!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with environment variables
  const envVarsWorkerScript = `
    export default {
      async fetch(request, env, ctx) {
        const url = new URL(request.url);
        // Return the value of the requested environment variable
        if (url.pathname.startsWith('/env/')) {
          const varName = url.pathname.split('/env/')[1];
          const value = env[varName];
          return new Response(value || 'undefined', {
            status: 200,
            headers: { 'Content-Type': 'text/plain' }
          });
        }
        // Return all environment variables
        if (url.pathname === '/env') {
          const envVars = Object.entries(env)
            .filter(([key]) => key !== 'COUNTER' && !key.includes('Durable')) // Filter out bindings
            .map(([key, value]) => \`\${key}: \${value}\`)
            .join('\\n');
          return new Response(envVars, {
            status: 200,
            headers: { 'Content-Type': 'text/plain' }
          });
        }
        return new Response('Hello with environment variables!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with original Counter class
  const doMigrationWorkerScriptV1 = `
    export class Counter {
      constructor(state, env) {
        this.state = state;
        this.env = env;
        this.counter = 0;
      }
      async fetch(request) {
        this.counter++;
        return new Response('Counter V1: ' + this.counter, { status: 200 });
      }
    }
    export default {
      async fetch(request, env, ctx) {
        if (request.url.includes('/counter')) {
          const id = env.COUNTER.idFromName('default');
          const stub = env.COUNTER.get(id);
          return stub.fetch(request);
        }
        return new Response('Hello with Counter V1!', { status: 200 });
      }
    };
  `;
  // Sample ESM worker script with renamed CounterV2 class
  const doMigrationWorkerScriptV2 = `
    export class CounterV2 {
      constructor(state, env) {
        this.state = state;
        this.env = env;
        this.counter = 0;
      }
      async fetch(request) {
        this.counter++;
        return new Response('Counter V2: ' + this.counter, { status: 200 });
      }
    }
    export default {
      async fetch(request, env, ctx) {
        if (request.url.includes('/counter')) {
          const id = env.COUNTER.idFromName('default');
          const stub = env.COUNTER.get(id);
          return stub.fetch(request);
        }
        return new Response('Hello with Counter V2!', { status: 200 });
      }
    };
  `;
  // Sample worker script with a scheduled handler
  const cronWorkerScript = `
    export default {
      async fetch(request, env, ctx) {
        return new Response('Worker with cron is running!', { status: 200 });
      },
      async scheduled(event, env, ctx) {
        // Log the scheduled event details
        console.log('Scheduled event received:', event.scheduledTime, event.cron);
        // In a real worker, you would perform tasks here
      },
    };
  `;
  // Sample worker script with scheduled handler and KV namespace
  const cronKvWorkerScript = `
    export default {
      async fetch(request, env, ctx) {
        // Use the KV binding
        if (request.url.includes('/last-run')) {
          const value = await env.CRON_STATS.get('last_run');
          return new Response('Last scheduled run: ' + (value || 'never'), { status: 200 });
        }
        return new Response('Worker with cron and KV is running!', { status: 200 });
      },
      async scheduled(event, env, ctx) {
        // Log event to KV
        await env.CRON_STATS.put('last_run', new Date().toISOString());
        await env.CRON_STATS.put(\`run_\${Date.now()}\`, JSON.stringify({
          cron: event.cron,
          scheduledTime: event.scheduledTime
        }));
      },
    };
  `;
  test("create, update, and delete worker (CJS format)", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-cjs-1`;
    let worker: Worker | undefined = undefined;
    try {
      // Create a worker with an explicit name
      worker = await Worker(workerName, {
        name: workerName,
        script: workerScript,
        format: "cjs",
      });
      // Apply to create the worker
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.format).toEqual("cjs");
      // Update the worker with a new script
      const updatedScript = `
        addEventListener('fetch', event => {
          event.respondWith(new Response('Hello updated world!', { status: 200 }));
        });
      `;
      worker = await Worker(workerName, {
        name: workerName,
        script: updatedScript,
        format: "cjs",
      });
      expect(worker.id).toEqual(worker.id);
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("create, update, and delete worker (ESM format)", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-esm-1`;
    let worker: Worker | undefined = undefined;
    try {
      // Create a worker with ESM format
      worker = await Worker(workerName, {
        name: workerName,
        script: esmWorkerScript,
        format: "esm", // Explicitly using ESM
      });
      // Apply to create the worker
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.format).toEqual("esm");
      // Update the worker with a new ESM script
      const updatedEsmScript = `
        export default {
          async fetch(request, env, ctx) {
            return new Response('Hello updated ESM world!', { status: 200 });
          }
        };
      `;
      worker = await Worker(workerName, {
        name: workerName,
        script: updatedEsmScript,
        format: "esm",
      });
      expect(worker.id).toEqual(worker.id);
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("convert between ESM and CJS formats", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-format-conversion-convert-1`;
    let worker: Worker | undefined = undefined;
    try {
      // First create with ESM format
      worker = await Worker(workerName, {
        name: workerName,
        script: esmWorkerScript,
        format: "esm",
      });
      expect(worker.format).toEqual("esm");
      // Update to CJS format
      worker = await Worker(workerName, {
        name: workerName,
        script: workerScript,
        format: "cjs",
      });
      expect(worker.format).toEqual("cjs");
      // Update back to ESM format
      worker = await Worker(workerName, {
        name: workerName,
        script: esmWorkerScript,
        format: "esm",
      });
      expect(worker.format).toEqual("esm");
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("fails when creating a worker with a duplicate name", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-duplicate`;
    try {
      // First, create a worker successfully
      await Worker(workerName, {
        name: workerName,
        script: workerScript,
        format: "cjs",
      });
      // Try to create another worker with the same name, which should fail
      const duplicateWorker = Worker(`${workerName}-dup`, {
        name: workerName, // Same name as firstWorker
        script: workerScript,
        format: "cjs",
      });
      await expect(duplicateWorker).rejects.toThrow(
        `Worker with name '${workerName}' already exists. Please use a unique name.`,
      );
    } finally {
      await destroy(scope);
    }
  });
  test("create and delete worker with Durable Object binding", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-do-binding-do-1`;
    let worker: Worker | undefined = undefined;
    try {
      // First create the worker without the DO binding
      worker = await Worker(workerName, {
        name: workerName,
        script: durableObjectWorkerScript,
        format: "esm",
        // No bindings yet
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeEmpty();
      // Create a Durable Object namespace
      const counterNamespace = new DurableObjectNamespace(
        "test-counter-namespace",
        {
          className: "Counter",
          scriptName: workerName,
        },
      );
      // Update the worker with the DO binding
      worker = await Worker(workerName, {
        name: workerName,
        script: durableObjectWorkerScript,
        format: "esm",
        bindings: {
          COUNTER: counterNamespace,
        },
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("create and delete worker with KV Namespace binding", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-kv-binding-kv-1`;
    let worker: Worker | undefined = undefined;
    let testKv: KVNamespace | undefined = undefined;
    try {
      // Create a KV namespace with initial values
      testKv = await KVNamespace("test-kv-namespace", {
        title: `${BRANCH_PREFIX} Test KV Namespace 2`,
        values: [
          {
            key: "testKey",
            value: "initial-value",
          },
        ],
      });
      // Create a worker with the KV Namespace binding
      worker = await Worker(workerName, {
        name: workerName,
        script: kvWorkerScript,
        format: "esm",
        bindings: {
          TEST_KV: testKv,
        },
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("create and delete worker with multiple bindings", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-multi-bindings-multi-1`;
    // Create a Durable Object namespace
    const counterNamespace = new DurableObjectNamespace(
      "test-counter-namespace",
      {
        className: "Counter",
        scriptName: workerName,
      },
    );
    // Create a KV namespace
    const testKv = await KVNamespace("test-kv-namespace", {
      title: `${BRANCH_PREFIX} Test KV Namespace 1`,
      values: [
        {
          key: "testKey",
          value: "initial-value",
        },
      ],
    });
    let worker: Worker | undefined = undefined;
    try {
      // First create the worker without bindings
      worker = await Worker(workerName, {
        name: workerName,
        script: multiBindingsWorkerScript,
        format: "esm",
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      // Update the worker with all bindings
      worker = await Worker(workerName, {
        name: workerName,
        script: multiBindingsWorkerScript,
        format: "esm",
        bindings: {
          COUNTER: counterNamespace,
          TEST_KV: testKv,
          API_KEY: "test-api-key-value",
        },
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  // Add a new test for environment variables
  test("create and test worker with environment variables", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-env-vars-env-1`;
    let worker: Worker | undefined = undefined;
    try {
      // Create a worker with environment variables
      worker = await Worker(workerName, {
        name: workerName,
        script: envVarsWorkerScript,
        format: "esm",
        env: {
          TEST_API_KEY: "test-api-key-123",
          NODE_ENV: "testing",
          APP_DEBUG: "true",
        },
        url: true, // Enable workers.dev URL to test the worker
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.env).toBeDefined();
      expect(worker.env?.TEST_API_KEY).toEqual("test-api-key-123");
      expect(worker.env?.NODE_ENV).toEqual("testing");
      expect(worker.url).toBeTruthy();
      if (worker.url) {
        // Test that the environment variables are accessible in the worker
        const response = await fetch(`${worker.url}/env/TEST_API_KEY`);
        expect(response.status).toEqual(200);
        const text = await response.text();
        expect(text).toEqual("test-api-key-123");
        // Test another environment variable
        const nodeEnvResponse = await fetch(`${worker.url}/env/NODE_ENV`);
        expect(nodeEnvResponse.status).toEqual(200);
        const nodeEnvText = await nodeEnvResponse.text();
        expect(nodeEnvText).toEqual("testing");
      }
      // Update the worker with different environment variables
      worker = await Worker(workerName, {
        name: workerName,
        script: envVarsWorkerScript,
        format: "esm",
        env: {
          TEST_API_KEY: "updated-key-456",
          NODE_ENV: "production",
          NEW_VAR: "new-value",
        },
        url: true,
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toEqual(worker.id);
      expect(worker.env?.TEST_API_KEY).toEqual("updated-key-456");
      expect(worker.env?.NODE_ENV).toEqual("production");
      expect(worker.env?.NEW_VAR).toEqual("new-value");
      // APP_DEBUG should no longer be present
      expect(worker.env?.APP_DEBUG).toBeUndefined();
      // Test that the updated environment variables are accessible
      const response = await fetch(`${worker.url}/env/TEST_API_KEY`);
      expect(response.status).toEqual(200);
      const text = await response.text();
      expect(text).toEqual("updated-key-456");
      // Test new environment variable
      const newVarResponse = await fetch(`${worker.url}/env/NEW_VAR`);
      expect(newVarResponse.status).toEqual(200);
      const newVarText = await newVarResponse.text();
      expect(newVarText).toEqual("new-value");
      // Test that the removed environment variable is no longer accessible
      const removedVarResponse = await fetch(`${worker.url}/env/APP_DEBUG`);
      expect(removedVarResponse.status).toEqual(200);
      const removedVarText = await removedVarResponse.text();
      expect(removedVarText).toEqual("undefined");
    } finally {
      await destroy(scope);
      // Verify the worker was deleted
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("migrate durable object by renaming class", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-do-migration-migrate-1`;
    let worker: Worker | undefined = undefined;
    try {
      // First create the worker with the original Counter class
      worker = await Worker(workerName, {
        name: workerName,
        script: doMigrationWorkerScriptV1,
        format: "esm",
      });
      // Apply to create the worker first
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      // Create a stable DO namespace with the original Counter class
      const counterNamespace = new DurableObjectNamespace(
        "test-counter-namespace",
        {
          className: "Counter",
          scriptName: workerName,
        },
      );
      // Update worker with the original Counter binding
      worker = await Worker(workerName, {
        name: workerName,
        script: doMigrationWorkerScriptV1,
        format: "esm",
        bindings: {
          COUNTER: counterNamespace,
        },
      });
      expect(worker.bindings).toBeDefined();
      // Now update the namespace to use CounterV2 class
      const updatedNamespace = new DurableObjectNamespace(
        "test-counter-namespace",
        {
          className: "CounterV2",
          scriptName: workerName,
        },
      );
      // Update worker with the migrated binding
      worker = await Worker(workerName, {
        name: workerName,
        script: doMigrationWorkerScriptV2,
        format: "esm",
        bindings: {
          COUNTER: updatedNamespace,
        },
      });
      expect(worker.bindings).toBeDefined();
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("add environment variables to worker with durable object", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-do-with-env-doenv-1`;
    let worker: Worker | undefined = undefined;
    try {
      // First create a worker with a Durable Object but no env vars
      worker = await Worker(workerName, {
        name: workerName,
        script: durableObjectWorkerScript,
        format: "esm",
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      // Create a Durable Object namespace
      const counterNamespace = new DurableObjectNamespace(
        "test-counter-env-namespace",
        {
          className: "Counter",
          scriptName: workerName,
        },
      );
      // Update the worker with the DO binding
      worker = await Worker(workerName, {
        name: workerName,
        script: durableObjectWorkerScript,
        format: "esm",
        bindings: {
          COUNTER: counterNamespace,
        },
      });
      // Apply the worker with binding
      expect(worker.bindings).toBeDefined();
      expect(worker.env).toBeUndefined();
      // Now update the worker by adding environment variables
      worker = await Worker(workerName, {
        name: workerName,
        script: durableObjectWorkerScript,
        format: "esm",
        bindings: {
          COUNTER: counterNamespace,
        },
        env: {
          API_SECRET: "test-secret-123",
          DEBUG_MODE: "true",
        },
      });
      expect(worker.bindings).toBeDefined();
      expect(worker.env).toBeDefined();
      expect(worker.env?.API_SECRET).toEqual("test-secret-123");
      expect(worker.env?.DEBUG_MODE).toEqual("true");
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("create and delete worker with R2 bucket binding", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-r2-binding-r2-1`;
    // Create a test R2 bucket
    let testBucket: R2Bucket | undefined;
    let worker: Worker<{ STORAGE: R2Bucket }> | undefined;
    try {
      testBucket = await R2Bucket("test-bucket", {
        name: `${BRANCH_PREFIX.toLowerCase()}-test-r2-bucket`,
        allowPublicAccess: false,
      });
      // Create a worker with the R2 bucket binding
      worker = await Worker(workerName, {
        name: workerName,
        script: r2WorkerScript,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          STORAGE: testBucket,
        },
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.bindings!.STORAGE).toBeDefined();
      // Test that the R2 binding is accessible in the worker
      const response = await fetch(`${worker.url}/r2-info`);
      expect(response.status).toEqual(200);
      const data = (await response.json()) as {
        hasR2: boolean;
        bucketName: string;
      };
      expect(data.hasR2).toEqual(true);
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  // Test for static assets
  test("create and test worker with static assets", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-assets`;
    let tempDir: string | undefined = undefined;
    try {
      // Create a temporary directory to store test assets
      tempDir = path.join(".out", "alchemy-assets-test");
      await fs.rm(tempDir, { recursive: true, force: true });
      // Ensure directory exists with proper permissions
      await fs.mkdir(tempDir, { recursive: true });
      // Create test files in the temporary directory
      const testContent = "Hello from static assets!";
      const cssContent = "body { color: blue; }";
      const jsonContent = JSON.stringify({
        message: "Hello from JSON",
        timestamp: Date.now(),
      });
      // Create a subdirectory with additional files
      const subDir = path.join(tempDir, "data");
      await Promise.all([
        fs.writeFile(path.join(tempDir, "index.html"), testContent),
        fs.writeFile(path.join(tempDir, "styles.css"), cssContent),
        fs.mkdir(subDir, { recursive: true }),
      ]);
      await fs.writeFile(path.join(subDir, "config.json"), jsonContent);
      // Create assets resource
      const assets = await Assets("static-assets", {
        path: tempDir,
      });
      // Create a worker that uses ESM format and serves static assets
      const workerWithAssetsScript = `
        export default {
          async fetch(request, env, ctx) {
            const url = new URL(request.url);
            if (url.pathname.startsWith("/api/")) {
              return new Response("Worker with assets is running!", {
                status: 200,
                headers: { 'Content-Type': 'text/plain' }
              });
            }
            return new Response("Not Found", { status: 404 });
          }
        };
      `;
      // Create the worker with assets binding
      const worker = await Worker(workerName, {
        name: workerName,
        script: workerWithAssetsScript,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          ASSETS: assets,
        },
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.url).toBeTruthy();
      expect(worker.bindings?.ASSETS).toBeTruthy();
      async function get(url: string) {
        const response = await fetch(url);
        if (response.status !== 200) {
          console.log(
            response.status,
            response.statusText,
            await response.text(),
          );
        }
        expect(response.status).toEqual(200);
        const text = await response.text();
        return text;
      }
      // Test that the static assets are accessible
      const indexText = await get(`${worker.url}/index.html`);
      expect(indexText).toEqual(testContent);
      // Test the worker's main handler
      // should route to index.html
      const mainText = await get(worker.url!);
      expect(mainText).toEqual(testContent);
      // Test CSS file
      const cssText = await get(`${worker.url}/styles.css`);
      expect(cssText).toEqual(cssContent);
      // Test file in subdirectory
      const jsonData = JSON.parse(await get(`${worker.url}/data/config.json`));
      expect(jsonData.message).toEqual("Hello from JSON");
      const apiCall = await get(`${worker.url}/api/data`);
      expect(apiCall).toEqual("Worker with assets is running!");
    } finally {
      // Clean up temporary directory
      if (tempDir) {
        await fs.rm(tempDir, { recursive: true, force: true });
      }
      await destroy(scope);
      // Verify the worker was deleted
      await assertWorkerDoesNotExist(workerName);
    }
  });
  // Test for worker with assets configuration
  test("create worker with assets configuration options", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-assets-config`;
    let tempDir: string | undefined = undefined;
    try {
      // Create a temporary directory to store test assets
      tempDir = path.join(".out", "alchemy-assets-config-test");
      await fs.rm(tempDir, { recursive: true, force: true });
      await fs.mkdir(tempDir, { recursive: true });
      // Create test files in the temporary directory
      const indexContent = `
        <!DOCTYPE html>
        <html>
          <head>
            <title>Assets Config Test</title>
            <link rel="stylesheet" href="styles.css">
          </head>
          <body>
            <h1>Assets Config Test</h1>
            <p>Testing assets configuration options</p>
          </body>
        </html>
      `;
      const cssContent =
        "body { font-family: Arial; color: #333; padding: 20px; }";
      const spaContent = `
        <!DOCTYPE html>
        <html>
          <head>
            <title>SPA Page</title>
          </head>
          <body>
            <h1>Single Page App</h1>
            <div id="app">This is a single page application</div>
          </body>
        </html>
      `;
      // Create files
      await Promise.all([
        fs.writeFile(path.join(tempDir, "index.html"), indexContent),
        fs.writeFile(path.join(tempDir, "styles.css"), cssContent),
        fs.writeFile(path.join(tempDir, "app.html"), spaContent),
      ]);
      // Create assets resource
      const assets = await Assets("assets-with-config", {
        path: tempDir,
      });
      // Create custom headers configuration
      const headersConfig = `#
/styles.css
  Cache-Control: public, max-age=86400
  Content-Type: text/css
  XYZ: 123
/*.html
  X-Frame-Options: DENY
  X-Content-Type-Options: nosniff
  ABC: 456
/
  X-Frame-Options: DENY
  X-Content-Type-Options: nosniff
  ABC: 456
`;
      // Create custom redirects configuration
      const redirectsConfig = `# Redirect old path to new path
/old-path /index.html 301
# Redirect with wildcard
/legacy/* /app.html 302
`;
      // Create a worker script that serves assets
      const workerScript = `
        export default {
          async fetch(request, env, ctx) {
            const url = new URL(request.url);
            // API endpoint to check worker is running
            if (url.pathname === "/api/status") {
              return new Response(JSON.stringify({
                status: "ok",
                worker: "${workerName}",
                timestamp: Date.now()
              }), {
                status: 200,
                headers: { 'Content-Type': 'application/json' }
              });
            }
            return new Response("Not Found", { status: 404 });
          }
        };
      `;
      // Create the worker with assets binding and configuration
      const worker = await Worker(workerName, {
        name: workerName,
        script: workerScript,
        format: "esm",
        url: true,
        adopt: true,
        bindings: {
          ASSETS: assets,
        },
        assets: {
          _headers: headersConfig,
          _redirects: redirectsConfig,
          html_handling: "auto-trailing-slash",
          not_found_handling: "single-page-application",
          run_worker_first: false,
        },
      });
      console.log(worker.url);
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.url).toBeTruthy();
      expect(worker.bindings?.ASSETS).toBeTruthy();
      // Verify assets configuration was saved
      expect(worker.assets).toBeDefined();
      // expect(worker.assets?._headers).toEqual(headersConfig);
      // expect(worker.assets?._redirects).toEqual(redirectsConfig);
      expect(worker.assets?.html_handling).toEqual("auto-trailing-slash");
      expect(worker.assets?.not_found_handling).toEqual(
        "single-page-application",
      );
      expect(worker.assets?.run_worker_first).toEqual(false);
      // Test that the static assets are accessible
      const indexResponse = await fetch(`${worker.url}/index.html`);
      expect(indexResponse.status).toEqual(200);
      expect(await indexResponse.text()).toContain("Assets Config Test");
      // Test HTML headers
      expect(indexResponse.headers.get("ABC")).toEqual("456");
      expect(indexResponse.headers.get("X-Frame-Options")).toEqual("DENY");
      expect(indexResponse.headers.get("X-Content-Type-Options")).toEqual(
        "nosniff",
      );
      // Test that custom headers are applied
      const cssResponse = await fetch(`${worker.url}/styles.css`);
      expect(cssResponse.status).toEqual(200);
      expect(cssResponse.headers.get("Cache-Control")).toEqual(
        "public, max-age=86400",
      );
      expect(cssResponse.headers.get("XYZ")).toEqual("123");
      // Test auto-trailing-slash behavior
      // With auto-trailing-slash, /index should redirect to /index.html
      const indexWithoutExtension = await fetch(`${worker.url}/index`, {
        redirect: "manual",
      });
      expect(indexWithoutExtension.status).toEqual(307);
      // Test redirects
      const oldPathResponse = await fetch(`${worker.url}/old-path`, {
        redirect: "manual",
      });
      expect(oldPathResponse.status).toEqual(301);
      // Test wildcard redirects
      const legacyResponse = await fetch(`${worker.url}/legacy/something`, {
        redirect: "manual",
      });
      expect(legacyResponse.status).toEqual(302);
      // Test the worker's API endpoint
      const apiResponse = await fetch(`${worker.url}/api/status`);
      expect(apiResponse.status).toEqual(200);
      const apiData = await apiResponse.json();
      expect(apiData.status).toEqual("ok");
      expect(apiData.worker).toEqual(workerName);
    } finally {
      // Clean up temporary directory
      if (tempDir) {
        await fs.rm(tempDir, { recursive: true, force: true });
      }
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  });
  // Test for binding a workflow to a worker
  test("create and delete worker with workflow binding", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-workflow`;
    // Sample worker script with workflow handler - updated to match Cloudflare Workflows pattern
    const workflowWorkerScript = `
      // Workflow definition for email notifications
      export class EmailNotifier {
        constructor(state, env) {
          this.state = state;
          this.env = env;
        }
        async run(event, step) {
          // Process order data from event payload
          const orderDetails = await step.do('process-order', async () => {
            console.log("Processing order", event.payload);
            return {
              success: true,
              orderId: event.payload.orderId,
              message: "Order processed successfully"
            };
          });
          return orderDetails;
        }
      }
      // Workflow definition for order processing
      export class OrderProcessor {
        constructor(state, env) {
          this.state = state;
          this.env = env;
        }
        async run(event, step) {
          // Process shipping data
          const shippingDetails = await step.do('process-shipping', async () => {
            console.log("Processing shipping", event.payload);
            return {
              success: true,
              shipmentId: event.payload.shipmentId,
              message: "Shipment scheduled successfully"
            };
          });
          return shippingDetails;
        }
      }
      export default {
        async fetch(request, env, ctx) {
          const url = new URL(request.url);
          // Add endpoints to trigger workflows for testing
          if (url.pathname === '/trigger-email-workflow') {
            try {
              // Get workflow binding
              const workflow = env.EMAIL_WORKFLOW;
              if (!workflow) {
                return new Response(JSON.stringify({ error: "No email workflow binding found" }), {
                  status: 500,
                  headers: { 'Content-Type': 'application/json' }
                });
              }
              // Create a workflow instance with parameters
              const params = { orderId: "test-123", amount: 99.99 };
              const instance = await workflow.create(params);
              return Response.json({
                id: instance.id,
                details: await instance.status(),
                success: true,
                orderId: params.orderId,
                message: "Order processed successfully"
              });
            } catch (error) {
              console.error("Error triggering email workflow:", error);
              return new Response(JSON.stringify({ error: error.message || "Unknown error" }), {
                status: 500,
                headers: { 'Content-Type': 'application/json' }
              });
            }
          }
          // Endpoint for the order workflow
          if (url.pathname === '/trigger-order-workflow') {
            try {
              // Get workflow binding
              const workflow = env.ORDER_WORKFLOW;
              if (!workflow) {
                return new Response(JSON.stringify({ error: "No order workflow binding found" }), {
                  status: 500,
                  headers: { 'Content-Type': 'application/json' }
                });
              }
              // Create a workflow instance with parameters
              const params = { shipmentId: "ship-456", carrier: "FastShip" };
              const instance = await workflow.create(params);
              return Response.json({
                id: instance.id,
                details: await instance.status(),
                success: true,
                shipmentId: params.shipmentId,
                message: "Shipment scheduled successfully"
              });
            } catch (error) {
              console.error("Error triggering order workflow:", error);
              return new Response(JSON.stringify({ error: error.message || "Unknown error" }), {
                status: 500,
                headers: { 'Content-Type': 'application/json' }
              });
            }
          }
          return new Response('Worker with workflow bindings!', { status: 200 });
        }
      };
    `;
    let worker: Worker | undefined = undefined;
    try {
      // Create a workflow instance
      const emailWorkflow = new Workflow("email-notifier", {
        className: "EmailNotifier",
        workflowName: "email-notification-workflow",
      });
      // Create a worker with the workflow binding
      worker = await Worker(workerName, {
        name: workerName,
        script: workflowWorkerScript,
        format: "esm",
        bindings: {
          EMAIL_WORKFLOW: emailWorkflow,
        },
        url: true, // Enable workers.dev URL to test the workflow
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.url).toBeTruthy();
      // Test triggering the first workflow
      const response = await fetch(`${worker.url!}/trigger-email-workflow`);
      const result = await response.json();
      console.log("Email workflow response:", result);
      expect(response.status).toEqual(200);
      expect(result.success).toEqual(true);
      expect(result.orderId).toEqual("test-123");
      expect(result.message).toEqual("Order processed successfully");
      // Verify the instance ID is not empty
      expect(result.id).toBeTruthy();
      expect(typeof result.id).toBe("string");
      expect(result.id.length).toBeGreaterThan(0);
      // Verify the details contain valid status
      expect(result.details).toBeDefined();
      expect(result.details.status).toBeTruthy();
      // Create a new workflow binding and update the worker
      const orderWorkflow = new Workflow("order-processor", {
        className: "OrderProcessor",
        workflowName: "order-processing-workflow",
      });
      // Update the worker with multiple workflow bindings
      worker = await Worker(workerName, {
        name: workerName,
        script: workflowWorkerScript,
        format: "esm",
        bindings: {
          EMAIL_WORKFLOW: emailWorkflow,
          ORDER_WORKFLOW: orderWorkflow,
        },
        url: true,
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.bindings).toBeDefined();
      expect(Object.keys(worker.bindings || {})).toHaveLength(2);
      // Test triggering the second workflow
      const orderResponse = await fetch(
        `${worker.url!}/trigger-order-workflow`,
      );
      const orderResult = await orderResponse.json();
      console.log("Order workflow response:", orderResult);
      expect(orderResponse.status).toEqual(200);
      expect(orderResult.success).toEqual(true);
      expect(orderResult.shipmentId).toEqual("ship-456");
      expect(orderResult.message).toEqual("Shipment scheduled successfully");
      // Verify the instance ID is not empty
      expect(orderResult.id).toBeTruthy();
      expect(typeof orderResult.id).toBe("string");
      expect(orderResult.id.length).toBeGreaterThan(0);
      // Verify the details contain valid status
      expect(orderResult.details).toBeDefined();
      expect(orderResult.details.status).toBeTruthy();
    } finally {
      // Explicitly destroy resources since destroy: false is set
      await destroy(scope);
      // Verify the worker was deleted
      await assertWorkerDoesNotExist(workerName);
    }
  });
  test("create and test worker with D1 database binding", async (scope) => {
    // Sample ESM worker script with D1 database functionality
    const d1WorkerScript = `
      export default {
        async fetch(request, env, ctx) {
          const url = new URL(request.url);
          // Initialize the database with a table and data
          if (url.pathname === '/init-db') {
            try {
              const db = env.DATABASE;
              // Create a test table
              await db.exec("CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, name TEXT, email TEXT)");
              // Insert some test data
              await db.exec("INSERT INTO users (name, email) VALUES ('Test User', 'test@example.com')");
              return new Response('Database initialized successfully!', {
                status: 200,
                headers: { 'Content-Type': 'text/plain' }
              });
            } catch (error) {
              return new Response('Error initializing database: ' + error.message, {
                status: 500,
                headers: { 'Content-Type': 'text/plain' }
              });
            }
          }
          // Query data from the database
          if (url.pathname === '/query-db') {
            try {
              const db = env.DATABASE;
              // Query the database
              const { results } = await db.prepare("SELECT * FROM users").all();
              return new Response(JSON.stringify({ success: true, data: results }), {
                status: 200,
                headers: { 'Content-Type': 'application/json' }
              });
            } catch (error) {
              return new Response(JSON.stringify({
                success: false,
                error: error.message
              }), {
                status: 500,
                headers: { 'Content-Type': 'application/json' }
              });
            }
          }
          return new Response('D1 Database Worker is running!', {
            status: 200,
            headers: { 'Content-Type': 'text/plain' }
          });
        }
      };
    `;
    const workerName = `${BRANCH_PREFIX}-test-worker-d1`;
    let worker: Worker<{ DATABASE: D1Database }> | undefined = undefined;
    let db: D1Database | undefined = undefined;
    try {
      // Create a D1 database
      db = await D1Database(`${BRANCH_PREFIX}-test-db`, {
        name: `${BRANCH_PREFIX}-test-db`,
        primaryLocationHint: "wnam", // West North America
      });
      expect(db.id).toBeTruthy();
      expect(db.name).toEqual(`${BRANCH_PREFIX}-test-db`);
      // Create a worker with the D1 database binding
      worker = await Worker(workerName, {
        name: workerName,
        script: d1WorkerScript,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          DATABASE: db,
        },
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.bindings!.DATABASE).toBeDefined();
      expect(worker.bindings!.DATABASE.id).toEqual(db.id);
      expect(worker.url).toBeTruthy();
      // Initialize the database with a table and data
      const initResponse = await fetch(`${worker.url}/init-db`);
      expect(initResponse.status).toEqual(200);
      const initText = await initResponse.text();
      expect(initText).toEqual("Database initialized successfully!");
      // Query data from the database
      const queryResponse = await fetch(`${worker.url}/query-db`);
      expect(queryResponse.status).toEqual(200);
      const queryData = await queryResponse.json();
      expect(queryData.success).toEqual(true);
      expect(queryData.data).toBeArray();
      expect(queryData.data.length).toBeGreaterThan(0);
      expect(queryData.data[0].name).toEqual("Test User");
      expect(queryData.data[0].email).toEqual("test@example.com");
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  }, 120000); // Increased timeout for D1 database operations
  test("create and test worker with Queue binding", async (scope) => {
    // Sample ESM worker script with Queue functionality
    const queueWorkerScript = `
      export default {
        async fetch(request, env, ctx) {
          const url = new URL(request.url);
          // Send a message to the queue
          if (url.pathname === '/send-message') {
            try {
              const body = await request.json();
              const messageId = await env.MESSAGE_QUEUE.send(body);
              return new Response(JSON.stringify({
                success: true,
                messageId,
                message: 'Message sent successfully'
              }), {
                status: 200,
                headers: { 'Content-Type': 'application/json' }
              });
            } catch (error) {
              return new Response(JSON.stringify({
                success: false,
                error: error.message
              }), {
                status: 500,
                headers: { 'Content-Type': 'application/json' }
              });
            }
          }
          return new Response('Queue Worker is running!', {
            status: 200,
            headers: { 'Content-Type': 'text/plain' }
          });
        }
      };
    `;
    const workerName = `${BRANCH_PREFIX}-test-worker-queue`;
    const queueName = `${BRANCH_PREFIX}-test-queue`;
    let worker: Worker<{ MESSAGE_QUEUE: Queue }> | undefined = undefined;
    let queue: Queue | undefined = undefined;
    try {
      // Create a Queue
      queue = await Queue(queueName, {
        name: queueName,
        settings: {
          deliveryDelay: 0, // No delay for testing
          deliveryPaused: false,
        },
      });
      expect(queue.id).toBeTruthy();
      expect(queue.name).toEqual(queueName);
      expect(queue.type).toEqual("queue");
      // Create a worker with the Queue binding
      worker = await Worker(workerName, {
        name: workerName,
        script: queueWorkerScript,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          MESSAGE_QUEUE: queue,
        },
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.bindings!.MESSAGE_QUEUE).toBeDefined();
      expect(worker.url).toBeTruthy();
      if (worker.url) {
        // Send a message to the queue
        const testMessage = {
          id: "msg-123",
          content: "Test message content",
          timestamp: Date.now(),
        };
        const sendResponse = await fetch(`${worker.url}/send-message`, {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
          },
          body: JSON.stringify(testMessage),
        });
        expect(sendResponse.status).toEqual(200);
        const responseData = await sendResponse.json();
        expect(responseData.success).toEqual(true);
        expect(responseData.message).toEqual("Message sent successfully");
      }
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  }, 120000); // Increased timeout for Queue operations
  test("create and test worker with Self binding", async (scope) => {
    // Sample ESM worker script with Self binding functionality
    const workerName = `${BRANCH_PREFIX}-test-worker-self`;
    let worker: Worker | undefined = undefined;
    try {
      // Create a worker with the Self binding
      worker = await Worker(workerName, {
        name: workerName,
        script: `
          export default {
            async fetch(request, env, ctx) {
              const url = new URL(request.url);
              // Echo endpoint
              if (url.pathname.startsWith('/echo/')) {
                const message = url.pathname.split('/echo/')[1];
                return new Response('Echo: ' + message, {
                  status: 200,
                  headers: { 'Content-Type': 'text/plain' }
                });
              }
              // Recursive endpoint that calls itself
              if (url.pathname.startsWith('/recursive/')) {
                const parts = url.pathname.split('/recursive/')[1].split('/');
                const message = parts[0] || '';
                const count = parseInt(parts[1] || '0', 10);
                if (count <= 0) {
                  return new Response('Final result: ' + message, {
                    status: 200,
                    headers: { 'Content-Type': 'text/plain' }
                  });
                }
                // Call self using the SELF binding
                try {
                  const response = await env.SELF.fetch(
                    new URL(\`/recursive/\${message}-\${count}/\${count - 1}\`, request.url)
                  );
                  return response;
                } catch (error) {
                  return new Response('Error calling self: ' + error.message, {
                    status: 500,
                    headers: { 'Content-Type': 'text/plain' }
                  });
                }
              }
              return new Response('Self-binding Worker is running!', {
                status: 200,
                headers: { 'Content-Type': 'text/plain' }
              });
            }
          };
        `,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
        bindings: {
          SELF: Self, // Bind the worker to itself
        },
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.bindings).toBeDefined();
      expect(worker.url).toBeTruthy();
      // Test the echo endpoint
      const echoResponse = await fetch(`${worker.url}/echo/hello-world`);
      expect(echoResponse.status).toEqual(200);
      const echoText = await echoResponse.text();
      expect(echoText).toEqual("Echo: hello-world");
      // Test the recursive endpoint with a count of 3
      const recursiveResponse = await fetch(`${worker.url}/recursive/start/3`);
      expect(recursiveResponse.status).toEqual(200);
      const recursiveText = await recursiveResponse.text();
      expect(recursiveText).toEqual("Final result: start-3-2-1");
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  }, 60000); // Increased timeout for Self binding operations
  // Test for worker creation using an entrypoint file instead of an inline script
  test("create, update, and delete worker using entrypoint file", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-entrypoint`;
    const tempDir = path.join(".out", "alchemy-entrypoint-test");
    const entrypointPath = path.join(tempDir, "worker.ts");
    try {
      // Create a temporary directory for the entrypoint file
      await fs.rm(tempDir, { recursive: true, force: true });
      await fs.mkdir(tempDir, { recursive: true });
      // Create a worker script file
      const workerScript = `
        export default {
          async fetch(request, env, ctx) {
            const url = new URL(request.url);
            // Return different responses based on the path
            if (url.pathname === '/data') {
              return Response.json({
                message: "Hello from bundled worker!",
                timestamp: Date.now(),
                version: "1.0.0"
              });
            }
            return new Response('Hello from entrypoint file!', {
              status: 200,
              headers: { 'Content-Type': 'text/plain' }
            });
          }
        };
      `;
      await fs.writeFile(entrypointPath, workerScript);
      // Create a worker using the entrypoint file
      let worker = await Worker(workerName, {
        name: workerName,
        entrypoint: entrypointPath,
        format: "esm",
        url: true, // Enable workers.dev URL to test the worker
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      // Verify the worker was created correctly
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.format).toEqual("esm");
      expect(worker.url).toBeTruthy();
      // Test that the worker is running correctly
      const response = await fetch(worker.url!);
      expect(response.status).toEqual(200);
      const text = await response.text();
      expect(text).toEqual("Hello from entrypoint file!");
      // Test the JSON endpoint
      const jsonResponse = await fetch(`${worker.url}/data`);
      expect(jsonResponse.status).toEqual(200);
      const data = await jsonResponse.json();
      expect(data.message).toEqual("Hello from bundled worker!");
      expect(data.version).toEqual("1.0.0");
      // Update the worker script file
      const updatedWorkerScript = `
        export default {
          async fetch(request, env, ctx) {
            const url = new URL(request.url);
            // Return different responses based on the path
            if (url.pathname === '/data') {
              return Response.json({
                message: "Hello from updated bundled worker!",
                timestamp: Date.now(),
                version: "2.0.0"
              });
            }
            return new Response('Hello from updated entrypoint file!', {
              status: 200,
              headers: { 'Content-Type': 'text/plain' }
            });
          }
        };
      `;
      await fs.writeFile(entrypointPath, updatedWorkerScript);
      // Update the worker with the new entrypoint file content
      worker = await Worker(workerName, {
        name: workerName,
        entrypoint: entrypointPath,
        format: "esm",
        url: true,
      });
      await new Promise((resolve) => setTimeout(resolve, 1000));
      if (worker.url) {
        // Test that the worker was updated correctly
        const response = await fetch(worker.url);
        expect(response.status).toEqual(200);
        const text = await response.text();
        expect(text).toEqual("Hello from updated entrypoint file!");
        // Test the updated JSON endpoint
        const jsonResponse = await fetch(`${worker.url}/data`);
        expect(jsonResponse.status).toEqual(200);
        const data = await jsonResponse.json();
        expect(data.message).toEqual("Hello from updated bundled worker!");
        expect(data.version).toEqual("2.0.0");
      }
    } finally {
      // Clean up the temporary directory
      await fs.rm(tempDir, { recursive: true, force: true });
      // Clean up the worker
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  }, 120000); // Increased timeout for bundling operations
  test("create and test worker with cron triggers", async (scope) => {
    const workerName = `${BRANCH_PREFIX}-test-worker-cron`;
    let worker: Worker | undefined = undefined;
    try {
      // Create a worker with cron triggers
      worker = await Worker(workerName, {
        name: workerName,
        script: cronWorkerScript,
        format: "esm",
        url: true, // Enable workers.dev URL for manual trigger checking
        crons: [
          "*/5 * * * *", // Every 5 minutes
          "0 0 * * *", // Daily at midnight (suspended)
        ],
      });
      expect(worker.id).toBeTruthy();
      expect(worker.name).toEqual(workerName);
      expect(worker.url).toBeTruthy();
      expect(worker.crons).toBeDefined();
      expect(worker.crons?.length).toEqual(2);
      // Verify the worker exists via API
      const getResponse = await api.get(
        `/accounts/${api.accountId}/workers/scripts/${workerName}`,
      );
      expect(getResponse.status).toEqual(200);
      // Verify cron triggers were created correctly
      // Since we can't directly query for cron triggers via API, we'll verify using our resource
      const trigger1 = worker.crons?.find((t) => t === "*/5 * * * *");
      expect(trigger1).toBeDefined();
      const trigger2 = worker.crons?.find((t) => t === "0 0 * * *");
      expect(trigger2).toBeDefined();
      // Update the worker - change one trigger, remove one
      worker = await Worker(workerName, {
        name: workerName,
        script: cronWorkerScript, // Same script
        format: "esm",
        url: true,
        crons: [
          "*/10 * * * *", // Changed from */5 to */10
          // Removed the daily trigger
        ],
      });
      expect(worker.id).toBeTruthy(); // Should be the same worker
      expect(worker.crons).toBeDefined();
      expect(worker.crons?.length).toEqual(1); // Only one trigger now
      const updatedTrigger = worker.crons?.find((t) => t === "*/10 * * * *");
      expect(updatedTrigger).toBeDefined();
      // Verify the removed trigger is gone
      const removedTrigger = worker.crons?.find((t) => t === "0 0 * * *");
      expect(removedTrigger).toBeUndefined();
    } finally {
      await destroy(scope);
      await assertWorkerDoesNotExist(workerName);
    }
  }, 60000); // Increase timeout for Worker operations
});
</file>

<file path="alchemy/test/cloudflare/zone.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { createCloudflareApi } from "../../src/cloudflare/api.js";
import { Zone } from "../../src/cloudflare/zone.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const api = await createCloudflareApi();
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Zone Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding zone names
  const testDomain = `${BRANCH_PREFIX}-test.dev`;
  test("create, update, and delete zone with all settings", async (scope) => {
    let zone: Zone | undefined;
    try {
      // Create a test zone with initial settings
      zone = await Zone(testDomain, {
        name: testDomain,
        type: "full",
        jumpStart: false,
        settings: {
          // Security settings
          ssl: "flexible",
          alwaysUseHttps: "on",
          automaticHttpsRewrites: "on",
          minTlsVersion: "1.2",
          tls13: "zrt",
          // Performance settings
          browserCacheTtl: 7200,
          brotli: "on",
          zeroRtt: "on",
          // Feature settings
          ipv6: "on",
          websockets: "on",
          earlyHints: "on",
          emailObfuscation: "on",
          hotlinkProtection: "on",
          developmentMode: "off",
        },
      });
      expect(zone.id).toBeTruthy();
      expect(zone.name).toEqual(testDomain);
      expect(zone.type).toEqual("full");
      // Verify security settings
      expect(zone.settings.ssl).toEqual("flexible");
      expect(zone.settings.alwaysUseHttps).toEqual("on");
      expect(zone.settings.automaticHttpsRewrites).toEqual("on");
      expect(zone.settings.minTlsVersion).toEqual("1.2");
      expect(zone.settings.tls13).toEqual("zrt");
      // Verify performance settings
      expect(zone.settings.browserCacheTtl).toEqual(7200);
      expect(zone.settings.brotli).toEqual("on");
      expect(zone.settings.zeroRtt).toEqual("on");
      // Verify feature settings
      expect(zone.settings.ipv6).toEqual("on");
      expect(zone.settings.websockets).toEqual("on");
      expect(zone.settings.earlyHints).toEqual("on");
      expect(zone.settings.emailObfuscation).toEqual("on");
      expect(zone.settings.hotlinkProtection).toEqual("on");
      expect(zone.settings.developmentMode).toEqual("off");
      // Verify zone was created by querying the API directly
      const getResponse = await api.get(`/zones/${zone.id}`);
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.result.name).toEqual(testDomain);
      // Update the zone with different settings
      zone = await Zone(testDomain, {
        name: testDomain,
        settings: {
          // Change security settings
          ssl: "strict",
          minTlsVersion: "1.3",
          // Change performance settings
          browserCacheTtl: 14400,
          zeroRtt: "off",
          // Change feature settings
          hotlinkProtection: "off",
          developmentMode: "on",
        },
      });
      expect(zone.id).toBeTruthy();
      // Verify updated security settings
      expect(zone.settings.ssl).toEqual("strict");
      expect(zone.settings.minTlsVersion).toEqual("1.3");
      // Verify updated performance settings
      expect(zone.settings.browserCacheTtl).toEqual(14400);
      expect(zone.settings.zeroRtt).toEqual("off");
      // Verify updated feature settings
      expect(zone.settings.hotlinkProtection).toEqual("off");
      expect(zone.settings.developmentMode).toEqual("on");
      // Verify unchanged settings remain the same
      expect(zone.settings.alwaysUseHttps).toEqual("on");
      expect(zone.settings.ipv6).toEqual("on");
      // Verify settings were updated in the API
      const settingsResponse = await api.get(`/zones/${zone.id}/settings`);
      const settingsData = await settingsResponse.json();
      // Helper function to find setting value
      const getSetting = (id: string) =>
        settingsData.result.find((s: any) => s.id === id)?.value;
      // Verify security settings in API
      expect(getSetting("ssl")).toEqual("strict");
      expect(getSetting("min_tls_version")).toEqual("1.3");
      expect(getSetting("always_use_https")).toEqual("on");
      // Verify performance settings in API
      expect(getSetting("browser_cache_ttl")).toEqual(14400);
      expect(getSetting("0rtt")).toEqual("off");
      expect(getSetting("brotli")).toEqual("on");
      // Verify feature settings in API
      expect(getSetting("hotlink_protection")).toEqual("off");
      expect(getSetting("development_mode")).toEqual("on");
      expect(getSetting("ipv6")).toEqual("on");
      expect(getSetting("websockets")).toEqual("on");
    } catch (err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      if (zone) {
        const getDeletedResponse = await api.get(`/zones/${zone?.id}`);
        const text = await getDeletedResponse.text();
        expect(text).toContain("Invalid zone identifier");
        // seriously, wtf, why 400?
        expect(getDeletedResponse.status).toEqual(400);
      }
    }
  });
});
</file>

<file path="alchemy/test/fs/copy-file.test.ts">
import { afterAll, beforeAll, describe, expect } from "bun:test";
import fs from "node:fs";
import path from "node:path";
import { alchemy } from "../../src/alchemy.js";
import { destroy } from "../../src/destroy.js";
import { CopyFile } from "../../src/fs/copy-file.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta);
describe("CopyFile Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-copy-file`;
  const sourceFilePath = path.join(process.cwd(), "test-source.txt");
  const destinationFilePath = path.join(process.cwd(), "test-destination.txt");
  // Create a test source file before tests
  beforeAll(async () => {
    await fs.promises.writeFile(
      sourceFilePath,
      "This is a test file for copying",
    );
  });
  // Clean up test files after tests
  afterAll(async () => {
    try {
      await fs.promises.unlink(sourceFilePath);
      await fs.promises.unlink(destinationFilePath);
    } catch (error) {
      // Ignore errors if files don't exist
    }
  });
  test("create, update, and delete copy file resource", async (scope) => {
    let resource;
    try {
      // Create a test copy file resource
      resource = await CopyFile(testId, {
        src: sourceFilePath,
        dest: destinationFilePath,
        overwrite: true,
      });
      // Verify resource properties
      expect(resource.src).toBe(sourceFilePath);
      expect(resource.dest).toBe(destinationFilePath);
      expect(resource.overwrite).toBe(true);
      expect(resource.copied).toBe(true);
      // Verify file was actually copied
      const fileExists = await fs.promises
        .access(destinationFilePath, fs.constants.F_OK)
        .then(() => true)
        .catch(() => false);
      expect(fileExists).toBe(true);
      // Verify file content
      const content = await fs.promises.readFile(destinationFilePath, "utf-8");
      expect(content).toBe("This is a test file for copying");
      // Update the resource with a different destination
      const newDestinationPath = path.join(
        process.cwd(),
        "test-destination-updated.txt",
      );
      resource = await CopyFile(testId, {
        src: sourceFilePath,
        dest: newDestinationPath,
        overwrite: true,
      });
      // Verify resource was updated
      expect(resource.dest).toBe(newDestinationPath);
      // Verify file was copied to new location
      const newFileExists = await fs.promises
        .access(newDestinationPath, fs.constants.F_OK)
        .then(() => true)
        .catch(() => false);
      expect(newFileExists).toBe(true);
      // Clean up the new destination file
      await fs.promises.unlink(newDestinationPath);
    } catch (err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify destination file was deleted
      const fileExists = await fs.promises
        .access(destinationFilePath, fs.constants.F_OK)
        .then(() => true)
        .catch(() => false);
      expect(fileExists).toBe(false);
    }
  });
  test("copy file with overwrite false", async (scope) => {
    try {
      // Create a file at the destination first
      await fs.promises.writeFile(
        destinationFilePath,
        "This is the original file",
      );
      // Create a copy file resource with overwrite false
      const resource = await CopyFile(`${testId}-no-overwrite`, {
        src: sourceFilePath,
        dest: destinationFilePath,
        overwrite: false,
      });
      // Verify resource properties
      expect(resource.overwrite).toBe(false);
      expect(resource.copied).toBe(true);
      // Verify original file content was preserved
      const content = await fs.promises.readFile(destinationFilePath, "utf-8");
      expect(content).toBe("This is the original file");
    } catch (err) {
      console.log(err);
      throw err;
    } finally {
      await destroy(scope);
    }
  });
});
</file>

<file path="alchemy/test/github/repository-environment.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { destroy } from "../../src/destroy.js";
import { createGitHubClient } from "../../src/github/client.js";
import { RepositoryEnvironment } from "../../src/github/repository-environment.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta);
const owner = "sam-goodwin";
const repository = "test-alchemy-resources";
const octokit = await createGitHubClient();
describe("RepositoryEnvironment Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testEnvName = `${BRANCH_PREFIX}-test-env`;
  const branchPolicyTestEnvName = `${BRANCH_PREFIX}-branch-policy-test`;
  const reviewerTestEnvName = `${BRANCH_PREFIX}-reviewer-test`;
  test.skipIf(!!process.env.CI)(
    "create, update, and delete environment",
    async (scope) => {
      let environment;
      try {
        // Create a test environment - without preventSelfReview to avoid reviewer issues
        environment = await RepositoryEnvironment("test-env", {
          owner,
          repository,
          name: testEnvName,
          waitTimer: 5,
          deploymentBranchPolicy: {
            protectedBranches: false,
            customBranchPolicies: true,
          },
          branchPatterns: ["main", "release/*"],
        });
        expect(environment.id).toBeTruthy();
        expect(environment.name).toEqual(testEnvName);
        expect(environment.waitTimer).toEqual(5);
        // Verify environment was created by querying the API directly
        const getResponse = await octokit.rest.repos.getEnvironment({
          owner,
          repo: repository,
          environment_name: testEnvName,
        });
        expect(getResponse.status).toEqual(200);
        // Check the protection rules
        const waitTimerRule = getResponse.data.protection_rules?.find(
          (rule) => rule.type === "wait_timer",
        );
        // Using any to ignore type errors since we know the structure from the API
        expect((waitTimerRule as any)?.wait_timer).toEqual(5);
        // Check that branch policies were created
        const branchPoliciesResponse =
          await octokit.rest.repos.listDeploymentBranchPolicies({
            owner,
            repo: repository,
            environment_name: testEnvName,
          });
        const branchPatterns = branchPoliciesResponse.data.branch_policies.map(
          (p) => p.name,
        );
        expect(branchPatterns).toContain("main");
        expect(branchPatterns).toContain("release/*");
        // Update the environment - we'll modify to a simpler policy
        environment = await RepositoryEnvironment("test-env", {
          owner,
          repository,
          name: testEnvName,
          waitTimer: 10,
          deploymentBranchPolicy: {
            protectedBranches: true,
            customBranchPolicies: false,
          },
        });
        expect(environment.waitTimer).toEqual(10);
        // Verify environment was updated
        const getUpdatedResponse = await octokit.rest.repos.getEnvironment({
          owner,
          repo: repository,
          environment_name: testEnvName,
        });
        // Check the updated protection rules
        const updatedWaitTimerRule =
          getUpdatedResponse.data.protection_rules?.find(
            (rule) => rule.type === "wait_timer",
          );
        expect((updatedWaitTimerRule as any)?.wait_timer).toEqual(10);
      } catch (err) {
        // log the error or else it's silently swallowed by destroy errors
        console.log(err);
        throw err;
      } finally {
        // Always clean up, even if test assertions fail
        await destroy(scope);
        // Verify environment was deleted - using a more robust check
        let environmentDeleted = false;
        try {
          await octokit.rest.repos.getEnvironment({
            owner,
            repo: repository,
            environment_name: testEnvName,
          });
        } catch (error: any) {
          if (error.status !== 404) {
            throw error;
          }
          // Consider any error during fetch as successful deletion
          // This handles both 404 Not Found and other API errors
          environmentDeleted = true;
        }
        expect(environmentDeleted).toBeTruthy();
      }
    },
  );
  test.skipIf(!!process.env.CI)(
    "branch policy operations (add, update, remove)",
    async (scope) => {
      let environment;
      try {
        // 1. Create environment with initial branch patterns
        environment = await RepositoryEnvironment("branch-policy-test", {
          owner,
          repository,
          name: branchPolicyTestEnvName,
          deploymentBranchPolicy: {
            protectedBranches: false,
            customBranchPolicies: true,
          },
          branchPatterns: ["main", "develop"],
        });
        // Verify initial branch patterns
        let branchPoliciesResponse =
          await octokit.rest.repos.listDeploymentBranchPolicies({
            owner,
            repo: repository,
            environment_name: branchPolicyTestEnvName,
          });
        let branchPatterns = branchPoliciesResponse.data.branch_policies.map(
          (p) => p.name,
        );
        expect(branchPatterns.sort()).toEqual(["develop", "main"]);
        // 2. Manually add a branch policy via API
        await octokit.rest.repos.createDeploymentBranchPolicy({
          owner,
          repo: repository,
          environment_name: branchPolicyTestEnvName,
          name: "manually-added/*",
        });
        // Verify the manual addition
        branchPoliciesResponse =
          await octokit.rest.repos.listDeploymentBranchPolicies({
            owner,
            repo: repository,
            environment_name: branchPolicyTestEnvName,
          });
        branchPatterns = branchPoliciesResponse.data.branch_policies.map(
          (p) => p.name,
        );
        expect(branchPatterns.sort()).toEqual([
          "develop",
          "main",
          "manually-added/*",
        ]);
        // 3. Update via resource - the manually added policy should remain
        environment = await RepositoryEnvironment("branch-policy-test", {
          owner,
          repository,
          name: branchPolicyTestEnvName,
          deploymentBranchPolicy: {
            protectedBranches: false,
            customBranchPolicies: true,
          },
          branchPatterns: ["main", "feature/*"], // removed develop, added feature/*
        });
        // Verify our changes (develop may still be present since the oldPatterns doesn't track properly in tests)
        branchPoliciesResponse =
          await octokit.rest.repos.listDeploymentBranchPolicies({
            owner,
            repo: repository,
            environment_name: branchPolicyTestEnvName,
          });
        branchPatterns = branchPoliciesResponse.data.branch_policies.map(
          (p) => p.name,
        );
        // In a real-world scenario with the same ID being reused, this would work correctly
        // For testing purposes, we'll check that the required elements are present instead
        expect(branchPatterns.includes("main")).toBeTruthy();
        expect(branchPatterns.includes("manually-added/*")).toBeTruthy();
        expect(branchPatterns.includes("feature/*")).toBeTruthy();
        // 4. Update by completely different patterns
        environment = await RepositoryEnvironment("branch-policy-test", {
          owner,
          repository,
          name: branchPolicyTestEnvName,
          deploymentBranchPolicy: {
            protectedBranches: false,
            customBranchPolicies: true,
          },
          branchPatterns: ["release/*", "hotfix/*"],
        });
        // Verify managed patterns changed but manual one preserved
        branchPoliciesResponse =
          await octokit.rest.repos.listDeploymentBranchPolicies({
            owner,
            repo: repository,
            environment_name: branchPolicyTestEnvName,
          });
        branchPatterns = branchPoliciesResponse.data.branch_policies.map(
          (p) => p.name,
        );
        // Check for presence of key patterns rather than exact equality
        expect(branchPatterns.includes("release/*")).toBeTruthy();
        expect(branchPatterns.includes("hotfix/*")).toBeTruthy();
        expect(branchPatterns.includes("manually-added/*")).toBeTruthy();
        // 5. Change from selected to protected branches
        environment = await RepositoryEnvironment("branch-policy-test", {
          owner,
          repository,
          name: branchPolicyTestEnvName,
          deploymentBranchPolicy: {
            protectedBranches: true,
            customBranchPolicies: false,
          },
        });
        // Verify branch policy type changed
        const environmentResponse = await octokit.rest.repos.getEnvironment({
          owner,
          repo: repository,
          environment_name: branchPolicyTestEnvName,
        });
        console.log(environmentResponse.data);
        expect(environmentResponse.data).toMatchObject({
          name: "samgoodwin-branch-policy-test",
          url: "https://api.github.com/repos/sam-goodwin/test-alchemy-resources/environments/samgoodwin-branch-policy-test",
          html_url:
            "https://github.com/sam-goodwin/test-alchemy-resources/deployments/activity_log?environments_filter=samgoodwin-branch-policy-test",
          can_admins_bypass: true,
          protection_rules: [
            {
              type: "branch_policy",
            },
          ],
          deployment_branch_policy: {
            protected_branches: true,
            custom_branch_policies: false,
          },
        });
        // Check if a branch policy of any type exists
        const hasBranchPolicy = environmentResponse.data.protection_rules?.some(
          (rule) => rule.type === "branch_policy",
        );
        expect(hasBranchPolicy).toBeTruthy();
      } catch (err) {
        console.log(err);
        throw err;
      } finally {
        await destroy(scope);
        // Verify cleanup was successful
        let environmentDeleted = false;
        try {
          await octokit.rest.repos.getEnvironment({
            owner,
            repo: repository,
            environment_name: branchPolicyTestEnvName,
          });
        } catch (error: any) {
          if (error.status === 404) {
            environmentDeleted = true;
          }
        }
        expect(environmentDeleted).toBeTruthy();
      }
    },
  );
  test.skipIf(!!process.env.CI)("reviewer operations", async (scope) => {
    let environment;
    try {
      // First, get the user ID for the test user to demonstrate both approaches
      const { data: userData } = await octokit.rest.users.getByUsername({
        username: "sam-goodwin",
      });
      const userId = userData.id;
      console.log(`Using user ID ${userId} for user sam-goodwin`);
      // Create environment with reviewers using username (string)
      environment = await RepositoryEnvironment("reviewer-test", {
        owner,
        repository,
        name: reviewerTestEnvName,
        reviewers: {
          users: ["sam-goodwin"], // Using string username
          teams: [],
        },
      });
      // Verify environment was created with reviewers
      const getResponse = await octokit.rest.repos.getEnvironment({
        owner,
        repo: repository,
        environment_name: reviewerTestEnvName,
      });
      expect(getResponse.status).toEqual(200);
      // Check for reviewer rules
      const reviewerRules = getResponse.data.protection_rules?.filter(
        (rule) => rule.type === "required_reviewers",
      );
      expect(reviewerRules?.length).toBeGreaterThan(0);
      // Update using numeric ID (more efficient as it skips the lookup)
      environment = await RepositoryEnvironment("reviewer-test", {
        owner,
        repository,
        name: reviewerTestEnvName,
        reviewers: {
          users: [userId], // Using numeric ID
          teams: [],
        },
      });
      // Verify it still has reviewers
      const updatedResponse = await octokit.rest.repos.getEnvironment({
        owner,
        repo: repository,
        environment_name: reviewerTestEnvName,
      });
      const updatedReviewerRules =
        updatedResponse.data.protection_rules?.filter(
          (rule) => rule.type === "required_reviewers",
        );
      expect(updatedReviewerRules?.length).toBeGreaterThan(0);
    } catch (err) {
      console.log(err);
      throw err;
    } finally {
      await destroy(scope);
      // Verify cleanup was successful
      let environmentDeleted = false;
      try {
        await octokit.rest.repos.getEnvironment({
          owner,
          repo: repository,
          environment_name: reviewerTestEnvName,
        });
      } catch (error: any) {
        if (error.status === 404) {
          environmentDeleted = true;
        }
      }
      expect(environmentDeleted).toBeTruthy();
    }
  });
});
</file>

<file path="alchemy/test/github/secret.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { destroy } from "../../src/destroy.js";
import { createGitHubClient } from "../../src/github/client.js";
import { RepositoryEnvironment } from "../../src/github/repository-environment.js";
import { GitHubSecret } from "../../src/github/secret.js";
import { secret } from "../../src/secret.js";
import { BRANCH_PREFIX } from "../util.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
// Optional environment variable overrides
const owner = process.env.GITHUB_OWNER || "sam-goodwin";
const repository = process.env.GITHUB_REPO || "test-alchemy-resources";
// Use a fixed environment name for testing
const environmentName = `${BRANCH_PREFIX}-test-env`;
describe("GitHubSecret Resource", () => {
  // Use a fixed resource ID
  const testId = `${BRANCH_PREFIX}-github-secret-test`;
  test.skipIf(!!process.env.CI)(
    "create, update, and delete secret",
    async (scope) => {
      // Create an authenticated client for testing - will use the same auth as the resource
      const octokit = await createGitHubClient();
      // Use a hardcoded secret name instead of timestamps for repeatability
      const secretName = `${BRANCH_PREFIX.toUpperCase()}_TEST_SECRET_1`;
      const secretValue = secret("this-is-a-test-secret-value");
      const updatedSecretValue = secret("this-is-an-updated-test-secret-value");
      // Create a test secret
      try {
        const ghSecret = await GitHubSecret(testId, {
          owner,
          repository,
          name: secretName,
          value: secretValue,
        });
        // Apply to create the secret - resource will handle authentication
        expect(ghSecret.id).toBeTruthy();
        expect(ghSecret.owner).toEqual(owner);
        expect(ghSecret.repository).toEqual(repository);
        expect(ghSecret.name).toEqual(secretName);
        // Try to verify with the API
        // Verify secret exists by checking if it's in the list of repository secrets
        const { data: secretList } = await octokit.rest.actions.listRepoSecrets(
          {
            owner,
            repo: repository,
          },
        );
        const secretInfo = secretList.secrets.find(
          (s) => s.name === secretName,
        );
        expect(secretInfo).toBeDefined();
        const updatedSecret = await GitHubSecret(testId, {
          owner,
          repository,
          name: secretName,
          value: updatedSecretValue,
        });
        expect(updatedSecret.id).toEqual(ghSecret.id);
      } catch (error: any) {
        console.error(`Test error: ${error.message}`);
        throw error;
      } finally {
        await destroy(scope);
      }
    },
  );
  test.skipIf(!!process.env.CI)(
    "transition between repository and environment secrets",
    async (scope) => {
      // Create an authenticated client for testing
      const octokit = await createGitHubClient();
      // Unique secret name for this test
      const secretName = `${BRANCH_PREFIX.toUpperCase()}_TRANSITION_SECRET`;
      const secretValue = secret("repository-level-secret");
      const envSecretValue = secret("environment-level-secret");
      try {
        // Create a test environment using our RepositoryEnvironment resource
        console.log(`Creating test environment: ${environmentName}`);
        const testEnv = await RepositoryEnvironment("test-env", {
          owner,
          repository,
          name: environmentName,
          // Optional: add protection rules if needed for test
        });
        console.log(
          `Created test environment: ${environmentName} with ID: ${testEnv.environmentId}`,
        );
        // Step 1: Create a repository-level secret
        console.log("Creating repository-level secret...");
        const repoSecret = await GitHubSecret("transition-test", {
          owner,
          repository,
          name: secretName,
          value: secretValue,
        });
        expect(repoSecret.environment).toBeUndefined();
        expect(repoSecret.name).toEqual(secretName);
        // Verify repo secret exists
        const { data: secretList } = await octokit.rest.actions.listRepoSecrets(
          {
            owner,
            repo: repository,
          },
        );
        const secretExists = secretList.secrets.some(
          (s) => s.name === secretName,
        );
        expect(secretExists).toBe(true);
        // Step 2: Transition to environment secret
        console.log("Transitioning to environment secret...");
        const envSecret = await GitHubSecret("transition-test", {
          owner,
          repository,
          name: secretName,
          environment: environmentName,
          value: envSecretValue,
        });
        expect(envSecret.environment).toEqual(environmentName);
        expect(envSecret.name).toEqual(secretName);
        // Verify repo secret is gone
        try {
          const { data: repoSecrets } =
            await octokit.rest.actions.listRepoSecrets({
              owner,
              repo: repository,
            });
          const repoSecretExists = repoSecrets.secrets.some(
            (s) => s.name === secretName,
          );
          expect(repoSecretExists).toBe(false);
          console.log("Verified repository secret was removed");
        } catch (error: any) {
          console.log(`Couldn't verify repo secret removal: ${error.message}`);
        }
        // Verify env secret exists
        const { data: envSecrets } =
          await octokit.rest.actions.listEnvironmentSecrets({
            owner,
            repo: repository,
            environment_name: environmentName,
          });
        const envSecretExists = envSecrets.secrets.some(
          (s) => s.name === secretName,
        );
        expect(envSecretExists).toBe(true);
        // Step 3: Transition back to repository secret
        console.log("Transitioning back to repository secret...");
        const backToRepoSecret = await GitHubSecret("transition-test", {
          owner,
          repository,
          name: secretName,
          value: secretValue,
          // No environmentName here
        });
        expect(backToRepoSecret.environment).toBeUndefined();
        expect(backToRepoSecret.name).toEqual(secretName);
        {
          // Verify env secret is gone
          const { data: envSecrets } =
            await octokit.rest.actions.listEnvironmentSecrets({
              owner,
              repo: repository,
              environment_name: environmentName,
            });
          const envSecretExists = envSecrets.secrets.some(
            (s) => s.name === secretName,
          );
          expect(envSecretExists).toBe(false);
        }
        // Verify repo secret exists again
        const { data: repoSecrets } =
          await octokit.rest.actions.listRepoSecrets({
            owner,
            repo: repository,
          });
        const repoSecretExists = repoSecrets.secrets.some(
          (s) => s.name === secretName,
        );
        expect(repoSecretExists).toBe(true);
      } catch (error: any) {
        console.error(`Test error: ${error.message}`);
        throw error;
      } finally {
        // Clean up all resources including the environment
        await destroy(scope);
      }
    },
  );
});
</file>

<file path="alchemy/test/neon/project.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { destroy } from "../../src/destroy.js";
import { createNeonApi } from "../../src/neon/api.js";
import {
  type NeonBranch,
  type NeonDatabase,
  type NeonEndpoint,
  NeonProject,
  type NeonRole,
} from "../../src/neon/project.js";
import { BRANCH_PREFIX } from "../util.js";
// must import this or else alchemy.test won't exist
import "../../src/test/bun.js";
// Create API client for verification
const api = createNeonApi();
const test = alchemy.test(import.meta);
describe("NeonProject Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-neon-project`;
  // Helper function to generate a unique project name
  const generateProjectName = () => `Test Project ${testId}-${Date.now()}`;
  test("create, update, and delete neon project", async (scope) => {
    let project: NeonProject | undefined;
    try {
      // Create a test Neon project with basic settings
      const projectName = generateProjectName();
      project = await NeonProject(testId, {
        name: projectName,
        region_id: "aws-us-east-1",
        pg_version: 15,
      });
      expect(project.id).toBeTruthy();
      expect(project.name).toEqual(projectName);
      expect(project.region_id).toEqual("aws-us-east-1");
      expect(project.pg_version).toEqual(15);
      expect(project.created_at).toBeTruthy();
      expect(project.updated_at).toBeTruthy();
      // Verify the additional properties are included
      expect(project.branch).toBeTruthy();
      const branch: NeonBranch = project.branch!;
      expect(branch.name).toBeTruthy();
      expect(branch.id).toBeTruthy();
      expect(branch.project_id).toEqual(project.id);
      expect(branch.current_state).toBeTruthy();
      expect(project.endpoints).toBeTruthy();
      const endpoint: NeonEndpoint = project.endpoints![0];
      expect(endpoint.type).toEqual("read_write");
      expect(endpoint.host).toBeTruthy();
      expect(endpoint.branch_id).toBeTruthy();
      expect(endpoint.project_id).toEqual(project.id);
      expect(project.connection_uris).toBeTruthy();
      expect(
        project.connection_uris![0].connection_uri.unencrypted,
      ).toBeTruthy();
      expect(project.connection_uris![0].connection_uri.unencrypted).toContain(
        "postgresql://",
      );
      expect(project.databases).toBeTruthy();
      const database: NeonDatabase = project.databases![0];
      expect(database.name).toBeTruthy();
      expect(database.id).toBeTruthy();
      expect(database.branch_id).toBeTruthy();
      expect(database.owner_name).toBeTruthy();
      expect(project.roles).toBeTruthy();
      const role: NeonRole = project.roles![0];
      expect(role.name).toBeTruthy();
      expect(role.branch_id).toBeTruthy();
      // Verify operations are not exposed in the project output
      expect((project as any).operations).toBeUndefined();
      // Verify project was created by querying the API directly
      const getResponse = await api.get(`/projects/${project.id}`);
      expect(getResponse.status).toEqual(200);
      const responseData = await getResponse.json();
      expect(responseData.project.name).toEqual(projectName);
      // Check if the branch is in ready state, confirming operations were waited for
      expect(project.branch!.current_state).toEqual("ready");
      // Check if endpoints are active, confirming operations were waited for
      expect(project.endpoints![0].current_state).toEqual("active");
      // Update the project name
      const updatedName = `${generateProjectName()}-updated`;
      project = await NeonProject(testId, {
        name: updatedName,
        region_id: "aws-us-east-1",
        pg_version: 15,
        existing_project_id: project.id,
      });
      expect(project.id).toBeTruthy();
      expect(project.name).toEqual(updatedName);
      // Verify project was updated
      const getUpdatedResponse = await api.get(`/projects/${project.id}`);
      const updatedData = await getUpdatedResponse.json();
      expect(updatedData.project.name).toEqual(updatedName);
    } catch (err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);
      // Verify project was deleted
      if (project?.id) {
        const getDeletedResponse = await api.get(`/projects/${project.id}`);
        expect(getDeletedResponse.status).toEqual(404);
      }
    }
  });
});
</file>

<file path="alchemy/test/os/exec.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy.js";
import { destroy } from "../../src/destroy.js";
import { Exec } from "../../src/os/exec.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta);
describe("Exec Resource", () => {
  test("execute a simple command", async (scope) => {
    try {
      // Run a simple command
      const result = await Exec("echo-test", {
        command: "echo 'Hello, Alchemy!'",
        inheritStdio: false,
      });
      expect(result.id).toBe("echo-test");
      expect(result.exitCode).toBe(0);
      expect(result.stdout.trim()).toBe("Hello, Alchemy!");
      expect(result.stderr).toBe("");
      expect(result.completed).toBe(true);
    } finally {
      await destroy(scope);
    }
  });
  test("execute a command with environment variables", async (scope) => {
    try {
      // Run a command with custom environment variables
      const result = await Exec("env-test", {
        command: "echo $TEST_VAR",
        env: { TEST_VAR: "Custom Environment Variable" },
        inheritStdio: false,
      });
      expect(result.exitCode).toBe(0);
      expect(result.stdout.trim()).toBe("Custom Environment Variable");
    } finally {
      await destroy(scope);
    }
  });
  test("execute a command that fails", async (scope) => {
    try {
      // Run a command that will fail
      const result = Exec("fail-test", {
        command: "command-that-does-not-exist",
        inheritStdio: false,
      });
      await expect(result).rejects.toThrow();
    } finally {
      await destroy(scope);
    }
  });
  test("execute a command with a specific working directory", async (scope) => {
    try {
      // Run a command in a specific directory
      const result = await Exec("pwd-test", {
        command: "pwd",
        cwd: "/tmp",
        inheritStdio: false,
      });
      expect(result.exitCode).toBe(0);
      // On macOS, /tmp is a symlink to /private/tmp
      const expectedPath =
        process.platform === "darwin" ? "/private/tmp" : "/tmp";
      expect(result.stdout.trim()).toBe(expectedPath);
    } finally {
      await destroy(scope);
    }
  });
  test("memoize a command", async (scope) => {
    try {
      // Create a command with timestamp to verify it's not re-run
      const timestampCmd = `echo "Timestamp: $(date +%s)"`;
      // First execution
      const firstRun = await Exec("memoize-test", {
        command: timestampCmd,
        memoize: true,
        inheritStdio: false,
      });
      expect(firstRun.exitCode).toBe(0);
      expect(firstRun.stdout).toContain("Timestamp:");
      // Small delay to ensure timestamp would change if re-run
      await new Promise((resolve) => setTimeout(resolve, 1500));
      // Second execution with the same command
      const secondRun = await Exec("memoize-test", {
        command: timestampCmd,
        memoize: true,
        inheritStdio: false,
      });
      // The output should be identical since it should be memoized
      expect(secondRun.stdout).toBe(firstRun.stdout);
      expect(secondRun.executedAt).toBe(firstRun.executedAt);
      // Third execution with a different command
      const thirdRun = await Exec("memoize-test", {
        command: `echo "Different command: $(date +%s)"`,
        memoize: true,
        inheritStdio: false,
      });
      // This should execute and have different output
      expect(thirdRun.stdout).not.toBe(secondRun.stdout);
      expect(thirdRun.executedAt).not.toBe(secondRun.executedAt);
    } finally {
      await destroy(scope);
    }
  });
});
</file>

<file path="alchemy/test/util/dedent.test.ts">
import { describe, expect, it } from "bun:test";
import { dedent } from "../../src/util/dedent.js";
describe("dedent", () => {
  it("removes common indentation", () => {
    const s = dedent`
      line1
        line2
      line3
    `;
    expect(s).toBe("line1\n  line2\nline3");
  });
  it("removes leading and trailing blank lines", () => {
    const s = dedent`
      line1
      line2
    `;
    expect(s).toBe("line1\nline2");
  });
  it("preserves extra indentation", () => {
    const s = dedent`
      level1
        level2
          level3
    `;
    expect(s).toBe("level1\n  level2\n    level3");
  });
  it("handles empty template", () => {
    const s = dedent``;
    expect(s).toBe("");
  });
  it("handles single line", () => {
    const s = dedent`single line`;
    expect(s).toBe("single line");
  });
  it("interpolates values correctly", () => {
    const value = "world";
    const s = dedent`
      hello ${value}
      bye
    `;
    expect(s).toBe("hello world\nbye");
  });
  it("preserves blank lines in between", () => {
    const s = dedent`
      line1
      line3
    `;
    expect(s).toBe("line1\n\nline3");
  });
  it("returns empty for only whitespace lines", () => {
    const s = dedent`
      `;
    expect(s).toBe("");
  });
});
</file>

<file path="alchemy/test/esbuild.test.ts">
import { afterAll, expect } from "bun:test";
import fs from "node:fs/promises";
import path from "node:path";
import { alchemy } from "../src/alchemy.js";
import { Bundle } from "../src/esbuild/bundle.js";
import { BRANCH_PREFIX } from "./util.js";
import { destroy } from "../src/destroy.js";
import "../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const out = path.join(".alchemy", ".out");
const outputFile = path.join(out, "handler.js");
afterAll(async () => {
  await fs.rmdir(out);
});
test("bundle and cleanup", async (scope) => {
  const bundle = await Bundle("bundle", {
    entryPoint: path.join(import.meta.dirname, "handler.ts"),
    outdir: out,
    format: "esm",
    platform: "node",
    target: "node18",
  });
  try {
    // Apply the bundle
    expect(bundle.path).toBe(outputFile);
    expect(bundle.hash).toBeTruthy();
    // Verify the file exists and contains our code
    expect(await fs.exists(outputFile)).toBe(true);
    const contents = await fs.readFile(outputFile, "utf-8");
    expect(contents).toContain("Hello from bundled handler");
  } finally {
    await destroy(scope);
    expect(await fs.exists(outputFile)).toBe(false);
  }
});
</file>

<file path="alchemy/test/handler.ts">
export async function handler(event: any) {
  console.log("Received event:", JSON.stringify(event));
  // For Lambda URL, the actual payload is in the body
  const payload = event.body
    ? typeof event.body === "string"
      ? JSON.parse(event.body)
      : event.body
    : event;
  return {
    statusCode: 200,
    body: JSON.stringify({
      message: "Hello from bundled handler!",
      event: payload,
    }),
  };
}
// test case for handlers with _, 0-9, and A-Z
export const _myHandler012 = handler;
</file>

<file path="alchemy/test/run.ts">
import { runChangedTests } from "../src/test/prune.js";
/**
 * This script detects which tests have changed using esbuild and git and then runs only those tests.
 */
const sinceIdx = process.argv.findIndex((arg) => arg === "--since");
const since =
  (sinceIdx !== -1 ? process.argv[sinceIdx + 1] : undefined) ?? "HEAD~1";
await runChangedTests(import.meta.dirname, since);
</file>

<file path="alchemy/test/scope.test.ts">
import { describe, expect } from "bun:test";
import fs from "node:fs/promises";
import { alchemy } from "../src/alchemy.js";
import { destroy } from "../src/destroy.js";
import { File } from "../src/fs/file.js";
import { Scope } from "../src/scope.js";
import { BRANCH_PREFIX } from "./util.js";
import "../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("Scope", () => {
  test("should maintain scope context and track resources", async (scope) => {
    try {
      await File("file", {
        path: "test.txt",
        content: "Hello World",
      });
      const content = await fs.readFile("test.txt", "utf-8");
      expect(content).toBe("Hello World");
      expect(Scope.current).toEqual(scope);
      expect(scope.resources.size).toBe(1);
      expect(scope).toBe(scope);
    } finally {
      await destroy(scope);
    }
  });
});
</file>

<file path="alchemy/test/serde.test.ts">
import { describe, expect } from "bun:test";
import { alchemy } from "../src/alchemy.js";
import { Secret } from "../src/secret.js";
import { deserialize, serialize } from "../src/serde.js";
import { BRANCH_PREFIX } from "./util.js";
import "../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
describe("serde", async () => {
  test("serializes and deserializes primitive values", async (scope) => {
    // Test primitive values
    const testCases = [42, "hello", true, null, undefined];
    for (const value of testCases) {
      const serialized = await serialize(scope, value);
      const deserialized = await deserialize(scope, serialized);
      expect(deserialized).toEqual(value);
    }
  });
  test("serializes and deserializes arrays", async (scope) => {
    const array = [1, "two", true, null];
    const serialized = await serialize(scope, array);
    const deserialized = await deserialize(scope, serialized);
    expect(deserialized).toEqual(array);
  });
  test("serializes and deserializes nested objects", async (scope) => {
    const obj = {
      a: 1,
      b: {
        c: "hello",
        d: [1, 2, 3],
        e: {
          f: true,
        },
      },
    };
    const serialized = await serialize(scope, obj);
    const deserialized = await deserialize(scope, serialized);
    expect(deserialized).toEqual(obj);
  });
  test("serializes and deserializes secrets", async (scope) => {
    const secret = alchemy.secret("sensitive-data");
    const serialized = await serialize(scope, secret);
    expect(serialized).toHaveProperty("@secret");
    expect(typeof serialized["@secret"]).toBe("string");
    expect(serialized["@secret"]).not.toContain("sensitive-data");
    const deserialized = await deserialize(scope, serialized);
    expect(deserialized).toBeInstanceOf(Secret);
    expect(deserialized.unencrypted).toBe("sensitive-data");
  });
  test("serializes scope to undefined", async (scope) => {
    const objWithScope = {
      scope: scope,
      data: "test",
    };
    const serialized = await serialize(scope, objWithScope);
    expect(serialized).toEqual({
      scope: {
        "@scope": null,
      },
      data: "test",
    });
  });
  test("handles complex objects with secrets", async (scope) => {
    const complexObj = {
      name: "test",
      credentials: {
        username: "user",
        password: alchemy.secret("super-secret"),
        apiKey: alchemy.secret("api-key-123"),
      },
      settings: {
        enabled: true,
        tokens: [alchemy.secret("token1"), alchemy.secret("token2")],
      },
    };
    const serialized = await serialize(scope, complexObj);
    const deserialized = await deserialize(scope, serialized);
    // Verify structure
    expect(deserialized).toHaveProperty("name", "test");
    expect(deserialized.credentials.username).toBe("user");
    expect(deserialized.credentials.password).toBeInstanceOf(Secret);
    expect(deserialized.credentials.password.unencrypted).toBe("super-secret");
    expect(deserialized.credentials.apiKey.unencrypted).toBe("api-key-123");
    expect(deserialized.settings.enabled).toBe(true);
    expect(deserialized.settings.tokens[0].unencrypted).toBe("token1");
    expect(deserialized.settings.tokens[1].unencrypted).toBe("token2");
  });
  test("props", async (scope) => {
    const props = {
      name: "alchemy.run",
      type: "full",
    };
    const serialized = await serialize(scope, props);
    expect(serialized).toEqual(props);
  });
  test("symbol property", async (scope) => {
    const props = {
      [Symbol.for("foo")]: "bar",
    };
    const serialized = await serialize(scope, props);
    expect(serialized).toEqual({
      "Symbol(foo)": "bar",
    });
    expect(await deserialize(scope, serialized)).toEqual(props);
  });
  test("symbol value", async (scope) => {
    const props = {
      foo: Symbol.for("bar"),
    };
    const serialized = await serialize(scope, props);
    expect(serialized).toEqual({
      foo: {
        "@symbol": "Symbol(bar)",
      },
    });
    expect(await deserialize(scope, serialized)).toEqual(props);
  });
  test("unique symbol property should error", async (scope) => {
    expect(
      serialize(scope, {
        [Symbol()]: "bar",
      }),
    ).rejects.toThrow();
    expect(
      serialize(scope, {
        [Symbol("foo")]: "bar",
      }),
    ).rejects.toThrow();
  });
  test("unique symbol value should error", async (scope) => {
    expect(
      serialize(scope, {
        foo: Symbol(),
      }),
    ).rejects.toThrow();
    expect(
      serialize(scope, {
        foo: Symbol("bar"),
      }),
    ).rejects.toThrow();
  });
  test("key that looks like a symbol errors", async (scope) => {
    expect(
      serialize(scope, {
        "Symbol(foo)": "bar",
      }),
    ).rejects.toThrow();
    expect(
      serialize(scope, {
        "Symbol()": "bar",
      }),
    ).rejects.toThrow();
    expect(
      serialize(scope, {
        "Symbol(Symbol.asyncDispose)": "bar",
      }),
    ).rejects.toThrow();
  });
});
</file>

<file path="alchemy/test/stripe.test.ts">
import { describe, expect } from "bun:test";
import Stripe from "stripe";
import { alchemy } from "../src/alchemy.js";
import { destroy } from "../src/destroy.js";
import { Price } from "../src/stripe/price.js";
import { Product } from "../src/stripe/product.js";
import { WebhookEndpoint } from "../src/stripe/webhook.js";
import { BRANCH_PREFIX } from "./util.js";
import "../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const stripeApiKey = import.meta.env.STRIPE_API_KEY;
if (!stripeApiKey) {
  throw new Error("STRIPE_API_KEY environment variable is required");
}
// Initialize a Stripe client for verification
const stripe = new Stripe(stripeApiKey);
describe("Stripe Resources", () => {
  test("create and destroy stripe resources", async (scope) => {
    // Create a test product
    // Resources that we'll need to clean up
    let product;
    let webhook;
    let price;
    try {
      const productName = `${BRANCH_PREFIX} Alchemy Test Product`;
      product = await Product(`${BRANCH_PREFIX}-product`, {
        name: productName,
        description: "A product created by Alchemy tests",
      });
      expect(product.id).toBeTruthy();
      expect(product.name).toBe(productName);
      // Verify with Stripe API
      expect((await stripe.products.retrieve(product.id)).name).toBe(
        productName,
      );
      // Create a price for the product
      price = await Price(`${BRANCH_PREFIX}-price`, {
        product: product.id,
        currency: "usd",
        unitAmount: 1500, // $15.00
        recurring: {
          interval: "month",
        },
      });
      expect(price.id).toBeTruthy();
      expect(price.unitAmount).toBe(1500);
      expect(price.recurring?.interval).toBe("month");
      // Verify with Stripe API
      expect((await stripe.prices.retrieve(price.id)).unit_amount).toBe(1500);
      // Create a webhook endpoint
      webhook = await WebhookEndpoint(`${BRANCH_PREFIX}-webhook`, {
        url: "https://example.com/alchemy-webhook",
        enabledEvents: [
          "checkout.session.completed",
          "customer.subscription.created",
        ],
        description: "Webhook for Alchemy tests",
      });
      // Apply the webhook
      expect(webhook.id).toBeTruthy();
      expect(webhook.url).toBe("https://example.com/alchemy-webhook");
      expect(webhook.secret).toBeTruthy();
      // Verify with Stripe API
      expect((await stripe.webhookEndpoints.retrieve(webhook.id)).url).toBe(
        "https://example.com/alchemy-webhook",
      );
    } finally {
      await destroy(scope);
      // Verify clean up
      if (product?.id) {
        await assertProductDeactivated(product.id);
      }
      if (price?.id) {
        await assertPriceDeactivated(price.id);
      }
      if (webhook?.id) {
        await assertWebhookDeleted(webhook.id);
      }
    }
  });
});
// Helper functions for verification
async function assertProductDeactivated(productId: string) {
  try {
    const product = await stripe.products.retrieve(productId);
    // Products are deactivated, not deleted
    expect(product.active).toBe(false);
  } catch (error) {
    // If product is not found, that's also acceptable
    if (
      error instanceof Stripe.errors.StripeError &&
      error.code === "resource_missing"
    ) {
      return;
    }
    throw error;
  }
}
async function assertPriceDeactivated(priceId: string) {
  try {
    const price = await stripe.prices.retrieve(priceId);
    // Prices are deactivated, not deleted
    expect(price.active).toBe(false);
  } catch (error) {
    // If price is not found, that's also acceptable
    if (
      error instanceof Stripe.errors.StripeError &&
      error.code === "resource_missing"
    ) {
      return;
    }
    throw error;
  }
}
async function assertWebhookDeleted(webhookId: string) {
  try {
    await stripe.webhookEndpoints.retrieve(webhookId);
    throw new Error("Webhook still exists");
  } catch (error) {
    // Webhook should be deleted, so we expect a resource_missing error
    if (error instanceof Stripe.errors.StripeError) {
      expect(error.code).toBe("resource_missing");
    } else {
      throw error;
    }
  }
}
</file>

<file path="alchemy/test/util.ts">
import os from "node:os";
/**
 * Sanitize a string to be safe for AWS resource names
 * Replaces any characters that aren't alphanumeric, hyphen, or underscore
 */
function sanitizeForAwsResourceName(str: string): string {
  // Replace any character that's not alphanumeric, hyphen, or underscore with a hyphen
  return str.replace(/[^a-zA-Z0-9\-_]/g, "-");
}
/**
 * Branch prefix for resource names to avoid naming conflicts in CI/CD
 *
 * Uses BRANCH_PREFIX environment variable in CI/CD environments
 * Falls back to current user's name in local development
 * Sanitizes to ensure only valid characters for AWS resource names
 */
export const BRANCH_PREFIX = sanitizeForAwsResourceName(
  process.env.BRANCH_PREFIX || os.userInfo().username,
);
</file>

<file path="alchemy/tsconfig.json">
{
  "extends": "../tsconfig.base.json",
  "include": ["src/**/*"],
  "compilerOptions": {
    "composite": true,
    "noEmit": false,
    "outDir": "./lib",
    "rootDir": "./src",
    "sourceMap": true,
    "declarationMap": true,
    "module": "Preserve",
    "moduleResolution": "Bundler",
    "target": "ESNext"
  }
}
</file>

<file path="alchemy/tsconfig.test.json">
{
  "extends": "./tsconfig.json",
  "include": ["src/**/*.ts", "test/**/*.ts"],
  "compilerOptions": {
    "rootDir": ".",
    "noEmit": true,
    "types": ["bun-types", "@cloudflare/workers-types"]
  }
}
</file>

<file path="alchemy-web/.vitepress/theme/index.ts">
import TwoslashFloatingVue from "@shikijs/vitepress-twoslash/client";
import "@shikijs/vitepress-twoslash/style.css";
import "virtual:group-icons.css";
import type { Theme as ThemeConfig } from "vitepress";
import Theme from "vitepress/theme-without-fonts";
import "./style.css";
export default {
  extends: Theme,
  enhanceApp(ctx) {
    ctx.app.use(TwoslashFloatingVue);
  },
} satisfies ThemeConfig;
</file>

<file path="alchemy-web/.vitepress/theme/style.css">
/**
* Customize default theme styling by overriding CSS variables:
* https://github.com/vuejs/vitepress/blob/main/src/client/theme-default/styles/vars.css
*/
/**
* Colors
*
* Each colors have exact same color scale system with 3 levels of solid
* colors with different brightness, and 1 soft color.
*
* - `XXX-1`: The most solid color used mainly for colored text. It must
*   satisfy the contrast ratio against when used on top of `XXX-soft`.
*
* - `XXX-2`: The color used mainly for hover state of the button.
*
* - `XXX-3`: The color for solid background, such as bg color of the button.
*   It must satisfy the contrast ratio with pure white (#ffffff) text on
*   top of it.
*
* - `XXX-soft`: The color used for subtle background such as custom container
*   or badges. It must satisfy the contrast ratio when putting `XXX-1` colors
*   on top of it.
*
*   The soft color must be semi transparent alpha channel. This is crucial
*   because it allows adding multiple "soft" colors on top of each other
*   to create a accent, such as when having inline code block inside
*   custom containers.
*
* - `default`: The color used purely for subtle indication without any
*   special meanings attached to it such as bg color for menu hover state.
*
* - `brand`: Used for primary brand colors, such as link text, button with
*   brand theme, etc.
*
* - `tip`: Used to indicate useful information. The default theme uses the
*   brand color for this by default.
*
* - `warning`: Used to indicate warning to the users. Used in custom
*   container, badges, etc.
*
* - `danger`: Used to show error, or dangerous message to the users. Used
*   in custom container, badges, etc.
* -------------------------------------------------------------------------- */
:root {
  --vp-c-default-1: var(--vp-c-gray-1);
  --vp-c-default-2: var(--vp-c-gray-2);
  --vp-c-default-3: var(--vp-c-gray-3);
  --vp-c-default-soft: var(--vp-c-gray-soft);
  --vp-c-brand-1: var(--vp-c-indigo-1);
  --vp-c-brand-2: var(--vp-c-indigo-2);
  --vp-c-brand-3: var(--vp-c-indigo-3);
  --vp-c-brand-soft: var(--vp-c-indigo-soft);
  --vp-c-tip-1: var(--vp-c-brand-1);
  --vp-c-tip-2: var(--vp-c-brand-2);
  --vp-c-tip-3: var(--vp-c-brand-3);
  --vp-c-tip-soft: var(--vp-c-brand-soft);
  --vp-c-warning-1: var(--vp-c-yellow-1);
  --vp-c-warning-2: var(--vp-c-yellow-2);
  --vp-c-warning-3: var(--vp-c-yellow-3);
  --vp-c-warning-soft: var(--vp-c-yellow-soft);
  --vp-c-danger-1: var(--vp-c-red-1);
  --vp-c-danger-2: var(--vp-c-red-2);
  --vp-c-danger-3: var(--vp-c-red-3);
  --vp-c-danger-soft: var(--vp-c-red-soft);
}
/**
* Component: Button
* -------------------------------------------------------------------------- */
:root {
  --vp-button-brand-border: transparent;
  --vp-button-brand-text: var(--vp-c-white);
  --vp-button-brand-bg: var(--vp-c-brand-3);
  --vp-button-brand-hover-border: transparent;
  --vp-button-brand-hover-text: var(--vp-c-white);
  --vp-button-brand-hover-bg: var(--vp-c-brand-2);
  --vp-button-brand-active-border: transparent;
  --vp-button-brand-active-text: var(--vp-c-white);
  --vp-button-brand-active-bg: var(--vp-c-brand-1);
}
/**
* Component: Home
* -------------------------------------------------------------------------- */
:root {
  --vp-home-hero-name-color: transparent;
  --vp-home-hero-name-background: -webkit-linear-gradient(
    120deg,
    #bd34fe 30%,
    #41d1ff
  );
  --vp-home-hero-image-background-image: linear-gradient(
    -45deg,
    #bd34fe 50%,
    #47caff 50%
  );
  --vp-home-hero-image-filter: blur(44px);
}
@media (min-width: 640px) {
  :root {
    --vp-home-hero-image-filter: blur(56px);
  }
}
@media (min-width: 960px) {
  :root {
    --vp-home-hero-image-filter: blur(68px);
  }
}
/**
* Component: Custom Block
* -------------------------------------------------------------------------- */
:root {
  --vp-custom-block-tip-border: transparent;
  --vp-custom-block-tip-text: var(--vp-c-text-1);
  --vp-custom-block-tip-bg: var(--vp-c-brand-soft);
  --vp-custom-block-tip-code-bg: var(--vp-c-brand-soft);
}
/**
* Component: Algolia
* -------------------------------------------------------------------------- */
.DocSearch {
  --docsearch-primary-color: var(--vp-c-brand-1) !important;
}
</file>

<file path="alchemy-web/.vitepress/config.mts">
import { transformerTwoslash } from "@shikijs/vitepress-twoslash";
import fs from "fs";
import footnotePlugin from "markdown-it-footnote";
import path from "path";
import { defineConfig } from "vitepress";
import {
  groupIconMdPlugin,
  groupIconVitePlugin,
} from "vitepress-plugin-group-icons";
import { processFrontmatterFiles } from "../../alchemy/src/web/vitepress";

const description = "Alchemy: Typescript-native Infrastructure-as-Code";

// https://vitepress.dev/reference/site-config
export default defineConfig({
  title: "Alchemy",
  description: "Alchemy Docs",
  head: [
    ["link", { rel: "icon", type: "image/png", href: "/potion.png" }],
    ["meta", { property: "og:type", content: "website" }],
    ["meta", { property: "og:title", content: "Alchemy" }],
    ["meta", { property: "og:description", content: description }],
    ["meta", { property: "og:url", content: "https://alchemy.run" }],
    ["meta", { name: "twitter:title", content: "Alchemy" }],
    [
      "meta",
      {
        name: "twitter:description",
        content: description,
      },
    ],
  ],
  markdown: {
    // @ts-ignore
    codeTransformers: [transformerTwoslash()],
    theme: { light: "light-plus", dark: "dark-plus" },
    config: (md) => md.use(footnotePlugin).use(groupIconMdPlugin),
  },
  vite: {
    plugins: [groupIconVitePlugin() as any],
  },
  // https://vitepress.dev/reference/default-theme-config
  themeConfig: {
    nav: [
      { text: "Home", link: "/" },
      { text: "Docs", link: "/docs/getting-started" },
    ],
    socialLinks: [
      { icon: "github", link: "https://github.com/sam-goodwin/alchemy" },
      { icon: "discord", link: "https://discord.gg/jwKw8dBJdN" },
      { icon: "x", link: "https://twitter.com/samgoodwin89" },
    ],
    sidebar: [
      { text: "Get Started", link: "/docs/getting-started" },
      { text: "What is Alchemy?", link: "/docs/what-is-alchemy" },
      await generateSidebar("Guides"),
      await generateSidebar("Concepts"),
      await generateProvidersSidebar(),
    ],
    search: { provider: "local" },
  },
});

async function generateSidebar(title: string) {
  const folder = title.toLowerCase();
  return {
    text: title,
    collapsed: false,
    items: await processFrontmatterFiles(`docs/${folder}`, `/docs/${folder}`),
  };
}

/**
 * Generate sidebar items for providers by traversing the file system
 */
async function generateProvidersSidebar() {
  const providersDir = path.join(process.cwd(), "docs/providers");
  const providers = fs
    .readdirSync(providersDir)
    .filter((dir) => fs.statSync(path.join(providersDir, dir)).isDirectory())
    .sort();

  const items = await Promise.all(
    providers.map(async (provider) => {
      const providerDir = path.join(providersDir, provider);
      const files = fs
        .readdirSync(providerDir)
        .filter((file) => file.endsWith(".md"))
        .sort();

      const fileItems = files.map((file) => {
        // Convert filename to display text (e.g., astro-file.md -> AstroFile)
        const baseName = path.basename(file, ".md");
        const displayName = baseName
          .split("-")
          .map((part) => part.charAt(0).toUpperCase() + part.slice(1))
          .join("");

        return {
          text: displayName,
          link: `/docs/providers/${provider}/${baseName}`,
        };
      });

      return {
        text: provider,
        collapsed: true,
        items: fileItems,
      };
    })
  );

  return {
    text: "Providers",
    collapsed: false,
    items,
  };
}
</file>

<file path="alchemy-web/blogs/2025-04-08-decade-long-journey.md">
---
title: "My decade long journey with IaC and why it needs to be un-bundled"
date: "2025-04-08"
description: "An intro to my blog journey."
---

A post on my decade long journey with Infrastructure-as-Code, why I built my own minimal library in pure TypeScript and why I think you should at least entertain the idea of "un-bundling IaC" and returning to simplicity.

I built alchemy after years of working with every other option, from CloudFormation, CDK, to Pulumi, Terraform and Kubernetes. IaC is non-negotiable in my opinion, and is one of my favorite technologies as a developer.

I started with CloudFormation since I worked at Amazon and really hated that. JSON is just not expressive enough for me and debugging broken stacks was was always something I dreaded. I'm pretty sure the CFN website still squashes the whole error message into a 10 pixel wide box .

The CDK is an upgrade on that (because yay for TypeScript) but it is still always going to be limited by the CloudFormation service, which is very slow to change and use.

Being developed by corporate giant Amazon and with the founder moved on to new ideas, you just have to accept that things will move more slowly and you have no say or control over that. It's how things are in a big centralized company.

One mega wart with the CDK technically is its awful coupling to synchronous I/O, making it damn near impossible to do anything async. Every user inevitably runs into this, googles it and is met with "fuck off" in the GitHub issues. Then we're forced to hack around it, which is not pretty. Not allowing is async is basically not allowing JavaScript. I doubt it'll ever be fixed.

They're also stuck on CJS. Taking a dependency on the CDK and using it anywhere other than locally will 10x the size of your app and destroy your DX. It's a tangled mess of of complicated, legacy TypeScript code generating complicated, proprietary JSON files uploaded to the complicated, opaque, proprietary CloudFormation service 

Why? How does this serve the user?

Later, I moved on to Pulumi, which was a nice change of pace since it runs locally and is much faster. You can cancel a deployment by hitting Ctrl+C (hallelujah!) and it also supports more than just AWS, which is great because everything should be managed sensibly in code.

However, Pulumi is largely a wrapper around Terraform. If you thought you were going to escape the layers, you were sorely mistaken. That JavaScript is just lipstick on the pig that are clunky "providers" implemented with Go, running in a separate process. You can't just run Pulumi everywhere (like the browser) and it even struggles to run in AWS Lambda if you're using ESM.

Pulumi Custom Resources are possible but more of an afterthought and a PITA to implement. They have many sharp edges and gotchas, like the resource code having to be serialized and their coupling to CJS - so if you import the wrong thing with ESM, it just breaks. I couldn't even use AWS SDK v3 in a simple custom resource because of how leaky these hacks are.

If Pulumi bricks itself by getting into some weird state, good luck fixing it. Their state files are complicated and their providers are opaque, so you're really just stuck running `pulumi refresh` and praying, or surgically removing and restoring resources one by one. It's not transparent.

I've used Terraform when I've been forced into it. It does exactly what it claims to do, but I don't love it because it's a custom DSL and a heavy toolchain. And for what? Calling a few CRUD APIs? Way overkill.

If it doesn't already exist in Terraform, then just forget it. Every time I think about implementing a custom resource for Terraform, I just can't bring myself to do it. Let me just write a function in my language, please! 

Lately, I've been using SST because I've been doing a ton of web development. At first, I really liked SST because of its local development experience. `sst dev` gives you live deploy, a TUI multiplexer and a proxy from the cloud to your local code. This is great for building web apps in AWS.

But, SST is a wrapper around Pulumi!! (which is a wrapper around terraform (which is a wrapper around the underlying SDK ( ... ( ... ( ... )))) ...

Layers. Layers. Layers. When will it ever end?

As my app grew, SST's bugs and opinions ate away at me. I got blocked by broken resources that have race conditions and it was impossible to work around (still is, by the way). I also wanted to deploy a nested app using another `sst.config.ts` but it conflicted with their assumptions around generated sst-env.d.ts files.

Again, I was let down by the complexity and opinions(!) of my chosen IaC framework. And for what? To help me call a few CRUD APIs and track my Resources?

Honestly, it just seems insane how far we've drifted away from simplicity in this area. This became even more apparent as I started using Cursor more and more to write code.

You see, I've found myself doing more frontend than I've ever done before, and I'm not a good frontend developer. So, I relied on Cursor to write most of the code for me and (as many others have experienced) it totally blew my mind 

Cursor is just really, really, really good at TypeScript, React and Tailwind. I've built a functioning and (if i don't say so myself) good looking SPA. It's been a blast. As a "backend guy", i feel my world has opened up.

But, this got me thinking ... you know what else Cursor is really great at? Perhaps even better at?

 Interacting with CRUD APIs.

While there's a ton of frontend training data for LLMs, there's just as much (if not more) training data for CRUD lifecycle operations. They've also ingested all of Kubernetes, Terraform, Pulumi, SST and the AWS CDK's training data. Modern LLMs know it very well.

Long story short, I discovered that Cursor can pretty much one-shot the implementation of Resources. All of the resources in Alchemy are entirely generated on-demand (5 minute time investment, tops). When I run into a bug, I just explain it to Cursor who fixes it immediately.

Working this way may seem like more work at first glance, but in practice I think it's not. I will never get blocked by working this way. I will never have to wait for another person to prioritize my problem, merge a fix and release the change. I will never be confused about what's actually happening under the covers.

This is a game changer for me. It means we don't need tools like Terraform to build layers of "provider" suites for us. We just need the engine - the bit that tracks state and decides what to create/update/delete. The rest can be generated at near zero cost.

I suspect a lot of people gripe with me on this claim of "zero cost" because they have not yet embraced the AI-generation workflow. Their instinct is right, but outdated.

Before LLMs, I would agree that this was infeasible, but I think we've finally crossed the threshold where LLMs can do this work trivially and respond in real-time to your requirements.

If this is not obvious to you, then I suggest forcing yourself to practice with AI code generation. When it fucks up, try blaming yourself instead of blaming and discarding the LLM. I think you're missing a skill.

This is why adoption curves are a thing, do you want to be a laggard?

At the end of the day, you need to realize that agency is going to matter more and more as time progresses and that shackling yourself to a mega-provider who doesn't even know your name is a ticket to inefficiency.

I think we've mostly been hoodwinked into thinking that because managing infrastructure is complicated, we need complicated solutions. Now is the time for that pendulum to swing back in the other direction and "un-bundle" IaC.
</file>

<file path="alchemy-web/blogs/index.md">
---
layout: page
title: Blog
---

<script setup>
// Use Vite's glob import feature to dynamically import all blog posts
const blogModules = import.meta.glob('./*.md', { eager: true });

// Filter out the index.md file and create blog post entries
const blogPosts = Object.entries(blogModules)
  .filter(([path]) => !path.includes('index.md'))
  .map(([path, module]) => {
    // Get the frontmatter and create a formatted path
    const frontmatter = module.frontmatter;
    const pagePath = path.replace('./', '/blogs/').replace('.md', '');
    
    return {
      path: pagePath,
      frontmatter
    };
  })
  // Make sure each post has a date in frontmatter
  .filter(post => post.frontmatter && post.frontmatter.date)
  // Sort by date (newest first)
  .sort((a, b) => new Date(b.frontmatter.date) - new Date(a.frontmatter.date));
</script>

# Blog

<ul>
  <li v-for="post in blogPosts" :key="post.path">
    <a :href="post.path">{{ post.frontmatter.title }}</a>
    <br />
    <small>{{ new Date(post.frontmatter.date).toLocaleDateString() }}</small>
    <p v-if="post.frontmatter.description">{{ post.frontmatter.description }}</p>
  </li>
</ul>

<div v-if="blogPosts.length === 0">
  <p>No blog posts found. Make sure your blog posts have a date in the frontmatter.</p>
</div>
</file>

<file path="alchemy-web/docs/advanced/serde.md">
# Serialization and Deserialization in Alchemy

Alchemy uses a sophisticated serialization system to properly handle JavaScript objects, special types, and sensitive data. This system is crucial for correctly storing and retrieving resource state.

## Overview

The `serialize` and `deserialize` functions in Alchemy handle the conversion between in-memory JavaScript objects and their JSON-compatible representation for storage:

- **serialize**: Converts JavaScript objects to JSON-compatible structures, handling special cases
- **deserialize**: Converts the serialized data back into JavaScript objects with proper typing

## Special Type Handling

Alchemy's serialization system handles several special cases:

### Secrets

Secrets are automatically encrypted when serialized and decrypted when deserialized:

```typescript
// In memory
const apiKey = alchemy.secret("my-secret-api-key");

// Serialized representation
{
  "@secret": "Tgz3e/WAscu4U1oanm5S4YXH..." // encrypted value
}
```

This ensures sensitive information isn't stored in plain text in state files.

### Dates

JavaScript Date objects are serialized with an ISO timestamp:

```typescript
// In memory
const createdAt = new Date();

// Serialized representation
{
  "@date": "2023-06-15T12:30:45.123Z"
}
```

### Schema Types

Type definitions created with ArkType are properly serialized:

```typescript
// In memory
const schema = Type.String();

// Serialized representation
{
  "@schema": { /* schema definition */ }
}
```

### Objects and Circular References

The serialization system properly handles complex object structures including:

- Nested objects
- Arrays
- Maps
- Sets
- Circular references (objects that reference each other)

## Using the Serialization System

The serialization system is primarily used by Alchemy's state store implementations but can be useful in custom resources too:

```typescript
import { serialize, deserialize } from "alchemy";

// Serialize an object
const serializedData = await serialize(scope, complexObject);

// Store serialized data (e.g., in a database)
await db.put("my-key", JSON.stringify(serializedData));

// Later, retrieve and deserialize
const storedData = await db.get("my-key");
const deserializedObject = await deserialize(scope, JSON.parse(storedData));
```

## Encryption and Passwords

When serializing secrets, a password must be set on the scope:

```typescript
const app = await alchemy("my-app", {
  password: process.env.SECRET_PASSPHRASE,
});
```

If you attempt to serialize a secret without a password, you'll get an error:

```
Error: Cannot serialize secret without password
```

Similarly, when deserializing encrypted secrets, the same password must be provided.

## Serialization Options

The `serialize` function accepts options to control the serialization process:

```typescript
// Skip encryption (for debugging or special cases)
const serializedData = await serialize(scope, value, {
  encrypt: false
});
```

## Implementation Details

The serialization system uses a recursive approach to handle nested structures:

1. **Arrays** are processed element by element
2. **Objects** are processed property by property
3. **Special types** are detected and replaced with tagged values
4. **Circular references** are detected and properly handled

During deserialization, the process is reversed, restoring the original structure including special types.

## Skipped and Excluded Types

Some types are excluded or skipped during serialization:

- **Scope objects** are skipped (set to `undefined`)
- **Functions** are not specially handled (converted to `undefined` by JSON)
- **Symbols** are not specially handled (converted to `undefined` by JSON)

## Related Concepts

- [State Management](../concepts/state.md)
- [Secrets Management](../concepts/secret.md)
- [Custom State Stores](../guides/custom-state-store.md)
</file>

<file path="alchemy-web/docs/concepts/bindings.md">
---
order: 100
---

# Bindings

Bindings allow resources to connect to each other in a type-safe way. In Alchemy, bindings are most commonly used with Cloudflare Workers to give them access to other resources.

## What are Bindings?

Bindings expose resources to your code at runtime. For example, they allow a Cloudflare Worker to access:

- KV Namespaces
- Durable Objects
- R2 Buckets
- Secrets and variables

## Using Bindings in Workers

```typescript
// alchemy.run.ts
import { Worker, KVNamespace } from "alchemy/cloudflare";

// Create a KV namespace
const myKV = await KVNamespace("MY_KV", {
  title: "my-kv-namespace"
});

// Bind the KV namespace to a worker
const myWorker = await Worker("my-worker", {
  name: "my-worker",
  entrypoint: "./src/worker.ts",
  bindings: {
    MY_KV: myKV,
    API_KEY: "secret-key",
    DEBUG_MODE: true
  }
});
```

The worker can then access these bindings through the `env` parameter:

```typescript
// src/worker.ts
export default {
  async fetch(request: Request, env: any, ctx: any) {
    // Access the KV namespace binding
    const value = await env.MY_KV.get("key");
    
    // Access other bindings
    const apiKey = env.API_KEY;
    const isDebug = env.DEBUG_MODE;
    
    return new Response(`Value: ${value}`);
  }
};
```

## Type-Safe Bindings

To make bindings type-safe, create an `env.d.ts` file:

```typescript
/// <reference types="./env.d.ts" />

import type { myWorker } from "./alchemy.run";

export type WorkerEnv = typeof myWorker.Env;

declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends WorkerEnv {}
  }
}
```

Then, use the type in your worker:

```typescript
// src/worker.ts
export default {
  async fetch(request: Request, env: WorkerEnv, ctx: any) {
    // Type-safe access to bindings
    const value = await env.MY_KV.get("key");
    const apiKey = env.API_KEY;
    
    return new Response(`Value: ${value}`);
  }
};
```

## Binding Types

Alchemy supports several binding types:

| Binding Type | Description | Example |
|--------------|-------------|---------|
| KV Namespace | Key-value storage | `MY_KV: myKV` |
| Durable Object | Stateful objects | `COUNTER: counter` |
| R2 Bucket | Object storage | `STORAGE: bucket` |
| Secret | Sensitive value | `API_KEY: alchemy.secret("key")` |
| Variable | Plain text value | `DEBUG: "true"` |

## Binding Resources vs Values

Alchemy handles bindings differently based on what's being bound:

```typescript
const worker = await Worker("worker", {
  // ...
  bindings: {
    // Resource bindings (automatically set up in Cloudflare)
    KV_STORE: kvNamespace,
    COUNTER: durableObject,
    BUCKET: r2Bucket,
    
    // Value bindings (passed as environment variables)
    API_KEY: alchemy.secret(process.env.API_KEY),
    DEBUG: "true",
    VERSION: "1.0.0"
  }
});
```
</file>

<file path="alchemy-web/docs/concepts/destroy.md">
---
order: 9
---
# Destroy

Resource destruction in Alchemy removes resources from both your state file and the underlying infrastructure.

## Resource vs. Application Destruction

### Application Destruction
```typescript
// Destroys all resources in the application
const app = await alchemy("my-app", {
  phase: "destroy"  // or process.argv.includes("--destroy") ? "destroy" : "up"
});
```
Use for: Complete teardown of environments, cleaning up all infrastructure managed by the app.

### Resource/Scope Destruction
```typescript
// Destroys only the specified resource(s)
await destroy(myResource);  // Single resource
await destroy(scope);       // All resources in scope
```
Use for: Targeted cleanup of specific resources or test resources without affecting the rest of your app.

## Ways to Destroy Resources

### 1. Code Removal

```typescript
// Remove or comment out resource declarations to destroy them
// const myFile = await File("config.json", { ... });
```

### 2. Using the --destroy Flag

```typescript
// In alchemy.run.ts
const app = await alchemy("my-app", {
  stage: "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up"
});

// Run with: bun ./alchemy.run.ts --destroy
```

### 3. Programmatic Destruction

```typescript
// Destroy a specific resource
import { destroy } from "alchemy";
await destroy(myFile);
```

## Destruction Order

Resources are destroyed in dependency order: dependents first, then dependencies.

## Best Practices

```typescript
// When implementing custom resources, handle deletion phase
if (this.phase === "delete") {
  await api.delete(`/resources/${this.output.id}`);
  return this.destroy();
}
```
</file>

<file path="alchemy-web/docs/concepts/phase.md">
---
order: 2
---

# Phase

An Alchemy app can run in one of three phases:
1. `"up"` - resources should be created, updated and deleted as necessary.
2. `"destroy"` - all resources in the stage should be deleted and the program should not proceed
3. `"read"` - run the program end-to-end but do not create, update or delete any resources

## `"up"`

The **Up** phase creates, updates and deletes resources. This is the default mode and the most common. It's how you deploy your app (synchronize resources).

```ts
const app = await alchemy("my-app", {
  phase: "up"
});

const worker = await Worker("my-app", { .. }); // <- will be created or updated

await app.finalize(); // <- will delete orphaned resources
```

## `"destroy"`

The **Destroy** phase deletes all resources and scopes within the `my-app.${stage}` (e.g. `prod` below).

```ts
const app = await alchemy("my-app", {
  phase: "destroy",
  stage: "prod", // <- this stage will be destroyed
});

// execution will not proceed to the following lines

const worker = await Worker("my-app", { .. }); // <- never executed
```

## `"read"`

The **Read** phase runs the program but never creates, updates or deletes any resources. It is useful for building shell scripts that need access to infrastructure properties (e.g. the )

```ts
const app = await alchemy("my-app", {
  phase: "read"
});

// will reconstruct itself from state and error if it does not exist
const worker = await Worker("my-app", { .. });

worker.url; // <- populated from `.alchemy/` state

await app.finalize() // <- will not delete any orphaned resources
```

> [!TIP]
> You can write your own scripts that run commands and pass infrstructure properties as environment variables with a very simple node script.
> 1. Set the `phase` to `"read"`, e.g. using an env variable:
> ```ts
> // ./alchemy.run.ts
> const app = await alchemy({
>   phase: process.env.PHASE ?? "up"    
> });
>
> // export your infrastructure
> export const website = await Worker(..);
> ```
> 2. Import the `website` from your `alchemy.run.ts` module and execute a shell command. `alchemy/os` exposes a convenient async exec command that inherits stdio by default, but you can use anything.
> ```ts
> // ./scripts/build.ts
> import { exec } from "alchemy/os";
> import { website } from "./alchemy.run";
> 
> await exec("astro build", {
>   BACKEND_URL: website.url    
> })
> ```
> 3. Finally, execute your command `bash`:
> ```sh
> PHASE=read bun ./scripts/build.ts
> ```
</file>

<file path="alchemy-web/docs/concepts/resource.md">
---
order: 1
---

# Resource

Resources are the core building blocks of Alchemy. Each resource represents a piece of infrastructure or configuration that can be created, updated, and deleted automatically.

## What is a Resource?

A Resource is simply a memoized async function that implemented a lifecycle handler for three phases:
1. `create` - what to do when first creating the resource
2. `update` - what to do when updating a resource
3. `delete` - what to when deleting a resource

## Resource ID

When creating a resource, you always pass an `id` that is unique within the Resource's [Scope](../concepts/scope.md).

```ts
await MyResource("id")
```

This ID is what Alchemy uses to track the state of the resource and trigger the appropriate create/update/delete phase.

## Resource Props

Each Resource has an interface for its "input properties"

```typescript
export interface DatabaseProps {
  name: string;
  branchId: string;
  projectId: string;
  // Other properties...
}
```

## Resource Instance

Each Resource has an interface for its "output attributes":

```typescript
export interface Database extends Resource<"neon::Database">, DatabaseProps {
  id: string;
  createdAt: number;
  // Additional properties...
}
```

> [!CAUTION]
> This interface must extend `Resource<..>`

## Resource Provider

Each Resource exports a "Provider" function with a globally unique name and an implementation of the lifecycle handler logic.

```typescript
export const Database = Resource(
  "neon::Database",
  async function(this: Context<Database>, id: string, props: DatabaseProps): Promise<Database> {
    if (this.phase === "delete") {
      // Delete resource logic
      // ...
      return this.destroy();
    } else if (this.phase === "update") {
      // Update resource logic
      // ...
      return this({/* updated resource */});
    } else {
      // Create resource logic
      // ...
      return this({/* new resource */});
    }
  }
);
```

> [!TIP]
> By Convention, the name of this exported `const` should match the name of your Resource's interface.

Let's break this down a bit futher, since it may seem confusing at first.

## Resource FQN

Each Resource has a globally unique name (aka. fully qualified name), e.g `"neon:Database"`:

```ts
export const Database = Resource("neon::Database"),
```

Alchemy and uses this FQN to delete orphaned resources (stored in your [State](../concepts/state.md) files) by looking up the corresponding "provider".

## Lifecycle Function

The Resource's lifecycle handler is defined using an `async function` declaration with 3 required arguments:

```ts
async function(
  // the resource's state/context is bound to `this`
  this: Context<Database>, 
  // the id of the resource (unique within a SCope)
  id: string, 
  // the input properties
  props: DatabaseProps
): Promise<Database>
```

> [!CAUTION]
> It must be function declaration (not an arrow function) because the Resource's context is passed through as the `this: Context<Database>` parameter.

## Lifecycle Phases

The lifecycle handler is a simple function that handles the 3 phases: `"create"`, `"update"` or `"delete"`:

```ts
if (this.phase === "delete") {
  // Delete resource logic
  // ...
  return this.destroy();
} else if (this.phase === "update") {
  // Update resource logic
  // ...
  return this({/* updated properties */});
} else {
  // Create resource logic
  // ...
  return this({/* initial properties */});
}
```

## `this.destroy()`

When a resource is being deleted, you must return `this.destroy()` to signal that the resource deletion process is complete.

> [!TIP]
> This also enables type inference since `this.destroy()` returns `never`, so the type of the resource can be inferred from the return type of the function.

## `this({..})`

To construct the resource (including your properites and Alchemy's intrinsic properties), call `this(props)` with your output properties:

```ts
return this({/* updated properties */});
```

What's going on here? `this` is a function? Huh?

Alchemy resources are implemented with pure functions, but are designed to emulate classes (except with an async constructor that implements a CRUD lifecycle handler).

`this` is analagous to `super` in a standard class:
```ts
return super({/* updated properties */});
```

> [!TIP]
> If this syntax freaks you out too much, it is also aliased as `this.create`:
> ```ts
> return this.create({/* updated properties */});
> ```

## Testing

See the [Testing](./testing.md) documentation for a comprehensive walkthrough on how to test your own resources.
</file>

<file path="alchemy-web/docs/concepts/scope.md">
---
order: 2
---

# Scope

Scopes in Alchemy are hierarchical containers that organize resources and other scopes, similar to a file system.

```typescript
// Scope hierarchy
app (Application Scope)
 dev (Stage Scope)
    api (Nested Scope)
    database (Resource)
 prod (Stage Scope)
```

## Application Scope

The top-level scope created using the `alchemy()` function:

```typescript
import alchemy from "alchemy";

// Create root scope
const app = await alchemy("my-app");

// Create a resource in this scope
const file = await File("config", { path: "./config.json", content: "{}" });
```

State directory structure:
```
.alchemy/
  my-app/  # Application scope
    $USER/ # Default stage (username)
      config.json
```

## Stage Scope

A scope directly under the application scope for separating environments:

```typescript
// Create app with explicit stage
const app = await alchemy("my-app", {
  stage: "prod"
});

// Resource in prod stage
const database = await Database("main", { /* props */ });
```

```
.alchemy/
  my-app/
    prod/  ## Stage scope
      main.json
```

## Resource Scope

Each resource gets its own scope for managing child resources:

```typescript
export const WebApp = Resource(
  "my::WebApp",
  async function (this, id, props) {
    // Child resources automatically scoped to this WebApp
    const database = await Database("db", {});
    const apiGateway = await ApiGateway("api", {});
    
    return this({
      id,
      url: apiGateway.url,
      dbConnectionString: database.connectionString
    });
  }
);

// Usage
const app = await WebApp("my-app", {});
```

```
.alchemy/
  my-app/
    dev/
      my-app.json
      my-app/  # Resource scope
        db.json
        api.json
```

## Nested Scope

Create custom nested scopes to organize related resources:

```typescript
// Create nested scopes
await alchemy.run("backend", async () => {
  await ApiGateway("api", {});
  await Function("handler", {});
});

await alchemy.run("frontend", async () => {
  await Bucket("assets", {});
});
```

```
.alchemy/
  my-app/
    dev/
      backend/
        api.json
        handler.json
      frontend/
        assets.json
```

## Scope Finalization

When finalized, scopes delete any orphaned resources (resources in state but not in code):

```typescript
const app = await alchemy("my-app");

await Bucket("assets", {});
// If a previously existing resource is removed from code,
// it will be deleted during finalization

await app.finalize(); // Manual finalization
```

Application scopes need manual finalization, but nested scopes finalize automatically when their execution completes. 

## Test Scope

Alchemy provides isolated test scopes that automatically clean up after tests:

```typescript
import { alchemy } from "../../src/alchemy";
import "../../src/test/bun";

// Create test scope from filename
const test = alchemy.test(import.meta);

// Each test gets an isolated sub-scope
test("create resource", async (scope) => {
  const resource = await Resource("test-resource", {});
  expect(resource.id).toBeTruthy();
  // Resources auto-cleaned when test completes
});
```

Example from Cloudflare Worker tests:

```typescript
import { alchemy } from "../../src/alchemy";
import { Worker } from "../../src/cloudflare/worker";
import "../../src/test/bun";
import { BRANCH_PREFIX } from "../util";

const test = alchemy.test(import.meta, { prefix: BRANCH_PREFIX });

describe("Worker Resource", () => {
  test("create worker", async (scope) => {
    const worker = await Worker(`${BRANCH_PREFIX}-test-worker`, {
      script: "// Worker code",
      format: "esm",
    });
    
    expect(worker.id).toBeTruthy();
  });
});
```

For more details on testing with Alchemy, see [Testing in Alchemy](./testing.md).
</file>

<file path="alchemy-web/docs/concepts/secret.md">
---
order: 4
---

# Secret

Alchemy provides built-in mechanisms for handling sensitive data securely. This guide explains how to manage secrets in your Alchemy resources.

## What are Secrets?

Secrets in Alchemy are sensitive values that need special handling to prevent exposure in logs, state files, or source code. Examples include:

- API keys and tokens
- Passwords and credentials
- Private certificates
- Connection strings with credentials

## Encryption Password

Secrets are encrypted using a password that you provide when initializing your Alchemy app:

```typescript
const app = await alchemy("my-app", {
  stage: "dev",
  password: process.env.SECRET_PASSPHRASE,
});
```

> [!IMPORTANT]
> Always store your encryption password securely and never commit it to source control.

## Using the alchemy.secret() Function

The primary way to handle secrets in Alchemy is with the `alchemy.secret()` function:

```typescript
// Create a secret from an environment variable
const apiKey = alchemy.secret(process.env.API_KEY);
```

When a secret is stored in state, it is automatically encrypted:

```json
{
  "props": {
    "key": {
      "@secret": "Tgz3e/WAscu4U1oanm5S4YXH..."
    }
  }
}
```

## Multiple Secret Values

You can create multiple secrets in your application:

```typescript
// Create multiple secrets from environment variables
const apiKey = alchemy.secret(process.env.API_KEY);
const databaseUrl = alchemy.secret(process.env.DATABASE_URL);
const jwtSecret = alchemy.secret(process.env.JWT_SECRET);
```

## Using Secrets in Resources

Secrets can be passed to resources like Cloudflare Workers. First, define your worker script:

```typescript
// worker-script.ts
export default {
  async fetch(request, env, ctx) {
    const url = new URL(request.url);
    
    if (url.pathname.startsWith('/env/')) {
      const varName = url.pathname.split('/env/')[1];
      const value = env[varName];
      return new Response(value || 'undefined', { 
        status: 200,
        headers: { 'Content-Type': 'text/plain' }
      });
    }
    
    return new Response('Secret is safe: ' + env.API_KEY, { status: 200 });
  }
};
```

Then use the script and bind the secrets:

```typescript
// Use the script with secrets
const worker = await Worker("multi-secret-worker", {
  name: "multi-secret-worker",
  script: workerScript,
  format: "esm",
  bindings: {
    API_KEY: alchemy.secret(process.env.API_KEY),
    DATABASE_URL: alchemy.secret(process.env.DATABASE_URL),
    JWT_SECRET: alchemy.secret(process.env.JWT_SECRET)
  }
});
```
</file>

<file path="alchemy-web/docs/concepts/state.md">
---
order: 3
---

# State

Alchemy uses a transparent and pluggable state management system to track resource lifecycles and enable idempotent operations. It's designed to be simple, with multiple backend options ranging from local files to cloud storage.

## What is State in Alchemy?

State in Alchemy consists of resource data that tracks the current status, properties, and outputs of each resource. By default, it's stored in JSON files in a `.alchemy` directory, organized by app and stage:

```
.alchemy/
  my-app/
    dev/
      my-resource.json
      my-other-resource.json
```

## State File Structure

Each state file contains the full information about a resource:

```json
{
  "provider": "service::ResourceName",
  "data": {},
  "status": "updated",
  "output": {
    "id": "resource-123",
    "name": "My Resource",
    "createdAt": 1679012345678
  },
  "props": {
    "name": "My Resource",
    "description": "This is a test resource"
  }
}
```

The state file includes:

- **provider**: The resource type identifier
- **data**: Internal provider-specific data
- **status**: Current lifecycle status (created, updated, deleted)
- **output**: The resource's current output values
- **props**: The resource's input properties

## How Alchemy Uses State

Alchemy uses state to determine the appropriate action for each resource:

1. **No state file**: The resource is created
2. **State exists + props unchanged**: The resource is skipped
3. **State exists + props changed**: The resource is updated
4. **Resource removed from code**: The resource is deleted

This approach enables idempotent operations - running the same code multiple times produces the same result, avoiding duplicate resource creation.

## State Location

By default, Alchemy stores state files in the `.alchemy` directory in your project root. This approach has several benefits:

- **Transparency**: State files are plain JSON and can be inspected and modified manually
- **Versioning**: State can be committed to source control with your code
- **Portability**: No external service dependencies required

## State Inspection

State files can be directly inspected:

```bash
cat .alchemy/my-app/dev/my-resource.json
```

This transparency helps with debugging and understanding what Alchemy is doing.

## Customizing State Storage

Alchemy supports multiple state storage backends. You can use the default file system store or integrate with cloud services like Cloudflare R2:

```typescript
// Example with Cloudflare R2 state store
const app = await alchemy("my-app", {
  stage: "prod",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  stateStore: (scope) => new R2RestStateStore(scope, {
    apiKey: alchemy.secret(process.env.CLOUDFLARE_API_KEY),
    email: process.env.CLOUDFLARE_EMAIL,
    bucketName: process.env.CLOUDFLARE_BUCKET_NAME!,
  })
});
```

> [!TIP]
> Learn how to implement your own state storage in [Custom State Stores Guide](../guides/custom-state-store.md)

## Security and Secrets

State files may contain sensitive information. Alchemy provides a mechanism to encrypt sensitive values using the `alchemy.secret()` function:

```typescript
const apiKey = alchemy.secret(process.env.API_KEY);

await ApiResource("my-api", {
  key: apiKey
});
```

Secrets are encrypted in state files:

```json
{
  "props": {
    "key": {
      "@secret": "Tgz3e/WAscu4U1oanm5S4YXH..."
    }
  }
}
```

> [!IMPORTANT]
> Always use `alchemy.secret()` for sensitive values to prevent them from being stored in plain text.

> [!NOTE]
> Learn more about secrets management in [Concepts: Secrets](./secret.md)
</file>

<file path="alchemy-web/docs/concepts/testing.md">
---
order: 5
---

# Testing

Alchemy resources are easy to test since they're just functions, but Alchemy also offers a simple `alchemy.test` utility to help isolate your [Scopes](../concepts/scope.md) for each test suite.

## Test Setup

Import alchemy's test utility and your resource:

```typescript
import { describe, expect } from "bun:test";
import alchemy, { destroy } from "alchemy";
import { Database } from "../src/neon/database";

// make sure to augment `alchemy` by importing your preferred testing utility
import "alchemy/test/bun";
```

## Test Scope Creation

Create a `test` function at the top of your test suite:

```typescript
// Create test scope using filename
const test = alchemy.test(import.meta);
```

We pass `import.meta` so that all the resources created in this test suite will be isolated from other tests.

## Resource Test Implementation

Now, create a test as you ordinarily would:

```typescript
test("create, update, and delete database", async (scope) => {
  // ..
});
```

Note how our test is passed a `scope` value - we'll use that at the end to clean up our resources.

Inside our test, we can simple create and update our resources, make assertions, etc.:
```ts
// Create resource
let database = await Database(testId, {
  name: `${testId}-db`,
  // Other required properties...
});

// Test assertions
expect(database.id).toBeTruthy();

// Update resource
database = await Database(testId, {
  // Updated properties...
});
```

Finally, wrap all of this in a `try-finally` so that we can ensure our test resources are cleaned up.

```ts
try {
  // (create, update and assertions)
} finally {
  // delete all resources
  await destroy(scope);
  
  // Verify resource was deleted if you want to
}
```

> [!TIP]
> It's recommended to use a `try-finally` so that you can assert the resource was actually deleted.
</file>

<file path="alchemy-web/docs/guides/cloudflare-auth.md">
---
order: 0
---

# Cloudflare Auth

There are three supported ways of authorizing Alchemy with Cloudflare:
1. API Token - a token you create once with limited scopes
2. OAuth - a token created by `wrangler login`
3. Global API Key (legacy) - the global, highly permissive API key

## API Token

First you need to [create an API Token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) and then use it in your Alchemy app.

By default, Alchemy will use the `CLOUDFLARE_API_TOKEN` environment variable if set.

You can store the token in your `.env` file
```sh
CLOUDFLARE_API_TOKEN=<token>
```

Or set when running your script:
```sh
CLOUDFLARE_API_TOKEN=<token> bun ./alchemy.run.ts
```

You can explciitly set an `apiToken` when creating a Cloudflare Resource, such as a `Worker`:

```ts
await Worker("my-worker", {
  apiToken: alchemy.secret(process.env.MY_TOKEN)
});
```

## OAuth Token

If you don't specify `CLOUDFLARE_API_KEY` or `CLOUDFLARE_API_TOKEN`, then Alchemy will use the OAuth Token and Refresh Token to authenticate with Cloudflare.

First, make sure you've logged in with wrangler:
```sh
wrangler login
```

Then, run your script (without `CLOUDFLARE_API_KEY` or `CLOUDFLARE_API_TOKEN` environment variables):
```sh
bun ./alchemy.run.ts
```

## Global API Key

After you verify your Cloudflare Account's Email, you will be given a [Global API Key](https://developers.cloudflare.com/fundamentals/api/get-started/keys/).

> [!CAUTION]
> These keys have several limitations that make them less secure than API tokens. Whenever possible, use API tokens to interact with the Cloudflare API. 
>
> See [Cloudflare's API Docs](https://developers.cloudflare.com/api/).

By default, Alchemy will use the `CLOUDFLARE_API_KEY` environment variable if set.

You can store the token in your `.env` file
```sh
CLOUDFLARE_API_KEY=<token>
```

Or set when running your script:
```sh
CLOUDFLARE_API_KEY=<token> bun ./alchemy.run.ts
```

You can explciitly set an `apiKey` when creating a Cloudflare Resource, such as a `Worker`:

```ts
await Worker("my-worker", {
  apiKey: alchemy.secret(process.env.MY_GLOBAL_KEY)
});
```

## Email

When using [Global API Keys](#global-api-key), Alchemy must be configured with the API Key's email.

By default, Alchemy will use the `CLOUDFLARE_EMAIL` if set

```sh
CLOUDFLARE_EMAIL=me@example.com CLOUDFLARE_API_KEY=<token> bun ./alchemy.run.ts
```

You can explicitly set `email` when creating a Cloudlfare Resource:

```ts
await Worker("my-worker", {
  apiKey: alchemy.secret(process.env.MY_GLOBAL_KEY),
  email: "me@example.com"
});
```

## Account ID

By default, Alchemy will resolve the account ID from the API or OAuth token.

```sh
# will use wrangler login and resolve the first account you have acces to (ideal for personal accounts)
bun ./alchemy.run.ts
```

> [!CAUTION]
> If your token has access to more than one account, Alchemy chooses the first one arbitrarily.

You can override the default account ID with the `CLOUDFLARE_ACCOUNT_ID` environment variable:

```sh
CLOUDFLARE_ACCOUNT_ID=<account-id> bun ./alchemy.run.ts
```

Or by setting `accountId` when creating a Cloudflare Resource:
```ts
await Worker("my-worker", {
  accountId: "my-account-id",
});
```
</file>

<file path="alchemy-web/docs/guides/cloudflare-durable-objects.md">
---
order: 5
---

# Durable Object

This guide explains how to create, bind and use Cloudflare Durable Objects within your Worker scripts.

> [!TIP]
> We assume you're familiar with Cloudflare Durable Objects already. If not, read [Cloudflare Durable Objects](https://developers.cloudflare.com/durable-objects/) first.

## Create a Durable Object Namespace

At a bare minimum, you need to create a `DurableObjectNamespace` object as a stable reference to your Durable Object namespace.

```ts
import { DurableObjectNamespace } from "alchemy/cloudflare";

const counter = new DurableObjectNamespace("counter", {
  className: "Counter",
  // whether you want a sqllite db per DO (usually yes!)
  sqlite: true
});
```

If you're paying close attention, you'll notice that we call `new DurableObjectNamespace` instead of `await DurableObjectNamespace` like you might have come to expect from Alchemy Resources.

This is because of oddities in Cloudflare's API design. Durable Object namespaces are not resources in the traditional sense because they cannot exist without a Worker.

## Bind the Durable Object to a Worker

Instead, you create a Durable Object namespace and then bind it to your Worker:

```ts
export const worker = await Worker("Worker", {
  name: "my-worker",
  entrypoint: "./index.ts"
  bindings: {
    // bind the Durable Object namespace to your Worker
    COUNTER: counter,
  },
});
```

## Implement the Durable Object class

Now, we have a Worker with a Durable Object running within it. To use this Durable Object, our Worker script must include a class for the Durable Object and then some code in the `fetch` handler to interact with it.

A simple Durable Object may look like so:

```ts
export class Counter {
  private state: DurableObjectState;
  private count: number;

  constructor(state, env) {
    this.state = state;
    this.count = 0;
  }

  async fetch(request) {
    const url = new URL(request.url);
    const path = url.pathname;

    // Retrieve current count
    this.count = await this.state.storage.get("count") || 0;

    if (path === "/increment") {
      this.count++;
      await this.state.storage.put("count", this.count);
    } else if (path === "/decrement") {
      this.count--;
      await this.state.storage.put("count", this.count);
    }

    return Response.json({ count: this.count });
  }
}
```

> [!TIP]
> See Cloudflare's [Durable Objects Guide](https://developers.cloudflare.com/durable-objects/get-started/) for more details on implementing Durable Objects.

## Access the Durable Object from your Worker

Now, our `fetch` handler can get a Durable Object instance via the `COUNTER` binding:

```ts
import { env } from "cloudflare:workers";

export default {
  async fetch(request: Request) {
    const url = new URL(request.url);
    
    // Create an ID for the Counter (different IDs = different Counter instances)
    const id = env.COUNTER.idFromName("A");
    
    // Get a stub for the Counter instance
    const stub = env.COUNTER.get(id);
    
    // Forward the request to the Durable Object
    return stub.fetch(request);
  },
};
```

## Type-safe Bindings

Remember, for `env.` to be type-safe, you need to configure your `src/env.d.ts` to infer the types from your worker:

```ts
// src/env.d.ts
import type { worker } from "./alchemy.run";

export type WorkerEnv = typeof worker.Env;

declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends WorkerEnv {}
  }
}
```

> [!TIP]
> See the [Bindings](../concepts/bindings.md) for more information.
</file>

<file path="alchemy-web/docs/guides/cloudflare-nuxt-pipeline.md">
---
order: 4
---

# Nuxt

This guide walks through deploying a full-stack Nuxt 3 application with a backend Pipeline to Cloudflare using Alchemy.

## Create a new Nuxt 3 Project

Start by creating a new Nuxt 3 project:

```sh
bun create nuxt-app 
cd my-nuxt-app
bun install
```

Install alchemy and Cloudflare:

```sh
bun add alchemy cloudflare
```

## Configure Nuxt for Cloudflare

Update `nuxt.config.ts` to work with Cloudflare Workers:

```typescript
// nuxt.config.ts
export default defineNuxtConfig({
  compatibilityDate: "2025-04-21",
  devtools: { enabled: true },
  nitro: {
    preset: "cloudflare-module",
    prerender: {
      routes: ["/"],
      autoSubfolderIndex: false,
    },
  },
});
```

## Create `alchemy.run.ts`

Create an `alchemy.run.ts` file in the root of your project. We'll build this file step by step:

### 1. Set up imports and initialize app

```typescript
// ./alchemy.run.ts
import alchemy from "alchemy";
import { Pipeline, R2Bucket, Nuxt } from "alchemy/cloudflare";

const R2_BUCKET_NAME = "example-bucket";
const PIPELINE_NAME = "example-pipeline";

const app = await alchemy("nuxt-pipeline-app", {
  stage: process.env.USER ?? "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  quiet: !process.argv.includes("--verbose"),
  password: process.env.ALCHEMY_PASS,
});
```

### 2. Create R2 bucket for data storage

```typescript
const bucket = await R2Bucket("bucket", {
  name: R2_BUCKET_NAME,
});
```

### 3. Configure data pipeline

```typescript
const pipeline = await Pipeline("pipeline", {
  name: PIPELINE_NAME,
  source: [{ type: "binding", format: "json" }],
  destination: {
    type: "r2",
    format: "json",
    path: {
      bucket: bucket.name,
    },
    credentials: {
      accessKeyId: alchemy.secret(process.env.R2_ACCESS_KEY_ID),
      secretAccessKey: alchemy.secret(process.env.R2_SECRET_ACCESS_KEY),
    },
    batch: {
      maxMb: 10,
      maxSeconds: 5,
      maxRows: 100,
    },
  },
});
```

> [!CAUTION]
> Set `R2_ACCESS_KEY_ID`, `R2_SECRET_ACCESS_KEY`, and `ALCHEMY_PASS` environment variables before deployment.

### 4. Configure Nuxt website with bindings

```typescript
export const website = await Nuxt("website", {
  bindings: {
    R2_BUCKET: bucket,
    PIPELINE: pipeline,
  },
});

console.log({
  url: website.url,
});

await app.finalize();
```


## Infer Binding Types

Create an `src/env.d.ts` file to support type hints for Cloudflare bindings:

```typescript
// src/env.d.ts
/// <reference types="@cloudflare/workers-types" />

import type { website } from './alchemy.run';

export type WorkerEnv = typeof website.Env;

declare module 'cloudflare:workers' {
  namespace Cloudflare {
    export interface Env extends WorkerEnv {}
  }
}
```

## Add API Route for Pipeline

Create a Nuxt server API route to send data to the pipeline:

```typescript
// server/api/pipeline.post.ts
import { env } from "cloudflare:workers";

export default defineEventHandler(async (event) => {
  try {
    const body = await readBody(event);
    const pipeline = env.PIPELINE;
    const data = body.data;

    if (!data) {
      throw new Error("Missing 'data' property in request body");
    }

    await pipeline.send([{ value: data }]);

    return { success: true, message: "Data sent to pipeline." };
  } catch (error) {
    console.error("Error sending data to pipeline:", error);
    throw createError({
      statusCode: 500,
      statusMessage: error instanceof Error ? error.message : "Pipeline error",
    });
  }
});
```

## Create Frontend Interface

Create a simple form to interact with the pipeline:

```vue
<!-- pages/index.vue -->
<template>
  <div>
    <h1>Nuxt 3 + Alchemy + Cloudflare Pipeline Demo</h1>
    <form @submit.prevent="sendToPipeline">
      <label for="dataInput">Data to send:</label>
      <input id="dataInput" v-model="dataToSend" type="text" required />
      <button type="submit" :disabled="loading">Send to Pipeline</button>
    </form>
    <p v-if="message">{{ message }}</p>
    <p v-if="error" style="color: red">{{ error }}</p>
  </div>
</template>

<script setup lang="ts">
import { ref } from "vue";

const dataToSend = ref("");
const loading = ref(false);
const message = ref("");
const error = ref("");

async function sendToPipeline() {
  loading.value = true;
  message.value = "";
  error.value = "";

  try {
    const response = await fetch("/api/pipeline", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({ data: dataToSend.value }),
    });

    const result = await response.json();

    if (!response.ok) {
      throw new Error(result.statusMessage || "Failed to send data");
    }

    message.value = result.message || "Data sent successfully!";
    dataToSend.value = "";
  } catch (err) {
    error.value =
      err instanceof Error ? err.message : "An unknown error occurred.";
    console.error("Error sending to pipeline:", err);
  } finally {
    loading.value = false;
  }
}
</script>

<style scoped>
form {
  display: flex;
  flex-direction: column;
  gap: 10px;
  max-width: 300px;
  margin-top: 20px;
}
button {
  padding: 10px;
  background-color: #007bff;
  color: white;
  border: none;
  border-radius: 4px;
  cursor: pointer;
}
</style>
```


## Deploy Your Application

Login to Cloudflare:

```sh
wrangler login
```

Run your Alchemy script to deploy the application:

```sh
bun ./alchemy.run
```

It should output the URL of your deployed site:

```sh
{
  url: "https://your-site.your-account.workers.dev"
}
```

Click the URL to see your site. Test sending data via the form; it should appear in your R2 bucket shortly after.

## Local Development

To run your application locally, use the Nuxt development server:

```sh
bun run dev
```

This will start a local development server:

```sh
Nuxt 3.9.0 with Nitro 2.8.1
 
   Local:    http://localhost:3000/
   Network:  use --host to expose this
```

## Tear Down

When you're finished experimenting, you can tear down the application:

```sh
bun ./alchemy.run --destroy
```
</file>

<file path="alchemy-web/docs/guides/cloudflare-queue.md">
---
order: 6
---

# Queue

This guide explains how to create and use Cloudflare Queues with your Worker applications.

> [!TIP]
> We assume you're familiar with Cloudflare Queues already. If not, read [Cloudflare Queues](https://developers.cloudflare.com/queues/) first.

## Create a Queue

Create a Queue with a type for the message payload:

```ts
import { Queue } from "alchemy/cloudflare";

// Define the message payload type
export const queue = await Queue<{
  name: string;
  email: string;
}>("my-worker-queue");
```

## Configure Queue Producer

Bind the Queue to your Worker as an environment variable to send messages.

```ts
import { Worker } from "alchemy/cloudflare";

export const worker = await Worker("my-worker", {
  entrypoint: "./src/worker.ts",
  bindings: {
    QUEUE: queue, // Bind queue as QUEUE environment variable
  },
});
```

## Send Messages Using Producer

Access the Queue from your Worker's fetch handler to send messages.

```ts
// src/worker.ts
import type { worker } from "../alchemy.run";

export default {
  async fetch(request: Request, env: typeof worker.Env) {
    // Send a message to the queue
    await env.QUEUE.send({
      name: "John Doe",
      email: "john.doe@example.com",
    });
    
    return new Response("Ok");
  },
};
```

## Configure Queue Consumer

Register your Worker as a consumer of the Queue by adding it to eventSources.

```ts
import { Worker } from "alchemy/cloudflare";

export const worker = await Worker("my-worker", {
  // add the event source
  eventSources: [queue],
});
```

## Process Messages Using Consumer

Implement the queue handler using a type-safe batch parameter.

```ts
// src/worker.ts
import type { queue, worker } from "../alchemy.run";

export default {
  // other handlers like fetch...
  
  // Process queue messages with proper type safety
  async queue(batch: typeof queue.Batch, env: typeof worker.Env) {
    // Process each message in the batch
    for (const message of batch.messages) {
      console.log(message);
      // Acknowledge individual message
      message.ack();
    }
    
    // Or acknowledge all messages at once
    // batch.ackAll();
  },
};
```

> [!TIP]
> Using `typeof queue.Batch` provides better type safety than generic types, as it directly references the typed queue you created.

## Generate Wrangler Config

Create the Wrangler configuration file to include the Queue binding.

```ts
import { WranglerJson } from "alchemy/cloudflare";

await WranglerJson("wrangler.jsonc", {
  worker,
});
```

## Type-safe Environment

Set up type definitions for your Worker environment for better type safety.

```ts
// src/env.d.ts
import type { worker } from "./alchemy.run";

export type WorkerEnv = typeof worker.Env;

declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends WorkerEnv {}
  }
}
```

## Complete Example

A complete implementation example showing both producer and consumer roles in the same Worker.

```ts
// alchemy.run.ts
import alchemy from "alchemy";
import { Queue, Worker, WranglerJson } from "alchemy/cloudflare";

const app = await alchemy("queue-example");

// Create a typed queue with export
export const queue = await Queue<{
  name: string;
  email: string;
}>("example-worker-queue");

// Create worker as both producer and consumer
export const worker = await Worker("example-worker", {
  entrypoint: "./src/worker.ts",
  bindings: {
    QUEUE: queue,  // Producer: bind queue for sending messages
  },
  eventSources: [queue],  // Consumer: register worker to receive messages
});

// Generate wrangler config
await WranglerJson("wrangler.jsonc", {
  worker,
});

await app.finalize();
```

```ts
// src/worker.ts
import type { queue, worker } from "../alchemy.run";

export default {
  // Producer: send messages
  async fetch(request: Request, env: typeof worker.Env) {
    await env.QUEUE.send({
      name: "John Doe",
      email: "john.doe@example.com",
    });
    return new Response("Ok");
  },
  
  // Consumer: process messages with type-safe batch
  async queue(batch: typeof queue.Batch, env: typeof worker.Env) {
    for (const message of batch.messages) {
      console.log(message);
      message.ack();
    }
    batch.ackAll();
  },
};
```
</file>

<file path="alchemy-web/docs/guides/cloudflare-redwood.md">
---
order: 3
---

# Redwood

This guide demonstrates how to deploy a Redwood application with Drizzle to Cloudflare using Alchemy.

## Create a new Redwood Project

Start by creating a new Redwood project using the Drizzle template:

```bash
bunx degit redwoodjs/example-drizzle my-cloudflare-app
cd my-cloudflare-app
bun install
```

Install `cloudflare` and `alchemy`:
```sh
bun add alchemy cloudflare
```

## Create `alchemy.run.ts`

```ts
// ./alchemy.run.ts
import "alchemy/cloudflare";
import alchemy from "alchemy";
import { D1Database, Redwood } from "alchemy/cloudflare";

const app = await alchemy("cloudflare-redwood", {
  stage: process.env.USER ?? "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  quiet: process.argv.includes("--verbose") ? false : true,
});

// (resources go here)

await app.finalize(); // must be at end
```

> [!NOTE]
> See the [Getting Started](../getting-started) guide if this is unfamiliar.

## Create Redwood and Database

Import the `Redwood` and `D1Database` resources to configure your application:

```ts
const database = await D1Database("redwood-db", {
  name: "redwood-db",
  migrationsDir: "drizzle",
});

export const website = await Redwood("redwood-website", {
  bindings: {
    DB: database,
  },
});
```

Log out the website's URL:
```ts
console.log({
  url: website.url
})
```

## Deploy Redwood Application

Login to Cloudflare:

```sh
wrangler login
```

Run `alchemy.run.ts` script to deploy:

```sh
bun ./alchemy.run
```

It should log out the URL of your deployed site:
```sh
{
  url: "https://your-site.your-sub-domain.workers.dev",
}
```

Click the endpoint to see your Redwood application!

## Working with Drizzle Schema and Migrations

The Redwood Drizzle template includes a database schema defined using Drizzle ORM. Let's explore and modify the schema.

### Understanding the Existing Schema

The schema files are located in the `api/db` directory. Take a look at the existing schema:

```sh
cat api/db/schema.ts
```

The default schema typically includes a basic user model. Let's modify this schema to add a posts table for a blog.

### Modifying the Schema

Edit the schema file to add a posts table:

```ts
// api/db/schema.ts
import { sql } from "drizzle-orm";
import { integer, sqliteTable, text } from "drizzle-orm/sqlite-core";

export const users = sqliteTable("users", {
  id: text("id").primaryKey(),
  name: text("name"),
  email: text("email").notNull(),
  hashedPassword: text("hashed_password"),
  salt: text("salt"),
  resetToken: text("reset_token"),
  resetTokenExpiresAt: integer("reset_token_expires_at"),
  createdAt: integer("created_at", { mode: "timestamp" }).default(sql`CURRENT_TIMESTAMP`),
  updatedAt: integer("updated_at", { mode: "timestamp" }).default(sql`CURRENT_TIMESTAMP`),
});

// Add a new posts table
export const posts = sqliteTable("posts", {
  id: text("id").primaryKey(),
  title: text("title").notNull(),
  body: text("body").notNull(),
  userId: text("user_id").references(() => users.id),
  createdAt: integer("created_at", { mode: "timestamp" }).default(sql`CURRENT_TIMESTAMP`),
  updatedAt: integer("updated_at", { mode: "timestamp" }).default(sql`CURRENT_TIMESTAMP`),
});
```

### Generating a Migration

After modifying the schema, generate a migration:

```sh
bun migrate:new
```

This will create a new migration file in the `drizzle` directory.

### Deploy with Migrations

Now that we've modified the schema and generated migrations, let's redeploy our application with the updated database schema:

```sh
bun ./alchemy.run
```

The D1Database resource will automatically apply migrations from the directory we specified earlier (`migrationsDir: "drizzle"`).


## Local Development

Redwood has integrated development tooling. Run the development server:

```sh
bun run dev
```

This will start both the web and API sides of your Redwood application:

```sh
  VITE v6.3.2  ready in 2848 ms

    Local:   http://localhost:5173/
    Network: use --host to expose
    Debug:   http://localhost:5173/__debug
    press h + enter to show help
^C%
```

## Tear Down

That's it! You can now tear down the app (if you want to):

```bash
bun ./alchemy.run --destroy
```
</file>

<file path="alchemy-web/docs/guides/cloudflare-tanstack-start.md">
---
order: 2
---

# TanStack Start

This guide walks through how to deploy a TanStack Start application to Cloudflare Workers with Alchemy.

## Create a new TanStack Start Project

Start by creating a TanStack Start project:

```sh
bunx gitpick TanStack/router/tree/main/examples/react/start-basic start-basic
cd start-basic
bun install
```

> [!NOTE]
> See TanStack's [Quick Start](https://tanstack.com/start/latest/docs/framework/react/quick-start) guide for more details on TanStack Start applications.

## Install Alchemy and Cloudflare

Install the required dependencies:

```sh
bun add alchemy cloudflare
```

## Create `alchemy.run.ts`

Create an `alchemy.run.ts` file in the root of your project:

```ts
// ./alchemy.run.ts
import "alchemy/cloudflare";
import alchemy from "alchemy";
import { TanStackStart } from "alchemy/cloudflare";

const app = await alchemy("tanstack-app", {
  stage: process.env.USER ?? "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  quiet: process.argv.includes("--verbose") ? false : true,
});

// (resources go here)

await app.finalize(); // must be at end
```

## Add the TanStackStart Resource

Add the TanStackStart resource to your `alchemy.run.ts` file just before the `finalize()` call:

```ts
const website = await TanStackStart("tanstack-website", {
  command: "bun run build"
});

console.log({
  url: website.url,
});
```

## Configure TanStack for Cloudflare

TanStack Start needs configuration to work properly with Cloudflare Workers. Update your `app.config.ts` file:

```ts
// app.config.ts
import { defineConfig } from "@tanstack/react-start/config";
import tsConfigPaths from "vite-tsconfig-paths";
import { cloudflareWorkersDevEnvironmentShim } from "alchemy/cloudflare";

const external = ["node:async_hooks", "cloudflare:workers"];

export default defineConfig({
  tsr: {
    appDirectory: "src",
  },
  server: {
    preset: "cloudflare-module",
    experimental: {
      asyncContext: true,
    },
    unenv: {
      external,
    },
  },
  vite: {
    plugins: [
      // Provides a polyfill for Cloudflare Workers env during development
      cloudflareWorkersDevEnvironmentShim(),
      // Resolves paths based on tsconfig
      tsConfigPaths({
        projects: ["./tsconfig.json"],
      }),
    ],
    build: {
      rollupOptions: {
        external,
      },
    },
  },
});
```

> [!CAUTION]
> Make sure to configure this shim or else local development won't work for server functions or middleware.
> ```ts
> // Provides a polyfill for Cloudflare Workers env during development
> cloudflareWorkersDevEnvironmentShim(),
> ```

## Modify DEPLOY_URL

Modify `./src/utils/users.tsx` to support non-local domains:

```ts
// must check if window is not undefined since the bundler also places this code server-side
export const DEPLOY_URL = typeof window !== "undefined" ? window.location.origin : "http://localhost:3000";
```

## Deploy Your Application

Login to Cloudflare:

```sh
wrangler login
```

Run your Alchemy script to deploy the application:

```sh
bun ./alchemy.run
```

It should output the URL of your deployed site:

```sh
{
  url: "https://your-site.your-sub-domain.workers.dev",
}
```

Click the URL to see your TanStack Start application live!

## Local Development

To run your application locally, use the TanStack Start development server:

```sh
bun run dev
```

This will start a local development server with hot module reloading:

```sh
  VITE v5.0.10  ready in 237 ms

    Local:   http://localhost:5173/
    Network: use --host to expose
    press h + enter to show help
```

## Tear Down

When you're finished experimenting, you can tear down the application:

```bash
bun ./alchemy.run --destroy
```

This will remove all Cloudflare resources created by this deployment.
</file>

<file path="alchemy-web/docs/guides/cloudflare-vitejs.md">
---
order: 1
---

# Vite

This guide demonstrates how to deploy a Vite.js React TypeScript application with a Hono API to Cloudflare using Alchemy.

## Create a new Vite.js Project

Start by creating a new Vite.js project:

```bash
bun create vite my-cloudflare-app --template react-ts
cd my-cloudflare-app
bun install
```

Install `cloudflare` and `alchemy`:
```sh
bun add alchemy cloudflare
```

Update your `tsconfig.json` to register `@cloudflare/workers-types` globally:

```json
{
  "compilerOptions": {
    // make sure to register this globally
    "types": ["@cloudflare/workers-types",],
  },
  "include": ["src/**/*.ts", "src/**/*.tsx"]
}
```

## Create `alchemy.run.ts`

```ts
// ./alchemy.run.ts
import alchemy from "alchemy";

const app = await alchemy("cloudflare-vite", {
  stage: process.env.USER ?? "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  quiet: process.argv.includes("--verbose") ? false : true,
});

// (resources go here)

await app.finalize(); // must be at end
```

> [!NOTE]
> See the [Getting Started](../getting-started) guide if this is unfamiliar.

## Create Vite

Import the `Vite` and configure your build command and assets directory:

```ts
import { Vite } from "alchemy/cloudflare";

export const website = await Vite("website", {
  // command to build the vite site (run vite build)
  command: "bun run build",
  // where the build command will store the assets
  assets: "./dist",
});
```

Log out the website's URL:
```ts
console.log({
  url: website.url
})
```

## Deploy Static Site

Login to Cloudflare:

```sh
wrangler login
```

Run `alchemy.run.ts` script to deploy:

```sh
bun ./alchemy.run
```

It should log out the URL of your deployed site:
```sh
{
  url: "https://your-site.your-sub-domain.workers.dev",
}
```

Click the endpoint to see your site!

## Add a Backend API

Create an entrypoint for your server, `src/index.ts` with a Hono app:

```ts
import { env } from "cloudflare:workers";

export const api = new Hono();

// create a route
api.get("/hello", (c) => c.text("Hello World"));

export default {
  async fetch(request: Request): Promise<Response> {
    return api.fetch(request)
  },
};
```

Update `Vite` to use our custom server entrypoint:

```ts
export const website = await Vite("website", {
  command: "bun run build",
  assets: "./dist",
  // configure our server's entrypoint
  main: "./src/index.ts"
});
```

## Deploy Static Site and API

Re-run to deploy the new worker code:

```sh
bun ./alchemy.run
```

Test the API route is set up correctly with `curl`:

```sh
curl https://your-site.workers.dev/api/hello
```

It should output:
```
Hello World
```

> [!TIP]
> You can call this API from your frontend code with `fetch`:
>
> ```ts
> await fetch(`${window.origin}/api/hello`)
> ```

## Local Development

Edit the `./vite.config.ts` file and configure the `cloudflare()` plugin:

```ts
import { cloudflare } from "@cloudflare/vite-plugin";
import react from "@vitejs/plugin-react";
import { defineConfig } from "vite";

// https://vite.dev/config/
export default defineConfig({
  plugins: [react(), cloudflare()],
});
```

Now you can run `vite dev`:
```sh
bun vite dev
```

The vite dev server will start as normal, along with your Worker and Cloudflare Resources running locally in miniflare (matching a deployment as closely as possible).

```sh
VITE v6.2.2  ready in 1114 ms

  Local:   http://localhost:5173/
  Network: use --host to expose
  Debug:   http://localhost:5173/__debug
  press h + enter to show help
```

## Tear Down

That's it! You can now tear down the app (if you want to):

```bash
bun ./alchemy.run --destroy
```
</file>

<file path="alchemy-web/docs/guides/cloudflare-workflows.md">
---
order: 5
---

# Workflow

This guide explains how to create, bind and use Cloudflare Workflows within your Worker scripts.

> [!TIP]
> We assume you're familiar with Cloudflare Workflows already. If not, read [Cloudflare Workflows](https://developers.cloudflare.com/workflows/) first.

## Create a Workflow

At a bare minimum, you need to create a `Workflow` object as a stable reference to your Workflow.

```ts
import { Workflow } from "alchemy/cloudflare";

const orderProcessor = new Workflow("orderProcessor");
```

If you're paying close attention, you'll notice that we call `new Workflow` instead of `await Workflow` like you might have come to expect from Alchemy Resources.

This is because of oddities in Cloudflare's API design. Workflows are not resources in the traditional sense because they cannot exist without a Worker.

## Bind the Workflow to a Worker

Instead, you create a Workflow object and then bind it to your Worker:

```ts
export const worker = await Worker("Worker", {
  name: "my-worker",
  entrypoint: "./index.ts"
  bindings: {
    // bind the workflow to your Worker
    ORDER_PROCESSOR: orderProcessor,
  },
});
```

## Implement the Workflow class

Now, we have a Worker with a Workflow running within it. To use this Workflow, our Worker script must include a class for the workflow and then some code in the `fetch` handler to trigger it.

A simple workflow may look like so:

```ts
export class OrderProcessor extends WorkflowEntrypoint {
  constructor(state, env) {
    this.state = state;
    this.env = env;
  }

  async run(event, step) {
    const shippingDetails = await step.do("process-shipping", async () => {
      return {
        success: true,
        shipmentId: event.payload.shipmentId,
        message: "Shipment scheduled successfully",
      };
    });
    return shippingDetails;
  }
}
```

> [!TIP]
> See Cloudflare's [Workflow Guide](https://developers.cloudflare.com/workflows/get-started/guide/) for more details on implementing workflows.

## Trigger the Workflow from your Worker

Now, our `fetch` handler can create a Workflow instance (start a workflow) via the `ORDER_PROCESSOR` binding:

```ts
import { env } from "cloudflare:workers";

export default {
  async fetch(request: Request) {
    const url = new URL(request.url);
    const params = { orderId: "test-123", amount: 99.99 };
    const instance = await env.ORDER_PROCESSOR.create(params);

    return Response.json({
      id: instance.id,
      details: await instance.status(),
      success: true,
      orderId: params.orderId,
      message: "Order processed successfully",
    });
  },
};
```

## Type-safe Bindings

Remember, for `env.` to be type-safe, you need to configure your `src/env.d.ts` to infer the types from your worker:

```ts
// src/env.d.ts
import type { worker } from "./alchemy.run";

export type WorkerEnv = typeof worker.Env;

declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends WorkerEnv {}
  }
}
```

> [!TIP]
> See the [Bindings](../concepts/bindings.md) for more information.
</file>

<file path="alchemy-web/docs/guides/custom-resources.md">
---
order: 6
---

# Custom Resources

In Alchemy, a Resource is "just a function". This makes it super easy to generate resources for your use-cases using Agentic IDEs like Cursor, Claude Code, Windsurf, etc.

## Cursorrules

To start generating resources, copy Alchemy's [.cursorrules](https://github.com/sam-goodwin/alchemy/blob/main/.cursorrules) into your repo

> [!NOTE]
> All of Alchemy's "built-in" resouces are generated this way, so it is tried and tested.

## Simple Prompt Example

As an example, let's show how easy it is to generate a resource for Neon's famous serverless `Database` Resource.

It usually doesn't take much to get 90% of the way there - a simple prompt with a link to the API docs is a good start:

> Create a Resource for managing a Neon Database
> See: https://api-docs.neon.tech/reference/createprojectbranchdatabase

This will generate the Resource implementation and tests.

## Resource Implememtation

See the [Resource Documentation](../concepts/resource.md) for a comprehensive overview of a Resource.

## Test Suite Implementation

See the [Testing Documentation](../concepts/testing.md) for a comprehensive overview of how to test your Resources.
</file>

<file path="alchemy-web/docs/guides/custom-state-store.md">
---
order: 7
---

# Custom State Store

Alchemy's state management system is designed to be pluggable, allowing you to implement your own storage backends. This guide walks you through creating a custom state store implementation.

> [!NOTE]  
> This guide builds on the concepts from [State Management](../concepts/state.md). Familiarize yourself with how Alchemy handles state before creating a custom state store.

## Understanding the StateStore Interface

All state stores in Alchemy implement the `StateStore` interface:

```typescript
export interface StateStore {
  /** Initialize the state container if one is required */
  init?(): Promise<void>;
  
  /** Delete the state container if one exists */
  deinit?(): Promise<void>;
  
  /** List all resources in the given stage. */
  list(): Promise<string[]>;
  
  /** Return the number of items in this store */
  count(): Promise<number>;
  
  /** Get a state by key */
  get(key: string): Promise<State | undefined>;
  
  /** Get multiple states by their keys */
  getBatch(ids: string[]): Promise<Record<string, State>>;
  
  /** Get all states in the store */
  all(): Promise<Record<string, State>>;
  
  /** Set a state for a key */
  set(key: string, value: State): Promise<void>;
  
  /** Delete a state by key */
  delete(key: string): Promise<void>;
}
```

## Consistency Requirements

Alchemy relies on consistent state operations, particularly for the `get` and `set` methods. When implementing a custom state store:

- **Strong Consistency**: Operations must be strongly consistent, especially between `get` and `set`. If you set a value and immediately get it, you should receive the updated value.
- **Atomicity**: State changes should be atomic to avoid partial updates that could corrupt the state.
- **Durability**: Once a state is set, it should be persisted reliably to avoid data loss.

These requirements ensure Alchemy correctly tracks resource state and makes appropriate decisions about resource lifecycle.

## Serialization and Special Types

Alchemy uses a special serialization system to handle JavaScript objects, dates, secrets, and other complex types. Always use the provided `serialize` and `deserialize` functions from Alchemy to properly handle these types:

```typescript
import { serialize, deserialize } from "alchemy";

// When storing state:
const serializedData = await serialize(this.scope, value);

// When retrieving state:
const state = await deserialize(this.scope, rawData) as State;
```

> [!IMPORTANT]
> For detailed information on Alchemy's serialization system, see the [Serialization and Deserialization](../advanced/serde.md) guide.

## Creating a Custom State Store

Let's walk through implementing a custom state store using a cloud storage service. We'll follow the pattern used in Alchemy's built-in state stores.

### Basic Structure

Your custom state store should:

1. Accept a scope in the constructor
2. Implement all required StateStore methods
3. Handle serialization and deserialization of state data

Here's a skeleton implementation:

```typescript
import { deserialize, serialize } from "alchemy";
import type { Scope, State, StateStore } from "alchemy";

export interface MyCustomStoreOptions {
  // Options specific to your storage backend
  endpoint?: string;
  apiKey?: string;
}

export class MyCustomStateStore implements StateStore {
  constructor(
    public readonly scope: Scope,
    private options: MyCustomStoreOptions
  ) {
    // Initialize any properties needed
  }

  async init(): Promise<void> {
    // Set up the storage backend if needed
  }

  async deinit(): Promise<void> {
    // Clean up resources if needed
  }

  async list(): Promise<string[]> {
    // List all state keys in the store
  }

  async count(): Promise<number> {
    // Return the count of items
    const keys = await this.list();
    return keys.length;
  }

  async get(key: string): Promise<State | undefined> {
    // Get state by key
  }

  async getBatch(ids: string[]): Promise<Record<string, State>> {
    // Get multiple states efficiently
  }

  async all(): Promise<Record<string, State>> {
    // Get all states
    const keys = await this.list();
    return this.getBatch(keys);
  }

  async set(key: string, value: State): Promise<void> {
    // Store state
  }

  async delete(key: string): Promise<void> {
    // Delete state
  }
}
```

## Example: In-Memory State Store

Here's a simple in-memory state store implementation:

```typescript
/**
 * A simple in-memory state store implementation
 * Note: This is for demonstration - it doesn't persist between runs
 */
export class InMemoryStateStore implements StateStore {
  // Map to store the state data in memory
  private stateMap: Map<string, any> = new Map();
  
  constructor(
    public readonly scope: Scope,
    private options: { namespace?: string } = {}
  ) {
    // Create a scope-specific namespace for the state
    this.namespace = options.namespace || scope.chain.join('/');
  }

  // Optional init method, not really needed for in-memory store
  async init(): Promise<void> {
    // Nothing to initialize for in-memory store
    console.log(`Initialized in-memory state store for scope: ${this.namespace}`);
  }

  // Optional cleanup method
  async deinit(): Promise<void> {
    // Clear all state for this scope
    const keyPrefix = `${this.namespace}/`;
    
    for (const key of this.stateMap.keys()) {
      if (key.startsWith(keyPrefix)) {
        this.stateMap.delete(key);
      }
    }
  }

  // List all resources in this scope
  async list(): Promise<string[]> {
    const keyPrefix = `${this.namespace}/`;
    const result: string[] = [];
    
    for (const key of this.stateMap.keys()) {
      if (key.startsWith(keyPrefix)) {
        // Remove the prefix and return the actual resource ID
        result.push(key.substring(keyPrefix.length));
      }
    }
    
    return result;
  }

  // Return the count of items in this scope
  async count(): Promise<number> {
    return (await this.list()).length;
  }

  // Get a state by key
  async get(key: string): Promise<State | undefined> {
    const fullKey = `${this.namespace}/${key}`;
    const serializedState = this.stateMap.get(fullKey);
    
    if (!serializedState) {
      return undefined;
    }
    
    // Deserialize the state
    const state = await deserialize(this.scope, serializedState) as State;
    
    // Ensure scope is set on output
    return {
      ...state,
      output: {
        ...(state.output || {}),
        Scope: this.scope,
      },
    };
  }

  // Get multiple states
  async getBatch(ids: string[]): Promise<Record<string, State>> {
    const result: Record<string, State> = {};
    
    for (const id of ids) {
      const state = await this.get(id);
      if (state) {
        result[id] = state;
      }
    }
    
    return result;
  }

  // Get all states in this scope
  async all(): Promise<Record<string, State>> {
    const keys = await this.list();
    return this.getBatch(keys);
  }

  // Set a state
  async set(key: string, value: State): Promise<void> {
    const fullKey = `${this.namespace}/${key}`;
    
    // Serialize the state to handle cycles
    const serializedData = await serialize(this.scope, value);
    
    // Store in the map
    this.stateMap.set(fullKey, serializedData);
  }

  // Delete a state
  async delete(key: string): Promise<void> {
    const fullKey = `${this.namespace}/${key}`;
    this.stateMap.delete(fullKey);
  }
}
```

## Key Implementation Details

When implementing a custom state store, pay attention to these important details:

### 1. State Serialization

Always use Alchemy's `serialize` and `deserialize` functions to handle state data:

```typescript
// When storing state:
const serializedData = await serialize(this.scope, value);

// When retrieving state:
const state = await deserialize(this.scope, rawData) as State;
```

These functions handle cycles in the state graph and encrypt/decrypt secrets.

### 2. Key Naming and Paths

State keys often include characters that may be problematic in certain storage systems (like slashes). Consider encoding/decoding keys:

```typescript
private convertKeyForStorage(key: string): string {
  return key.replaceAll("/", ":");
}

private convertKeyFromStorage(key: string): string {
  return key.replaceAll(":", "/");
}
```

### 3. Scope Awareness

State stores should be aware of their scope and use it to organize data:

```typescript
constructor(public readonly scope: Scope, options: Options) {
  const scopePath = scope.chain.join("/");
  this.namespace = `alchemy/${scopePath}`;
}
```

### 4. Error Handling

Be sure to handle common errors gracefully:

- Return `undefined` for missing states
- Throw clear errors for authentication/permission issues
- Consider implementing retry logic for transient failures

### 5. Setting Scope on Output

When returning a state, always ensure the scope is set on the output:

```typescript
return {
  ...state,
  output: {
    ...(state.output || {}),
    Scope: this.scope,
  },
};
```

## Using a Custom State Store

To use your custom state store, pass it to the Alchemy app initialization:

```typescript
const app = await alchemy("my-app", {
  stage: "prod",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  stateStore: (scope) => new InMemoryStateStore(scope)
});

// ... resource declarations ...

await app.finalize();
```

## Testing Your State Store

It's important to thoroughly test your state store implementation:

```typescript
// Create a test file for your state store
import { describe, expect } from "bun:test";
import { alchemy } from "alchemy";
import { InMemoryStateStore } from "./in-memory-state-store";

const test = alchemy.test(import.meta)

describe("InMemoryStateStore", () => {
  
  test("basic operations", async (scope) => {
    const store = new InMemoryStateStore(scope);
    await store.init();
    
    // Test basic operations
    await store.set("test-key", { /* sample state */ });
    const state = await store.get("test-key");
    expect(state).toBeDefined();
    
    // Test list and count
    const keys = await store.list();
    expect(keys).toContain("test-key");
    
    // Test delete
    await store.delete("test-key");
    const deletedState = await store.get("test-key");
    expect(deletedState).toBeUndefined();
    
    await store.deinit();
  });
});
```
</file>

<file path="alchemy-web/docs/providers/ai/astro-file.md">
# AstroFile

The AstroFile resource lets you generate [Astro](https://astro.build) components using AI models.

# Minimal Example

Create a simple Astro component with basic content.

```ts
import { AstroFile } from "alchemy/ai";

const header = await AstroFile("header", {
  path: "./src/components/Header.astro",
  prompt: "Generate an Astro header component with a logo and navigation menu"
});
```

# Generate Component with Data Types

Generate an Astro component that uses TypeScript types.

```ts
import { AstroFile } from "alchemy/ai";

const blogPost = await AstroFile("blog-post", {
  path: "./src/pages/blog/[slug].astro",
  prompt: await alchemy`
    Create an Astro blog post page that:
    - Uses getStaticPaths to generate pages from a CMS
    - Renders markdown content
    - Includes author info and publication date
    
    Use these types:
    ${alchemy.file("src/types/Blog.ts")}
  `,
  temperature: 0.2
});
```

# Custom System Prompt

Use a custom system prompt to control the AI model's output.

```ts
import { AstroFile } from "alchemy/ai";

const layout = await AstroFile("main-layout", {
  path: "./src/layouts/MainLayout.astro",
  prompt: "Create a main layout with header, footer, and content slots",
  system: "You are an expert Astro developer. Create a single Astro layout file inside ```astro fences with no additional text. Follow Astro best practices and include proper typing in the frontmatter section.",
  model: {
    id: "claude-3-opus-20240229",
    provider: "anthropic"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/ai/css-file.md">
# CSSFile

The CSSFile resource lets you generate CSS files using AI models like [OpenAI GPT-4](https://platform.openai.com/docs/models/gpt-4) or [Anthropic Claude](https://www.anthropic.com/claude).

# Minimal Example

Generate a simple CSS file with basic styles.

```ts
import { CSSFile } from "alchemy/ai";

const styles = await CSSFile("main-styles", {
  path: "./public/css/main.css",
  prompt: "Generate modern CSS styles for a company website with primary color #0062ff and responsive layout"
});
```

# Generate CSS Based on HTML

Generate CSS styles by referencing existing HTML components.

```ts
import { CSSFile } from "alchemy/ai";

const componentStyles = await CSSFile("component-styles", {
  path: "./src/styles/component.css", 
  prompt: await alchemy`
    Create CSS styles for this HTML component:
    ${alchemy.file("src/components/Card.html")}
    
    Include hover effects and dark/light theme support
  `,
  temperature: 0.2
});
```

# Generate CSS Animations

Generate reusable CSS animations with a custom system prompt.

```ts
import { CSSFile } from "alchemy/ai";

const animations = await CSSFile("animations", {
  path: "./src/styles/animations.css",
  prompt: "Create CSS animations for fade, slide, pulse, bounce, scale and rotate effects",
  system: "You are an expert CSS animator. Create animations with vendor prefixes for browser compatibility.",
  model: {
    id: "claude-3-opus-20240229",
    provider: "anthropic"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/ai/data.md">
# Data

The Data resource uses AI models to generate structured content based on a schema. It leverages the [Vercel AI SDK](https://sdk.vercel.ai/docs) for content generation with type validation.

## Minimal Example

Generate structured data using an ArkType schema:

```ts
import { Data } from "alchemy/ai";
import { type } from "arktype";

const productSchema = type({
  name: "string",
  description: "string", 
  features: "string[]",
  price: "number"
});

const product = await Data("new-product", {
  schema: productSchema,
  prompt: "Generate a product description for a new smartphone"
});

console.log(product.object); // Typed as per schema
```

## With Message History

Use message history for iterative content generation:

```ts
import { Data } from "alchemy/ai";
import { type } from "arktype";

const feedbackSchema = type({
  rating: "number",
  positives: "string[]",
  improvements: "string[]",
  summary: "string"
});

const feedback = await Data("product-feedback", {
  schema: feedbackSchema,
  messages: [
    { role: "user", content: "I'd like feedback on my product design" },
    { role: "assistant", content: "I'd be happy to provide feedback. What's your product?" },
    { role: "user", content: "It's a new smart home device that..." }
  ],
  system: "You are a product design expert providing structured feedback"
});
```

## With File Context

Use alchemy template literals to include file context:

```ts
import { Data } from "alchemy/ai";
import { type } from "arktype";

const docSchema = type({
  summary: "string",
  parameters: {
    name: "string",
    type: "string", 
    description: "string"
  }[],
  returns: "string"
});

const docs = await Data("function-docs", {
  schema: docSchema,
  prompt: await alchemy`
    Generate documentation for this function:
    ${alchemy.file("src/utils/format.ts")}
  `,
  system: "You are a technical documentation writer"
});
```
</file>

<file path="alchemy-web/docs/providers/ai/document.md">
# Document

The Document resource lets you generate markdown documentation using [AI models](https://platform.openai.com/docs/models) like GPT-4 and Claude.

# Minimal Example

Creates a markdown document from a prompt.

```ts
import { Document } from "alchemy/ai";

const docs = await Document("api-docs", {
  title: "API Documentation", 
  prompt: "Generate API documentation for a REST API"
});

console.log(docs.content); // Generated markdown content
```

# Generate Documentation from Source Files

Uses alchemy template literals to include file context in the prompt.

```ts
import { Document } from "alchemy/ai";

const apiDocs = await Document("api-docs", {
  title: "API Documentation",
  path: "./docs/api.md",
  prompt: await alchemy`
    Generate API documentation based on these source files:
    ${alchemy.file("src/api.ts")}
    ${alchemy.file("src/types.ts")}
  `,
  model: {
    id: "gpt-4o",
    provider: "openai"
  }
});
```

# Iterative Document Generation

Uses message history for back-and-forth document generation.

```ts
import { Document } from "alchemy/ai";

const apiDocs = await Document("api-docs", {
  title: "API Documentation",
  messages: [
    { role: "user", content: "Create API documentation for these files" },
    { role: "assistant", content: "I'll help you create API documentation. Please provide the files." },
    { role: "user", content: "Here are the files: [file contents]" }
  ],
  system: "You are a technical documentation writer. Generate clear and concise API documentation.",
  temperature: 0.2
});
```
</file>

<file path="alchemy-web/docs/providers/ai/html-file.md">
# HTMLFile

The HTMLFile resource lets you generate HTML files using AI models like [OpenAI GPT-4](https://platform.openai.com/docs/models/gpt-4) or [Anthropic Claude](https://www.anthropic.com/claude).

# Minimal Example

Creates a basic HTML file with AI-generated content.

```ts
import { HTMLFile } from "alchemy/ai";

const page = await HTMLFile("landing", {
  path: "./public/index.html",
  prompt: "Generate a simple landing page with a hero section, features list, and contact form"
});
```

# Generate with Context

Uses file context to generate HTML that matches existing code.

```ts
import { HTMLFile } from "alchemy/ai";

const component = await HTMLFile("card", {
  path: "./components/card.html", 
  prompt: await alchemy`
    Create an HTML card component that matches the style of:
    ${alchemy.file("components/button.html")}
  `
});
```

# Custom Model Configuration

Specifies a custom model and temperature for more controlled generation.

```ts
import { HTMLFile } from "alchemy/ai";

const form = await HTMLFile("contact-form", {
  path: "./components/form.html",
  prompt: "Generate an accessible contact form with validation",
  model: {
    id: "claude-3-opus-20240229",
    provider: "anthropic"
  },
  temperature: 0.2
});
```
</file>

<file path="alchemy-web/docs/providers/ai/json-file.md">
# JSONFile

The JSONFile resource lets you generate JSON files using AI models with optional schema validation.

## Minimal Example

Generate a simple JSON configuration file:

```ts
import { JSONFile } from "alchemy/ai";

const config = await JSONFile("app-config", {
  path: "./config/app.json",
  prompt: "Generate a configuration for a web application with server settings, database connection details, and logging configuration"
});
```

## Schema Validation

Use ArkType schemas to validate and type the generated JSON:

```ts
import { JSONFile } from "alchemy/ai";
import { type } from "arktype";

const userSchema = type({
  users: [{
    id: "string",
    name: "string", 
    email: "string",
    role: "'admin' | 'user' | 'guest'",
    permissions: "string[]"
  }]
});

const userData = await JSONFile("user-data", {
  path: "./data/users.json",
  schema: userSchema,
  prompt: "Generate sample user data with various roles and permissions",
  temperature: 0.2
});

// Type-safe access
console.log(userData.json.users[0].role); // Typed as 'admin' | 'user' | 'guest'
```

## Custom Formatting

Control JSON formatting with pretty-printing options:

```ts
import { JSONFile } from "alchemy/ai";

const apiMock = await JSONFile("api-mock", {
  path: "./mocks/products.json",
  prompt: "Create mock data for a product catalog API with 10 products",
  pretty: true,
  indent: 4
});
```
</file>

<file path="alchemy-web/docs/providers/ai/typescript-file.md">
# TypeScriptFile

The TypeScriptFile resource lets you generate TypeScript code files using AI models like [OpenAI GPT-4](https://platform.openai.com/docs/models/gpt-4) or [Anthropic Claude](https://www.anthropic.com/claude).

# Minimal Example

Generate a simple TypeScript utility file:

```ts
import { TypeScriptFile } from "alchemy/ai";

const utils = await TypeScriptFile("string-utils", {
  path: "./src/utils/string-utils.ts",
  prompt: "Generate TypeScript utility functions for string manipulation (capitalize, truncate, camelCase, kebabCase)"
});
```

# Generate with Context

Use alchemy template literals to include file context:

```ts
import { TypeScriptFile } from "alchemy/ai";

const service = await TypeScriptFile("user-service", {
  path: "./src/services/UserService.ts",
  prompt: await alchemy`
    Create a UserService class using the types from:
    ${alchemy.file("src/types/User.ts")}
  `,
  temperature: 0.2
});
```

# Custom Formatting

Configure Prettier formatting options:

```ts
import { TypeScriptFile } from "alchemy/ai";

const component = await TypeScriptFile("button", {
  path: "./src/components/Button.tsx",
  prompt: "Generate a reusable React button component with variants and sizes",
  prettierConfig: {
    semi: false,
    singleQuote: true,
    printWidth: 120
  }
});
```

# Custom Model

Use a specific AI model and provider:

```ts
import { TypeScriptFile } from "alchemy/ai";

const hook = await TypeScriptFile("use-form", {
  path: "./src/hooks/useForm.ts", 
  prompt: "Create a React form hook with validation and submission handling",
  model: {
    id: "claude-3-opus-20240229",
    provider: "anthropic"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/ai/vue-file.md">
# VueFile

The VueFile resource lets you generate [Vue.js](https://vuejs.org/) single-file components using AI models.

# Minimal Example

Creates a basic Vue component file with the specified content.

```ts
import { VueFile } from "alchemy/ai";

const button = await VueFile("button", {
  path: "./src/components/Button.vue",
  prompt: "Generate a reusable button component with primary and secondary variants"
});
```

# Generate Component with Context

Uses existing files as reference to generate a component that matches your codebase style.

```ts
import { VueFile } from "alchemy/ai";

const userCard = await VueFile("user-card", {
  path: "./src/components/UserCard.vue",
  prompt: await alchemy`
    Create a UserCard component that follows the styling from:
    ${alchemy.file("src/components/Card.vue")}
    
    Using the user type from:
    ${alchemy.file("src/types/User.ts")}
  `,
  temperature: 0.2
});
```

# Custom System Prompt

Provides specific instructions to the AI model about component generation.

```ts
import { VueFile } from "alchemy/ai";

const form = await VueFile("registration-form", {
  path: "./src/components/RegistrationForm.vue",
  prompt: "Generate a registration form with email, password validation and submit handler",
  system: "You are an expert Vue developer specializing in form components. Create a single Vue component inside ```vue fences with no additional text.",
  model: {
    id: "claude-3-opus-20240229",
    provider: "anthropic"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/ai/yaml-file.md">
# YAMLFile

The YAMLFile resource lets you generate [YAML](https://yaml.org/) files using AI models with optional schema validation.

# Minimal Example

Generate a simple YAML configuration file:

```ts
import { YAMLFile } from "alchemy/ai";

const config = await YAMLFile("config", {
  path: "./config.yml",
  prompt: "Generate a basic nginx configuration with server name and port"
});
```

# Schema Validation

Use a schema to validate and type the generated YAML:

```ts
import { YAMLFile } from "alchemy/ai";
import { type } from "arktype";

const configSchema = type({
  server: {
    name: "string",
    port: "number",
    ssl: "boolean"
  }
});

const config = await YAMLFile("config", {
  path: "./config.yml",
  schema: configSchema,
  prompt: "Generate an nginx configuration with SSL enabled"
});

// Type-safe access to the generated YAML
console.log(config.yaml.server.port); // number
```

# Custom System Prompt

Customize the AI's behavior with a system prompt:

```ts
import { YAMLFile } from "alchemy/ai";

const workflow = await YAMLFile("github-workflow", {
  path: "./.github/workflows/ci.yml",
  prompt: "Create a GitHub Actions workflow for a Node.js project with testing and deployment",
  system: "You are a DevOps expert specializing in GitHub Actions. Create a single YAML file with proper syntax.",
  model: {
    id: "claude-3-opus-20240229",
    provider: "anthropic"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/aws/bucket.md">
# Bucket

The Bucket resource lets you create and manage [Amazon S3 buckets](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html) for object storage.

# Minimal Example

Create a basic S3 bucket with default settings:

```ts
import { Bucket } from "alchemy/aws";

const bucket = await Bucket("storage", {
  bucketName: "my-app-storage",
  tags: {
    Environment: "production"
  }
});
```

# Bucket with Versioning

Create a bucket with versioning enabled for change tracking:

```ts
import { Bucket } from "alchemy/aws";

const versionedBucket = await Bucket("document-archive", {
  bucketName: "document-archive",
  tags: {
    Environment: "production",
    Purpose: "document-storage",
    Versioning: "enabled"
  }
});
```

# Development Bucket

Create a temporary bucket for development/testing:

```ts
import { Bucket } from "alchemy/aws";

const devBucket = await Bucket("dev-testing", {
  bucketName: "dev-testing",
  tags: {
    Environment: "development",
    Temporary: "true"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/aws/function.md">
# AWS Lambda Function

The Function resource lets you create and manage [AWS Lambda functions](https://docs.aws.amazon.com/lambda/latest/dg/welcome.html) with support for Node.js runtimes, environment variables, and function URLs.

## Minimal Example

Create a basic Lambda function with default settings:

```ts
import { Function } from "alchemy/aws";

const func = await Function("api", {
  functionName: "my-api",
  bundle: bundle,
  roleArn: role.arn,
  handler: "index.handler"
});
```

## With Environment Variables

Add environment variables to configure the function:

```ts
const func = await Function("api", {
  functionName: "my-api", 
  bundle: bundle,
  roleArn: role.arn,
  handler: "index.handler",
  environment: {
    TABLE_NAME: table.name,
    QUEUE_URL: queue.url,
  }
});
```

## With Function URL

Create a public HTTP endpoint for the function:

```ts
const func = await Function("api", {
  functionName: "my-api",
  bundle: bundle,
  roleArn: role.arn,
  handler: "index.handler",
  url: {
    authType: "NONE",
    cors: {
      allowOrigins: ["*"],
      allowMethods: ["GET", "POST"],
      allowHeaders: ["content-type"]
    }
  }
});
```

## With Custom Configuration

Customize memory, timeout and other settings:

```ts
const func = await Function("worker", {
  functionName: "worker",
  bundle: bundle,
  roleArn: role.arn,
  handler: "worker.process",
  runtime: "nodejs20.x",
  architecture: "arm64",
  memorySize: 512,
  timeout: 30,
  tags: {
    Environment: "production"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/aws/policy-attachment.md">
# PolicyAttachment

The PolicyAttachment resource lets you attach [AWS IAM policies](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html) to IAM roles.

## Minimal Example

Attach an AWS managed policy to a role:

```ts
import { PolicyAttachment } from "alchemy/aws";

const adminAccess = await PolicyAttachment("admin-policy", {
  policyArn: "arn:aws:iam::aws:policy/AdministratorAccess", 
  roleName: role.name
});
```

## Attach Custom Policy

Attach a custom policy created with the Policy resource:

```ts
import { PolicyAttachment } from "alchemy/aws";

const customPolicy = await PolicyAttachment("custom-policy", {
  policyArn: policy.arn,
  roleName: role.name
});
```

## Multiple Policy Attachments 

Attach multiple policies to a role:

```ts
import { PolicyAttachment } from "alchemy/aws";

const s3Access = await PolicyAttachment("s3-access", {
  policyArn: "arn:aws:iam::aws:policy/AmazonS3FullAccess",
  roleName: role.name
});

const sqsAccess = await PolicyAttachment("sqs-access", {
  policyArn: "arn:aws:iam::aws:policy/AmazonSQSFullAccess", 
  roleName: role.name
});
```
</file>

<file path="alchemy-web/docs/providers/aws/policy.md">
# Policy

The Policy resource lets you create and manage [AWS IAM Policies](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html) that define permissions for AWS services and resources.

# Minimal Example

Create a basic policy that allows S3 bucket access:

```ts
import { Policy } from "alchemy/aws";

const s3Policy = await Policy("bucket-access", {
  policyName: "s3-bucket-access", 
  document: {
    Version: "2012-10-17",
    Statement: [{
      Effect: "Allow",
      Action: [
        "s3:GetObject",
        "s3:PutObject"
      ],
      Resource: `${bucket.arn}/*`
    }]
  }
});
```

# Multiple Statements

Create a policy with multiple statements and conditions:

```ts
import { Policy } from "alchemy/aws";

const apiPolicy = await Policy("api-access", {
  policyName: "api-gateway-access",
  document: {
    Version: "2012-10-17", 
    Statement: [
      {
        Sid: "InvokeAPI",
        Effect: "Allow",
        Action: "execute-api:Invoke",
        Resource: `${api.executionArn}/*`,
        Condition: {
          StringEquals: {
            "aws:SourceVpc": vpc.id
          }
        }
      },
      {
        Sid: "ReadLogs",
        Effect: "Allow", 
        Action: [
          "logs:GetLogEvents",
          "logs:FilterLogEvents"
        ],
        Resource: `${api.logGroupArn}:*`
      }
    ]
  },
  description: "Allows invoking API Gateway endpoints and reading logs",
  tags: {
    Service: "API Gateway",
    Environment: "production" 
  }
});
```

# Deny Policy

Create a policy that denies access based on tags:

```ts
import { Policy } from "alchemy/aws";

const denyPolicy = await Policy("deny-production", {
  policyName: "deny-production-access",
  document: {
    Version: "2012-10-17",
    Statement: [{
      Effect: "Deny",
      Action: "*", 
      Resource: "*",
      Condition: {
        StringEquals: {
          "aws:ResourceTag/Environment": "production"
        }
      }
    }]
  }
});
```
</file>

<file path="alchemy-web/docs/providers/aws/queue.md">
# Queue

The Queue resource lets you create and manage [Amazon Simple Queue Service (SQS)](https://aws.amazon.com/sqs/) queues for reliable message delivery between distributed application components.

## Minimal Example

Create a standard SQS queue with default settings:

```ts
import { Queue } from "alchemy/aws";

const queue = await Queue("my-queue", {
  queueName: "my-queue",
  tags: {
    Environment: "production"
  }
});
```

## FIFO Queue

Create a FIFO queue with content-based deduplication:

```ts
import { Queue } from "alchemy/aws";

const fifoQueue = await Queue("orders-queue", {
  queueName: "orders-queue.fifo", 
  fifo: true,
  contentBasedDeduplication: true,
  visibilityTimeout: 30
});
```

## Custom Queue Configuration

Create a queue with custom message handling settings:

```ts
import { Queue } from "alchemy/aws";

const customQueue = await Queue("large-messages", {
  queueName: "large-messages",
  messageRetentionPeriod: 345600, // 4 days
  maximumMessageSize: 262144,     // 256 KB
  visibilityTimeout: 60,
  delaySeconds: 5,
  receiveMessageWaitTimeSeconds: 20
});
```
</file>

<file path="alchemy-web/docs/providers/aws/role.md">
# Role

The Role resource lets you create and manage [AWS IAM Roles](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html) that define permissions for AWS services and users.

## Minimal Example

Create a basic Lambda execution role with permissions to write logs:

```ts
import { Role } from "alchemy/aws";

const role = await Role("lambda-role", {
  roleName: "lambda-role",
  assumeRolePolicy: {
    Version: "2012-10-17", 
    Statement: [{
      Effect: "Allow",
      Principal: {
        Service: "lambda.amazonaws.com"
      },
      Action: "sts:AssumeRole"
    }]
  },
  policies: [{
    policyName: "logs",
    policyDocument: {
      Version: "2012-10-17",
      Statement: [{
        Effect: "Allow",
        Action: [
          "logs:CreateLogGroup",
          "logs:CreateLogStream", 
          "logs:PutLogEvents"
        ],
        Resource: "*"
      }]
    }
  }]
});
```

## With Managed Policies

Attach AWS managed policies to grant common permissions:

```ts
import { Role } from "alchemy/aws";

const role = await Role("readonly-role", {
  roleName: "readonly-role", 
  assumeRolePolicy: {
    Version: "2012-10-17",
    Statement: [{
      Effect: "Allow",
      Principal: {
        Service: "lambda.amazonaws.com"
      },
      Action: "sts:AssumeRole"
    }]
  },
  managedPolicyArns: [
    "arn:aws:iam::aws:policy/ReadOnlyAccess"
  ]
});
```

## Multiple Inline Policies

Create a role with multiple inline policies and custom session duration:

```ts
import { Role } from "alchemy/aws";

const role = await Role("custom-role", {
  roleName: "custom-role",
  assumeRolePolicy: {
    Version: "2012-10-17",
    Statement: [{
      Effect: "Allow",
      Principal: {
        Service: "lambda.amazonaws.com"
      },
      Action: "sts:AssumeRole"
    }]
  },
  maxSessionDuration: 7200,
  policies: [
    {
      policyName: "logs",
      policyDocument: {
        Version: "2012-10-17",
        Statement: [{
          Effect: "Allow",
          Action: [
            "logs:CreateLogGroup",
            "logs:CreateLogStream",
            "logs:PutLogEvents"
          ],
          Resource: "*"
        }]
      }
    },
    {
      policyName: "s3",
      policyDocument: {
        Version: "2012-10-17", 
        Statement: [{
          Effect: "Allow",
          Action: "s3:ListBucket",
          Resource: "*"
        }]
      }
    }
  ]
});
```
</file>

<file path="alchemy-web/docs/providers/aws/ses.md">
# SES

The SES resource lets you create and manage [Amazon Simple Email Service (SES)](https://docs.aws.amazon.com/ses/latest/dg/Welcome.html) configuration sets and email identities.

## Minimal Example

Create a basic configuration set for sending emails:

```ts
import { SES } from "alchemy/aws";

const configSet = await SES("email-config", {
  configurationSetName: "my-email-config",
  sendingOptions: {
    SendingEnabled: true
  }
});
```

## Create Domain Identity with DKIM

Create and verify a domain identity with DKIM signing enabled:

```ts
const domainIdentity = await SES("domain-identity", {
  emailIdentity: "example.com", 
  enableDkim: true,
  tags: {
    Environment: "production"
  }
});
```

## Configure Tracking Options

Set up tracking options for open and click tracking:

```ts
const emailConfig = await SES("tracking-config", {
  configurationSetName: "tracking-config",
  trackingOptions: {
    CustomRedirectDomain: "click.example.com"
  },
  suppressionOptions: {
    SuppressedReasons: ["BOUNCE", "COMPLAINT"]
  }
});
```
</file>

<file path="alchemy-web/docs/providers/aws/table.md">
# DynamoDB Table

The Table resource lets you create and manage [Amazon DynamoDB tables](https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Introduction.html) for NoSQL database storage.

# Minimal Example

Create a basic table with just a partition key:

```ts
import { Table } from "alchemy/aws";

const table = await Table("users", {
  tableName: "users",
  partitionKey: {
    name: "userId", 
    type: "S"
  }
});
```

# Table with Sort Key

Add a sort key to enable range queries and composite keys:

```ts
const table = await Table("events", {
  tableName: "events",
  partitionKey: {
    name: "deviceId",
    type: "S"
  },
  sortKey: {
    name: "timestamp",
    type: "N"
  }
});
```

# Provisioned Capacity

Configure provisioned read/write capacity for predictable workloads:

```ts
const table = await Table("orders", {
  tableName: "orders",
  partitionKey: {
    name: "orderId",
    type: "S"
  },
  billingMode: "PROVISIONED",
  readCapacity: 100,
  writeCapacity: 50,
  tags: {
    Environment: "production"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/account-api-token.md">
# AccountApiToken

Creates a [Cloudflare API Token](https://developers.cloudflare.com/api/tokens/) with specified permissions and access controls.

# Minimal Example

Create a basic API token with read-only permissions.

```ts
import { AccountApiToken, PermissionGroups } from "alchemy/cloudflare";

const permissions = await PermissionGroups("cloudflare-permissions");

const token = await AccountApiToken("readonly-token", {
  name: "Readonly Zone Token",
  policies: [{
    effect: "allow",
    permissionGroups: [
      { id: permissions["Zone Read"].id },
      { id: permissions["Analytics Read"].id }
    ],
    resources: {
      "com.cloudflare.api.account.zone.*": "*"
    }
  }]
});
```

# With Time and IP Restrictions

Create a token with time-based and IP address restrictions.

```ts
import { AccountApiToken } from "alchemy/cloudflare";

const restrictedToken = await AccountApiToken("restricted-token", {
  name: "Restricted Access Token", 
  policies: [{
    effect: "allow",
    permissionGroups: [
      { id: permissions["Worker Routes Edit"].id }
    ],
    resources: {
      "com.cloudflare.api.account.worker.route.*": "*"
    }
  }],
  notBefore: "2024-01-01T00:00:00Z",
  expiresOn: "2024-12-31T23:59:59Z",
  condition: {
    requestIp: {
      in: ["192.168.1.0/24"],
      notIn: ["192.168.1.100/32"]
    }
  }
});
```

# Bind to a Worker

Use the token in a Worker binding.

```ts
import { Worker, AccountApiToken } from "alchemy/cloudflare";

const token = await AccountApiToken("api-token", {
  name: "Worker API Token",
  policies: [{
    effect: "allow", 
    permissionGroups: [
      { id: permissions["Zone Read"].id }
    ],
    resources: {
      "com.cloudflare.api.account.zone.*": "*" 
    }
  }]
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    API_TOKEN: token
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/account-id.md">
# AccountId

The AccountId resource retrieves a Cloudflare [Account ID](https://developers.cloudflare.com/fundamentals/setup/find-account-and-zone-ids/) for use with other Cloudflare resources.

# Minimal Example

Get the account ID from environment variables or API token:

```ts
import { AccountId } from "alchemy/cloudflare";

const accountId = await AccountId("my-account");
```

# With Explicit API Key

Provide an API key and email directly:

```ts 
import { AccountId } from "alchemy/cloudflare";

const accountId = await AccountId("my-account", {
  apiKey: alchemy.secret(process.env.CF_API_KEY),
  email: "user@example.com"
});
```

# Bind to a Worker

Use the account ID with a Worker:

```ts
import { Worker, AccountId } from "alchemy/cloudflare";

const accountId = await AccountId("my-account");

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  accountId: accountId
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/ai-gateway.md">
# AiGateway

The AiGateway resource lets you create and manage [Cloudflare AI Gateway](https://developers.cloudflare.com/workers-ai/get-started/workers-ai-gateway/) configurations for accessing AI models through Cloudflare Workers.

# Minimal Example

Create a basic AI Gateway with default settings:

```ts
import { AiGateway } from "alchemy/cloudflare";

const gateway = await AiGateway("my-ai-gateway", {
  name: "my-ai-gateway"
});
```

# With Authentication and Rate Limiting

Configure an AI Gateway with authentication and rate limiting:

```ts
import { AiGateway } from "alchemy/cloudflare";

const secureGateway = await AiGateway("secure-gateway", {
  name: "secure-gateway",
  authentication: true,
  rateLimitingInterval: 60,
  rateLimitingLimit: 100,
  rateLimitingTechnique: "sliding"
});
```

# With Logging and Logpush

Create an AI Gateway with logging and logpush enabled:

```ts
import { AiGateway } from "alchemy/cloudflare";

const loggingGateway = await AiGateway("logging-gateway", {
  name: "logging-gateway",
  collectLogs: true,
  logpush: true,
  logpushPublicKey: "mypublickey..."
});
```

# Bind to a Worker

Use the AI Gateway in a Cloudflare Worker:

```ts
import { Worker, AiGateway } from "alchemy/cloudflare";

const gateway = await AiGateway("my-gateway", {
  name: "my-gateway"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    AI: gateway
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/assets.md">
# Assets

The Assets resource lets you add [static assets](https://developers.cloudflare.com/workers/configuration/sites/) to your Cloudflare Workers.

# Minimal Example

Create a basic assets bundle from a local directory:

```ts
import { Assets } from "alchemy/cloudflare";

const staticAssets = await Assets("static", {
  path: "./src/assets"
});
```

# Bind to a Worker

Bind the assets to a worker to serve them:

```ts
import { Worker, Assets } from "alchemy/cloudflare";

const staticAssets = await Assets("static", {
  path: "./src/assets"
});

const worker = await Worker("frontend", {
  name: "frontend-worker", 
  entrypoint: "./src/worker.ts",
  bindings: {
    ASSETS: staticAssets
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/bucket.md">
# R2Bucket

Creates and manages [Cloudflare R2 Buckets](https://developers.cloudflare.com/r2/buckets/) for object storage with S3 compatibility.

# Minimal Example

Create a basic R2 bucket with default settings:

```ts
import { R2Bucket } from "alchemy/cloudflare";

const bucket = await R2Bucket("my-bucket", {
  name: "my-bucket"
});
```

# With Location Hint

Create a bucket with location hint for optimal performance:

```ts
import { R2Bucket } from "alchemy/cloudflare";

const euBucket = await R2Bucket("eu-bucket", {
  name: "eu-bucket", 
  locationHint: "eu",
  jurisdiction: "eu"
});
```

# With Public Access

Create a development bucket with public access enabled:

```ts
import { R2Bucket } from "alchemy/cloudflare";

const publicBucket = await R2Bucket("public-assets", {
  name: "public-assets",
  allowPublicAccess: true
});
```

# With Auto-Emptying

Create a bucket that will be automatically emptied when deleted:

```ts
import { R2Bucket } from "alchemy/cloudflare";

const tempBucket = await R2Bucket("temp-storage", {
  name: "temp-storage",
  empty: true // All objects will be deleted when this resource is destroyed
});
```

# Bind to a Worker

```ts
import { Worker, R2Bucket } from "alchemy/cloudflare";

const bucket = await R2Bucket("my-bucket", {
  name: "my-bucket"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    BUCKET: bucket
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/custom-domain.md">
# CustomDomain

The CustomDomain resource lets you attach a [custom domain](https://developers.cloudflare.com/workers/configuration/routing/custom-domains/) to a Cloudflare Worker.

# Minimal Example

Bind a domain to a worker:

```ts
import { Worker, CustomDomain } from "alchemy/cloudflare";

const worker = await Worker("api", {
  name: "api-worker",
  entrypoint: "./src/api.ts"
});

const domain = await CustomDomain("api-domain", {
  name: "api.example.com", 
  zoneId: "YOUR_ZONE_ID",
  workerName: worker.name
});
```

# With Environment

Bind a domain to a specific worker environment:

```ts
import { Worker, CustomDomain } from "alchemy/cloudflare";

const domain = await CustomDomain("staging-domain", {
  name: "staging.example.com",
  zoneId: "YOUR_ZONE_ID", 
  workerName: "my-worker",
  environment: "staging"
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/d1-database.md">
# D1Database

The D1Database component lets you add [Cloudflare D1 Databases](https://developers.cloudflare.com/d1/) to your app.

# Minimal Example

Create a basic D1 database with default settings.

```ts
import { D1Database } from "alchemy/cloudflare";

const db = await D1Database("my-db", {
  name: "my-db"
});
```

# With Migrations

Create a database with SQL migrations.

```ts
import { D1Database } from "alchemy/cloudflare";

const db = await D1Database("users-db", {
  name: "users-db",
  migrationsDir: "./migrations",
  migrationsTable: "schema_migrations" 
});
```

# With Location Hint

Create a database with a specific location hint for optimal performance.

```ts
import { D1Database } from "alchemy/cloudflare";

const db = await D1Database("eu-db", {
  name: "eu-db",
  primaryLocationHint: "weur",
  readReplication: {
    mode: "auto"
  }
});
```

# Bind to a Worker

```ts
import { Worker, D1Database } from "alchemy/cloudflare";

const db = await D1Database("my-db", {
  name: "my-db"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    DB: db
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/dns-records.md">
# DnsRecords

Manages DNS records in a Cloudflare zone using the [Cloudflare DNS API](https://developers.cloudflare.com/api/operations/dns-records-for-a-zone-list-dns-records).

# Minimal Example

Create a basic A record pointing to an IP address.

```ts
import { DnsRecords } from "alchemy/cloudflare";

const records = await DnsRecords("example-dns", {
  zoneId: "YOUR_ZONE_ID",
  records: [{
    name: "www.example.com", 
    type: "A",
    content: "192.0.2.1",
    proxied: true
  }]
});
```

# Email Records

Create MX and TXT records for email routing.

```ts
import { DnsRecords } from "alchemy/cloudflare";

const emailRecords = await DnsRecords("email-dns", {
  zoneId: "YOUR_ZONE_ID", 
  records: [
    {
      name: "example.com",
      type: "MX",
      content: "aspmx.l.google.com",
      priority: 1
    },
    {
      name: "example.com", 
      type: "TXT",
      content: "v=spf1 include:_spf.google.com ~all"
    }
  ]
});
```

# Proxied Records

Create proxied records to take advantage of Cloudflare's CDN and security features.

```ts
import { DnsRecords } from "alchemy/cloudflare";

const proxiedRecords = await DnsRecords("proxied-dns", {
  zoneId: "YOUR_ZONE_ID",
  records: [
    {
      name: "www.example.com",
      type: "A", 
      content: "192.0.2.1",
      proxied: true,
      ttl: 1 // Auto TTL when proxied
    },
    {
      name: "blog.example.com",
      type: "CNAME",
      content: "www.example.com",
      proxied: true
    }
  ]
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/durable-object-namespace.md">
# DurableObjectNamespace

A [Durable Object Namespace](https://developers.cloudflare.com/workers/runtime-apis/durable-objects/) represents a globally unique namespace for Durable Objects that provide strongly consistent storage and coordination.

# Minimal Example

Create a basic Durable Object namespace for stateful chat rooms.

```ts
import { DurableObjectNamespace } from "alchemy/cloudflare";

const rooms = new DurableObjectNamespace("chat-rooms", {
  className: "ChatRoom"
});
```

# Create with SQLite Storage

Create a Durable Object with SQLite storage for user data.

```ts
import { DurableObjectNamespace } from "alchemy/cloudflare";

const users = new DurableObjectNamespace("user-store", {
  className: "User",
  sqlite: true
});
```

# Create in Production Environment

Create a Durable Object in production for game state management.

```ts
import { DurableObjectNamespace } from "alchemy/cloudflare";

const game = new DurableObjectNamespace("game-state", {
  className: "GameState", 
  scriptName: "game-worker",
  environment: "production"
});
```

# Bind to a Worker

Bind a Durable Object namespace to a Worker to enable access.

```ts
import { Worker, DurableObjectNamespace } from "alchemy/cloudflare";

const counter = new DurableObjectNamespace("counter", {
  className: "Counter"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    COUNTER: counter
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/hyperdrive.md">
# Hyperdrive

[Cloudflare Hyperdrive](https://developers.cloudflare.com/hyperdrive/) provides serverless connection pooling and caching for PostgreSQL databases.

# Minimal Example

Create a basic Hyperdrive connection to a PostgreSQL database.

```ts
import { Hyperdrive } from "alchemy/cloudflare";

const db = await Hyperdrive("my-postgres-db", {
  name: "my-postgres-db", 
  origin: {
    database: "postgres",
    host: "database.example.com",
    password: alchemy.secret("your-password"),
    port: 5432,
    user: "postgres"
  }
});
```

# With Caching Disabled

Create a Hyperdrive connection with caching disabled.

```ts
const noCacheDb = await Hyperdrive("no-cache-db", {
  name: "no-cache-db",
  origin: {
    database: "postgres",
    host: "database.example.com", 
    password: alchemy.secret(process.env.DB_PASSWORD),
    port: 5432,
    user: "postgres"
  },
  caching: {
    disabled: true
  }
});
```

# With mTLS Configuration

Create a Hyperdrive connection with mTLS security.

```ts
const secureDb = await Hyperdrive("secure-db", {
  name: "secure-db",
  origin: {
    database: "postgres",
    host: "database.example.com",
    password: alchemy.secret(process.env.DB_PASSWORD),
    port: 5432,
    user: "postgres"
  },
  mtls: {
    ca_certificate_id: "00000000-0000-0000-0000-0000000000",
    mtls_certificate_id: "00000000-0000-0000-0000-0000000000",
    sslmode: "verify-full"
  }
});
```

# With Access Client Credentials

Create a Hyperdrive connection using access client credentials.

```ts
const accessDb = await Hyperdrive("access-db", {
  name: "access-db",
  origin: {
    database: "postgres",
    host: "database.example.com",
    access_client_id: "client-id",
    access_client_secret: alchemy.secret(process.env.ACCESS_CLIENT_SECRET),
    port: 5432,
    user: "postgres"
  }
});
```

# Bind to a Worker

Use Hyperdrive with a Cloudflare Worker.

```ts
import { Worker, Hyperdrive } from "alchemy/cloudflare";

const db = await Hyperdrive("my-db", {
  name: "my-db",
  origin: {
    database: "postgres",
    host: "database.example.com",
    password: alchemy.secret("password"),
    user: "postgres"
  }
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    DB: db
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/kv-namespace.md">
# KVNamespace

A [Cloudflare KV Namespace](https://developers.cloudflare.com/kv/concepts/kv-namespaces/) is a key-value store that can be used to store data for your application.

# Minimal Example

Create a basic KV namespace for storing user data.

```ts
import { KVNamespace } from "alchemy/cloudflare";

const users = await KVNamespace("users", {
  title: "user-data"
});
```

# With Initial Values and TTL

Create a KV namespace with initial values and expiration.

```ts
import { KVNamespace } from "alchemy/cloudflare";

const sessions = await KVNamespace("sessions", {
  title: "user-sessions", 
  values: [{
    key: "session_123",
    value: { userId: "user_456", role: "admin" },
    expirationTtl: 3600 // Expires in 1 hour
  }]
});
```

# With Metadata

Create a KV namespace with metadata for caching.

```ts
import { KVNamespace } from "alchemy/cloudflare";

const assets = await KVNamespace("assets", {
  title: "static-assets",
  values: [{
    key: "main.js",
    value: "content...",
    metadata: {
      contentType: "application/javascript",
      etag: "abc123"
    }
  }]
});
```

# Bind to a Worker

Bind a KV namespace to a Worker for data access.

```ts
import { Worker, KVNamespace } from "alchemy/cloudflare";

const store = await KVNamespace("store", {
  title: "data-store"
});

await Worker("api", {
  name: "api-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    STORE: store
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/nuxt.md">
# Nuxt

Deploy a [Nuxt](https://nuxt.com) application to Cloudflare Pages with automatically configured defaults.

# Minimal Example

Deploy a basic Nuxt site with default settings.

```ts
import { Nuxt } from "alchemy/cloudflare";

const nuxtSite = await Nuxt("my-nuxt-app");
```

# Custom Bindings

Add database and other bindings to your Nuxt app.

```ts
import { Nuxt, D1Database } from "alchemy/cloudflare";

const db = await D1Database("my-db", {
  name: "my-db"
});

const nuxtSiteWithDb = await Nuxt("my-nuxt-app-with-db", {
  command: "npm run build:cloudflare", // Custom build command
  bindings: {
    DB: db // Add custom bindings
  }
});
```

# Bind to a Worker

Bind a Nuxt app to a Cloudflare Worker.

```ts
import { Worker, Nuxt } from "alchemy/cloudflare";

const nuxtApp = await Nuxt("my-nuxt-app", {
  command: "npm run build"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    NUXT: nuxtApp
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/permission-groups.md">
# PermissionGroups

Lists all permission groups available for a Cloudflare account and returns a typed map of permission names to their IDs. Used when creating API tokens for Cloudflare services like R2.

# Minimal Example

Get all permission groups including those for R2:

```ts
import { PermissionGroups } from "alchemy/cloudflare";

const permissions = await PermissionGroups("cloudflare-permissions");
```

# Create API Token with Permissions

Use with AccountApiToken to create a token with proper permissions:

```ts
import { PermissionGroups, AccountApiToken } from "alchemy/cloudflare";

const permissions = await PermissionGroups("cloudflare-permissions");

const token = await AccountApiToken("r2-token", {
  name: "R2 Read-Only Token", 
  policies: [{
    effect: "allow",
    resources: {
      "com.cloudflare.edge.r2.bucket.abc123_default_my-bucket": "*"
    },
    permissionGroups: [{
      id: permissions["Workers R2 Storage Bucket Item Read"].id
    }]
  }]
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/pipeline.md">
# Pipeline

The [Pipeline](https://developers.cloudflare.com/workers/configuration/pipelines/) resource lets you create and manage Cloudflare Pipelines for collecting, transforming and routing data.

# Minimal Example

Create a basic pipeline with an R2 bucket destination:

```ts
import { Pipeline, R2Bucket } from "alchemy/cloudflare";

const bucket = await R2Bucket("logs-bucket", {
  name: "logs-bucket"
});

const pipeline = await Pipeline("logs-pipeline", {
  name: "logs-pipeline", 
  destination: {
    type: "r2",
    format: "json",
    path: {
      bucket: bucket.name,
      prefix: "app-logs"
    },
    credentials: {
      accessKeyId: alchemy.secret(process.env.R2_ACCESS_KEY_ID!),
      secretAccessKey: alchemy.secret(process.env.R2_SECRET_ACCESS_KEY!)
    }
  }
});
```

# Custom Source Configuration

Configure a pipeline with custom HTTP source settings:

```ts
import { Pipeline } from "alchemy/cloudflare";

const customPipeline = await Pipeline("custom-pipeline", {
  name: "custom-pipeline",
  source: [{
    type: "http",
    format: "json", 
    authentication: true,
    cors: {
      origins: ["https://example.com"]
    }
  }],
  destination: {
    type: "r2",
    format: "json",
    path: {
      bucket: "my-bucket",
      prefix: "data"
    },
    credentials: {
      accessKeyId: alchemy.secret(process.env.R2_ACCESS_KEY_ID!),
      secretAccessKey: alchemy.secret(process.env.R2_SECRET_ACCESS_KEY!)
    },
    compression: {
      type: "gzip"
    }
  }
});
```

# Bind to a Worker

Use the pipeline in a worker:

```ts
import { Worker, Pipeline } from "alchemy/cloudflare";

const pipeline = await Pipeline("logs-pipeline", {
  name: "logs-pipeline",
  destination: {
    type: "r2",
    format: "json",
    path: {
      bucket: "logs-bucket",
      prefix: "app-logs"
    },
    credentials: {
      accessKeyId: alchemy.secret(process.env.R2_ACCESS_KEY_ID!),
      secretAccessKey: alchemy.secret(process.env.R2_SECRET_ACCESS_KEY!)
    }
  }
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    PIPELINE: pipeline
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/queue-consumer.md">
# QueueConsumer

Creates a consumer for a [Cloudflare Queue](https://developers.cloudflare.com/queues/platform/consumers/) that processes messages using a Worker.

# Minimal Example

Create a basic queue consumer with default settings.

```ts
import { Queue, QueueConsumer } from "alchemy/cloudflare";

const queue = await Queue("notifications", {
  name: "notifications"
});

const consumer = await QueueConsumer("notification-processor", {
  queue,
  scriptName: "notification-worker"
});
```

# Custom Settings

Configure batch size, concurrency, retries and other settings.

```ts
import { Queue, QueueConsumer } from "alchemy/cloudflare";

const consumer = await QueueConsumer("batch-processor", {
  queue,
  scriptName: "batch-worker", 
  settings: {
    batchSize: 50,         // Process 50 messages at once
    maxConcurrency: 10,    // Allow 10 concurrent invocations
    maxRetries: 5,         // Retry failed messages up to 5 times
    maxWaitTimeMs: 2000,   // Wait up to 2 seconds to fill a batch
    retryDelay: 60         // Wait 60 seconds before retrying failed messages
  }
});
```

# Bind to a Worker

Bind a queue consumer to a worker.

```ts
import { Worker, QueueConsumer } from "alchemy/cloudflare";

const consumer = await QueueConsumer("my-consumer", {
  queue,
  scriptName: "my-worker"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    myConsumer: consumer
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/queue.md">
# Queue

The Queue component lets you add [Cloudflare Queue](https://developers.cloudflare.com/queues/) to your app for reliable message delivery between workers.

# Minimal Example

Create a basic queue with default settings.

```ts
import { Queue } from "alchemy/cloudflare";

const queue = await Queue("my-queue", {
  name: "my-queue"
});
```

# Queue with Custom Settings

Configure queue behavior with delivery delay and message retention.

```ts
import { Queue } from "alchemy/cloudflare";

const queue = await Queue("delayed-queue", {
  name: "delayed-queue",
  settings: {
    deliveryDelay: 30, // 30 second delay
    messageRetentionPeriod: 86400, // Store messages for 1 day
    deliveryPaused: false
  }
});
```

# Bind to a Worker

Attach a queue to a worker for processing messages.

```ts
import { Worker, Queue } from "alchemy/cloudflare";

const queue = await Queue("my-queue", {
  name: "my-queue"
});

await Worker("my-worker", {
  name: "my-worker", 
  script: "console.log('Hello, world!')",
  bindings: {
    MY_QUEUE: queue
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/redwood.md">
# Redwood

Deploy a RedwoodJS application to Cloudflare Pages with automatically configured defaults. This resource handles the deployment of RedwoodJS applications with optimized settings for Cloudflare Workers.

# Minimal Example

Deploy a basic RedwoodJS application with default settings:

```ts
import { Redwood } from "alchemy/cloudflare";

const redwoodApp = await Redwood("my-redwood-app");
```

# With Database Binding

Add a D1 database binding to your RedwoodJS application:

```ts
import { Redwood, D1Database } from "alchemy/cloudflare";

const database = await D1Database("redwood-db");

const redwoodApp = await Redwood("redwood-with-db", {
  bindings: {
    DB: database
  }
});
```

# Custom Build Configuration

Deploy with custom build command and environment variables:

```ts
import { Redwood } from "alchemy/cloudflare";

const redwoodApp = await Redwood("custom-redwood", {
  command: "bun run test && RWSDK_DEPLOY=1 bun run build:production",
  bindings: {
    API_KEY: alchemy.secret("api-key-secret")
  },
  vars: {
    NODE_ENV: "production",
    APP_ENV: "staging"
  }
});
```

# Bind to a Worker

Bind a RedwoodJS application to a Worker:

```ts
import { Worker, Redwood } from "alchemy/cloudflare";

const redwoodApp = await Redwood("my-redwood-app", {
  name: "redwood-worker",
  command: "bun run build"
});

await Worker("my-worker", {
  name: "my-worker", 
  script: "console.log('Hello from worker')",
  bindings: {
    REDWOOD: redwoodApp
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/route.md">
# Route

The Route resource lets you map URL patterns to [Cloudflare Workers](https://developers.cloudflare.com/workers/configuration/routing/routes/).

# Minimal Example

Map a domain pattern to a Worker:

```ts
import { Route } from "alchemy/cloudflare";

const route = await Route("api-route", {
  pattern: "api.example.com/*", 
  script: "my-worker",
  zoneId: "your-zone-id"
});
```

# Route with Worker Resource

Use a Worker resource directly:

```ts
import { Worker, Route } from "alchemy/cloudflare";

const worker = await Worker("api", {
  script: `
    export default {
      fetch(request) {
        return new Response("Hello from API!");
      }
    }
  `
});

const route = await Route("api-route", {
  pattern: "api.example.com/*",
  script: worker,
  zoneId: "your-zone-id"
});
```

# Bind to a Worker

Routes are automatically bound to the specified Worker:

```ts
import { Worker, Route } from "alchemy/cloudflare";

const route = await Route("my-route", {
  pattern: "api.example.com/*",
  script: "my-worker",
  zoneId: "your-zone-id"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    myRoute: route
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/tanstack-start.md">
# TanStackStart

Deploy a TanStack Start application to Cloudflare Pages with automatically configured defaults.

# Minimal Example

```ts
import { TanStackStart } from "alchemy/cloudflare";

const app = await TanStackStart("my-app");
```

# With Custom Build Command

```ts
import { TanStackStart } from "alchemy/cloudflare";

const app = await TanStackStart("my-app", {
  command: "bun run test && bun run build:production"
});
```

# With Database Binding

```ts
import { TanStackStart, D1Database } from "alchemy/cloudflare";

const database = await D1Database("my-db", {
  name: "my-db"
});

const app = await TanStackStart("my-app", {
  bindings: {
    DB: database
  }
});
```

# With Environment Variables

```ts
import { TanStackStart } from "alchemy/cloudflare";

const app = await TanStackStart("my-app", {
  bindings: {
    API_KEY: alchemy.secret(process.env.API_KEY)
  },
  vars: {
    NODE_ENV: "production",
    APP_ENV: "staging"
  }
});
```

# Bind to a Worker

```ts
import { Worker, TanStackStart } from "alchemy/cloudflare";

const app = await TanStackStart("my-app");

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    APP: app
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/vite.md">
# Vite

Deploy a [Vite](https://vitejs.dev/) application to Cloudflare Workers with automatic configuration.

# Minimal Example

Deploy a basic Vite app with default settings.

```ts
import { Vite } from "alchemy/cloudflare";

const app = await Vite("my-vite-app", {
  name: "my-vite-app",
  command: "bun run build"
});
```

# With Custom Bindings

Add database and environment bindings to the Vite app.

```ts
import { Vite, D1Database } from "alchemy/cloudflare";

const db = await D1Database("my-db", {
  name: "my-db"
});

const app = await Vite("my-vite-app", {
  name: "my-vite-app",
  bindings: {
    DB: db,
    API_KEY: alchemy.secret(process.env.API_KEY)
  }
});
```

# With Custom Build Configuration

Customize the build command and output paths.

```ts
import { Vite } from "alchemy/cloudflare";

const app = await Vite("my-vite-app", {
  name: "my-vite-app",
  command: "bun run test && bun run build:production",
  main: "./dist/worker.js",
  assets: "./dist/client"
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/website.md">
# Website

The Website resource deploys a static website to Cloudflare Pages with an optional Worker for server-side functionality.

# Minimal Example

Deploy a static site from a local directory:

```ts
import { Website } from "alchemy/cloudflare";

const site = await Website("my-site", {
  name: "my-site",
  command: "npm run build",
  assets: "./dist"
});
```

# With Custom Worker

Add server-side functionality with a Worker:

```ts
const site = await Website("my-site", {
  name: "my-site", 
  command: "npm run build",
  assets: "./dist",
  main: "./src/worker.ts",
  bindings: {
    DB: database,
    API_KEY: alchemy.secret(process.env.API_KEY)
  }
});
```

# With Advanced Configuration

Configure caching, routing and other options:

```ts
const site = await Website("my-site", {
  name: "my-site",
  command: "npm run build",
  assets: {
    dist: "./dist",
    html_handling: "force-trailing-slash",
    not_found_handling: "single-page-application",
    _headers: "/*\n  Cache-Control: public, max-age=3600",
    _redirects: "/old/* /new/:splat 301"
  },
  compatibilityFlags: ["nodejs_compat"],
  wrangler: true
});
```

# Bind to a Worker

Use the Website's assets in another Worker:

```ts
import { Worker, Website } from "alchemy/cloudflare";

const site = await Website("my-site", {
  command: "npm run build",
  assets: "./dist"
});

await Worker("api", {
  name: "api-worker",
  script: "console.log('Hello')",
  bindings: {
    ASSETS: site 
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/worker.md">
# Worker

A [Cloudflare Worker](https://developers.cloudflare.com/workers/) is a serverless function that runs on Cloudflare's global network.

# Minimal Example

Create a basic HTTP handler worker:

```ts
import { Worker } from "alchemy/cloudflare";

const worker = await Worker("api", {
  name: "api-worker", 
  entrypoint: "./src/api.ts"
});
```

# With Bindings

Attach resources like KV, R2, or Durable Objects:

```ts
import { Worker, KVNamespace, DurableObjectNamespace } from "alchemy/cloudflare";

const kv = await KVNamespace("cache", { title: "cache-store" });
const users = new DurableObjectNamespace("users", { className: "Users" });

const worker = await Worker("api", {
  name: "api-worker",
  entrypoint: "./src/api.ts",
  bindings: {
    CACHE: kv,
    USERS: users
  }
});
```

# With Static Assets

Serve static files from a directory:

```ts
import { Worker, Assets } from "alchemy/cloudflare";

const assets = await Assets("static", {
  path: "./public"
});

const worker = await Worker("frontend", {
  name: "frontend-worker", 
  entrypoint: "./src/worker.ts",
  bindings: {
    ASSETS: assets
  }
});
```

# With Cron Triggers

Schedule recurring tasks:

```ts
import { Worker } from "alchemy/cloudflare";

const worker = await Worker("cron", {
  name: "cron-worker",
  entrypoint: "./src/cron.ts",
  crons: ["0 0 * * *"] // Run daily at midnight
});
```

# Bind to a Worker

Use a worker as a binding in another worker:

```ts
import { Worker } from "alchemy/cloudflare";

const api = await Worker("api", {
  name: "api-worker",
  entrypoint: "./src/api.ts"
});

const frontend = await Worker("frontend", {
  name: "frontend-worker",
  entrypoint: "./src/frontend.ts",
  bindings: {
    API: api
  }
});
```

# With Custom Domain Routing

```ts
import { Worker, Route, Zone } from "alchemy/cloudflare";

const zone = await Zone("example-zone", {
  name: "example.com",
  type: "full",
});

const api = await Worker("api", {
  name: "api-worker",
  entrypoint: "./src/api.ts"
});

const route = await Route("route", {
  zoneId: zone.id,
  worker: api,
  pattern: "api.example.com/*"
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/workflow.md">
# Workflow

A [Cloudflare Workflow](https://developers.cloudflare.com/workers/configuration/workflows/) allows you to define reusable logic that can be shared across multiple Workers.

# Minimal Example

Create a basic workflow that can be bound to a Worker.

```ts
import { Workflow } from "alchemy/cloudflare";

const workflow = await Workflow("my-workflow", {
  workflowName: "my-workflow",
  className: "MyWorkflow"
});
```

# Bind to a Worker

Bind a workflow to a Worker to use its functionality.

```ts
import { Worker, Workflow } from "alchemy/cloudflare";

const workflow = await Workflow("my-workflow", {
  workflowName: "my-workflow", 
  className: "MyWorkflow"
});

await Worker("my-worker", {
  name: "my-worker",
  script: "console.log('Hello, world!')",
  bindings: {
    WORKFLOW: workflow
  }
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/wrangler.json.md">
# WranglerJson

The WranglerJson resource generates a `wrangler.json` configuration file for a Cloudflare Worker. This file is used by the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/) to deploy and manage Workers.

# Minimal Example

Creates a basic wrangler.json file for a Worker:

```ts
import { Worker, WranglerJson } from "alchemy/cloudflare";

const worker = await Worker("api", {
  name: "api-worker", 
  entrypoint: "./src/index.ts"
});

await WranglerJson("wrangler", {
  worker
});
```

# With Custom Path

Specify a custom path for the wrangler.json file:

```ts
await WranglerJson("wrangler", {
  worker,
  path: "./config/wrangler.dev.json"
});
```

# With Bindings

Generate wrangler.json with Worker bindings:

```ts
const kv = await KVNamespace("cache", {
  title: "cache-store"
});

const queue = await Queue("tasks", {
  name: "task-queue"
});

const worker = await Worker("api", {
  name: "api-worker",
  entrypoint: "./src/index.ts",
  bindings: {
    CACHE: kv,
    TASKS: queue
  }
});

await WranglerJson("wrangler", {
  worker
});
```
</file>

<file path="alchemy-web/docs/providers/cloudflare/zone.md">
# Zone

The Zone resource lets you manage [Cloudflare DNS zones](https://developers.cloudflare.com/dns/zone-setups/) and their configuration settings.

# Minimal Example

Create a basic DNS zone with default settings.

```ts
import { Zone } from "alchemy/cloudflare";

const zone = await Zone("example-zone", {
  name: "example.com",
  type: "full",
  delete: true //Default true: Delete's Zone on --destroy
});
```

# Enhanced Security Settings

Configure a zone with strict SSL and enhanced security settings.

```ts
const secureZone = await Zone("secure-zone", {
  name: "secure.example.com",
  settings: {
    ssl: "strict",
    alwaysUseHttps: "on", 
    minTlsVersion: "1.3",
    tls13: "zrt"
  }
});
```

# Performance Optimization

Create a zone optimized for performance with HTTP/3 and caching.

```ts
const fastZone = await Zone("fast-zone", {
  name: "fast.example.com", 
  settings: {
    browserCacheTtl: 7200,
    brotli: "on",
    http3: "on",
    earlyHints: "on"
  }
});
```

# Development Mode

Configure a zone for development with specific features enabled.

```ts
const devZone = await Zone("dev-zone", {
  name: "dev.example.com",
  settings: {
    developmentMode: "on",
    websockets: "on",
    hotlinkProtection: "on"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/dns/import-dns.md">
# ImportDnsRecords

The ImportDnsRecords resource lets you import DNS records from any domain using [Cloudflare's DNS-over-HTTPS API](https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-https/).

# Minimal Example

Import all default DNS record types for a domain.

```ts
import { ImportDnsRecords } from "alchemy/dns";

const dnsRecords = await ImportDnsRecords("example-com", {
  domain: "example.com"
});
```

# Import Specific Record Types

Import only specified DNS record types.

```ts
import { ImportDnsRecords } from "alchemy/dns";

const records = await ImportDnsRecords("example-com", {
  domain: "example.com",
  recordTypes: ["A", "MX"]
});
```

# Transfer Records to Cloudflare

Import DNS records and transfer them to a Cloudflare zone.

```ts
import { ImportDnsRecords, DnsRecords } from "alchemy/dns";

const dnsRecords = await ImportDnsRecords("dns-records", {
  domain: "example.com"
});

await DnsRecords("transfer-records", {
  zoneId: zone.id,
  records: dnsRecords.records
});
```
</file>

<file path="alchemy-web/docs/providers/esbuild/bundle.md">
# Bundle

The Bundle resource uses [esbuild](https://esbuild.github.io/) to bundle JavaScript and TypeScript files into optimized output.

# Minimal Example

Bundle a TypeScript file into ESM format:

```ts
import { Bundle } from "alchemy/esbuild";

const bundle = await Bundle("handler", {
  entryPoint: "src/handler.ts",
  format: "esm"
});
```

# Bundle with Output Directory

Specify an output directory and additional build options:

```ts
const bundle = await Bundle("api", {
  entryPoint: "src/api.ts", 
  outdir: ".build",
  format: "esm",
  platform: "node",
  target: "node18",
  minify: true,
  sourcemap: true
});
```

# Bundle with External Dependencies

Exclude packages from the bundle:

```ts
const bundle = await Bundle("app", {
  entryPoint: "src/app.ts",
  format: "esm",
  external: ["aws-sdk", "lodash"],
  platform: "node"
});
```

# Bundle for Browser

Create a browser-compatible IIFE bundle:

```ts
const bundle = await Bundle("web", {
  entryPoint: "src/main.ts",
  outfile: "dist/bundle.js",
  format: "iife", 
  platform: "browser",
  minify: true,
  sourcemap: "external"
});
```
</file>

<file path="alchemy-web/docs/providers/fs/copy-file.md">
# CopyFile

The CopyFile resource lets you copy files from one location to another in the filesystem.

# Minimal Example

Copy a file to a new location:

```ts
import { CopyFile } from "alchemy/fs";

const copiedFile = await CopyFile("config-copy", {
  src: "config.json", 
  dest: "backup/config.json"
});
```

# Copy Without Overwriting

Copy a file only if the destination doesn't already exist:

```ts
import { CopyFile } from "alchemy/fs";

const safeCopy = await CopyFile("safe-copy", {
  src: "data.json",
  dest: "backup/data.json", 
  overwrite: false
});
```
</file>

<file path="alchemy-web/docs/providers/fs/file.md">
# File

The File resource lets you create, update and delete files in the filesystem with automatic directory creation and cleanup.

## Minimal Example

Create a simple text file:

```ts
import { File } from "alchemy/fs";

const config = await File("config.txt", {
  path: "config.txt", 
  content: "some configuration data"
});
```

## Create File in Nested Directory

The File resource will automatically create parent directories as needed:

```ts
import { File } from "alchemy/fs";

const log = await File("logs/app.log", {
  path: "logs/app.log",
  content: "application log entry"
});
```

## Update File Path and Content

When updating a file's path, the old file is automatically removed:

```ts
import { File } from "alchemy/fs";

let file = await File("config.json", {
  path: "config.json",
  content: '{ "version": "1.0.0" }'
});

// Later, update path and content (old file will be removed)
file = await File("config.json", {
  path: "config/config.json", 
  content: '{ "version": "1.0.1" }'
});
```

## Static File Types

The fs service provides specialized file types for common formats:

```ts
import { StaticJsonFile, StaticTypeScriptFile, StaticYamlFile } from "alchemy/fs";

// Create formatted JSON file
const config = await StaticJsonFile("config.json", {
  api: { endpoint: "https://api.example.com" }
});

// Create formatted TypeScript file 
const component = await StaticTypeScriptFile("Component.ts", `
  export function Component() {
    return <div>Hello</div>
  }
`);

// Create YAML file
const deployment = await StaticYamlFile("deploy.yaml", {
  service: { replicas: 3 }
});
```
</file>

<file path="alchemy-web/docs/providers/fs/folder.md">
# Folder

The Folder resource creates and manages directories in the filesystem with automatic parent directory creation and cleanup on deletion.

# Minimal Example

Create a directory using the ID as the path:

```ts
import { Folder } from "alchemy/fs";

const dir = await Folder("uploads");
```

# Custom Path

Create a directory with an explicit path:

```ts
import { Folder } from "alchemy/fs";

const logs = await Folder("logs", {
  path: "var/log/app"
});
```

# Recursive Creation

Create nested directories with recursive creation enabled (default):

```ts
import { Folder } from "alchemy/fs";

const nested = await Folder("nested", {
  path: "path/to/nested/dir",
  recursive: true 
});
```

# Cleanup Options

Control folder deletion behavior:

```ts
import { Folder } from "alchemy/fs";

const temp = await Folder("temp", {
  path: "temp",
  delete: true, // Delete on destroy (default)
  clean: true // Remove contents on delete
});
```
</file>

<file path="alchemy-web/docs/providers/fs/static-astro-file.md">
# StaticAstroFile

The StaticAstroFile resource lets you create [Astro](https://astro.build) component files with automatic formatting and directory creation.

# Minimal Example

Creates a basic Astro component file:

```ts
import { StaticAstroFile } from "alchemy/fs";

const component = await StaticAstroFile("Header.astro", `
---
const title = "Hello World";
---

<h1>{title}</h1>
`);
```

# Custom Path

Creates an Astro component in a specific directory:

```ts
import { StaticAstroFile } from "alchemy/fs";

const component = await StaticAstroFile("header", 
  "src/components/Header.astro",
  `---
  import Logo from '../components/Logo.astro';
  const navItems = ['Home', 'About', 'Contact'];
  ---
  
  <header>
    <Logo />
    <nav>
      {navItems.map(item => (
        <li><a href={item}>{item}</a></li>
      ))}
    </nav>
  </header>
`);
```

# Full Component Example

Creates a complete Astro component with styles:

```ts
import { StaticAstroFile } from "alchemy/fs";

const component = await StaticAstroFile("Header.astro", `
---
import Logo from '../components/Logo.astro';
const navItems = ['Home', 'About', 'Contact'];
---

<header class="header">
  <Logo />
  <nav>
    <ul>
      {navItems.map(item => (
        <li><a href={item}>{item}</a></li>
      ))}
    </ul>
  </nav>
</header>

<style>
  .header {
    display: flex;
    justify-content: space-between;
    padding: 1rem;
  }
</style>
`);
```
</file>

<file path="alchemy-web/docs/providers/fs/static-css-file.md">
# StaticCSSFile

The StaticCSSFile resource creates and manages static CSS files in your project using [Alchemy's File System](https://alchemy.run/docs/concepts/fs) capabilities.

# Minimal Example

Creates a basic CSS file with styles:

```ts
import { StaticCSSFile } from "alchemy/fs";

const styles = await StaticCSSFile("styles.css", `
  .container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 0 1rem;
  }
`);
```

# Custom Path

Creates a CSS file at a specific path:

```ts
import { StaticCSSFile } from "alchemy/fs";

const styles = await StaticCSSFile("main", 
  "src/styles/main.css",
  `.button {
    background-color: #0062ff;
    color: white;
    border: none;
    padding: 0.5rem 1rem;
    border-radius: 4px;
  }`
);
```
</file>

<file path="alchemy-web/docs/providers/fs/static-html-file.md">
# StaticHTMLFile

The StaticHTMLFile resource creates static HTML files with automatic directory creation and cleanup.

# Minimal Example

Creates a basic HTML file:

```ts
import { StaticHTMLFile } from "alchemy/fs";

const page = await StaticHTMLFile("index.html", `
  <!DOCTYPE html>
  <html>
    <head><title>My Page</title></head>
    <body>Hello World</body>
  </html>
`);
```

# Custom Path

Creates an HTML file at a specific path:

```ts
import { StaticHTMLFile } from "alchemy/fs";

const page = await StaticHTMLFile("home", "pages/index.html", `
  <!DOCTYPE html>
  <html>
    <head>
      <title>Home</title>
      <link rel="stylesheet" href="style.css">
    </head>
    <body>
      <h1>Welcome</h1>
      <p>This is my homepage.</p>
    </body>
  </html>
`);
```
</file>

<file path="alchemy-web/docs/providers/fs/static-json-file.md">
# StaticJsonFile

The StaticJsonFile resource creates formatted JSON files using [Prettier](https://prettier.io/) for consistent formatting.

# Minimal Example

Creates a simple JSON configuration file.

```ts
import { StaticJsonFile } from "alchemy/fs";

const config = await StaticJsonFile("config.json", {
  name: "my-app",
  version: "1.0.0"
});
```

# Custom Path

Creates a JSON file at a specific path.

```ts
import { StaticJsonFile } from "alchemy/fs";

const config = await StaticJsonFile("config", "config/settings.json", {
  api: {
    endpoint: "https://api.example.com",
    version: "v1"
  },
  features: ["auth", "logging"]
});
```

# Complex Configuration

Creates a JSON file with nested configuration.

```ts
import { StaticJsonFile } from "alchemy/fs";

const config = await StaticJsonFile("app-config.json", {
  app: {
    name: "my-app",
    version: "1.0.0",
    settings: {
      theme: "dark",
      notifications: true
    }
  },
  database: {
    host: "localhost",
    port: 5432,
    credentials: {
      user: "admin",
      password: "secret"
    }
  },
  features: [
    "authentication",
    "authorization",
    "logging"
  ]
});
```
</file>

<file path="alchemy-web/docs/providers/fs/static-text-file.md">
# StaticTextFile

The StaticTextFile resource creates and manages plain text files in the filesystem using [Alchemy's File System](https://alchemy.run/docs/concepts/fs) capabilities.

# Minimal Example

Creates a simple text file with content:

```ts
import { StaticTextFile } from "alchemy/fs";

const readme = await StaticTextFile("README.md", 
  "# Project Name\n\nProject description goes here."
);
```

# Custom Path

Creates a text file at a specific path:

```ts
import { StaticTextFile } from "alchemy/fs";

const changelog = await StaticTextFile("CHANGELOG.md",
  "docs/CHANGELOG.md",
  "# Changelog\n\n## v1.0.0\n\n- Initial release"
);
```

# Nested Directory

Creates a text file in a nested directory structure (directories are created automatically):

```ts
import { StaticTextFile } from "alchemy/fs";

const log = await StaticTextFile("app.log",
  "logs/app/app.log", 
  "Application started successfully"
);
```
</file>

<file path="alchemy-web/docs/providers/fs/static-typescript-file.md">
# StaticTypeScriptFile

Creates formatted TypeScript files using [Prettier](https://prettier.io/) for consistent code style.

# Minimal Example

Creates a TypeScript file with automatic formatting.

```ts
import { StaticTypeScriptFile } from "alchemy/fs";

const file = await StaticTypeScriptFile("types.ts", `
  interface User {
    id: string;
    name: string;
    email: string;
  }
`);
```

# Create File with Custom Path

Creates a TypeScript file at a specific path.

```ts
import { StaticTypeScriptFile } from "alchemy/fs";

const component = await StaticTypeScriptFile("components/Button.tsx", `
  interface ButtonProps {
    text: string;
    onClick: () => void;
  }

  export function Button({ text, onClick }: ButtonProps) {
    return <button onClick={onClick}>{text}</button>;
  }
`);
```

# Create React Component

Creates a TypeScript React component with proper formatting.

```ts
import { StaticTypeScriptFile } from "alchemy/fs";

const component = await StaticTypeScriptFile("UserProfile.tsx", `
  interface Props {
    user: {
      name: string;
      avatar: string;
    };
  }

  export function UserProfile({ user }: Props) {
    return (
      <div className="profile">
        <img src={user.avatar} alt={user.name} />
        <h2>{user.name}</h2>
      </div>
    );
  }
`);
```
</file>

<file path="alchemy-web/docs/providers/fs/static-vue-file.md">
# StaticVueFile

The StaticVueFile resource creates [Vue.js](https://vuejs.org/) single-file component files (.vue) with template, script and style sections.

# Minimal Example

Creates a basic Vue component file with template, script and style sections.

```ts
import { StaticVueFile } from "alchemy/fs";

const button = await StaticVueFile("Button.vue", `
<template>
  <button class="btn">{{ text }}</button>
</template>

<script>
export default {
  props: {
    text: String
  }
}
</script>

<style>
.btn {
  padding: 0.5rem 1rem;
}
</style>
`);
```

# Custom Path

Creates a Vue component file at a specific path.

```ts
import { StaticVueFile } from "alchemy/fs";

const header = await StaticVueFile("Header", 
  "components/Header.vue",
  `<template>
    <header>
      <h1>{{ title }}</h1>
      <nav>
        <slot></slot>
      </nav>
    </header>
  </template>

  <script>
  export default {
    props: {
      title: String
    }
  }
  </script>
`);
```
</file>

<file path="alchemy-web/docs/providers/fs/static-yaml-file.md">
# StaticYamlFile

The StaticYamlFile resource creates YAML files with formatted content using the [YAML](https://yaml.org/) format.

# Minimal Example

Creates a simple YAML configuration file.

```ts
import { StaticYamlFile } from "alchemy/fs";

const config = await StaticYamlFile("config.yaml", {
  server: {
    host: "localhost",
    port: 3000
  }
});
```

# Nested Configuration

Creates a YAML file with nested configuration objects.

```ts
import { StaticYamlFile } from "alchemy/fs";

const config = await StaticYamlFile("config.yaml", {
  server: {
    host: "localhost",
    port: 3000
  },
  database: {
    url: "postgresql://localhost:5432/db",
    pool: {
      min: 1, 
      max: 10
    }
  }
});
```

# Custom Path

Creates a YAML file at a specific path.

```ts
import { StaticYamlFile } from "alchemy/fs";

const config = await StaticYamlFile("config", "config/app.yaml", {
  environment: "production",
  features: ["auth", "api", "storage"]
});
```
</file>

<file path="alchemy-web/docs/providers/github/repository-environment.md">
# RepositoryEnvironment

The RepositoryEnvironment resource lets you manage [GitHub repository environments](https://docs.github.com/en/actions/deployment/targeting-different-environments/using-environments-for-deployment) for deployment protection rules and secrets.

# Minimal Example

Create a basic environment with no protection rules:

```ts
import { RepositoryEnvironment } from "alchemy/github";

const devEnv = await RepositoryEnvironment("dev-environment", {
  owner: "my-org",
  repository: "my-repo", 
  name: "development"
});
```

# Production Environment with Approvals

Create a production environment with approval requirements and protected branches:

```ts
import { RepositoryEnvironment } from "alchemy/github";

const prodEnv = await RepositoryEnvironment("prod-environment", {
  owner: "my-org",
  repository: "my-repo",
  name: "production",
  waitTimer: 10, // 10 minute delay
  preventSelfReview: true,
  reviewers: {
    teams: ["platform-team"], // team name
    users: ["security-admin"] // username
  },
  deploymentBranchPolicy: {
    protectedBranches: true,
    customBranchPolicies: false
  }
});
```

# Custom Branch Patterns

Create an environment with custom branch deployment patterns:

```ts
import { RepositoryEnvironment } from "alchemy/github";

const stagingEnv = await RepositoryEnvironment("staging-environment", {
  owner: "my-org",
  repository: "my-repo",
  name: "staging",
  reviewers: {
    teams: [1234567], // team ID
    users: [7654321]  // user ID
  },
  deploymentBranchPolicy: {
    protectedBranches: false,
    customBranchPolicies: true
  },
  branchPatterns: ["main", "release/*"]
});
```
</file>

<file path="alchemy-web/docs/providers/github/secret.md">
# GitHubSecret

The GitHubSecret resource lets you manage [GitHub Actions secrets](https://docs.github.com/en/actions/security-guides/encrypted-secrets) in repositories and environments.

# Minimal Example

Create a repository-level secret:

```ts
import { GitHubSecret } from "alchemy/github";

const secret = await GitHubSecret("api-key", {
  owner: "my-org",
  repository: "my-repo", 
  name: "API_KEY",
  value: alchemy.secret("my-secret-value")
});
```

# Environment Secret

Create a secret scoped to a specific environment:

```ts
import { GitHubSecret } from "alchemy/github";

const secret = await GitHubSecret("prod-secret", {
  owner: "my-org",
  repository: "my-repo",
  name: "DEPLOY_KEY",
  value: alchemy.secret("secret-value"),
  environment: "production"
});
```

# Multiple Secrets

Create multiple secrets in a repository:

```ts
import { GitHubSecret } from "alchemy/github";

const secrets = await Promise.all([
  GitHubSecret("aws-secret", {
    owner: "my-org",
    repository: "my-repo",
    name: "AWS_KEY",
    value: alchemy.secret(process.env.AWS_KEY)
  }),
  GitHubSecret("db-secret", {
    owner: "my-org", 
    repository: "my-repo",
    name: "DB_PASSWORD",
    value: alchemy.secret(process.env.DB_PASSWORD)
  })
]);
```
</file>

<file path="alchemy-web/docs/providers/neon/project.md">
# NeonProject

The NeonProject resource lets you create and manage [Neon serverless PostgreSQL](https://neon.tech) projects.

# Minimal Example

Create a basic Neon project with default settings:

```ts
import { NeonProject } from "alchemy/neon";

const project = await NeonProject("my-project", {
  name: "My Project"
});
```

# Custom Region and Version

Create a project in a specific region with a specific PostgreSQL version:

```ts
import { NeonProject } from "alchemy/neon";

const project = await NeonProject("eu-project", {
  name: "EU Project",
  region_id: "aws-eu-west-1", 
  pg_version: 16,
  apiKey: alchemy.secret(process.env.NEON_API_KEY)
});
```

# Custom Branch Name

Create a project with a custom default branch name:

```ts
import { NeonProject } from "alchemy/neon";

const project = await NeonProject("dev-project", {
  name: "Development Project",
  default_branch_name: "development"
});
```
</file>

<file path="alchemy-web/docs/providers/os/exec.md">
# Exec

The Exec resource allows you to execute shell commands as part of your Alchemy infrastructure. It provides a way to run system commands with full control over the execution environment and output handling.

## Minimal Example

Execute a simple shell command:

```ts
import { Exec } from "alchemy/os";

const result = await Exec("list-files", {
  command: "ls -la"
});

console.log(result.stdout);
```

## Working Directory and Environment

Run a command in a specific directory with custom environment variables:

```ts
import { Exec } from "alchemy/os";

const build = await Exec("build-project", {
  command: "npm run build",
  cwd: "./my-project",
  env: { 
    NODE_ENV: "production"
  }
});
```

## Command Memoization 

Cache command output and only re-run when the command changes:

```ts
import { Exec } from "alchemy/os";

const status = await Exec("git-status", {
  command: "git status",
  memoize: true
});
```

## Custom Buffer Size

Handle large command output by increasing the buffer size:

```ts
import { Exec } from "alchemy/os";

const logs = await Exec("get-logs", {
  command: "cat large-log-file.log", 
  maxBuffer: 10 * 1024 * 1024 // 10MB
});
```
</file>

<file path="alchemy-web/docs/providers/stripe/price.md">
# Price

The Price resource lets you create and manage [Stripe Prices](https://stripe.com/docs/api/prices) for products.

# Minimal Example

Create a one-time fixed price for a product:

```ts
import { Price } from "alchemy/stripe";

const price = await Price("basic-license", {
  currency: "usd", 
  unitAmount: 2999, // $29.99
  product: "prod_xyz"
});
```

# Recurring Subscription Price

Create a recurring subscription price with fixed monthly billing:

```ts
import { Price } from "alchemy/stripe";

const subscriptionPrice = await Price("pro-monthly", {
  currency: "usd",
  unitAmount: 1499, // $14.99/month
  product: "prod_xyz",
  recurring: {
    interval: "month",
    usageType: "licensed"
  }
});
```

# Metered Usage Price

Create a metered price for usage-based billing:

```ts
import { Price } from "alchemy/stripe";

const meteredPrice = await Price("storage", {
  currency: "usd", 
  unitAmount: 25, // $0.25 per GB
  product: "prod_xyz",
  recurring: {
    interval: "month",
    usageType: "metered",
    aggregateUsage: "sum"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/stripe/product.md">
# Product

The Product resource lets you create and manage [Stripe Products](https://stripe.com/docs/api/products) for your Stripe account.

# Minimal Example

Create a basic digital product:

```ts
import { Product } from "alchemy/stripe";

const product = await Product("basic-software", {
  name: "Basic Software License",
  description: "Single-user license for basic software package"
});
```

# Physical Product

Create a physical product with shipping details:

```ts
import { Product } from "alchemy/stripe";

const product = await Product("premium-hardware", {
  name: "Premium Hardware Kit", 
  description: "Complete hardware kit with premium components",
  shippable: true,
  images: ["https://example.com/hardware-kit.jpg"],
  unitLabel: "kit",
  statementDescriptor: "PREMIUM HW KIT"
});
```

# Service Product

Create a service product with tax code:

```ts
import { Product } from "alchemy/stripe";

const product = await Product("consulting", {
  name: "Professional Consulting",
  description: "Expert consulting services", 
  type: "service",
  taxCode: "txcd_10000000",
  metadata: {
    industry: "technology",
    expertise: "cloud"
  }
});
```
</file>

<file path="alchemy-web/docs/providers/stripe/webhook.md">
# WebhookEndpoint

The WebhookEndpoint resource lets you create and manage [Stripe Webhook Endpoints](https://stripe.com/docs/api/webhook_endpoints) to receive notifications about events in your Stripe account.

# Minimal Example

Create a basic webhook endpoint to receive payment notifications:

```ts
import { WebhookEndpoint } from "alchemy/stripe";

const webhook = await WebhookEndpoint("payments", {
  url: "https://api.example.com/webhooks/stripe",
  enabledEvents: ["payment_intent.succeeded", "payment_intent.payment_failed"],
  description: "Payment notifications webhook"
});
```

# Subscription Events

Create a webhook to monitor subscription lifecycle events:

```ts
import { WebhookEndpoint } from "alchemy/stripe";

const webhook = await WebhookEndpoint("subscriptions", {
  url: "https://api.example.com/webhooks/subscriptions", 
  enabledEvents: [
    "customer.subscription.created",
    "customer.subscription.updated",
    "customer.subscription.deleted",
    "invoice.payment_succeeded",
    "invoice.payment_failed"
  ],
  metadata: {
    type: "subscription-events"
  }
});
```

# Connect Platform Events

Create a webhook for Stripe Connect platform events:

```ts
import { WebhookEndpoint } from "alchemy/stripe";

const webhook = await WebhookEndpoint("connect", {
  url: "https://api.example.com/webhooks/connect",
  enabledEvents: [
    "account.updated",
    "account.application.deauthorized", 
    "payout.created",
    "payout.failed"
  ],
  connect: true,
  metadata: {
    platform: "connect"
  }
});
```
</file>

<file path="alchemy-web/docs/getting-started.md">
# Getting Started with Alchemy

> [!TIP]
> Read [What is Alchemy](./what-is-alchemy.md) to get an overview of Alchemy and how it's different than tradtional IaC

## Installation

Start by installing the Alchemy library using Bun (or your preferred package manager):

::: code-group

```sh [bun]
bun add alchemy
```

```sh [npm]
npm add alchemy
```

```sh [pnpm]
pnpm add alchemy
```

```sh [yarn]
yarn add alchemy
```

:::

## Create Your First Alchemy App

Create a file named `alchemy.run.ts` in your project directory and follow these steps:

> [!TIP]
> `alchemy.run.ts` is just a convention - you can run Alchemy in any script or JavaScript environment.

### Step 1: Initialize the Alchemy Application Scope

```typescript
import alchemy from "alchemy";

// Initialize the Alchemy application scope
const app = await alchemy("my-first-app", {
  stage: "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
});
```

> [!NOTE]
> Learn more about Alchemy scopes in [Concepts: Scope](./concepts/scope.md)

### Step 2: Instantiate a Resource

A Resource is just an async function that takes a unique id (e.g. `config`) and some properties.

```typescript
import { File } from "alchemy/fs";

// Create a file resource
const hello = await File("hello", {
  path: "./hello.txt",
  content: "hello world"
});

console.log(`Created file at: ${hello.path}`);
```

> [!NOTE]
> Learn more about Alchemy resources in [Concepts: Resource](./concepts/resource.md)

### Step 3: Finalize the Application

At the end of our script, call `finalize`.

```typescript
// Finalize the app to apply changes
await app.finalize();
```

This is necessary for deleting what are called "orphaned resources" (more on that below).

> [!NOTE]
> Learn more about finalization and destroying resources in [Concepts: Destroy](./concepts/destroy.md)

## Run the Script

Now we simply run the script. Alchemy is just pure TypeScript, so you can run it with any JS engine, e.g. `bun`:

```bash
bun ./alchemy.run.ts
```

You will see output similar to:

```
Create:  "my-first-app/dev/hello"
Created: "my-first-app/dev/hello"
```

This indicates that Alchemy has:
1. Identified that the resource needs to be created
2. Successfully created the resource

We now have a `./hello.txt` file in our project:
```
hello world
```

> [!TIP]
> If you're familiar with other IaC tools, this should feel similar to `terraform apply`, `pulumi up`, `cdk deploy` or `sst deploy`

## Understanding State

After running your app, Alchemy creates a `.alchemy` directory to store state:

```sh
.alchemy/
  my-first-app/         # app
    dev/                # stage
      hello.txt.json  # resource
```

State files help Alchemy determine whether to create, update, delete, or skip resources on subsequent runs.

If you run the same script again without changes, you'll see no operations performed because the state hasn't changed.

> [!NOTE]
> Learn more about Alchemy state in [Concepts: State](./concepts/state.md)

## Update our File

Let's now update our `alchemy.run.ts` script to change the content of the file:

```ts
const hello = await File("hello", {
  // path: "./hello.txt",
  path: "./hello-world.txt",
  // content: "hello world"
  content: "Hello, world!"
});
```

Now, when we re-run the script, we'll see:
```
Update:  "my-first-app/dev/hello"
Updated: "my-first-app/dev/hello"
```

And now the `hello.txt` file is gone and replaced with `hello-world.txt` with different content:
```
Hello, World
```

Notice how we didn't have to write any code to delete the old file?

In a nutshell, that's the point of Infrastructure-as-Code - we just write code that creates the state we want and Alchemy takes care of deciding what to create, update or delete and in what order.

## Destroy the Resource

Let's now comment out the `File` and run it again.

```typescript
// const hello = await File("hello", {
//   path: "./hello-world.txt",
//   content: "Hello, world!"
// });
```

> [!CAUTION]
> Now, before we run our script again, you need to first add a "naked" impot of `alchemy/fs` at the top of our `alchemy.run.ts` script.
> ```typescript
> import "alchemy/fs"
> ```
> If you forget this, you would get an error
> `Cannot destroy resource "my-first-app/dev/hello" type fs::File - no provider found. You may need to import the provider in your alchemy.config.ts.`
> 
> This is because IDEs usually remove unused imports. If you don't import the resource, the delete handler won't be registered which Alchemy needs to delete the resource.

The output should look like:

```
Delete:  "my-first-app/dev/hello"
Deleted: "my-first-app/dev/hello"
```

And the `hello-world.txt` file is now gone.

> [!NOTE]
> You can read more about how to destroy resoruces and stacks in [Concepts: Destroy](./concepts/destroy.md)

## Next Steps

This was a very simple example using the local file system. Now, you might want to do something more interesting like deploy some Cloudflare resources or build your own!

- [Deploy a ViteJS site to Cloudflare](./guides/cloudflare-vitejs)
- [Build your own Custom Resource](./guides/custom-resources.md)
</file>

<file path="alchemy-web/docs/index.md">
# Alchemy

Alchemy is an embeddable, zero-dependency Infrastructure-as-Code library in pure TypeScript that runs anywhere JavaScript runs.

- [What is Alchemy?](./what-is-alchemy.md)
- [Getting Started](./getting-started.md)
</file>

<file path="alchemy-web/docs/what-is-alchemy.md">
# What is Alchemy

Alchemy is an embeddable, zero-dependency, Infrastructure-as-Code (IaC) library written in pure TypeScript that runs anywhere that JavaScript runs - including the browser, serverless functions or even durable workflows.

## What is Infrastructure as Code?

Infrastructure-as-Code is the practice of using code to define your infrastructure configuration instead of manually creating it. 

Let's say you need a database. Instead of clicking through a cloud console or executing a CLI command, you simply write:

```typescript
const database = await Database("main", { 
  engine: "postgres",
  size: "small"
});

// Access properties directly
console.log(database.connectionString);
```

Run this code, and the actual database gets created. Run it twice without changes, and nothing happens. Change the size to `"medium"` and run it again - your database will be updated. Remove the code and run it again, the database will be deleted.

Your code is the blueprint for repeatable infrastructure. Alchemy keeps track of all the resources and handles the synchronization between your code and the real world.

## How is Alchemy different than traditonal IaC?

Unlike similar tools like Terraform, Pulumi, SST and CloudFormation, Alchemy is implemented in pure ESM-native TypeScript code. 

The Terraform, Pulumi and SST ecosystem are all tied together. SST is on top of Pulumi, which is again on top of Terraform. Terraform and Pulumi are implemented in Go and generate TypeScript "wrappers" that depend on a separate Go process.

The AWS CDK genereates CloudFormation JSON, depends on a managed service to run and only supports AWS services. Extending CloudFormation requires you deploy a Lambda Function (which is an ordeal).

All together, IaC without Alchemy is a clunky, heavy, opinionated toolchain that mostly works against you as a user. Alchemy simplifies the entire stack down to pure async functions.

## Zero Dependencies

Alchemy adopts a philosophy of zero-dependencies and web standards so that it can run anywhere with minimal impact on bundle size.

All you gotta do is install `alchemy` and you're good to go.

```sh
bun add alchemy
```

## Just Async Functions

Resources in Alchemy are implemented with async functions instead of complex class abstractions with sharp edge gotchas, inter-process-communication or hosted services.

This means you can create resources in any async environment and gain access to its physical properties immediately:

```typescript
// Create a resource by awaiting a function
const worker = await Worker("api", {
  name: "my-api",
  entrypoint: "./src/index.ts"
});

console.log(worker.workerName) // string
```

Contrast this with Pulumi which relies on a complex graph abstraction:
```ts
const worker = new Worker("api", {
  name: "my-api",
  entrypoint: "./src/index.ts"
});

worker.workerName // Output<string>

// requires a complex abstraction just to log a value 
pulumi.export(worker.workerName)
```

## Runs Anywhere

Alchemy works in any JavaScript environment including browsers, serverless functions, and durable workflows.

```typescript
// Browser environment
const app = await alchemy("my-browser-app");

// Lambda function
export const handler = async () => {
  await alchemy.run("customer-id", async () => {
    await Worker(..)
  })
};
```

## Transparent State

State is stored as plain JSON files you can inspect, edit, and version control.

```json
// .alchemy/my-app/prod/api.json
{
  "provider": "cloudflare::Worker",
  "status": "created",
  "output": {
    "id": "my-api",
    "url": "https://my-api.workers.dev"
  },
  "props": {
    "name": "my-api",
    "entrypoint": "./src/index.ts"
  }
}
```

> [!NOTE]
> You usually don't want to edit these files, but when things go wrong, having state that is easy to understand and change is useful.

## Pluggable State

Alchemy supports custom state backends including file systems, cloud storage, or databases.

```typescript
// Use Cloudflare R2 for state
import { R2RestStateStore } from "alchemy/cloudflare";

const app = await alchemy("my-app", {
  stateStore: (scope) => new R2RestStateStore(scope, {
    bucketName: "my-state-bucket"
  })
});
```

By default, Alchemy assumes you want to store state files locally for development purposes, but since Alchemy can run anywhere - you may want to store state in the the browser, or a Cloudflare Durable Object!

[Learn more about custom state stores](./guides/custom-state-store.md)

## Direct API Integration

> `fetch` is all you need

Alchemy resources call service APIs directly using `fetch`, instead of using SDKs that often come with heavy dependencies and runtime requirements.

```typescript
// Resource implementation using direct API calls
if (this.phase === "delete") {
  await fetch(`https://api.example.com/resources/${this.output.id}`, {
    method: "DELETE",
    headers: { "Authorization": `Bearer ${apiKey}` }
  });
  return this.destroy();
}
```

## Custom Resources in Minutes

Create new resource types with a simple function that implements create, update, and delete operations.

```typescript
export const Database = Resource(
  "myservice::Database",
  async function(this: Context<Database>, id: string, props: DatabaseProps): Promise<Database> {
    if (this.phase === "delete") {
      // Delete logic
      return this.destroy();
    } else if (this.phase === "update") {
      // Update logic
      return this({ id: "db-123", ...props });
    } else {
      // Create logic
      return this({ id: "db-123", ...props });
    }
  }
);
```

## Optimized for AI

Alchemy provides a `.cursorrules` file to help AI tools generate resource implementations at 90% accuracy on the first try.

```typescript
// 1. Copy Alchemy's .cursorrules into your repo
// 2. Ask AI: "Create a resource for Neon Database"
// 3. Get a working implementation in seconds

// Result: Complete implementation with proper lifecycle handling
export const Database = Resource(
  "neon::Database",
  async function(this: Context<Database>, id: string, props: DatabaseProps): Promise<Database> {
    // Full resource implementation generated by AI
  }
);
```

[Learn more about AI-generated resources](./guides/custom-resources.md)

## Fast Deployments

Alchemy deployments are fast because they run directly in JavaScript without spawning external processes or slow toolchains.

```typescript
// No IPC, no Go toolchains, no CloudFormation waiting
// Just direct JavaScript execution calling APIs
// $ time bun ./alchemy.run.ts
// real    0m1.234s
```

## Flexible Scoping

Alchemy organizes resources with a hierarchical scope system that supports infinite nesting and isolation.

```typescript
// Root and stage scopes
const app = await alchemy("my-app", { 
  stage: "prod",
  password: "prod-secret"  // Encryption password for this scope
});
```

## Secure Secrets

Alchemy encrypts sensitive values in state files.

```typescript
// Define a secret
const apiKey = alchemy.secret(process.env.API_KEY);

// Use it in a resource
const worker = await Worker("api", {
  bindings: { API_KEY: apiKey }
});

// In state files, it's encrypted
// "API_KEY": { "@secret": "Tgz3e/WAscu4U1oanm5S4YXH..." }
```

## Scoped Encryption and State

Each scope can have a different encryption password and state store.

```ts
// Nested scopes can have different passwords and state stores
await alchemy.run("backend", { 
  password: "backend-secret",
  stateStore: new DatabaseStateStore()
}, async (scope) => {
  // Create resources in this scope
  await Worker("api", { /* ... */ });
  
  // Deeper nesting works too
  await alchemy.run("database", async () => {
    await Database("main", { /* ... */ });
  });
});
```

## Application Examples

Alchemy works for a wide range of infrastructure use cases.

```typescript
// Cloudflare Workers and Static Sites
const assets = await Assets("Assets", {
  path: "./dist"
})

const site = await Worker("Website", {
  name: "my-app",
  bindings: {
    ASSETS: assets
  }
});

// AWS Lambda Functions
const func = await Function("api", {
  handler: "src/lambda.handler",
  environment: { TABLE_NAME: table.name }
});

// Third-party APIs like Stripe
const product = await Product("pro-plan", {
  name: "Pro Plan",
  description: "Professional subscription tier"
});
```

## Getting Started

Ready to try Alchemy? Check out our [Getting Started guide](./getting-started.md) to build your first Alchemy app.
</file>

<file path="alchemy-web/.gitignore">
.vitepress/cache
</file>

<file path="alchemy-web/index.md">
---
layout: home
title: Alchemy

hero:
  name: Alchemy
  text: Create, Update, Delete
  image: /alchemist.webp

  tagline: Infrastructure-as-Code without the dead weight. Written in pure TypeScript, optimized for Gen-AI.
  actions:
    - theme: brand
      text: Get Started
      link: /docs/getting-started
    - theme: alt
      text: Star on GitHub 
      link: https://github.com/sam-goodwin/alchemy
---
</file>

<file path="alchemy-web/package.json">
{
  "name": "alchemy-web",
  "scripts": {
    "docs:gen": "bun alchemy.run.ts",
    "docs:dev": "vitepress dev",
    "docs:build": "vitepress build",
    "docs:preview": "vitepress preview"
  },
  "dependencies": {
    "vitepress-plugin-group-icons": "^1.5.2"
  },
  "devDependencies": {
    "@shikijs/vitepress-twoslash": "^3.4.0",
    "markdown-it-footnote": "^4.0.0",
    "vitepress": "^1.6.3",
    "vue": "^3.5.13"
  }
}
</file>

<file path="examples/aws-app/src/index.ts">
export function handler(event: any, context: any) {
  console.log("Hello, World!");
}
</file>

<file path="examples/aws-app/alchemy.run.ts">
import alchemy from "alchemy";
import { Function, Queue, Role, Table } from "alchemy/aws";
import { R2RestStateStore } from "alchemy/cloudflare";
import { Bundle } from "alchemy/esbuild";
import path from "node:path";
import { fileURLToPath } from "node:url";
const app = await alchemy("aws-app", {
  // decide the mode/stage however you want
  phase: process.argv[2] === "destroy" ? "destroy" : "up",
  stage: process.argv[3],
  quiet: process.argv.includes("--quiet"),
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
});
const __dirname = path.dirname(fileURLToPath(import.meta.url));
const [queue, table, role] = await Promise.all([
  Queue("alchemy-items-queue", {
    queueName: "alchemy-items-queue",
    visibilityTimeout: 30,
    messageRetentionPeriod: 345600, // 4 days
  }),
  // Create DynamoDB table
  Table("alchemy-items-table", {
    tableName: "alchemy-items",
    partitionKey: {
      name: "id",
      type: "S",
    },
  }),
  // Create Lambda execution role with DynamoDB access
  Role("alchemy-api-role", {
    roleName: "alchemy-api-lambda-role",
    assumeRolePolicy: {
      Version: "2012-10-17",
      Statement: [
        {
          Effect: "Allow",
          Principal: {
            Service: "lambda.amazonaws.com",
          },
          Action: "sts:AssumeRole",
        },
      ],
    },
  }),
]);
// Create Lambda function
const bundle = await Bundle("api-bundle", {
  entryPoint: path.join(__dirname, "src", "index.ts"),
  outdir: ".out",
  format: "esm",
  platform: "node",
  target: "node20",
  minify: true,
  sourcemap: true,
  // Don't bundle aws-sdk as it's provided by Lambda
  external: ["@aws-sdk/*"],
});
const api = await Function("api", {
  functionName: "alchemy-items-api",
  bundle,
  roleArn: role.arn,
  handler: "index.handler",
  environment: {
    TABLE_NAME: table.tableName,
  },
  url: {
    // Enable public access
    authType: "NONE",
    cors: {
      allowOrigins: ["*"],
      allowMethods: ["GET", "POST", "PUT", "DELETE"],
      allowHeaders: ["content-type"],
    },
  },
});
await app.finalize();
</file>

<file path="examples/aws-app/package.json">
{
  "name": "aws-app",
  "version": "0.0.0",
  "private": true,
  "scripts": {
    "dev": "bun run index.ts",
    "deploy": "bun run --env-file ../../.env ./alchemy.run.ts",
    "destroy": "bun run --env-file ../../.env ./alchemy.run.ts --destroy"
  },
  "dependencies": {
    "alchemy": "workspace:*"
  }
}
</file>

<file path="examples/aws-app/tsconfig.json">
{
  "extends": "../../tsconfig.base.json",
  "include": ["src/**/*.ts", "alchemy.run.ts"],
  "compilerOptions": {
    "composite": true,
    "resolveJsonModule": true
  },
  "references": [{ "path": "../../alchemy/tsconfig.json" }]
}
</file>

<file path="examples/cloudflare-nuxt-pipeline/pages/index.vue">
<template>
  <div>
    <h1>Nuxt 3 + Alchemy + Cloudflare Pipeline Demo</h1>
    <form @submit.prevent="sendToPipeline">
      <label for="dataInput">Data to send:</label>
      <input id="dataInput" v-model="dataToSend" type="text" required />
      <button type="submit" :disabled="loading">Send to Pipeline</button>
    </form>
    <p v-if="message">{{ message }}</p>
    <p v-if="error" style="color: red">{{ error }}</p>
  </div>
</template>
<script setup lang="ts">
import { ref } from "vue";
const dataToSend = ref("");
const loading = ref(false);
const message = ref("");
const error = ref("");
async function sendToPipeline() {
  loading.value = true;
  message.value = "";
  error.value = "";
  try {
    const response = await fetch("/api/pipeline", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
      },
      body: JSON.stringify({ data: dataToSend.value }),
    });
    const result = (await response.json()) as {
      message?: string;
      statusMessage?: string;
    };
    if (!response.ok) {
      throw new Error(result.statusMessage || "Failed to send data");
    }
    message.value = result.message || "Data sent successfully!";
    dataToSend.value = ""; // Clear input after success
  } catch (err) {
    error.value =
      err instanceof Error ? err.message : "An unknown error occurred.";
    console.error("Error sending to pipeline:", err);
  } finally {
    loading.value = false;
  }
}
</script>
<style scoped>
form {
  display: flex;
  flex-direction: column;
  gap: 10px;
  max-width: 300px;
  margin-top: 20px;
}
label {
  font-weight: bold;
}
input {
  padding: 8px;
  border: 1px solid #ccc;
  border-radius: 4px;
}
button {
  padding: 10px;
  background-color: #007bff;
  color: white;
  border: none;
  border-radius: 4px;
  cursor: pointer;
}
button:disabled {
  background-color: #ccc;
  cursor: not-allowed;
}
</style>
</file>

<file path="examples/cloudflare-nuxt-pipeline/public/robots.txt">
User-Agent: *
Disallow:
</file>

<file path="examples/cloudflare-nuxt-pipeline/server/api/pipeline.post.ts">
import { env } from "cloudflare:workers";
export default defineEventHandler(async (event) => {
  try {
    const body = await readBody(event);
    // @ts-ignore
    const pipeline = env.PIPELINE;
    const data = body.data;
    if (!data) {
      throw new Error("Missing 'data' property in request body");
    }
    // Always send data wrapped in an array
    await pipeline.send([{ value: data }]);
    return { success: true, message: "Data sent to pipeline." };
  } catch (error) {
    console.error("Error sending data to pipeline:", error);
    throw createError({
      statusCode: 500,
      statusMessage: error instanceof Error ? error.message : "Pipeline error",
    });
  }
});
</file>

<file path="examples/cloudflare-nuxt-pipeline/server/tsconfig.json">
{
  "extends": "../.nuxt/tsconfig.server.json"
}
</file>

<file path="examples/cloudflare-nuxt-pipeline/.gitignore">
# Nuxt dev/build outputs
.output
.data
.nuxt
.nitro
.cache
dist

# Node dependencies
node_modules

# Logs
logs
*.log

# Misc
.DS_Store
.fleet
.idea

# Local env files
.env
.env.*
!.env.example
wrangler.jsonc
</file>

<file path="examples/cloudflare-nuxt-pipeline/alchemy.run.ts">
import alchemy from "alchemy";
import { Nuxt, Pipeline, R2Bucket, R2RestStateStore } from "alchemy/cloudflare";
const BRANCH_PREFIX = process.env.BRANCH_PREFIX ?? "";
const app = await alchemy("cloudflare-nuxt-pipeline", {
  stage: process.env.USER ?? "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  quiet: !process.argv.includes("--verbose"),
  password: process.env.SECRET_PASSPHRASE,
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
});
const bucket = await R2Bucket(
  `cloudflare-nuxt-pipeline-bucket${BRANCH_PREFIX}`,
);
const pipeline = await Pipeline(
  `cloudflare-nuxt-pipeline-pipeline${BRANCH_PREFIX}`,
  {
    source: [{ type: "binding", format: "json" }],
    destination: {
      type: "r2",
      format: "json",
      path: {
        bucket: bucket.name,
      },
      credentials: {
        accessKeyId: alchemy.secret(process.env.R2_ACCESS_KEY_ID),
        secretAccessKey: alchemy.secret(process.env.R2_SECRET_ACCESS_KEY),
      },
      batch: {
        maxMb: 10,
        // testing value. recommended - 300
        maxSeconds: 5,
        maxRows: 100,
      },
    },
  },
);
export const website = await Nuxt(
  `cloudflare-nuxt-pipeline-website${BRANCH_PREFIX}`,
  {
    bindings: {
      R2_BUCKET: bucket,
      PIPELINE: pipeline,
    },
  },
);
console.log({
  url: website.url,
});
await app.finalize(); // must be at end
</file>

<file path="examples/cloudflare-nuxt-pipeline/app.vue">
<template>
  <NuxtPage />
</template>
</file>

<file path="examples/cloudflare-nuxt-pipeline/env.d.ts">
/// <reference types="@cloudflare/workers-types" />
import type { worker } from "./alchemy.run.js";
export type WorkerEnv = typeof worker.Env;
declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends WorkerEnv {}
  }
}
</file>

<file path="examples/cloudflare-nuxt-pipeline/index.ts">
/// <reference types="@cloudflare/workers-types" />
import type { WorkerEnv } from "./env";
// @ts-ignore - Suppress type errors if the module isn't found during editing/linting
import nitroApp from "./.output/server/index.mjs";
export default {
  async fetch(
    request: Request,
    environment: WorkerEnv,
    ctx: ExecutionContext,
  ): Promise<Response> {
    const url = new URL(request.url);
    if (url.pathname.startsWith("/api/")) {
      return nitroApp.fetch(request, environment, ctx);
    }
    return environment.ASSETS.fetch(request);
  },
};
</file>

<file path="examples/cloudflare-nuxt-pipeline/nuxt.config.ts">
// https://nuxt.com/docs/api/configuration/nuxt-config
export default defineNuxtConfig({
  compatibilityDate: "2025-04-21",
  devtools: { enabled: true },
  nitro: {
    preset: "cloudflare-module",
    prerender: {
      routes: ["/"],
      autoSubfolderIndex: false,
    },
  },
});
</file>

<file path="examples/cloudflare-nuxt-pipeline/package.json">
{
  "name": "nuxt-pipeline",
  "private": true,
  "type": "module",
  "scripts": {
    "build": "nuxt build",
    "dev": "nuxt dev",
    "generate": "nuxt generate",
    "preview": "nuxt preview",
    "postinstall": "nuxt prepare",
    "deploy": "bun run --env-file ../../.env ./alchemy.run.ts",
    "destroy": "bun run --env-file ../../.env ./alchemy.run.ts --destroy"
  },
  "dependencies": {
    "@cloudflare/workers-types": "^4.20250421.0",
    "cloudflare": "^4.2.0",
    "nuxt": "^3.16.2",
    "vue": "^3.5.13",
    "vue-router": "^4.5.0"
  }
}
</file>

<file path="examples/cloudflare-nuxt-pipeline/README.md">
# Nuxt 3 + Alchemy Basic Example

This example demonstrates deploying a basic Nuxt 3 application to Cloudflare Workers using Alchemy.

It includes:

- A simple Nuxt 3 frontend.
- A Nitro API route (`/api/pipeline`) that sends data to a Cloudflare Pipeline.
- Static asset serving via Cloudflare Workers Assets.
- Configuration using `alchemy.run.ts`.

## Setup

1.  **Install Dependencies:** Navigate to the root of the Alchemy repository and run:
    ```bash
    bun install
    ```
    This will install dependencies for the core library and all examples, including this one.

2.  **Cloudflare Credentials:** Ensure you have your Cloudflare API token and Account ID configured as environment variables:
    ```bash
    export CLOUDFLARE_API_TOKEN="your_api_token"
    export CLOUDFLARE_ACCOUNT_ID="your_account_id"
    ```
    You can also place these in a `.env` file in the repository root.

## Running the Deployment

1.  **Navigate to Example Directory:**
    ```bash
    cd examples/nuxt3-basic
    ```

2.  **Run Alchemy Deployment:**
    ```bash
    bun run deploy
    ```
    Or directly:
    ```bash
    bun ../../src/cli.ts run
    ```

This command will:

- Execute the `bun run build` script defined in `alchemy.run.ts` to build the Nuxt application.
- Provision the Cloudflare Pipeline queue (`nuxt3-pipeline-demo`).
- Upload the static assets from `./.output/public` to Cloudflare Workers Assets.
- Deploy the Cloudflare Worker (`nuxt3-basic-worker`) using the entrypoint `./.output/server/index.mjs`.
- Bind the Assets service and Pipeline queue to the worker.
- Output the URL of the deployed worker.

## Development

To run the Nuxt development server locally:

1.  Navigate to the example directory:
    ```bash
    cd examples/nuxt3-basic
    ```
2.  Run the development server:
    ```bash
    bun run dev
    ```

Note: The `/api/pipeline` route will not function correctly in the local development environment as it relies on Cloudflare environment bindings injected by Alchemy during deployment.

## Cleanup

To destroy the Cloudflare resources created by this example, run:

```bash
cd examples/nuxt3-basic
bun ../../src/cli.ts destroy
```
</file>

<file path="examples/cloudflare-nuxt-pipeline/tsconfig.json">
{
  // https://nuxt.com/docs/guide/concepts/typescript
  "extends": "./.nuxt/tsconfig.json",
  "compilerOptions": {
    "types": ["@cloudflare/workers-types", "@types/node"],
    "jsx": "react-jsx"
  },
  "references": [{ "path": "../../alchemy/tsconfig.json" }]
}
</file>

<file path="examples/cloudflare-redwood/drizzle/meta/_journal.json">
{
  "version": "7",
  "dialect": "sqlite",
  "entries": [
    {
      "idx": 0,
      "version": "6",
      "when": 1743024718213,
      "tag": "0000_lame_kitty_pryde",
      "breakpoints": true
    }
  ]
}
</file>

<file path="examples/cloudflare-redwood/drizzle/meta/0000_snapshot.json">
{
  "version": "6",
  "dialect": "sqlite",
  "id": "da6e7ea7-3118-455b-914c-14ff9239bd40",
  "prevId": "00000000-0000-0000-0000-000000000000",
  "tables": {
    "users": {
      "name": "users",
      "columns": {
        "id": {
          "name": "id",
          "type": "integer",
          "primaryKey": true,
          "notNull": true,
          "autoincrement": true
        },
        "name": {
          "name": "name",
          "type": "text",
          "primaryKey": false,
          "notNull": true,
          "autoincrement": false
        },
        "email": {
          "name": "email",
          "type": "text",
          "primaryKey": false,
          "notNull": true,
          "autoincrement": false
        }
      },
      "indexes": {
        "users_email_unique": {
          "name": "users_email_unique",
          "columns": ["email"],
          "isUnique": true
        }
      },
      "foreignKeys": {},
      "compositePrimaryKeys": {},
      "uniqueConstraints": {},
      "checkConstraints": {}
    }
  },
  "views": {},
  "enums": {},
  "_meta": {
    "schemas": {},
    "tables": {},
    "columns": {}
  },
  "internal": {
    "indexes": {}
  }
}
</file>

<file path="examples/cloudflare-redwood/drizzle/0000_lame_kitty_pryde.sql">
CREATE TABLE `users` (
	`id` integer PRIMARY KEY AUTOINCREMENT NOT NULL,
	`name` text NOT NULL,
	`email` text NOT NULL
);
--> statement-breakpoint
CREATE UNIQUE INDEX `users_email_unique` ON `users` (`email`);
</file>

<file path="examples/cloudflare-redwood/src/app/pages/Home.tsx">
import type { RequestInfo } from "@redwoodjs/sdk/worker";
import { users } from "../../db/schema.js";
export async function Home({ ctx }: RequestInfo) {
  const allUsers = await ctx.db.select().from(users).all();
  return (
    <div>
      <h1>Hello World</h1>
      <pre>{JSON.stringify(allUsers, null, 2)}</pre>
    </div>
  );
}
</file>

<file path="examples/cloudflare-redwood/src/app/shared/links.ts">
import { defineLinks } from "@redwoodjs/sdk/router";
export const link = defineLinks(["/"]);
</file>

<file path="examples/cloudflare-redwood/src/app/Document.tsx">
export const Document: React.FC<{ children: React.ReactNode }> = ({
  children,
}) => (
  <html lang="en">
    <head>
      <meta charSet="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <title>@redwoodjs/starter-drizzle</title>
      <script type="module" src="/src/client.tsx" />
    </head>
    <body>
      <div id="root">{children}</div>
    </body>
  </html>
);
</file>

<file path="examples/cloudflare-redwood/src/app/headers.ts">
import type { RouteMiddleware } from "@redwoodjs/sdk/router";
import { IS_DEV } from "@redwoodjs/sdk/constants";
export const setCommonHeaders =
  (): RouteMiddleware =>
  ({ headers, rw: { nonce } }) => {
    if (!IS_DEV) {
      // Forces browsers to always use HTTPS for a specified time period (2 years)
      headers.set(
        "Strict-Transport-Security",
        "max-age=63072000; includeSubDomains; preload",
      );
    }
    // Forces browser to use the declared content-type instead of trying to guess/sniff it
    headers.set("X-Content-Type-Options", "nosniff");
    // Stops browsers from sending the referring webpage URL in HTTP headers
    headers.set("Referrer-Policy", "no-referrer");
    // Explicitly disables access to specific browser features/APIs
    headers.set(
      "Permissions-Policy",
      "geolocation=(), microphone=(), camera=()",
    );
    // Defines trusted sources for content loading and script execution:
    headers.set(
      "Content-Security-Policy",
      `default-src 'self'; script-src 'self' 'nonce-${nonce}' https://challenges.cloudflare.com; style-src 'self' 'unsafe-inline'; frame-src https://challenges.cloudflare.com; object-src 'none';`,
    );
  };
</file>

<file path="examples/cloudflare-redwood/src/db/schema.ts">
// schema.ts
import { int, sqliteTable, text } from "drizzle-orm/sqlite-core";
export const users = sqliteTable("users", {
  id: int().primaryKey({ autoIncrement: true }),
  name: text().notNull(),
  email: text().notNull().unique(),
});
</file>

<file path="examples/cloudflare-redwood/src/db/seed.ts">
import { defineScript } from "@redwoodjs/sdk/worker";
import { drizzle } from "drizzle-orm/d1";
import { users } from "./schema.js";
export default defineScript(async ({ env }) => {
  const db = drizzle(env.DB);
  // Insert a user
  await db.insert(users).values({
    name: "__change me__",
    email: "__change me__",
  });
  // Verify the insert by selecting all users
  const result = await db.select().from(users).all();
  console.log(" Finished seeding");
  return Response.json(result);
});
</file>

<file path="examples/cloudflare-redwood/src/client.tsx">
import { initClient } from "@redwoodjs/sdk/client";
initClient();
</file>

<file path="examples/cloudflare-redwood/src/worker.tsx">
import { index, render } from "@redwoodjs/sdk/router";
import { defineApp } from "@redwoodjs/sdk/worker";
import { env } from "cloudflare:workers";
import { drizzle } from "drizzle-orm/d1";
import { Document } from "src/Document";
import { setCommonHeaders } from "src/headers";
import { Home } from "src/pages/Home";
export interface Env {
  DB: D1Database;
}
export type AppContext = {
  db: ReturnType<typeof drizzle>;
};
export default defineApp([
  setCommonHeaders(),
  ({ ctx }) => {
    // setup db in appContext
    ctx.db = drizzle(env.DB);
  },
  render(Document, [index([Home])]),
]);
</file>

<file path="examples/cloudflare-redwood/types/env.d.ts">
/// <reference types="./env.d.ts" />
import type { website } from "../alchemy.run.js";
export type CloudFlareEnv = typeof website.Env;
declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends CloudFlareEnv {}
  }
}
</file>

<file path="examples/cloudflare-redwood/types/rw.d.ts">
import { AppContext } from "../src/worker.js";
declare module "@redwoodjs/sdk/worker" {
  export interface DefaultAppContext extends AppContext {}
}
</file>

<file path="examples/cloudflare-redwood/types/vite.d.ts">
declare module "*?url" {
  const result: string;
  export default result;
}
</file>

<file path="examples/cloudflare-redwood/.env.example">
CLOUDFLARE_ACCOUNT_ID=__change_me__
CLOUDFLARE_DATABASE_ID=__change_me__
CLOUDFLARE_D1_TOKEN=__change_me__
</file>

<file path="examples/cloudflare-redwood/.gitignore">
# Node modules
node_modules

# Logs
logs
*.log
npm-debug.log*
pnpm-debug.log*

# Environment variables
.env
.dev.vars

# Vite build output
dist

# TypeScript
*.tsbuildinfo

# IDEs and editors
.vscode/
.idea/
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

# MacOS
.DS_Store

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# pnpm store directory
.pnpm-store

# dotenv environment variables file
.env.local
.env.development.local
.env.test.local
.env.production.local

# Vite cache
.vite

# Coverage directory used by tools like istanbul
coverage

# Temporary files
*.tmp
*.temp

.wrangler
wrangler.jsonc
</file>

<file path="examples/cloudflare-redwood/.prettierrc">
{
  "overrides": [
    {
      "files": "*.jsonc",
      "options": {
        "trailingComma": "none"
      }
    }
  ]
}
</file>

<file path="examples/cloudflare-redwood/alchemy.run.ts">
import alchemy from "../../alchemy/src/";
import {
  D1Database,
  R2RestStateStore,
  Redwood,
} from "../../alchemy/src/cloudflare";
const BRANCH_PREFIX = process.env.BRANCH_PREFIX ?? "";
const app = await alchemy("cloudflare-redwood", {
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
});
const database = await D1Database(`cloudflare-redwood-db${BRANCH_PREFIX}`, {
  migrationsDir: "drizzle",
});
export const website = await Redwood(
  `cloudflare-redwood-website${BRANCH_PREFIX}`,
  {
    bindings: {
      DB: database,
    },
  },
);
console.log({
  url: website.url,
});
await app.finalize();
</file>

<file path="examples/cloudflare-redwood/drizzle.config.ts">
import "dotenv/config";
import { defineConfig } from "drizzle-kit";
export default defineConfig({
  out: "./drizzle",
  schema: "./src/db/schema.ts",
  dialect: "sqlite",
  driver: "d1-http",
  dbCredentials: {
    accountId: process.env.CLOUDFLARE_ACCOUNT_ID!,
    databaseId: process.env.CLOUDFLARE_DATABASE_ID!,
    token: process.env.CLOUDFLARE_D1_TOKEN!,
  },
});
</file>

<file path="examples/cloudflare-redwood/package.json">
{
  "name": "@redwoodjs/starter-drizzle",
  "version": "1.0.0",
  "description": "A RedwoodSDK starter for projects with a database using Drizzle",
  "main": "index.js",
  "type": "module",
  "keywords": [],
  "author": "",
  "license": "MIT",
  "private": true,
  "scripts": {
    "build": "vite build",
    "dev": "NODE_ENV=${NODE_ENV:-development} vite dev",
    "dev:init": "rw-scripts dev-init",
    "preview": "bun run build && bun run vite preview",
    "worker:run": "rw-scripts worker-run",
    "clean": "bun run clean:vite",
    "clean:vite": "rm -rf ./node_modules/.vite",
    "release": "rw-scripts ensure-deploy-env && bun run clean && bun run migrate:new && RWSDK_DEPLOY=1 bun run build && wrangler deploy",
    "format": "prettier --write ./src",
    "migrate:new": "drizzle-kit generate",
    "migrate:dev": "wrangler d1 migrations apply DB --local",
    "seed": "bun run worker:run ./src/db/seed.ts",
    "check": "bun run types",
    "types": "bun run tsc",
    "deploy": "bun run --env-file ../../.env ./alchemy.run.ts",
    "destroy": "bun run --env-file ../../.env ./alchemy.run.ts --destroy"
  },
  "dependencies": {
    "@redwoodjs/sdk": "^0.0.68",
    "dotenv": "^16.5.0",
    "drizzle-orm": "beta"
  },
  "devDependencies": {
    "@types/node": "^22.14.1",
    "@types/react": "^19.1.2",
    "@types/react-dom": "^19.1.2",
    "drizzle-kit": "beta",
    "tsx": "^4.19.3",
    "vite": "^6.3.2",
    "wrangler": "^4.12.1"
  }
}
</file>

<file path="examples/cloudflare-redwood/README.md">
# RedwoodSDK Example: Drizzle ORM

This starter makes it easy to start up a project with database using Drizzle.

## Creating your project

Create your new project:

```shell
npx degit redwoodjs/example-drizzle my-project-name
cd my-project-name
pnpm install
```

## Running the dev server

```shell
pnpm dev
```

Point your browser to the URL displayed in the terminal (e.g. `http://localhost:5173/`). You should see a "Hello World" message in your browser.

## Deploying your app

Within your project's `wrangler.jsonc` file, replace the placeholder values. For example:

```jsonc
{
  "name": "my-project-name",
  "main": "src/worker.tsx",
  "compatibility_date": "2024-09-23",
  "compatibility_flags": ["nodejs_compat"],
  "d1_databases": [
    {
      "binding": "DB",
      "database_name": "my-project-db",
      "database_id": "YOUR-DB-ID-HERE",
      "migrations_dir": "drizzle",
    },
  ],
}
```

You'll need a [Cloudflare account](https://www.cloudflare.com/) as this starter uses Cloudflare D1 for the database.

Create a new D1 database:

```shell
npx wrangler d1 create my-project-db
```

![New Database](./public/images/new-db.png)

Copy the `database_id` from the output and paste it into:

1. Your project's `wrangler.json` file
2. The `.env` file (copy from `.env.example`)

```text
CLOUDFLARE_ACCOUNT_ID=your-account-id
CLOUDFLARE_DATABASE_ID=your-database-id
CLOUDFLARE_D1_TOKEN=your-api-token
```

To get your Cloudflare credentials:

- **Account ID**: Find this under Workers & Pages in your Cloudflare dashboard
- **API Token**: Generate this under User Profile > API Tokens with the following permissions:
  - Account Settings: Read
  - D1: Edit

### Database Changes

The starter includes a basic user model in `src/db/schema.ts`:

```typescript
export const users = sqliteTable("users", {
  id: text("id").primaryKey(),
  name: text("name").notNull(),
  email: text("email").notNull().unique(),
  createdAt: integer("created_at", { mode: "timestamp" })
    .notNull()
    .default(sql`CURRENT_TIMESTAMP`),
});
```

When you need to make changes to your database schema:

1. Update your schema in `src/db/schema.ts`
2. Run `pnpm migrate:new` to create a new migration
3. Run `pnpm migrate:dev` to apply the migration

### Recommended Tools

VS Code extensions that make development easier:

- [SQLite Viewer](https://marketplace.cursorapi.com/items?itemName=qwtel.sqlite-viewer)
- [Better SQLite](https://marketplace.visualstudio.com/items?itemName=bettersqlite.better-sqlite3)

For database management, we recommend [Bee Keeper Studio](https://www.beekeeperstudio.io/).

## Further Reading

- [Drizzle Documentation](https://orm.drizzle.team)
- [Cloudflare D1 Documentation](https://developers.cloudflare.com/d1)
</file>

<file path="examples/cloudflare-redwood/tsconfig.json">
{
  "references": [
    {
      "path": "../../alchemy/tsconfig.json"
    }
  ],
  "compilerOptions": {
    /* Visit https://aka.ms/tsconfig.json to read more about this file */

    /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */
    "target": "es2021",
    /* Specify a set of bundled library declaration files that describe the target runtime environment. */
    "lib": ["DOM", "DOM.Iterable", "ESNext", "ES2022"],
    /* Specify what JSX code is generated. */
    "jsx": "react-jsx",

    /* Specify what module code is generated. */
    "module": "es2022",
    /* Specify how TypeScript looks up a file from a given module specifier. */
    "moduleResolution": "bundler",
    /* Specify type package names to be included without being referenced in a source file. */
    "types": ["./types/rw.d.ts"],
    "paths": {
      "@/*": ["./src/*"],
      "src/*": ["./src/app/*"]
    },
    /* Enable importing .json files */
    "resolveJsonModule": true,

    /* Enable error reporting in type-checked JavaScript files. */
    "checkJs": false,

    /* Disable emitting files from a compilation. */
    "noEmit": true,

    /* Ensure that each file can be safely transpiled without relying on other imports. */
    "isolatedModules": true,
    /* Allow 'import x from y' when a module doesn't have a default export. */
    "allowSyntheticDefaultImports": true,
    /* Ensure that casing is correct in imports. */
    "forceConsistentCasingInFileNames": true,

    /* Enable all strict type-checking options. */
    "strict": true,

    /* Skip type checking all .d.ts files. */
    "skipLibCheck": true
  }
}
</file>

<file path="examples/cloudflare-redwood/vite.config.mts">
import { redwood } from "@redwoodjs/sdk/vite";
import { defineConfig } from "vite";

export default defineConfig({
  plugins: [redwood()],
});
</file>

<file path="examples/cloudflare-redwood/worker-configuration.d.ts">
/* eslint-disable */
// Generated by Wrangler by running `wrangler types` (hash: 632ba9b9d2210af42da1008358873d8f)
// Runtime types generated with workerd@1.20250417.0 2025-04-02 nodejs_compat
declare namespace Cloudflare {
  interface Env {
    CLOUDFLARE_ACCOUNT_ID: string;
    CLOUDFLARE_DATABASE_ID: string;
    CLOUDFLARE_D1_TOKEN: string;
    DB: D1Database;
    ASSETS: Fetcher;
  }
}
interface Env extends Cloudflare.Env {}
type StringifyValues<EnvType extends Record<string, unknown>> = {
  [Binding in keyof EnvType]: EnvType[Binding] extends string
    ? EnvType[Binding]
    : string;
};
declare namespace NodeJS {
  interface ProcessEnv
    extends StringifyValues<
      Pick<
        Cloudflare.Env,
        | "CLOUDFLARE_ACCOUNT_ID"
        | "CLOUDFLARE_DATABASE_ID"
        | "CLOUDFLARE_D1_TOKEN"
      >
    > {}
}
// Begin runtime types
/*! *****************************************************************************
Copyright (c) Cloudflare. All rights reserved.
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0
THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.
See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */
/* eslint-disable */
// noinspection JSUnusedGlobalSymbols
declare var onmessage: never;
/**
 * An abnormal event (called an exception) which occurs as a result of calling a method or accessing a property of a web API.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/DOMException)
 */
declare class DOMException extends Error {
  constructor(message?: string, name?: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/DOMException/message) */
  readonly message: string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/DOMException/name) */
  readonly name: string;
  /**
   * @deprecated
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/DOMException/code)
   */
  readonly code: number;
  static readonly INDEX_SIZE_ERR: number;
  static readonly DOMSTRING_SIZE_ERR: number;
  static readonly HIERARCHY_REQUEST_ERR: number;
  static readonly WRONG_DOCUMENT_ERR: number;
  static readonly INVALID_CHARACTER_ERR: number;
  static readonly NO_DATA_ALLOWED_ERR: number;
  static readonly NO_MODIFICATION_ALLOWED_ERR: number;
  static readonly NOT_FOUND_ERR: number;
  static readonly NOT_SUPPORTED_ERR: number;
  static readonly INUSE_ATTRIBUTE_ERR: number;
  static readonly INVALID_STATE_ERR: number;
  static readonly SYNTAX_ERR: number;
  static readonly INVALID_MODIFICATION_ERR: number;
  static readonly NAMESPACE_ERR: number;
  static readonly INVALID_ACCESS_ERR: number;
  static readonly VALIDATION_ERR: number;
  static readonly TYPE_MISMATCH_ERR: number;
  static readonly SECURITY_ERR: number;
  static readonly NETWORK_ERR: number;
  static readonly ABORT_ERR: number;
  static readonly URL_MISMATCH_ERR: number;
  static readonly QUOTA_EXCEEDED_ERR: number;
  static readonly TIMEOUT_ERR: number;
  static readonly INVALID_NODE_TYPE_ERR: number;
  static readonly DATA_CLONE_ERR: number;
  get stack(): any;
  set stack(value: any);
}
type WorkerGlobalScopeEventMap = {
  fetch: FetchEvent;
  scheduled: ScheduledEvent;
  queue: QueueEvent;
  unhandledrejection: PromiseRejectionEvent;
  rejectionhandled: PromiseRejectionEvent;
};
declare abstract class WorkerGlobalScope extends EventTarget<WorkerGlobalScopeEventMap> {
  EventTarget: typeof EventTarget;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console) */
interface Console {
  assert(condition?: boolean, ...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/clear_static) */
  clear(): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/count_static) */
  count(label?: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/countreset_static) */
  countReset(label?: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/debug_static) */
  debug(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/dir_static) */
  dir(item?: any, options?: any): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/dirxml_static) */
  dirxml(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/error_static) */
  error(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/group_static) */
  group(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/groupcollapsed_static) */
  groupCollapsed(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/groupend_static) */
  groupEnd(): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/info_static) */
  info(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/log_static) */
  log(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/table_static) */
  table(tabularData?: any, properties?: string[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/time_static) */
  time(label?: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/timeend_static) */
  timeEnd(label?: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/timelog_static) */
  timeLog(label?: string, ...data: any[]): void;
  timeStamp(label?: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/trace_static) */
  trace(...data: any[]): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/console/warn_static) */
  warn(...data: any[]): void;
}
declare const console: Console;
type BufferSource = ArrayBufferView | ArrayBuffer;
type TypedArray =
  | Int8Array
  | Uint8Array
  | Uint8ClampedArray
  | Int16Array
  | Uint16Array
  | Int32Array
  | Uint32Array
  | Float32Array
  | Float64Array
  | BigInt64Array
  | BigUint64Array;
declare namespace WebAssembly {
  class CompileError extends Error {
    constructor(message?: string);
  }
  class RuntimeError extends Error {
    constructor(message?: string);
  }
  type ValueType =
    | "anyfunc"
    | "externref"
    | "f32"
    | "f64"
    | "i32"
    | "i64"
    | "v128";
  interface GlobalDescriptor {
    value: ValueType;
    mutable?: boolean;
  }
  class Global {
    constructor(descriptor: GlobalDescriptor, value?: any);
    value: any;
    valueOf(): any;
  }
  type ImportValue = ExportValue | number;
  type ModuleImports = Record<string, ImportValue>;
  type Imports = Record<string, ModuleImports>;
  type ExportValue = Function | Global | Memory | Table;
  type Exports = Record<string, ExportValue>;
  class Instance {
    constructor(module: Module, imports?: Imports);
    readonly exports: Exports;
  }
  interface MemoryDescriptor {
    initial: number;
    maximum?: number;
    shared?: boolean;
  }
  class Memory {
    constructor(descriptor: MemoryDescriptor);
    readonly buffer: ArrayBuffer;
    grow(delta: number): number;
  }
  type ImportExportKind = "function" | "global" | "memory" | "table";
  interface ModuleExportDescriptor {
    kind: ImportExportKind;
    name: string;
  }
  interface ModuleImportDescriptor {
    kind: ImportExportKind;
    module: string;
    name: string;
  }
  abstract class Module {
    static customSections(module: Module, sectionName: string): ArrayBuffer[];
    static exports(module: Module): ModuleExportDescriptor[];
    static imports(module: Module): ModuleImportDescriptor[];
  }
  type TableKind = "anyfunc" | "externref";
  interface TableDescriptor {
    element: TableKind;
    initial: number;
    maximum?: number;
  }
  class Table {
    constructor(descriptor: TableDescriptor, value?: any);
    readonly length: number;
    get(index: number): any;
    grow(delta: number, value?: any): number;
    set(index: number, value?: any): void;
  }
  function instantiate(module: Module, imports?: Imports): Promise<Instance>;
  function validate(bytes: BufferSource): boolean;
}
/**
 * This ServiceWorker API interface represents the global execution context of a service worker.
 * Available only in secure contexts.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/ServiceWorkerGlobalScope)
 */
interface ServiceWorkerGlobalScope extends WorkerGlobalScope {
  DOMException: typeof DOMException;
  WorkerGlobalScope: typeof WorkerGlobalScope;
  btoa(data: string): string;
  atob(data: string): string;
  setTimeout(callback: (...args: any[]) => void, msDelay?: number): number;
  setTimeout<Args extends any[]>(
    callback: (...args: Args) => void,
    msDelay?: number,
    ...args: Args
  ): number;
  clearTimeout(timeoutId: number | null): void;
  setInterval(callback: (...args: any[]) => void, msDelay?: number): number;
  setInterval<Args extends any[]>(
    callback: (...args: Args) => void,
    msDelay?: number,
    ...args: Args
  ): number;
  clearInterval(timeoutId: number | null): void;
  queueMicrotask(task: Function): void;
  structuredClone<T>(value: T, options?: StructuredSerializeOptions): T;
  reportError(error: any): void;
  fetch(
    input: RequestInfo | URL,
    init?: RequestInit<RequestInitCfProperties>,
  ): Promise<Response>;
  self: ServiceWorkerGlobalScope;
  crypto: Crypto;
  caches: CacheStorage;
  scheduler: Scheduler;
  performance: Performance;
  Cloudflare: Cloudflare;
  readonly origin: string;
  Event: typeof Event;
  ExtendableEvent: typeof ExtendableEvent;
  CustomEvent: typeof CustomEvent;
  PromiseRejectionEvent: typeof PromiseRejectionEvent;
  FetchEvent: typeof FetchEvent;
  TailEvent: typeof TailEvent;
  TraceEvent: typeof TailEvent;
  ScheduledEvent: typeof ScheduledEvent;
  MessageEvent: typeof MessageEvent;
  CloseEvent: typeof CloseEvent;
  ReadableStreamDefaultReader: typeof ReadableStreamDefaultReader;
  ReadableStreamBYOBReader: typeof ReadableStreamBYOBReader;
  ReadableStream: typeof ReadableStream;
  WritableStream: typeof WritableStream;
  WritableStreamDefaultWriter: typeof WritableStreamDefaultWriter;
  TransformStream: typeof TransformStream;
  ByteLengthQueuingStrategy: typeof ByteLengthQueuingStrategy;
  CountQueuingStrategy: typeof CountQueuingStrategy;
  ErrorEvent: typeof ErrorEvent;
  EventSource: typeof EventSource;
  ReadableStreamBYOBRequest: typeof ReadableStreamBYOBRequest;
  ReadableStreamDefaultController: typeof ReadableStreamDefaultController;
  ReadableByteStreamController: typeof ReadableByteStreamController;
  WritableStreamDefaultController: typeof WritableStreamDefaultController;
  TransformStreamDefaultController: typeof TransformStreamDefaultController;
  CompressionStream: typeof CompressionStream;
  DecompressionStream: typeof DecompressionStream;
  TextEncoderStream: typeof TextEncoderStream;
  TextDecoderStream: typeof TextDecoderStream;
  Headers: typeof Headers;
  Body: typeof Body;
  Request: typeof Request;
  Response: typeof Response;
  WebSocket: typeof WebSocket;
  WebSocketPair: typeof WebSocketPair;
  WebSocketRequestResponsePair: typeof WebSocketRequestResponsePair;
  AbortController: typeof AbortController;
  AbortSignal: typeof AbortSignal;
  TextDecoder: typeof TextDecoder;
  TextEncoder: typeof TextEncoder;
  navigator: Navigator;
  Navigator: typeof Navigator;
  URL: typeof URL;
  URLSearchParams: typeof URLSearchParams;
  URLPattern: typeof URLPattern;
  Blob: typeof Blob;
  File: typeof File;
  FormData: typeof FormData;
  Crypto: typeof Crypto;
  SubtleCrypto: typeof SubtleCrypto;
  CryptoKey: typeof CryptoKey;
  CacheStorage: typeof CacheStorage;
  Cache: typeof Cache;
  FixedLengthStream: typeof FixedLengthStream;
  IdentityTransformStream: typeof IdentityTransformStream;
  HTMLRewriter: typeof HTMLRewriter;
}
declare function addEventListener<Type extends keyof WorkerGlobalScopeEventMap>(
  type: Type,
  handler: EventListenerOrEventListenerObject<WorkerGlobalScopeEventMap[Type]>,
  options?: EventTargetAddEventListenerOptions | boolean,
): void;
declare function removeEventListener<
  Type extends keyof WorkerGlobalScopeEventMap,
>(
  type: Type,
  handler: EventListenerOrEventListenerObject<WorkerGlobalScopeEventMap[Type]>,
  options?: EventTargetEventListenerOptions | boolean,
): void;
/**
 * Dispatches a synthetic event event to target and returns true if either event's cancelable attribute value is false or its preventDefault() method was not invoked, and false otherwise.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventTarget/dispatchEvent)
 */
declare function dispatchEvent(
  event: WorkerGlobalScopeEventMap[keyof WorkerGlobalScopeEventMap],
): boolean;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Window/btoa) */
declare function btoa(data: string): string;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Window/atob) */
declare function atob(data: string): string;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/setTimeout) */
declare function setTimeout(
  callback: (...args: any[]) => void,
  msDelay?: number,
): number;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/setTimeout) */
declare function setTimeout<Args extends any[]>(
  callback: (...args: Args) => void,
  msDelay?: number,
  ...args: Args
): number;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/clearTimeout) */
declare function clearTimeout(timeoutId: number | null): void;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/setInterval) */
declare function setInterval(
  callback: (...args: any[]) => void,
  msDelay?: number,
): number;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/setInterval) */
declare function setInterval<Args extends any[]>(
  callback: (...args: Args) => void,
  msDelay?: number,
  ...args: Args
): number;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/clearInterval) */
declare function clearInterval(timeoutId: number | null): void;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/queueMicrotask) */
declare function queueMicrotask(task: Function): void;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/structuredClone) */
declare function structuredClone<T>(
  value: T,
  options?: StructuredSerializeOptions,
): T;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/reportError) */
declare function reportError(error: any): void;
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/fetch) */
declare function fetch(
  input: RequestInfo | URL,
  init?: RequestInit<RequestInitCfProperties>,
): Promise<Response>;
declare const self: ServiceWorkerGlobalScope;
/**
 * The Web Crypto API provides a set of low-level functions for common cryptographic tasks.
 * The Workers runtime implements the full surface of this API, but with some differences in
 * the [supported algorithms](https://developers.cloudflare.com/workers/runtime-apis/web-crypto/#supported-algorithms)
 * compared to those implemented in most browsers.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/web-crypto/)
 */
declare const crypto: Crypto;
/**
 * The Cache API allows fine grained control of reading and writing from the Cloudflare global network cache.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/cache/)
 */
declare const caches: CacheStorage;
declare const scheduler: Scheduler;
/**
 * The Workers runtime supports a subset of the Performance API, used to measure timing and performance,
 * as well as timing of subrequests and other operations.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/performance/)
 */
declare const performance: Performance;
declare const Cloudflare: Cloudflare;
declare const origin: string;
declare const navigator: Navigator;
type TestController = {};
interface ExecutionContext {
  waitUntil(promise: Promise<any>): void;
  passThroughOnException(): void;
  props: any;
}
type ExportedHandlerFetchHandler<Env = unknown, CfHostMetadata = unknown> = (
  request: Request<CfHostMetadata, IncomingRequestCfProperties<CfHostMetadata>>,
  env: Env,
  ctx: ExecutionContext,
) => Response | Promise<Response>;
type ExportedHandlerTailHandler<Env = unknown> = (
  events: TraceItem[],
  env: Env,
  ctx: ExecutionContext,
) => void | Promise<void>;
type ExportedHandlerTraceHandler<Env = unknown> = (
  traces: TraceItem[],
  env: Env,
  ctx: ExecutionContext,
) => void | Promise<void>;
type ExportedHandlerTailStreamHandler<Env = unknown> = (
  event: TailStream.TailEvent,
  env: Env,
  ctx: ExecutionContext,
) => TailStream.TailEventHandlerType | Promise<TailStream.TailEventHandlerType>;
type ExportedHandlerScheduledHandler<Env = unknown> = (
  controller: ScheduledController,
  env: Env,
  ctx: ExecutionContext,
) => void | Promise<void>;
type ExportedHandlerQueueHandler<Env = unknown, Message = unknown> = (
  batch: MessageBatch<Message>,
  env: Env,
  ctx: ExecutionContext,
) => void | Promise<void>;
type ExportedHandlerTestHandler<Env = unknown> = (
  controller: TestController,
  env: Env,
  ctx: ExecutionContext,
) => void | Promise<void>;
interface ExportedHandler<
  Env = unknown,
  QueueHandlerMessage = unknown,
  CfHostMetadata = unknown,
> {
  fetch?: ExportedHandlerFetchHandler<Env, CfHostMetadata>;
  tail?: ExportedHandlerTailHandler<Env>;
  trace?: ExportedHandlerTraceHandler<Env>;
  tailStream?: ExportedHandlerTailStreamHandler<Env>;
  scheduled?: ExportedHandlerScheduledHandler<Env>;
  test?: ExportedHandlerTestHandler<Env>;
  email?: EmailExportedHandler<Env>;
  queue?: ExportedHandlerQueueHandler<Env, QueueHandlerMessage>;
}
interface StructuredSerializeOptions {
  transfer?: any[];
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/PromiseRejectionEvent) */
declare abstract class PromiseRejectionEvent extends Event {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/PromiseRejectionEvent/promise) */
  readonly promise: Promise<any>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/PromiseRejectionEvent/reason) */
  readonly reason: any;
}
declare abstract class Navigator {
  sendBeacon(
    url: string,
    body?:
      | ReadableStream
      | string
      | (ArrayBuffer | ArrayBufferView)
      | Blob
      | FormData
      | URLSearchParams
      | URLSearchParams,
  ): boolean;
  readonly userAgent: string;
  readonly hardwareConcurrency: number;
}
/**
 * The Workers runtime supports a subset of the Performance API, used to measure timing and performance,
 * as well as timing of subrequests and other operations.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/performance/)
 */
interface Performance {
  /* [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/performance/#performancetimeorigin) */
  readonly timeOrigin: number;
  /* [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/performance/#performancenow) */
  now(): number;
}
interface AlarmInvocationInfo {
  readonly isRetry: boolean;
  readonly retryCount: number;
}
interface Cloudflare {
  readonly compatibilityFlags: Record<string, boolean>;
}
interface DurableObject {
  fetch(request: Request): Response | Promise<Response>;
  alarm?(alarmInfo?: AlarmInvocationInfo): void | Promise<void>;
  webSocketMessage?(
    ws: WebSocket,
    message: string | ArrayBuffer,
  ): void | Promise<void>;
  webSocketClose?(
    ws: WebSocket,
    code: number,
    reason: string,
    wasClean: boolean,
  ): void | Promise<void>;
  webSocketError?(ws: WebSocket, error: unknown): void | Promise<void>;
}
type DurableObjectStub<
  T extends Rpc.DurableObjectBranded | undefined = undefined,
> = Fetcher<
  T,
  "alarm" | "webSocketMessage" | "webSocketClose" | "webSocketError"
> & {
  readonly id: DurableObjectId;
  readonly name?: string;
};
interface DurableObjectId {
  toString(): string;
  equals(other: DurableObjectId): boolean;
  readonly name?: string;
}
interface DurableObjectNamespace<
  T extends Rpc.DurableObjectBranded | undefined = undefined,
> {
  newUniqueId(
    options?: DurableObjectNamespaceNewUniqueIdOptions,
  ): DurableObjectId;
  idFromName(name: string): DurableObjectId;
  idFromString(id: string): DurableObjectId;
  get(
    id: DurableObjectId,
    options?: DurableObjectNamespaceGetDurableObjectOptions,
  ): DurableObjectStub<T>;
  jurisdiction(
    jurisdiction: DurableObjectJurisdiction,
  ): DurableObjectNamespace<T>;
}
type DurableObjectJurisdiction = "eu" | "fedramp";
interface DurableObjectNamespaceNewUniqueIdOptions {
  jurisdiction?: DurableObjectJurisdiction;
}
type DurableObjectLocationHint =
  | "wnam"
  | "enam"
  | "sam"
  | "weur"
  | "eeur"
  | "apac"
  | "oc"
  | "afr"
  | "me";
interface DurableObjectNamespaceGetDurableObjectOptions {
  locationHint?: DurableObjectLocationHint;
}
interface DurableObjectState {
  waitUntil(promise: Promise<any>): void;
  readonly id: DurableObjectId;
  readonly storage: DurableObjectStorage;
  container?: Container;
  blockConcurrencyWhile<T>(callback: () => Promise<T>): Promise<T>;
  acceptWebSocket(ws: WebSocket, tags?: string[]): void;
  getWebSockets(tag?: string): WebSocket[];
  setWebSocketAutoResponse(maybeReqResp?: WebSocketRequestResponsePair): void;
  getWebSocketAutoResponse(): WebSocketRequestResponsePair | null;
  getWebSocketAutoResponseTimestamp(ws: WebSocket): Date | null;
  setHibernatableWebSocketEventTimeout(timeoutMs?: number): void;
  getHibernatableWebSocketEventTimeout(): number | null;
  getTags(ws: WebSocket): string[];
  abort(reason?: string): void;
}
interface DurableObjectTransaction {
  get<T = unknown>(
    key: string,
    options?: DurableObjectGetOptions,
  ): Promise<T | undefined>;
  get<T = unknown>(
    keys: string[],
    options?: DurableObjectGetOptions,
  ): Promise<Map<string, T>>;
  list<T = unknown>(
    options?: DurableObjectListOptions,
  ): Promise<Map<string, T>>;
  put<T>(
    key: string,
    value: T,
    options?: DurableObjectPutOptions,
  ): Promise<void>;
  put<T>(
    entries: Record<string, T>,
    options?: DurableObjectPutOptions,
  ): Promise<void>;
  delete(key: string, options?: DurableObjectPutOptions): Promise<boolean>;
  delete(keys: string[], options?: DurableObjectPutOptions): Promise<number>;
  rollback(): void;
  getAlarm(options?: DurableObjectGetAlarmOptions): Promise<number | null>;
  setAlarm(
    scheduledTime: number | Date,
    options?: DurableObjectSetAlarmOptions,
  ): Promise<void>;
  deleteAlarm(options?: DurableObjectSetAlarmOptions): Promise<void>;
}
interface DurableObjectStorage {
  get<T = unknown>(
    key: string,
    options?: DurableObjectGetOptions,
  ): Promise<T | undefined>;
  get<T = unknown>(
    keys: string[],
    options?: DurableObjectGetOptions,
  ): Promise<Map<string, T>>;
  list<T = unknown>(
    options?: DurableObjectListOptions,
  ): Promise<Map<string, T>>;
  put<T>(
    key: string,
    value: T,
    options?: DurableObjectPutOptions,
  ): Promise<void>;
  put<T>(
    entries: Record<string, T>,
    options?: DurableObjectPutOptions,
  ): Promise<void>;
  delete(key: string, options?: DurableObjectPutOptions): Promise<boolean>;
  delete(keys: string[], options?: DurableObjectPutOptions): Promise<number>;
  deleteAll(options?: DurableObjectPutOptions): Promise<void>;
  transaction<T>(
    closure: (txn: DurableObjectTransaction) => Promise<T>,
  ): Promise<T>;
  getAlarm(options?: DurableObjectGetAlarmOptions): Promise<number | null>;
  setAlarm(
    scheduledTime: number | Date,
    options?: DurableObjectSetAlarmOptions,
  ): Promise<void>;
  deleteAlarm(options?: DurableObjectSetAlarmOptions): Promise<void>;
  sync(): Promise<void>;
  sql: SqlStorage;
  transactionSync<T>(closure: () => T): T;
  getCurrentBookmark(): Promise<string>;
  getBookmarkForTime(timestamp: number | Date): Promise<string>;
  onNextSessionRestoreBookmark(bookmark: string): Promise<string>;
}
interface DurableObjectListOptions {
  start?: string;
  startAfter?: string;
  end?: string;
  prefix?: string;
  reverse?: boolean;
  limit?: number;
  allowConcurrency?: boolean;
  noCache?: boolean;
}
interface DurableObjectGetOptions {
  allowConcurrency?: boolean;
  noCache?: boolean;
}
interface DurableObjectGetAlarmOptions {
  allowConcurrency?: boolean;
}
interface DurableObjectPutOptions {
  allowConcurrency?: boolean;
  allowUnconfirmed?: boolean;
  noCache?: boolean;
}
interface DurableObjectSetAlarmOptions {
  allowConcurrency?: boolean;
  allowUnconfirmed?: boolean;
}
declare class WebSocketRequestResponsePair {
  constructor(request: string, response: string);
  get request(): string;
  get response(): string;
}
interface AnalyticsEngineDataset {
  writeDataPoint(event?: AnalyticsEngineDataPoint): void;
}
interface AnalyticsEngineDataPoint {
  indexes?: ((ArrayBuffer | string) | null)[];
  doubles?: number[];
  blobs?: ((ArrayBuffer | string) | null)[];
}
/**
 * An event which takes place in the DOM.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event)
 */
declare class Event {
  constructor(type: string, init?: EventInit);
  /**
   * Returns the type of event, e.g. "click", "hashchange", or "submit".
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/type)
   */
  get type(): string;
  /**
   * Returns the event's phase, which is one of NONE, CAPTURING_PHASE, AT_TARGET, and BUBBLING_PHASE.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/eventPhase)
   */
  get eventPhase(): number;
  /**
   * Returns true or false depending on how event was initialized. True if event invokes listeners past a ShadowRoot node that is the root of its target, and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/composed)
   */
  get composed(): boolean;
  /**
   * Returns true or false depending on how event was initialized. True if event goes through its target's ancestors in reverse tree order, and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/bubbles)
   */
  get bubbles(): boolean;
  /**
   * Returns true or false depending on how event was initialized. Its return value does not always carry meaning, but true can indicate that part of the operation during which event was dispatched, can be canceled by invoking the preventDefault() method.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/cancelable)
   */
  get cancelable(): boolean;
  /**
   * Returns true if preventDefault() was invoked successfully to indicate cancelation, and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/defaultPrevented)
   */
  get defaultPrevented(): boolean;
  /**
   * @deprecated
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/returnValue)
   */
  get returnValue(): boolean;
  /**
   * Returns the object whose event listener's callback is currently being invoked.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/currentTarget)
   */
  get currentTarget(): EventTarget | undefined;
  /**
   * Returns the object to which event is dispatched (its target).
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/target)
   */
  get target(): EventTarget | undefined;
  /**
   * @deprecated
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/srcElement)
   */
  get srcElement(): EventTarget | undefined;
  /**
   * Returns the event's timestamp as the number of milliseconds measured relative to the time origin.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/timeStamp)
   */
  get timeStamp(): number;
  /**
   * Returns true if event was dispatched by the user agent, and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/isTrusted)
   */
  get isTrusted(): boolean;
  /**
   * @deprecated
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/cancelBubble)
   */
  get cancelBubble(): boolean;
  /**
   * @deprecated
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/cancelBubble)
   */
  set cancelBubble(value: boolean);
  /**
   * Invoking this method prevents event from reaching any registered event listeners after the current one finishes running and, when dispatched in a tree, also prevents event from reaching any other objects.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/stopImmediatePropagation)
   */
  stopImmediatePropagation(): void;
  /**
   * If invoked when the cancelable attribute value is true, and while executing a listener for the event with passive set to false, signals to the operation that caused event to be dispatched that it needs to be canceled.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/preventDefault)
   */
  preventDefault(): void;
  /**
   * When dispatched in a tree, invoking this method prevents event from reaching any objects other than the current object.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/stopPropagation)
   */
  stopPropagation(): void;
  /**
   * Returns the invocation target objects of event's path (objects on which listeners will be invoked), except for any nodes in shadow trees of which the shadow root's mode is "closed" that are not reachable from event's currentTarget.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Event/composedPath)
   */
  composedPath(): EventTarget[];
  static readonly NONE: number;
  static readonly CAPTURING_PHASE: number;
  static readonly AT_TARGET: number;
  static readonly BUBBLING_PHASE: number;
}
interface EventInit {
  bubbles?: boolean;
  cancelable?: boolean;
  composed?: boolean;
}
type EventListener<EventType extends Event = Event> = (
  event: EventType,
) => void;
interface EventListenerObject<EventType extends Event = Event> {
  handleEvent(event: EventType): void;
}
type EventListenerOrEventListenerObject<EventType extends Event = Event> =
  | EventListener<EventType>
  | EventListenerObject<EventType>;
/**
 * EventTarget is a DOM interface implemented by objects that can receive events and may have listeners for them.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventTarget)
 */
declare class EventTarget<
  EventMap extends Record<string, Event> = Record<string, Event>,
> {
  constructor();
  /**
   * Appends an event listener for events whose type attribute value is type. The callback argument sets the callback that will be invoked when the event is dispatched.
   *
   * The options argument sets listener-specific options. For compatibility this can be a boolean, in which case the method behaves exactly as if the value was specified as options's capture.
   *
   * When set to true, options's capture prevents callback from being invoked when the event's eventPhase attribute value is BUBBLING_PHASE. When false (or not present), callback will not be invoked when event's eventPhase attribute value is CAPTURING_PHASE. Either way, callback will be invoked if event's eventPhase attribute value is AT_TARGET.
   *
   * When set to true, options's passive indicates that the callback will not cancel the event by invoking preventDefault(). This is used to enable performance optimizations described in  2.8 Observing event listeners.
   *
   * When set to true, options's once indicates that the callback will only be invoked once after which the event listener will be removed.
   *
   * If an AbortSignal is passed for options's signal, then the event listener will be removed when signal is aborted.
   *
   * The event listener is appended to target's event listener list and is not appended if it has the same type, callback, and capture.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventTarget/addEventListener)
   */
  addEventListener<Type extends keyof EventMap>(
    type: Type,
    handler: EventListenerOrEventListenerObject<EventMap[Type]>,
    options?: EventTargetAddEventListenerOptions | boolean,
  ): void;
  /**
   * Removes the event listener in target's event listener list with the same type, callback, and options.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventTarget/removeEventListener)
   */
  removeEventListener<Type extends keyof EventMap>(
    type: Type,
    handler: EventListenerOrEventListenerObject<EventMap[Type]>,
    options?: EventTargetEventListenerOptions | boolean,
  ): void;
  /**
   * Dispatches a synthetic event event to target and returns true if either event's cancelable attribute value is false or its preventDefault() method was not invoked, and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventTarget/dispatchEvent)
   */
  dispatchEvent(event: EventMap[keyof EventMap]): boolean;
}
interface EventTargetEventListenerOptions {
  capture?: boolean;
}
interface EventTargetAddEventListenerOptions {
  capture?: boolean;
  passive?: boolean;
  once?: boolean;
  signal?: AbortSignal;
}
interface EventTargetHandlerObject {
  handleEvent: (event: Event) => any | undefined;
}
/**
 * A controller object that allows you to abort one or more DOM requests as and when desired.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortController)
 */
declare class AbortController {
  constructor();
  /**
   * Returns the AbortSignal object associated with this object.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortController/signal)
   */
  get signal(): AbortSignal;
  /**
   * Invoking this method will set this object's AbortSignal's aborted flag and signal to any observers that the associated activity is to be aborted.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortController/abort)
   */
  abort(reason?: any): void;
}
/**
 * A signal object that allows you to communicate with a DOM request (such as a Fetch) and abort it if required via an AbortController object.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal)
 */
declare abstract class AbortSignal extends EventTarget {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/abort_static) */
  static abort(reason?: any): AbortSignal;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/timeout_static) */
  static timeout(delay: number): AbortSignal;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/any_static) */
  static any(signals: AbortSignal[]): AbortSignal;
  /**
   * Returns true if this AbortSignal's AbortController has signaled to abort, and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/aborted)
   */
  get aborted(): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/reason) */
  get reason(): any;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/abort_event) */
  get onabort(): any | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/abort_event) */
  set onabort(value: any | null);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/AbortSignal/throwIfAborted) */
  throwIfAborted(): void;
}
interface Scheduler {
  wait(delay: number, maybeOptions?: SchedulerWaitOptions): Promise<void>;
}
interface SchedulerWaitOptions {
  signal?: AbortSignal;
}
/**
 * Extends the lifetime of the install and activate events dispatched on the global scope as part of the service worker lifecycle. This ensures that any functional events (like FetchEvent) are not dispatched until it upgrades database schemas and deletes the outdated cache entries.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/ExtendableEvent)
 */
declare abstract class ExtendableEvent extends Event {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ExtendableEvent/waitUntil) */
  waitUntil(promise: Promise<any>): void;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CustomEvent) */
declare class CustomEvent<T = any> extends Event {
  constructor(type: string, init?: CustomEventCustomEventInit);
  /**
   * Returns any custom data event was created with. Typically used for synthetic events.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CustomEvent/detail)
   */
  get detail(): T;
}
interface CustomEventCustomEventInit {
  bubbles?: boolean;
  cancelable?: boolean;
  composed?: boolean;
  detail?: any;
}
/**
 * A file-like object of immutable, raw data. Blobs represent data that isn't necessarily in a JavaScript-native format. The File interface is based on Blob, inheriting blob functionality and expanding it to support files on the user's system.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob)
 */
declare class Blob {
  constructor(
    type?: ((ArrayBuffer | ArrayBufferView) | string | Blob)[],
    options?: BlobOptions,
  );
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/size) */
  get size(): number;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/type) */
  get type(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/slice) */
  slice(start?: number, end?: number, type?: string): Blob;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/arrayBuffer) */
  arrayBuffer(): Promise<ArrayBuffer>;
  bytes(): Promise<Uint8Array>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/text) */
  text(): Promise<string>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Blob/stream) */
  stream(): ReadableStream;
}
interface BlobOptions {
  type?: string;
}
/**
 * Provides information about files and allows JavaScript in a web page to access their content.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/File)
 */
declare class File extends Blob {
  constructor(
    bits: ((ArrayBuffer | ArrayBufferView) | string | Blob)[] | undefined,
    name: string,
    options?: FileOptions,
  );
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/name) */
  get name(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/File/lastModified) */
  get lastModified(): number;
}
interface FileOptions {
  type?: string;
  lastModified?: number;
}
/**
 * The Cache API allows fine grained control of reading and writing from the Cloudflare global network cache.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/cache/)
 */
declare abstract class CacheStorage {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CacheStorage/open) */
  open(cacheName: string): Promise<Cache>;
  readonly default: Cache;
}
/**
 * The Cache API allows fine grained control of reading and writing from the Cloudflare global network cache.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/cache/)
 */
declare abstract class Cache {
  /* [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/cache/#delete) */
  delete(
    request: RequestInfo | URL,
    options?: CacheQueryOptions,
  ): Promise<boolean>;
  /* [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/cache/#match) */
  match(
    request: RequestInfo | URL,
    options?: CacheQueryOptions,
  ): Promise<Response | undefined>;
  /* [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/cache/#put) */
  put(request: RequestInfo | URL, response: Response): Promise<void>;
}
interface CacheQueryOptions {
  ignoreMethod?: boolean;
}
/**
 * The Web Crypto API provides a set of low-level functions for common cryptographic tasks.
 * The Workers runtime implements the full surface of this API, but with some differences in
 * the [supported algorithms](https://developers.cloudflare.com/workers/runtime-apis/web-crypto/#supported-algorithms)
 * compared to those implemented in most browsers.
 *
 * [Cloudflare Docs Reference](https://developers.cloudflare.com/workers/runtime-apis/web-crypto/)
 */
declare abstract class Crypto {
  /**
   * Available only in secure contexts.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Crypto/subtle)
   */
  get subtle(): SubtleCrypto;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Crypto/getRandomValues) */
  getRandomValues<
    T extends
      | Int8Array
      | Uint8Array
      | Int16Array
      | Uint16Array
      | Int32Array
      | Uint32Array
      | BigInt64Array
      | BigUint64Array,
  >(buffer: T): T;
  /**
   * Available only in secure contexts.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Crypto/randomUUID)
   */
  randomUUID(): string;
  DigestStream: typeof DigestStream;
}
/**
 * This Web Crypto API interface provides a number of low-level cryptographic functions. It is accessed via the Crypto.subtle properties available in a window context (via Window.crypto).
 * Available only in secure contexts.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto)
 */
declare abstract class SubtleCrypto {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/encrypt) */
  encrypt(
    algorithm: string | SubtleCryptoEncryptAlgorithm,
    key: CryptoKey,
    plainText: ArrayBuffer | ArrayBufferView,
  ): Promise<ArrayBuffer>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/decrypt) */
  decrypt(
    algorithm: string | SubtleCryptoEncryptAlgorithm,
    key: CryptoKey,
    cipherText: ArrayBuffer | ArrayBufferView,
  ): Promise<ArrayBuffer>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/sign) */
  sign(
    algorithm: string | SubtleCryptoSignAlgorithm,
    key: CryptoKey,
    data: ArrayBuffer | ArrayBufferView,
  ): Promise<ArrayBuffer>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/verify) */
  verify(
    algorithm: string | SubtleCryptoSignAlgorithm,
    key: CryptoKey,
    signature: ArrayBuffer | ArrayBufferView,
    data: ArrayBuffer | ArrayBufferView,
  ): Promise<boolean>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/digest) */
  digest(
    algorithm: string | SubtleCryptoHashAlgorithm,
    data: ArrayBuffer | ArrayBufferView,
  ): Promise<ArrayBuffer>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/generateKey) */
  generateKey(
    algorithm: string | SubtleCryptoGenerateKeyAlgorithm,
    extractable: boolean,
    keyUsages: string[],
  ): Promise<CryptoKey | CryptoKeyPair>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/deriveKey) */
  deriveKey(
    algorithm: string | SubtleCryptoDeriveKeyAlgorithm,
    baseKey: CryptoKey,
    derivedKeyAlgorithm: string | SubtleCryptoImportKeyAlgorithm,
    extractable: boolean,
    keyUsages: string[],
  ): Promise<CryptoKey>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/deriveBits) */
  deriveBits(
    algorithm: string | SubtleCryptoDeriveKeyAlgorithm,
    baseKey: CryptoKey,
    length?: number | null,
  ): Promise<ArrayBuffer>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/importKey) */
  importKey(
    format: string,
    keyData: (ArrayBuffer | ArrayBufferView) | JsonWebKey,
    algorithm: string | SubtleCryptoImportKeyAlgorithm,
    extractable: boolean,
    keyUsages: string[],
  ): Promise<CryptoKey>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/exportKey) */
  exportKey(format: string, key: CryptoKey): Promise<ArrayBuffer | JsonWebKey>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/wrapKey) */
  wrapKey(
    format: string,
    key: CryptoKey,
    wrappingKey: CryptoKey,
    wrapAlgorithm: string | SubtleCryptoEncryptAlgorithm,
  ): Promise<ArrayBuffer>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/SubtleCrypto/unwrapKey) */
  unwrapKey(
    format: string,
    wrappedKey: ArrayBuffer | ArrayBufferView,
    unwrappingKey: CryptoKey,
    unwrapAlgorithm: string | SubtleCryptoEncryptAlgorithm,
    unwrappedKeyAlgorithm: string | SubtleCryptoImportKeyAlgorithm,
    extractable: boolean,
    keyUsages: string[],
  ): Promise<CryptoKey>;
  timingSafeEqual(
    a: ArrayBuffer | ArrayBufferView,
    b: ArrayBuffer | ArrayBufferView,
  ): boolean;
}
/**
 * The CryptoKey dictionary of the Web Crypto API represents a cryptographic key.
 * Available only in secure contexts.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CryptoKey)
 */
declare abstract class CryptoKey {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CryptoKey/type) */
  readonly type: string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CryptoKey/extractable) */
  readonly extractable: boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CryptoKey/algorithm) */
  readonly algorithm:
    | CryptoKeyKeyAlgorithm
    | CryptoKeyAesKeyAlgorithm
    | CryptoKeyHmacKeyAlgorithm
    | CryptoKeyRsaKeyAlgorithm
    | CryptoKeyEllipticKeyAlgorithm
    | CryptoKeyArbitraryKeyAlgorithm;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CryptoKey/usages) */
  readonly usages: string[];
}
interface CryptoKeyPair {
  publicKey: CryptoKey;
  privateKey: CryptoKey;
}
interface JsonWebKey {
  kty: string;
  use?: string;
  key_ops?: string[];
  alg?: string;
  ext?: boolean;
  crv?: string;
  x?: string;
  y?: string;
  d?: string;
  n?: string;
  e?: string;
  p?: string;
  q?: string;
  dp?: string;
  dq?: string;
  qi?: string;
  oth?: RsaOtherPrimesInfo[];
  k?: string;
}
interface RsaOtherPrimesInfo {
  r?: string;
  d?: string;
  t?: string;
}
interface SubtleCryptoDeriveKeyAlgorithm {
  name: string;
  salt?: ArrayBuffer | ArrayBufferView;
  iterations?: number;
  hash?: string | SubtleCryptoHashAlgorithm;
  $public?: CryptoKey;
  info?: ArrayBuffer | ArrayBufferView;
}
interface SubtleCryptoEncryptAlgorithm {
  name: string;
  iv?: ArrayBuffer | ArrayBufferView;
  additionalData?: ArrayBuffer | ArrayBufferView;
  tagLength?: number;
  counter?: ArrayBuffer | ArrayBufferView;
  length?: number;
  label?: ArrayBuffer | ArrayBufferView;
}
interface SubtleCryptoGenerateKeyAlgorithm {
  name: string;
  hash?: string | SubtleCryptoHashAlgorithm;
  modulusLength?: number;
  publicExponent?: ArrayBuffer | ArrayBufferView;
  length?: number;
  namedCurve?: string;
}
interface SubtleCryptoHashAlgorithm {
  name: string;
}
interface SubtleCryptoImportKeyAlgorithm {
  name: string;
  hash?: string | SubtleCryptoHashAlgorithm;
  length?: number;
  namedCurve?: string;
  compressed?: boolean;
}
interface SubtleCryptoSignAlgorithm {
  name: string;
  hash?: string | SubtleCryptoHashAlgorithm;
  dataLength?: number;
  saltLength?: number;
}
interface CryptoKeyKeyAlgorithm {
  name: string;
}
interface CryptoKeyAesKeyAlgorithm {
  name: string;
  length: number;
}
interface CryptoKeyHmacKeyAlgorithm {
  name: string;
  hash: CryptoKeyKeyAlgorithm;
  length: number;
}
interface CryptoKeyRsaKeyAlgorithm {
  name: string;
  modulusLength: number;
  publicExponent: ArrayBuffer | ArrayBufferView;
  hash?: CryptoKeyKeyAlgorithm;
}
interface CryptoKeyEllipticKeyAlgorithm {
  name: string;
  namedCurve: string;
}
interface CryptoKeyArbitraryKeyAlgorithm {
  name: string;
  hash?: CryptoKeyKeyAlgorithm;
  namedCurve?: string;
  length?: number;
}
declare class DigestStream extends WritableStream<
  ArrayBuffer | ArrayBufferView
> {
  constructor(algorithm: string | SubtleCryptoHashAlgorithm);
  readonly digest: Promise<ArrayBuffer>;
  get bytesWritten(): number | bigint;
}
/**
 * A decoder for a specific method, that is a specific character encoding, like utf-8, iso-8859-2, koi8, cp1261, gbk, etc.A decoder takes a stream of bytes as input and emits a stream of code points. For a more scalable, non-native library, see StringView  a C-like representation of strings based on typed arrays.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextDecoder)
 */
declare class TextDecoder {
  constructor(label?: string, options?: TextDecoderConstructorOptions);
  /**
   * Returns the result of running encoding's decoder. The method can be invoked zero or more times with options's stream set to true, and then once without options's stream (or set to false), to process a fragmented input. If the invocation without options's stream (or set to false) has no input, it's clearest to omit both arguments.
   *
   * ```
   * var string = "", decoder = new TextDecoder(encoding), buffer;
   * while(buffer = next_chunk()) {
   *   string += decoder.decode(buffer, {stream:true});
   * }
   * string += decoder.decode(); // end-of-queue
   * ```
   *
   * If the error mode is "fatal" and encoding's decoder returns error, throws a TypeError.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextDecoder/decode)
   */
  decode(
    input?: ArrayBuffer | ArrayBufferView,
    options?: TextDecoderDecodeOptions,
  ): string;
  get encoding(): string;
  get fatal(): boolean;
  get ignoreBOM(): boolean;
}
/**
 * TextEncoder takes a stream of code points as input and emits a stream of bytes. For a more scalable, non-native library, see StringView  a C-like representation of strings based on typed arrays.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextEncoder)
 */
declare class TextEncoder {
  constructor();
  /**
   * Returns the result of running UTF-8's encoder.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextEncoder/encode)
   */
  encode(input?: string): Uint8Array;
  /**
   * Runs the UTF-8 encoder on source, stores the result of that operation into destination, and returns the progress made as an object wherein read is the number of converted code units of source and written is the number of bytes modified in destination.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextEncoder/encodeInto)
   */
  encodeInto(
    input: string,
    buffer: ArrayBuffer | ArrayBufferView,
  ): TextEncoderEncodeIntoResult;
  get encoding(): string;
}
interface TextDecoderConstructorOptions {
  fatal: boolean;
  ignoreBOM: boolean;
}
interface TextDecoderDecodeOptions {
  stream: boolean;
}
interface TextEncoderEncodeIntoResult {
  read: number;
  written: number;
}
/**
 * Events providing information related to errors in scripts or in files.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/ErrorEvent)
 */
declare class ErrorEvent extends Event {
  constructor(type: string, init?: ErrorEventErrorEventInit);
  get filename(): string;
  get message(): string;
  get lineno(): number;
  get colno(): number;
  get error(): any;
}
interface ErrorEventErrorEventInit {
  message?: string;
  filename?: string;
  lineno?: number;
  colno?: number;
  error?: any;
}
/**
 * Provides a way to easily construct a set of key/value pairs representing form fields and their values, which can then be easily sent using the XMLHttpRequest.send() method. It uses the same format a form would use if the encoding type were set to "multipart/form-data".
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData)
 */
declare class FormData {
  constructor();
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/append) */
  append(name: string, value: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/append) */
  append(name: string, value: Blob, filename?: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/delete) */
  delete(name: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/get) */
  get(name: string): (File | string) | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/getAll) */
  getAll(name: string): (File | string)[];
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/has) */
  has(name: string): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/set) */
  set(name: string, value: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FormData/set) */
  set(name: string, value: Blob, filename?: string): void;
  /* Returns an array of key, value pairs for every entry in the list. */
  entries(): IterableIterator<[key: string, value: File | string]>;
  /* Returns a list of keys in the list. */
  keys(): IterableIterator<string>;
  /* Returns a list of values in the list. */
  values(): IterableIterator<File | string>;
  forEach<This = unknown>(
    callback: (
      this: This,
      value: File | string,
      key: string,
      parent: FormData,
    ) => void,
    thisArg?: This,
  ): void;
  [Symbol.iterator](): IterableIterator<[key: string, value: File | string]>;
}
interface ContentOptions {
  html?: boolean;
}
declare class HTMLRewriter {
  constructor();
  on(
    selector: string,
    handlers: HTMLRewriterElementContentHandlers,
  ): HTMLRewriter;
  onDocument(handlers: HTMLRewriterDocumentContentHandlers): HTMLRewriter;
  transform(response: Response): Response;
}
interface HTMLRewriterElementContentHandlers {
  element?(element: Element): void | Promise<void>;
  comments?(comment: Comment): void | Promise<void>;
  text?(element: Text): void | Promise<void>;
}
interface HTMLRewriterDocumentContentHandlers {
  doctype?(doctype: Doctype): void | Promise<void>;
  comments?(comment: Comment): void | Promise<void>;
  text?(text: Text): void | Promise<void>;
  end?(end: DocumentEnd): void | Promise<void>;
}
interface Doctype {
  readonly name: string | null;
  readonly publicId: string | null;
  readonly systemId: string | null;
}
interface Element {
  tagName: string;
  readonly attributes: IterableIterator<string[]>;
  readonly removed: boolean;
  readonly namespaceURI: string;
  getAttribute(name: string): string | null;
  hasAttribute(name: string): boolean;
  setAttribute(name: string, value: string): Element;
  removeAttribute(name: string): Element;
  before(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Element;
  after(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Element;
  prepend(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Element;
  append(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Element;
  replace(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Element;
  remove(): Element;
  removeAndKeepContent(): Element;
  setInnerContent(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Element;
  onEndTag(handler: (tag: EndTag) => void | Promise<void>): void;
}
interface EndTag {
  name: string;
  before(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): EndTag;
  after(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): EndTag;
  remove(): EndTag;
}
interface Comment {
  text: string;
  readonly removed: boolean;
  before(content: string, options?: ContentOptions): Comment;
  after(content: string, options?: ContentOptions): Comment;
  replace(content: string, options?: ContentOptions): Comment;
  remove(): Comment;
}
interface Text {
  readonly text: string;
  readonly lastInTextNode: boolean;
  readonly removed: boolean;
  before(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Text;
  after(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Text;
  replace(
    content: string | ReadableStream | Response,
    options?: ContentOptions,
  ): Text;
  remove(): Text;
}
interface DocumentEnd {
  append(content: string, options?: ContentOptions): DocumentEnd;
}
/**
 * This is the event type for fetchevents dispatched on theservice worker global scope. It contains information about the fetch, including therequest and how the receiver will treat the response. It provides the event.respondWith() method, which allows us to provide a response to this fetch.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/FetchEvent)
 */
declare abstract class FetchEvent extends ExtendableEvent {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FetchEvent/request) */
  readonly request: Request;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/FetchEvent/respondWith) */
  respondWith(promise: Response | Promise<Response>): void;
  passThroughOnException(): void;
}
type HeadersInit =
  | Headers
  | Iterable<Iterable<string>>
  | Record<string, string>;
/**
 * This Fetch API interface allows you to perform various actions on HTTP request and response headers. These actions include retrieving, setting, adding to, and removing. A Headers object has an associated header list, which is initially empty and consistsof zero or more name and value pairs. You can add to this using methods like append() (see Examples.)In all methods of this interface, header names are matched by case-insensitive byte sequence.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers)
 */
declare class Headers {
  constructor(init?: HeadersInit);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers/get) */
  get(name: string): string | null;
  getAll(name: string): string[];
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers/getSetCookie) */
  getSetCookie(): string[];
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers/has) */
  has(name: string): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers/set) */
  set(name: string, value: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers/append) */
  append(name: string, value: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Headers/delete) */
  delete(name: string): void;
  forEach<This = unknown>(
    callback: (this: This, value: string, key: string, parent: Headers) => void,
    thisArg?: This,
  ): void;
  /* Returns an iterator allowing to go through all key/value pairs contained in this object. */
  entries(): IterableIterator<[key: string, value: string]>;
  /* Returns an iterator allowing to go through all keys of the key/value pairs contained in this object. */
  keys(): IterableIterator<string>;
  /* Returns an iterator allowing to go through all values of the key/value pairs contained in this object. */
  values(): IterableIterator<string>;
  [Symbol.iterator](): IterableIterator<[key: string, value: string]>;
}
type BodyInit =
  | ReadableStream<Uint8Array>
  | string
  | ArrayBuffer
  | ArrayBufferView
  | Blob
  | URLSearchParams
  | FormData;
declare abstract class Body {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/body) */
  get body(): ReadableStream | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/bodyUsed) */
  get bodyUsed(): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/arrayBuffer) */
  arrayBuffer(): Promise<ArrayBuffer>;
  bytes(): Promise<Uint8Array>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/text) */
  text(): Promise<string>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/json) */
  json<T>(): Promise<T>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/formData) */
  formData(): Promise<FormData>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/blob) */
  blob(): Promise<Blob>;
}
/**
 * This Fetch API interface represents the response to a request.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response)
 */
declare var Response: {
  prototype: Response;
  new (body?: BodyInit | null, init?: ResponseInit): Response;
  error(): Response;
  redirect(url: string, status?: number): Response;
  json(any: any, maybeInit?: ResponseInit | Response): Response;
};
/**
 * This Fetch API interface represents the response to a request.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response)
 */
interface Response extends Body {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/clone) */
  clone(): Response;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/status) */
  status: number;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/statusText) */
  statusText: string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/headers) */
  headers: Headers;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/ok) */
  ok: boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/redirected) */
  redirected: boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/url) */
  url: string;
  webSocket: WebSocket | null;
  cf: any | undefined;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Response/type) */
  type: "default" | "error";
}
interface ResponseInit {
  status?: number;
  statusText?: string;
  headers?: HeadersInit;
  cf?: any;
  webSocket?: WebSocket | null;
  encodeBody?: "automatic" | "manual";
}
type RequestInfo<CfHostMetadata = unknown, Cf = CfProperties<CfHostMetadata>> =
  | Request<CfHostMetadata, Cf>
  | string;
/**
 * This Fetch API interface represents a resource request.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request)
 */
declare var Request: {
  prototype: Request;
  new <CfHostMetadata = unknown, Cf = CfProperties<CfHostMetadata>>(
    input: RequestInfo<CfProperties> | URL,
    init?: RequestInit<Cf>,
  ): Request<CfHostMetadata, Cf>;
};
/**
 * This Fetch API interface represents a resource request.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request)
 */
interface Request<CfHostMetadata = unknown, Cf = CfProperties<CfHostMetadata>>
  extends Body {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/clone) */
  clone(): Request<CfHostMetadata, Cf>;
  /**
   * Returns request's HTTP method, which is "GET" by default.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/method)
   */
  method: string;
  /**
   * Returns the URL of request as a string.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/url)
   */
  url: string;
  /**
   * Returns a Headers object consisting of the headers associated with request. Note that headers added in the network layer by the user agent will not be accounted for in this object, e.g., the "Host" header.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/headers)
   */
  headers: Headers;
  /**
   * Returns the redirect mode associated with request, which is a string indicating how redirects for the request will be handled during fetching. A request will follow redirects by default.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/redirect)
   */
  redirect: string;
  fetcher: Fetcher | null;
  /**
   * Returns the signal associated with request, which is an AbortSignal object indicating whether or not request has been aborted, and its abort event handler.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/signal)
   */
  signal: AbortSignal;
  cf: Cf | undefined;
  /**
   * Returns request's subresource integrity metadata, which is a cryptographic hash of the resource being fetched. Its value consists of multiple hashes separated by whitespace. [SRI]
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/integrity)
   */
  integrity: string;
  /* Returns a boolean indicating whether or not request can outlive the global in which it was created. */
  keepalive: boolean;
  /**
   * Returns the cache mode associated with request, which is a string indicating how the request will interact with the browser's cache when fetching.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/Request/cache)
   */
  cache?: "no-store";
}
interface RequestInit<Cf = CfProperties> {
  /* A string to set request's method. */
  method?: string;
  /* A Headers object, an object literal, or an array of two-item arrays to set request's headers. */
  headers?: HeadersInit;
  /* A BodyInit object or null to set request's body. */
  body?: BodyInit | null;
  /* A string indicating whether request follows redirects, results in an error upon encountering a redirect, or returns the redirect (in an opaque fashion). Sets request's redirect. */
  redirect?: string;
  fetcher?: Fetcher | null;
  cf?: Cf;
  /* A string indicating how the request will interact with the browser's cache to set request's cache. */
  cache?: "no-store";
  /* A cryptographic hash of the resource to be fetched by request. Sets request's integrity. */
  integrity?: string;
  /* An AbortSignal to set request's signal. */
  signal?: AbortSignal | null;
  encodeResponseBody?: "automatic" | "manual";
}
type Service<T extends Rpc.WorkerEntrypointBranded | undefined = undefined> =
  Fetcher<T>;
type Fetcher<
  T extends Rpc.EntrypointBranded | undefined = undefined,
  Reserved extends string = never,
> = (T extends Rpc.EntrypointBranded
  ? Rpc.Provider<T, Reserved | "fetch" | "connect">
  : unknown) & {
  fetch(input: RequestInfo | URL, init?: RequestInit): Promise<Response>;
  connect(address: SocketAddress | string, options?: SocketOptions): Socket;
};
interface KVNamespaceListKey<Metadata, Key extends string = string> {
  name: Key;
  expiration?: number;
  metadata?: Metadata;
}
type KVNamespaceListResult<Metadata, Key extends string = string> =
  | {
      list_complete: false;
      keys: KVNamespaceListKey<Metadata, Key>[];
      cursor: string;
      cacheStatus: string | null;
    }
  | {
      list_complete: true;
      keys: KVNamespaceListKey<Metadata, Key>[];
      cacheStatus: string | null;
    };
interface KVNamespace<Key extends string = string> {
  get(
    key: Key,
    options?: Partial<KVNamespaceGetOptions<undefined>>,
  ): Promise<string | null>;
  get(key: Key, type: "text"): Promise<string | null>;
  get<ExpectedValue = unknown>(
    key: Key,
    type: "json",
  ): Promise<ExpectedValue | null>;
  get(key: Key, type: "arrayBuffer"): Promise<ArrayBuffer | null>;
  get(key: Key, type: "stream"): Promise<ReadableStream | null>;
  get(
    key: Key,
    options?: KVNamespaceGetOptions<"text">,
  ): Promise<string | null>;
  get<ExpectedValue = unknown>(
    key: Key,
    options?: KVNamespaceGetOptions<"json">,
  ): Promise<ExpectedValue | null>;
  get(
    key: Key,
    options?: KVNamespaceGetOptions<"arrayBuffer">,
  ): Promise<ArrayBuffer | null>;
  get(
    key: Key,
    options?: KVNamespaceGetOptions<"stream">,
  ): Promise<ReadableStream | null>;
  get(key: Array<Key>, type: "text"): Promise<Map<string, string | null>>;
  get<ExpectedValue = unknown>(
    key: Array<Key>,
    type: "json",
  ): Promise<Map<string, ExpectedValue | null>>;
  get(
    key: Array<Key>,
    options?: Partial<KVNamespaceGetOptions<undefined>>,
  ): Promise<Map<string, string | null>>;
  get(
    key: Array<Key>,
    options?: KVNamespaceGetOptions<"text">,
  ): Promise<Map<string, string | null>>;
  get<ExpectedValue = unknown>(
    key: Array<Key>,
    options?: KVNamespaceGetOptions<"json">,
  ): Promise<Map<string, ExpectedValue | null>>;
  list<Metadata = unknown>(
    options?: KVNamespaceListOptions,
  ): Promise<KVNamespaceListResult<Metadata, Key>>;
  put(
    key: Key,
    value: string | ArrayBuffer | ArrayBufferView | ReadableStream,
    options?: KVNamespacePutOptions,
  ): Promise<void>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    options?: Partial<KVNamespaceGetOptions<undefined>>,
  ): Promise<KVNamespaceGetWithMetadataResult<string, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    type: "text",
  ): Promise<KVNamespaceGetWithMetadataResult<string, Metadata>>;
  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(
    key: Key,
    type: "json",
  ): Promise<KVNamespaceGetWithMetadataResult<ExpectedValue, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    type: "arrayBuffer",
  ): Promise<KVNamespaceGetWithMetadataResult<ArrayBuffer, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    type: "stream",
  ): Promise<KVNamespaceGetWithMetadataResult<ReadableStream, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    options: KVNamespaceGetOptions<"text">,
  ): Promise<KVNamespaceGetWithMetadataResult<string, Metadata>>;
  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(
    key: Key,
    options: KVNamespaceGetOptions<"json">,
  ): Promise<KVNamespaceGetWithMetadataResult<ExpectedValue, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    options: KVNamespaceGetOptions<"arrayBuffer">,
  ): Promise<KVNamespaceGetWithMetadataResult<ArrayBuffer, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Key,
    options: KVNamespaceGetOptions<"stream">,
  ): Promise<KVNamespaceGetWithMetadataResult<ReadableStream, Metadata>>;
  getWithMetadata<Metadata = unknown>(
    key: Array<Key>,
    type: "text",
  ): Promise<Map<string, KVNamespaceGetWithMetadataResult<string, Metadata>>>;
  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(
    key: Array<Key>,
    type: "json",
  ): Promise<
    Map<string, KVNamespaceGetWithMetadataResult<ExpectedValue, Metadata>>
  >;
  getWithMetadata<Metadata = unknown>(
    key: Array<Key>,
    options?: Partial<KVNamespaceGetOptions<undefined>>,
  ): Promise<Map<string, KVNamespaceGetWithMetadataResult<string, Metadata>>>;
  getWithMetadata<Metadata = unknown>(
    key: Array<Key>,
    options?: KVNamespaceGetOptions<"text">,
  ): Promise<Map<string, KVNamespaceGetWithMetadataResult<string, Metadata>>>;
  getWithMetadata<ExpectedValue = unknown, Metadata = unknown>(
    key: Array<Key>,
    options?: KVNamespaceGetOptions<"json">,
  ): Promise<
    Map<string, KVNamespaceGetWithMetadataResult<ExpectedValue, Metadata>>
  >;
  delete(key: Key): Promise<void>;
}
interface KVNamespaceListOptions {
  limit?: number;
  prefix?: string | null;
  cursor?: string | null;
}
interface KVNamespaceGetOptions<Type> {
  type: Type;
  cacheTtl?: number;
}
interface KVNamespacePutOptions {
  expiration?: number;
  expirationTtl?: number;
  metadata?: any | null;
}
interface KVNamespaceGetWithMetadataResult<Value, Metadata> {
  value: Value | null;
  metadata: Metadata | null;
  cacheStatus: string | null;
}
type QueueContentType = "text" | "bytes" | "json" | "v8";
interface Queue<Body = unknown> {
  send(message: Body, options?: QueueSendOptions): Promise<void>;
  sendBatch(
    messages: Iterable<MessageSendRequest<Body>>,
    options?: QueueSendBatchOptions,
  ): Promise<void>;
}
interface QueueSendOptions {
  contentType?: QueueContentType;
  delaySeconds?: number;
}
interface QueueSendBatchOptions {
  delaySeconds?: number;
}
interface MessageSendRequest<Body = unknown> {
  body: Body;
  contentType?: QueueContentType;
  delaySeconds?: number;
}
interface QueueRetryOptions {
  delaySeconds?: number;
}
interface Message<Body = unknown> {
  readonly id: string;
  readonly timestamp: Date;
  readonly body: Body;
  readonly attempts: number;
  retry(options?: QueueRetryOptions): void;
  ack(): void;
}
interface QueueEvent<Body = unknown> extends ExtendableEvent {
  readonly messages: readonly Message<Body>[];
  readonly queue: string;
  retryAll(options?: QueueRetryOptions): void;
  ackAll(): void;
}
interface MessageBatch<Body = unknown> {
  readonly messages: readonly Message<Body>[];
  readonly queue: string;
  retryAll(options?: QueueRetryOptions): void;
  ackAll(): void;
}
interface R2Error extends Error {
  readonly name: string;
  readonly code: number;
  readonly message: string;
  readonly action: string;
  readonly stack: any;
}
interface R2ListOptions {
  limit?: number;
  prefix?: string;
  cursor?: string;
  delimiter?: string;
  startAfter?: string;
  include?: ("httpMetadata" | "customMetadata")[];
}
declare abstract class R2Bucket {
  head(key: string): Promise<R2Object | null>;
  get(
    key: string,
    options: R2GetOptions & {
      onlyIf: R2Conditional | Headers;
    },
  ): Promise<R2ObjectBody | R2Object | null>;
  get(key: string, options?: R2GetOptions): Promise<R2ObjectBody | null>;
  put(
    key: string,
    value:
      | ReadableStream
      | ArrayBuffer
      | ArrayBufferView
      | string
      | null
      | Blob,
    options?: R2PutOptions & {
      onlyIf: R2Conditional | Headers;
    },
  ): Promise<R2Object | null>;
  put(
    key: string,
    value:
      | ReadableStream
      | ArrayBuffer
      | ArrayBufferView
      | string
      | null
      | Blob,
    options?: R2PutOptions,
  ): Promise<R2Object>;
  createMultipartUpload(
    key: string,
    options?: R2MultipartOptions,
  ): Promise<R2MultipartUpload>;
  resumeMultipartUpload(key: string, uploadId: string): R2MultipartUpload;
  delete(keys: string | string[]): Promise<void>;
  list(options?: R2ListOptions): Promise<R2Objects>;
}
interface R2MultipartUpload {
  readonly key: string;
  readonly uploadId: string;
  uploadPart(
    partNumber: number,
    value: ReadableStream | (ArrayBuffer | ArrayBufferView) | string | Blob,
    options?: R2UploadPartOptions,
  ): Promise<R2UploadedPart>;
  abort(): Promise<void>;
  complete(uploadedParts: R2UploadedPart[]): Promise<R2Object>;
}
interface R2UploadedPart {
  partNumber: number;
  etag: string;
}
declare abstract class R2Object {
  readonly key: string;
  readonly version: string;
  readonly size: number;
  readonly etag: string;
  readonly httpEtag: string;
  readonly checksums: R2Checksums;
  readonly uploaded: Date;
  readonly httpMetadata?: R2HTTPMetadata;
  readonly customMetadata?: Record<string, string>;
  readonly range?: R2Range;
  readonly storageClass: string;
  readonly ssecKeyMd5?: string;
  writeHttpMetadata(headers: Headers): void;
}
interface R2ObjectBody extends R2Object {
  get body(): ReadableStream;
  get bodyUsed(): boolean;
  arrayBuffer(): Promise<ArrayBuffer>;
  text(): Promise<string>;
  json<T>(): Promise<T>;
  blob(): Promise<Blob>;
}
type R2Range =
  | {
      offset: number;
      length?: number;
    }
  | {
      offset?: number;
      length: number;
    }
  | {
      suffix: number;
    };
interface R2Conditional {
  etagMatches?: string;
  etagDoesNotMatch?: string;
  uploadedBefore?: Date;
  uploadedAfter?: Date;
  secondsGranularity?: boolean;
}
interface R2GetOptions {
  onlyIf?: R2Conditional | Headers;
  range?: R2Range | Headers;
  ssecKey?: ArrayBuffer | string;
}
interface R2PutOptions {
  onlyIf?: R2Conditional | Headers;
  httpMetadata?: R2HTTPMetadata | Headers;
  customMetadata?: Record<string, string>;
  md5?: (ArrayBuffer | ArrayBufferView) | string;
  sha1?: (ArrayBuffer | ArrayBufferView) | string;
  sha256?: (ArrayBuffer | ArrayBufferView) | string;
  sha384?: (ArrayBuffer | ArrayBufferView) | string;
  sha512?: (ArrayBuffer | ArrayBufferView) | string;
  storageClass?: string;
  ssecKey?: ArrayBuffer | string;
}
interface R2MultipartOptions {
  httpMetadata?: R2HTTPMetadata | Headers;
  customMetadata?: Record<string, string>;
  storageClass?: string;
  ssecKey?: ArrayBuffer | string;
}
interface R2Checksums {
  readonly md5?: ArrayBuffer;
  readonly sha1?: ArrayBuffer;
  readonly sha256?: ArrayBuffer;
  readonly sha384?: ArrayBuffer;
  readonly sha512?: ArrayBuffer;
  toJSON(): R2StringChecksums;
}
interface R2StringChecksums {
  md5?: string;
  sha1?: string;
  sha256?: string;
  sha384?: string;
  sha512?: string;
}
interface R2HTTPMetadata {
  contentType?: string;
  contentLanguage?: string;
  contentDisposition?: string;
  contentEncoding?: string;
  cacheControl?: string;
  cacheExpiry?: Date;
}
type R2Objects = {
  objects: R2Object[];
  delimitedPrefixes: string[];
} & (
  | {
      truncated: true;
      cursor: string;
    }
  | {
      truncated: false;
    }
);
interface R2UploadPartOptions {
  ssecKey?: ArrayBuffer | string;
}
declare abstract class ScheduledEvent extends ExtendableEvent {
  readonly scheduledTime: number;
  readonly cron: string;
  noRetry(): void;
}
interface ScheduledController {
  readonly scheduledTime: number;
  readonly cron: string;
  noRetry(): void;
}
interface QueuingStrategy<T = any> {
  highWaterMark?: number | bigint;
  size?: (chunk: T) => number | bigint;
}
interface UnderlyingSink<W = any> {
  type?: string;
  start?: (controller: WritableStreamDefaultController) => void | Promise<void>;
  write?: (
    chunk: W,
    controller: WritableStreamDefaultController,
  ) => void | Promise<void>;
  abort?: (reason: any) => void | Promise<void>;
  close?: () => void | Promise<void>;
}
interface UnderlyingByteSource {
  type: "bytes";
  autoAllocateChunkSize?: number;
  start?: (controller: ReadableByteStreamController) => void | Promise<void>;
  pull?: (controller: ReadableByteStreamController) => void | Promise<void>;
  cancel?: (reason: any) => void | Promise<void>;
}
interface UnderlyingSource<R = any> {
  type?: "" | undefined;
  start?: (
    controller: ReadableStreamDefaultController<R>,
  ) => void | Promise<void>;
  pull?: (
    controller: ReadableStreamDefaultController<R>,
  ) => void | Promise<void>;
  cancel?: (reason: any) => void | Promise<void>;
  expectedLength?: number | bigint;
}
interface Transformer<I = any, O = any> {
  readableType?: string;
  writableType?: string;
  start?: (
    controller: TransformStreamDefaultController<O>,
  ) => void | Promise<void>;
  transform?: (
    chunk: I,
    controller: TransformStreamDefaultController<O>,
  ) => void | Promise<void>;
  flush?: (
    controller: TransformStreamDefaultController<O>,
  ) => void | Promise<void>;
  cancel?: (reason: any) => void | Promise<void>;
  expectedLength?: number;
}
interface StreamPipeOptions {
  /**
   * Pipes this readable stream to a given writable stream destination. The way in which the piping process behaves under various error conditions can be customized with a number of passed options. It returns a promise that fulfills when the piping process completes successfully, or rejects if any errors were encountered.
   *
   * Piping a stream will lock it for the duration of the pipe, preventing any other consumer from acquiring a reader.
   *
   * Errors and closures of the source and destination streams propagate as follows:
   *
   * An error in this source readable stream will abort destination, unless preventAbort is truthy. The returned promise will be rejected with the source's error, or with any error that occurs during aborting the destination.
   *
   * An error in destination will cancel this source readable stream, unless preventCancel is truthy. The returned promise will be rejected with the destination's error, or with any error that occurs during canceling the source.
   *
   * When this source readable stream closes, destination will be closed, unless preventClose is truthy. The returned promise will be fulfilled once this process completes, unless an error is encountered while closing the destination, in which case it will be rejected with that error.
   *
   * If destination starts out closed or closing, this source readable stream will be canceled, unless preventCancel is true. The returned promise will be rejected with an error indicating piping to a closed stream failed, or with any error that occurs during canceling the source.
   *
   * The signal option can be set to an AbortSignal to allow aborting an ongoing pipe operation via the corresponding AbortController. In this case, this source readable stream will be canceled, and destination aborted, unless the respective options preventCancel or preventAbort are set.
   */
  preventClose?: boolean;
  preventAbort?: boolean;
  preventCancel?: boolean;
  signal?: AbortSignal;
}
type ReadableStreamReadResult<R = any> =
  | {
      done: false;
      value: R;
    }
  | {
      done: true;
      value?: undefined;
    };
/**
 * This Streams API interface represents a readable stream of byte data. The Fetch API offers a concrete instance of a ReadableStream through the body property of a Response object.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream)
 */
interface ReadableStream<R = any> {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/locked) */
  get locked(): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/cancel) */
  cancel(reason?: any): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/getReader) */
  getReader(): ReadableStreamDefaultReader<R>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/getReader) */
  getReader(options: ReadableStreamGetReaderOptions): ReadableStreamBYOBReader;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/pipeThrough) */
  pipeThrough<T>(
    transform: ReadableWritablePair<T, R>,
    options?: StreamPipeOptions,
  ): ReadableStream<T>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/pipeTo) */
  pipeTo(
    destination: WritableStream<R>,
    options?: StreamPipeOptions,
  ): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream/tee) */
  tee(): [ReadableStream<R>, ReadableStream<R>];
  values(options?: ReadableStreamValuesOptions): AsyncIterableIterator<R>;
  [Symbol.asyncIterator](
    options?: ReadableStreamValuesOptions,
  ): AsyncIterableIterator<R>;
}
/**
 * This Streams API interface represents a readable stream of byte data. The Fetch API offers a concrete instance of a ReadableStream through the body property of a Response object.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStream)
 */
declare const ReadableStream: {
  prototype: ReadableStream;
  new (
    underlyingSource: UnderlyingByteSource,
    strategy?: QueuingStrategy<Uint8Array>,
  ): ReadableStream<Uint8Array>;
  new <R = any>(
    underlyingSource?: UnderlyingSource<R>,
    strategy?: QueuingStrategy<R>,
  ): ReadableStream<R>;
};
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultReader) */
declare class ReadableStreamDefaultReader<R = any> {
  constructor(stream: ReadableStream);
  get closed(): Promise<void>;
  cancel(reason?: any): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultReader/read) */
  read(): Promise<ReadableStreamReadResult<R>>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultReader/releaseLock) */
  releaseLock(): void;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBReader) */
declare class ReadableStreamBYOBReader {
  constructor(stream: ReadableStream);
  get closed(): Promise<void>;
  cancel(reason?: any): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBReader/read) */
  read<T extends ArrayBufferView>(
    view: T,
  ): Promise<ReadableStreamReadResult<T>>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBReader/releaseLock) */
  releaseLock(): void;
  readAtLeast<T extends ArrayBufferView>(
    minElements: number,
    view: T,
  ): Promise<ReadableStreamReadResult<T>>;
}
interface ReadableStreamBYOBReaderReadableStreamBYOBReaderReadOptions {
  min?: number;
}
interface ReadableStreamGetReaderOptions {
  /**
   * Creates a ReadableStreamBYOBReader and locks the stream to the new reader.
   *
   * This call behaves the same way as the no-argument variant, except that it only works on readable byte streams, i.e. streams which were constructed specifically with the ability to handle "bring your own buffer" reading. The returned BYOB reader provides the ability to directly read individual chunks from the stream via its read() method, into developer-supplied buffers, allowing more precise control over allocation.
   */
  mode: "byob";
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBRequest) */
declare abstract class ReadableStreamBYOBRequest {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBRequest/view) */
  get view(): Uint8Array | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBRequest/respond) */
  respond(bytesWritten: number): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamBYOBRequest/respondWithNewView) */
  respondWithNewView(view: ArrayBuffer | ArrayBufferView): void;
  get atLeast(): number | null;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultController) */
declare abstract class ReadableStreamDefaultController<R = any> {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultController/desiredSize) */
  get desiredSize(): number | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultController/close) */
  close(): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultController/enqueue) */
  enqueue(chunk?: R): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableStreamDefaultController/error) */
  error(reason: any): void;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableByteStreamController) */
declare abstract class ReadableByteStreamController {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableByteStreamController/byobRequest) */
  get byobRequest(): ReadableStreamBYOBRequest | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableByteStreamController/desiredSize) */
  get desiredSize(): number | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableByteStreamController/close) */
  close(): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableByteStreamController/enqueue) */
  enqueue(chunk: ArrayBuffer | ArrayBufferView): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ReadableByteStreamController/error) */
  error(reason: any): void;
}
/**
 * This Streams API interface represents a controller allowing control of aWritableStream's state. When constructing a WritableStream, the underlying sink is given a corresponding WritableStreamDefaultController instance to manipulate.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultController)
 */
declare abstract class WritableStreamDefaultController {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultController/signal) */
  get signal(): AbortSignal;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultController/error) */
  error(reason?: any): void;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStreamDefaultController) */
declare abstract class TransformStreamDefaultController<O = any> {
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStreamDefaultController/desiredSize) */
  get desiredSize(): number | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStreamDefaultController/enqueue) */
  enqueue(chunk?: O): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStreamDefaultController/error) */
  error(reason: any): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStreamDefaultController/terminate) */
  terminate(): void;
}
interface ReadableWritablePair<R = any, W = any> {
  /**
   * Provides a convenient, chainable way of piping this readable stream through a transform stream (or any other { writable, readable } pair). It simply pipes the stream into the writable side of the supplied pair, and returns the readable side for further use.
   *
   * Piping a stream will lock it for the duration of the pipe, preventing any other consumer from acquiring a reader.
   */
  writable: WritableStream<W>;
  readable: ReadableStream<R>;
}
/**
 * This Streams API interface providesa standard abstraction for writing streaming data to a destination, known as a sink. This object comes with built-in backpressure and queuing.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStream)
 */
declare class WritableStream<W = any> {
  constructor(
    underlyingSink?: UnderlyingSink,
    queuingStrategy?: QueuingStrategy,
  );
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStream/locked) */
  get locked(): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStream/abort) */
  abort(reason?: any): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStream/close) */
  close(): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStream/getWriter) */
  getWriter(): WritableStreamDefaultWriter<W>;
}
/**
 * This Streams API interface is the object returned by WritableStream.getWriter() and once created locks the < writer to the WritableStream ensuring that no other streams can write to the underlying sink.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter)
 */
declare class WritableStreamDefaultWriter<W = any> {
  constructor(stream: WritableStream);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/closed) */
  get closed(): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/ready) */
  get ready(): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/desiredSize) */
  get desiredSize(): number | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/abort) */
  abort(reason?: any): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/close) */
  close(): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/write) */
  write(chunk?: W): Promise<void>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/WritableStreamDefaultWriter/releaseLock) */
  releaseLock(): void;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStream) */
declare class TransformStream<I = any, O = any> {
  constructor(
    transformer?: Transformer<I, O>,
    writableStrategy?: QueuingStrategy<I>,
    readableStrategy?: QueuingStrategy<O>,
  );
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStream/readable) */
  get readable(): ReadableStream<O>;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TransformStream/writable) */
  get writable(): WritableStream<I>;
}
declare class FixedLengthStream extends IdentityTransformStream {
  constructor(
    expectedLength: number | bigint,
    queuingStrategy?: IdentityTransformStreamQueuingStrategy,
  );
}
declare class IdentityTransformStream extends TransformStream<
  ArrayBuffer | ArrayBufferView,
  Uint8Array
> {
  constructor(queuingStrategy?: IdentityTransformStreamQueuingStrategy);
}
interface IdentityTransformStreamQueuingStrategy {
  highWaterMark?: number | bigint;
}
interface ReadableStreamValuesOptions {
  preventCancel?: boolean;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CompressionStream) */
declare class CompressionStream extends TransformStream<
  ArrayBuffer | ArrayBufferView,
  Uint8Array
> {
  constructor(format: "gzip" | "deflate" | "deflate-raw");
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/DecompressionStream) */
declare class DecompressionStream extends TransformStream<
  ArrayBuffer | ArrayBufferView,
  Uint8Array
> {
  constructor(format: "gzip" | "deflate" | "deflate-raw");
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextEncoderStream) */
declare class TextEncoderStream extends TransformStream<string, Uint8Array> {
  constructor();
  get encoding(): string;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/TextDecoderStream) */
declare class TextDecoderStream extends TransformStream<
  ArrayBuffer | ArrayBufferView,
  string
> {
  constructor(label?: string, options?: TextDecoderStreamTextDecoderStreamInit);
  get encoding(): string;
  get fatal(): boolean;
  get ignoreBOM(): boolean;
}
interface TextDecoderStreamTextDecoderStreamInit {
  fatal?: boolean;
  ignoreBOM?: boolean;
}
/**
 * This Streams API interface providesa built-in byte length queuing strategy that can be used when constructing streams.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/ByteLengthQueuingStrategy)
 */
declare class ByteLengthQueuingStrategy
  implements QueuingStrategy<ArrayBufferView>
{
  constructor(init: QueuingStrategyInit);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ByteLengthQueuingStrategy/highWaterMark) */
  get highWaterMark(): number;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/ByteLengthQueuingStrategy/size) */
  get size(): (chunk?: any) => number;
}
/**
 * This Streams API interface providesa built-in byte length queuing strategy that can be used when constructing streams.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CountQueuingStrategy)
 */
declare class CountQueuingStrategy implements QueuingStrategy {
  constructor(init: QueuingStrategyInit);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CountQueuingStrategy/highWaterMark) */
  get highWaterMark(): number;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/CountQueuingStrategy/size) */
  get size(): (chunk?: any) => number;
}
interface QueuingStrategyInit {
  /**
   * Creates a new ByteLengthQueuingStrategy with the provided high water mark.
   *
   * Note that the provided high water mark will not be validated ahead of time. Instead, if it is negative, NaN, or not a number, the resulting ByteLengthQueuingStrategy will cause the corresponding stream constructor to throw.
   */
  highWaterMark: number;
}
interface ScriptVersion {
  id?: string;
  tag?: string;
  message?: string;
}
declare abstract class TailEvent extends ExtendableEvent {
  readonly events: TraceItem[];
  readonly traces: TraceItem[];
}
interface TraceItem {
  readonly event:
    | (
        | TraceItemFetchEventInfo
        | TraceItemJsRpcEventInfo
        | TraceItemScheduledEventInfo
        | TraceItemAlarmEventInfo
        | TraceItemQueueEventInfo
        | TraceItemEmailEventInfo
        | TraceItemTailEventInfo
        | TraceItemCustomEventInfo
        | TraceItemHibernatableWebSocketEventInfo
      )
    | null;
  readonly eventTimestamp: number | null;
  readonly logs: TraceLog[];
  readonly exceptions: TraceException[];
  readonly diagnosticsChannelEvents: TraceDiagnosticChannelEvent[];
  readonly scriptName: string | null;
  readonly entrypoint?: string;
  readonly scriptVersion?: ScriptVersion;
  readonly dispatchNamespace?: string;
  readonly scriptTags?: string[];
  readonly outcome: string;
  readonly executionModel: string;
  readonly truncated: boolean;
  readonly cpuTime: number;
  readonly wallTime: number;
}
interface TraceItemAlarmEventInfo {
  readonly scheduledTime: Date;
}
type TraceItemCustomEventInfo = {};
interface TraceItemScheduledEventInfo {
  readonly scheduledTime: number;
  readonly cron: string;
}
interface TraceItemQueueEventInfo {
  readonly queue: string;
  readonly batchSize: number;
}
interface TraceItemEmailEventInfo {
  readonly mailFrom: string;
  readonly rcptTo: string;
  readonly rawSize: number;
}
interface TraceItemTailEventInfo {
  readonly consumedEvents: TraceItemTailEventInfoTailItem[];
}
interface TraceItemTailEventInfoTailItem {
  readonly scriptName: string | null;
}
interface TraceItemFetchEventInfo {
  readonly response?: TraceItemFetchEventInfoResponse;
  readonly request: TraceItemFetchEventInfoRequest;
}
interface TraceItemFetchEventInfoRequest {
  readonly cf?: any;
  readonly headers: Record<string, string>;
  readonly method: string;
  readonly url: string;
  getUnredacted(): TraceItemFetchEventInfoRequest;
}
interface TraceItemFetchEventInfoResponse {
  readonly status: number;
}
interface TraceItemJsRpcEventInfo {
  readonly rpcMethod: string;
}
interface TraceItemHibernatableWebSocketEventInfo {
  readonly getWebSocketEvent:
    | TraceItemHibernatableWebSocketEventInfoMessage
    | TraceItemHibernatableWebSocketEventInfoClose
    | TraceItemHibernatableWebSocketEventInfoError;
}
interface TraceItemHibernatableWebSocketEventInfoMessage {
  readonly webSocketEventType: string;
}
interface TraceItemHibernatableWebSocketEventInfoClose {
  readonly webSocketEventType: string;
  readonly code: number;
  readonly wasClean: boolean;
}
interface TraceItemHibernatableWebSocketEventInfoError {
  readonly webSocketEventType: string;
}
interface TraceLog {
  readonly timestamp: number;
  readonly level: string;
  readonly message: any;
}
interface TraceException {
  readonly timestamp: number;
  readonly message: string;
  readonly name: string;
  readonly stack?: string;
}
interface TraceDiagnosticChannelEvent {
  readonly timestamp: number;
  readonly channel: string;
  readonly message: any;
}
interface TraceMetrics {
  readonly cpuTime: number;
  readonly wallTime: number;
}
interface UnsafeTraceMetrics {
  fromTrace(item: TraceItem): TraceMetrics;
}
/**
 * The URLinterface represents an object providing static methods used for creating object URLs.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL)
 */
declare class URL {
  constructor(url: string | URL, base?: string | URL);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/origin) */
  get origin(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/href) */
  get href(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/href) */
  set href(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/protocol) */
  get protocol(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/protocol) */
  set protocol(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/username) */
  get username(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/username) */
  set username(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/password) */
  get password(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/password) */
  set password(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/host) */
  get host(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/host) */
  set host(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/hostname) */
  get hostname(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/hostname) */
  set hostname(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/port) */
  get port(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/port) */
  set port(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/pathname) */
  get pathname(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/pathname) */
  set pathname(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/search) */
  get search(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/search) */
  set search(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/hash) */
  get hash(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/hash) */
  set hash(value: string);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/searchParams) */
  get searchParams(): URLSearchParams;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/toJSON) */
  toJSON(): string;
  /*function toString() { [native code] }*/
  toString(): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/canParse_static) */
  static canParse(url: string, base?: string): boolean;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/parse_static) */
  static parse(url: string, base?: string): URL | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/createObjectURL_static) */
  static createObjectURL(object: File | Blob): string;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URL/revokeObjectURL_static) */
  static revokeObjectURL(object_url: string): void;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams) */
declare class URLSearchParams {
  constructor(
    init?: Iterable<Iterable<string>> | Record<string, string> | string,
  );
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/size) */
  get size(): number;
  /**
   * Appends a specified key/value pair as a new search parameter.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/append)
   */
  append(name: string, value: string): void;
  /**
   * Deletes the given search parameter, and its associated value, from the list of all search parameters.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/delete)
   */
  delete(name: string, value?: string): void;
  /**
   * Returns the first value associated to the given search parameter.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/get)
   */
  get(name: string): string | null;
  /**
   * Returns all the values association with a given search parameter.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/getAll)
   */
  getAll(name: string): string[];
  /**
   * Returns a Boolean indicating if such a search parameter exists.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/has)
   */
  has(name: string, value?: string): boolean;
  /**
   * Sets the value associated to a given search parameter to the given value. If there were several values, delete the others.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/set)
   */
  set(name: string, value: string): void;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/URLSearchParams/sort) */
  sort(): void;
  /* Returns an array of key, value pairs for every entry in the search params. */
  entries(): IterableIterator<[key: string, value: string]>;
  /* Returns a list of keys in the search params. */
  keys(): IterableIterator<string>;
  /* Returns a list of values in the search params. */
  values(): IterableIterator<string>;
  forEach<This = unknown>(
    callback: (
      this: This,
      value: string,
      key: string,
      parent: URLSearchParams,
    ) => void,
    thisArg?: This,
  ): void;
  /*function toString() { [native code] } Returns a string containing a query string suitable for use in a URL. Does not include the question mark. */
  toString(): string;
  [Symbol.iterator](): IterableIterator<[key: string, value: string]>;
}
declare class URLPattern {
  constructor(
    input?: string | URLPatternInit,
    baseURL?: string | URLPatternOptions,
    patternOptions?: URLPatternOptions,
  );
  get protocol(): string;
  get username(): string;
  get password(): string;
  get hostname(): string;
  get port(): string;
  get pathname(): string;
  get search(): string;
  get hash(): string;
  test(input?: string | URLPatternInit, baseURL?: string): boolean;
  exec(
    input?: string | URLPatternInit,
    baseURL?: string,
  ): URLPatternResult | null;
}
interface URLPatternInit {
  protocol?: string;
  username?: string;
  password?: string;
  hostname?: string;
  port?: string;
  pathname?: string;
  search?: string;
  hash?: string;
  baseURL?: string;
}
interface URLPatternComponentResult {
  input: string;
  groups: Record<string, string>;
}
interface URLPatternResult {
  inputs: (string | URLPatternInit)[];
  protocol: URLPatternComponentResult;
  username: URLPatternComponentResult;
  password: URLPatternComponentResult;
  hostname: URLPatternComponentResult;
  port: URLPatternComponentResult;
  pathname: URLPatternComponentResult;
  search: URLPatternComponentResult;
  hash: URLPatternComponentResult;
}
interface URLPatternOptions {
  ignoreCase?: boolean;
}
/**
 * A CloseEvent is sent to clients using WebSockets when the connection is closed. This is delivered to the listener indicated by the WebSocket object's onclose attribute.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CloseEvent)
 */
declare class CloseEvent extends Event {
  constructor(type: string, initializer?: CloseEventInit);
  /**
   * Returns the WebSocket connection close code provided by the server.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CloseEvent/code)
   */
  readonly code: number;
  /**
   * Returns the WebSocket connection close reason provided by the server.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CloseEvent/reason)
   */
  readonly reason: string;
  /**
   * Returns true if the connection closed cleanly; false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/CloseEvent/wasClean)
   */
  readonly wasClean: boolean;
}
interface CloseEventInit {
  code?: number;
  reason?: string;
  wasClean?: boolean;
}
/**
 * A message received by a target object.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/MessageEvent)
 */
declare class MessageEvent extends Event {
  constructor(type: string, initializer: MessageEventInit);
  /**
   * Returns the data of the message.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/MessageEvent/data)
   */
  readonly data: ArrayBuffer | string;
}
interface MessageEventInit {
  data: ArrayBuffer | string;
}
type WebSocketEventMap = {
  close: CloseEvent;
  message: MessageEvent;
  open: Event;
  error: ErrorEvent;
};
/**
 * Provides the API for creating and managing a WebSocket connection to a server, as well as for sending and receiving data on the connection.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket)
 */
declare var WebSocket: {
  prototype: WebSocket;
  new (url: string, protocols?: string[] | string): WebSocket;
  readonly READY_STATE_CONNECTING: number;
  readonly CONNECTING: number;
  readonly READY_STATE_OPEN: number;
  readonly OPEN: number;
  readonly READY_STATE_CLOSING: number;
  readonly CLOSING: number;
  readonly READY_STATE_CLOSED: number;
  readonly CLOSED: number;
};
/**
 * Provides the API for creating and managing a WebSocket connection to a server, as well as for sending and receiving data on the connection.
 *
 * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket)
 */
interface WebSocket extends EventTarget<WebSocketEventMap> {
  accept(): void;
  /**
   * Transmits data using the WebSocket connection. data can be a string, a Blob, an ArrayBuffer, or an ArrayBufferView.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket/send)
   */
  send(message: (ArrayBuffer | ArrayBufferView) | string): void;
  /**
   * Closes the WebSocket connection, optionally using code as the the WebSocket connection close code and reason as the the WebSocket connection close reason.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket/close)
   */
  close(code?: number, reason?: string): void;
  serializeAttachment(attachment: any): void;
  deserializeAttachment(): any | null;
  /**
   * Returns the state of the WebSocket object's connection. It can have the values described below.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket/readyState)
   */
  readyState: number;
  /**
   * Returns the URL that was used to establish the WebSocket connection.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket/url)
   */
  url: string | null;
  /**
   * Returns the subprotocol selected by the server, if any. It can be used in conjunction with the array form of the constructor's second argument to perform subprotocol negotiation.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket/protocol)
   */
  protocol: string | null;
  /**
   * Returns the extensions selected by the server, if any.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/WebSocket/extensions)
   */
  extensions: string | null;
}
declare const WebSocketPair: {
  new (): {
    0: WebSocket;
    1: WebSocket;
  };
};
interface SqlStorage {
  exec<T extends Record<string, SqlStorageValue>>(
    query: string,
    ...bindings: any[]
  ): SqlStorageCursor<T>;
  get databaseSize(): number;
  Cursor: typeof SqlStorageCursor;
  Statement: typeof SqlStorageStatement;
}
declare abstract class SqlStorageStatement {}
type SqlStorageValue = ArrayBuffer | string | number | null;
declare abstract class SqlStorageCursor<
  T extends Record<string, SqlStorageValue>,
> {
  next():
    | {
        done?: false;
        value: T;
      }
    | {
        done: true;
        value?: never;
      };
  toArray(): T[];
  one(): T;
  raw<U extends SqlStorageValue[]>(): IterableIterator<U>;
  columnNames: string[];
  get rowsRead(): number;
  get rowsWritten(): number;
  [Symbol.iterator](): IterableIterator<T>;
}
interface Socket {
  get readable(): ReadableStream;
  get writable(): WritableStream;
  get closed(): Promise<void>;
  get opened(): Promise<SocketInfo>;
  get upgraded(): boolean;
  get secureTransport(): "on" | "off" | "starttls";
  close(): Promise<void>;
  startTls(options?: TlsOptions): Socket;
}
interface SocketOptions {
  secureTransport?: string;
  allowHalfOpen: boolean;
  highWaterMark?: number | bigint;
}
interface SocketAddress {
  hostname: string;
  port: number;
}
interface TlsOptions {
  expectedServerHostname?: string;
}
interface SocketInfo {
  remoteAddress?: string;
  localAddress?: string;
}
/* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource) */
declare class EventSource extends EventTarget {
  constructor(url: string, init?: EventSourceEventSourceInit);
  /**
   * Aborts any instances of the fetch algorithm started for this EventSource object, and sets the readyState attribute to CLOSED.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/close)
   */
  close(): void;
  /**
   * Returns the URL providing the event stream.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/url)
   */
  get url(): string;
  /**
   * Returns true if the credentials mode for connection requests to the URL providing the event stream is set to "include", and false otherwise.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/withCredentials)
   */
  get withCredentials(): boolean;
  /**
   * Returns the state of this EventSource object's connection. It can have the values described below.
   *
   * [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/readyState)
   */
  get readyState(): number;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/open_event) */
  get onopen(): any | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/open_event) */
  set onopen(value: any | null);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/message_event) */
  get onmessage(): any | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/message_event) */
  set onmessage(value: any | null);
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/error_event) */
  get onerror(): any | null;
  /* [MDN Reference](https://developer.mozilla.org/docs/Web/API/EventSource/error_event) */
  set onerror(value: any | null);
  static readonly CONNECTING: number;
  static readonly OPEN: number;
  static readonly CLOSED: number;
  static from(stream: ReadableStream): EventSource;
}
interface EventSourceEventSourceInit {
  withCredentials?: boolean;
  fetcher?: Fetcher;
}
interface Container {
  get running(): boolean;
  start(options?: ContainerStartupOptions): void;
  monitor(): Promise<void>;
  destroy(error?: any): Promise<void>;
  signal(signo: number): void;
  getTcpPort(port: number): Fetcher;
}
interface ContainerStartupOptions {
  entrypoint?: string[];
  enableInternet: boolean;
  env?: Record<string, string>;
}
type AiImageClassificationInput = {
  image: number[];
};
type AiImageClassificationOutput = {
  score?: number;
  label?: string;
}[];
declare abstract class BaseAiImageClassification {
  inputs: AiImageClassificationInput;
  postProcessedOutputs: AiImageClassificationOutput;
}
type AiImageToTextInput = {
  image: number[];
  prompt?: string;
  max_tokens?: number;
  temperature?: number;
  top_p?: number;
  top_k?: number;
  seed?: number;
  repetition_penalty?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  raw?: boolean;
  messages?: RoleScopedChatInput[];
};
type AiImageToTextOutput = {
  description: string;
};
declare abstract class BaseAiImageToText {
  inputs: AiImageToTextInput;
  postProcessedOutputs: AiImageToTextOutput;
}
type AiImageTextToTextInput = {
  image: string;
  prompt?: string;
  max_tokens?: number;
  temperature?: number;
  ignore_eos?: boolean;
  top_p?: number;
  top_k?: number;
  seed?: number;
  repetition_penalty?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  raw?: boolean;
  messages?: RoleScopedChatInput[];
};
type AiImageTextToTextOutput = {
  description: string;
};
declare abstract class BaseAiImageTextToText {
  inputs: AiImageTextToTextInput;
  postProcessedOutputs: AiImageTextToTextOutput;
}
type AiObjectDetectionInput = {
  image: number[];
};
type AiObjectDetectionOutput = {
  score?: number;
  label?: string;
}[];
declare abstract class BaseAiObjectDetection {
  inputs: AiObjectDetectionInput;
  postProcessedOutputs: AiObjectDetectionOutput;
}
type AiSentenceSimilarityInput = {
  source: string;
  sentences: string[];
};
type AiSentenceSimilarityOutput = number[];
declare abstract class BaseAiSentenceSimilarity {
  inputs: AiSentenceSimilarityInput;
  postProcessedOutputs: AiSentenceSimilarityOutput;
}
type AiAutomaticSpeechRecognitionInput = {
  audio: number[];
};
type AiAutomaticSpeechRecognitionOutput = {
  text?: string;
  words?: {
    word: string;
    start: number;
    end: number;
  }[];
  vtt?: string;
};
declare abstract class BaseAiAutomaticSpeechRecognition {
  inputs: AiAutomaticSpeechRecognitionInput;
  postProcessedOutputs: AiAutomaticSpeechRecognitionOutput;
}
type AiSummarizationInput = {
  input_text: string;
  max_length?: number;
};
type AiSummarizationOutput = {
  summary: string;
};
declare abstract class BaseAiSummarization {
  inputs: AiSummarizationInput;
  postProcessedOutputs: AiSummarizationOutput;
}
type AiTextClassificationInput = {
  text: string;
};
type AiTextClassificationOutput = {
  score?: number;
  label?: string;
}[];
declare abstract class BaseAiTextClassification {
  inputs: AiTextClassificationInput;
  postProcessedOutputs: AiTextClassificationOutput;
}
type AiTextEmbeddingsInput = {
  text: string | string[];
};
type AiTextEmbeddingsOutput = {
  shape: number[];
  data: number[][];
};
declare abstract class BaseAiTextEmbeddings {
  inputs: AiTextEmbeddingsInput;
  postProcessedOutputs: AiTextEmbeddingsOutput;
}
type RoleScopedChatInput = {
  role:
    | "user"
    | "assistant"
    | "system"
    | "tool"
    | (string & NonNullable<unknown>);
  content: string;
  name?: string;
};
type AiTextGenerationToolLegacyInput = {
  name: string;
  description: string;
  parameters?: {
    type: "object" | (string & NonNullable<unknown>);
    properties: {
      [key: string]: {
        type: string;
        description?: string;
      };
    };
    required: string[];
  };
};
type AiTextGenerationToolInput = {
  type: "function" | (string & NonNullable<unknown>);
  function: {
    name: string;
    description: string;
    parameters?: {
      type: "object" | (string & NonNullable<unknown>);
      properties: {
        [key: string]: {
          type: string;
          description?: string;
        };
      };
      required: string[];
    };
  };
};
type AiTextGenerationFunctionsInput = {
  name: string;
  code: string;
};
type AiTextGenerationResponseFormat = {
  type: string;
  json_schema?: any;
};
type AiTextGenerationInput = {
  prompt?: string;
  raw?: boolean;
  stream?: boolean;
  max_tokens?: number;
  temperature?: number;
  top_p?: number;
  top_k?: number;
  seed?: number;
  repetition_penalty?: number;
  frequency_penalty?: number;
  presence_penalty?: number;
  messages?: RoleScopedChatInput[];
  response_format?: AiTextGenerationResponseFormat;
  tools?:
    | AiTextGenerationToolInput[]
    | AiTextGenerationToolLegacyInput[]
    | (object & NonNullable<unknown>);
  functions?: AiTextGenerationFunctionsInput[];
};
type AiTextGenerationOutput =
  | {
      response?: string;
      tool_calls?: {
        name: string;
        arguments: unknown;
      }[];
    }
  | ReadableStream;
declare abstract class BaseAiTextGeneration {
  inputs: AiTextGenerationInput;
  postProcessedOutputs: AiTextGenerationOutput;
}
type AiTextToSpeechInput = {
  prompt: string;
  lang?: string;
};
type AiTextToSpeechOutput =
  | Uint8Array
  | {
      audio: string;
    };
declare abstract class BaseAiTextToSpeech {
  inputs: AiTextToSpeechInput;
  postProcessedOutputs: AiTextToSpeechOutput;
}
type AiTextToImageInput = {
  prompt: string;
  negative_prompt?: string;
  height?: number;
  width?: number;
  image?: number[];
  image_b64?: string;
  mask?: number[];
  num_steps?: number;
  strength?: number;
  guidance?: number;
  seed?: number;
};
type AiTextToImageOutput = ReadableStream<Uint8Array>;
declare abstract class BaseAiTextToImage {
  inputs: AiTextToImageInput;
  postProcessedOutputs: AiTextToImageOutput;
}
type AiTranslationInput = {
  text: string;
  target_lang: string;
  source_lang?: string;
};
type AiTranslationOutput = {
  translated_text?: string;
};
declare abstract class BaseAiTranslation {
  inputs: AiTranslationInput;
  postProcessedOutputs: AiTranslationOutput;
}
type Ai_Cf_Openai_Whisper_Input =
  | string
  | {
      /**
       * An array of integers that represent the audio data constrained to 8-bit unsigned integer values
       */
      audio: number[];
    };
interface Ai_Cf_Openai_Whisper_Output {
  /**
   * The transcription
   */
  text: string;
  word_count?: number;
  words?: {
    word?: string;
    /**
     * The second this word begins in the recording
     */
    start?: number;
    /**
     * The ending second when the word completes
     */
    end?: number;
  }[];
  vtt?: string;
}
declare abstract class Base_Ai_Cf_Openai_Whisper {
  inputs: Ai_Cf_Openai_Whisper_Input;
  postProcessedOutputs: Ai_Cf_Openai_Whisper_Output;
}
type Ai_Cf_Unum_Uform_Gen2_Qwen_500M_Input =
  | string
  | {
      /**
       * The input text prompt for the model to generate a response.
       */
      prompt?: string;
      /**
       * If true, a chat template is not applied and you must adhere to the specific model's expected formatting.
       */
      raw?: boolean;
      /**
       * Controls the creativity of the AI's responses by adjusting how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.
       */
      top_p?: number;
      /**
       * Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.
       */
      top_k?: number;
      /**
       * Random seed for reproducibility of the generation.
       */
      seed?: number;
      /**
       * Penalty for repeated tokens; higher values discourage repetition.
       */
      repetition_penalty?: number;
      /**
       * Decreases the likelihood of the model repeating the same lines verbatim.
       */
      frequency_penalty?: number;
      /**
       * Increases the likelihood of the model introducing new topics.
       */
      presence_penalty?: number;
      image: number[] | (string & NonNullable<unknown>);
      /**
       * The maximum number of tokens to generate in the response.
       */
      max_tokens?: number;
    };
interface Ai_Cf_Unum_Uform_Gen2_Qwen_500M_Output {
  description?: string;
}
declare abstract class Base_Ai_Cf_Unum_Uform_Gen2_Qwen_500M {
  inputs: Ai_Cf_Unum_Uform_Gen2_Qwen_500M_Input;
  postProcessedOutputs: Ai_Cf_Unum_Uform_Gen2_Qwen_500M_Output;
}
type Ai_Cf_Openai_Whisper_Tiny_En_Input =
  | string
  | {
      /**
       * An array of integers that represent the audio data constrained to 8-bit unsigned integer values
       */
      audio: number[];
    };
interface Ai_Cf_Openai_Whisper_Tiny_En_Output {
  /**
   * The transcription
   */
  text: string;
  word_count?: number;
  words?: {
    word?: string;
    /**
     * The second this word begins in the recording
     */
    start?: number;
    /**
     * The ending second when the word completes
     */
    end?: number;
  }[];
  vtt?: string;
}
declare abstract class Base_Ai_Cf_Openai_Whisper_Tiny_En {
  inputs: Ai_Cf_Openai_Whisper_Tiny_En_Input;
  postProcessedOutputs: Ai_Cf_Openai_Whisper_Tiny_En_Output;
}
interface Ai_Cf_Openai_Whisper_Large_V3_Turbo_Input {
  /**
   * Base64 encoded value of the audio data.
   */
  audio: string;
  /**
   * Supported tasks are 'translate' or 'transcribe'.
   */
  task?: string;
  /**
   * The language of the audio being transcribed or translated.
   */
  language?: string;
  /**
   * Preprocess the audio with a voice activity detection model.
   */
  vad_filter?: string;
  /**
   * A text prompt to help provide context to the model on the contents of the audio.
   */
  initial_prompt?: string;
  /**
   * The prefix it appended the the beginning of the output of the transcription and can guide the transcription result.
   */
  prefix?: string;
}
interface Ai_Cf_Openai_Whisper_Large_V3_Turbo_Output {
  transcription_info?: {
    /**
     * The language of the audio being transcribed or translated.
     */
    language?: string;
    /**
     * The confidence level or probability of the detected language being accurate, represented as a decimal between 0 and 1.
     */
    language_probability?: number;
    /**
     * The total duration of the original audio file, in seconds.
     */
    duration?: number;
    /**
     * The duration of the audio after applying Voice Activity Detection (VAD) to remove silent or irrelevant sections, in seconds.
     */
    duration_after_vad?: number;
  };
  /**
   * The complete transcription of the audio.
   */
  text: string;
  /**
   * The total number of words in the transcription.
   */
  word_count?: number;
  segments?: {
    /**
     * The starting time of the segment within the audio, in seconds.
     */
    start?: number;
    /**
     * The ending time of the segment within the audio, in seconds.
     */
    end?: number;
    /**
     * The transcription of the segment.
     */
    text?: string;
    /**
     * The temperature used in the decoding process, controlling randomness in predictions. Lower values result in more deterministic outputs.
     */
    temperature?: number;
    /**
     * The average log probability of the predictions for the words in this segment, indicating overall confidence.
     */
    avg_logprob?: number;
    /**
     * The compression ratio of the input to the output, measuring how much the text was compressed during the transcription process.
     */
    compression_ratio?: number;
    /**
     * The probability that the segment contains no speech, represented as a decimal between 0 and 1.
     */
    no_speech_prob?: number;
    words?: {
      /**
       * The individual word transcribed from the audio.
       */
      word?: string;
      /**
       * The starting time of the word within the audio, in seconds.
       */
      start?: number;
      /**
       * The ending time of the word within the audio, in seconds.
       */
      end?: number;
    }[];
  }[];
  /**
   * The transcription in WebVTT format, which includes timing and text information for use in subtitles.
   */
  vtt?: string;
}
declare abstract class Base_Ai_Cf_Openai_Whisper_Large_V3_Turbo {
  inputs: Ai_Cf_Openai_Whisper_Large_V3_Turbo_Input;
  postProcessedOutputs: Ai_Cf_Openai_Whisper_Large_V3_Turbo_Output;
}
type Ai_Cf_Baai_Bge_M3_Input = BGEM3InputQueryAndContexts | BGEM3InputEmbedding;
interface BGEM3InputQueryAndContexts {
  /**
   * A query you wish to perform against the provided contexts. If no query is provided the model with respond with embeddings for contexts
   */
  query?: string;
  /**
   * List of provided contexts. Note that the index in this array is important, as the response will refer to it.
   */
  contexts: {
    /**
     * One of the provided context content
     */
    text?: string;
  }[];
  /**
   * When provided with too long context should the model error out or truncate the context to fit?
   */
  truncate_inputs?: boolean;
}
interface BGEM3InputEmbedding {
  text: string | string[];
  /**
   * When provided with too long context should the model error out or truncate the context to fit?
   */
  truncate_inputs?: boolean;
}
type Ai_Cf_Baai_Bge_M3_Output =
  | BGEM3OuputQuery
  | BGEM3OutputEmbeddingForContexts
  | BGEM3OuputEmbedding;
interface BGEM3OuputQuery {
  response?: {
    /**
     * Index of the context in the request
     */
    id?: number;
    /**
     * Score of the context under the index.
     */
    score?: number;
  }[];
}
interface BGEM3OutputEmbeddingForContexts {
  response?: number[][];
  shape?: number[];
  /**
   * The pooling method used in the embedding process.
   */
  pooling?: "mean" | "cls";
}
interface BGEM3OuputEmbedding {
  shape?: number[];
  /**
   * Embeddings of the requested text values
   */
  data?: number[][];
  /**
   * The pooling method used in the embedding process.
   */
  pooling?: "mean" | "cls";
}
declare abstract class Base_Ai_Cf_Baai_Bge_M3 {
  inputs: Ai_Cf_Baai_Bge_M3_Input;
  postProcessedOutputs: Ai_Cf_Baai_Bge_M3_Output;
}
interface Ai_Cf_Black_Forest_Labs_Flux_1_Schnell_Input {
  /**
   * A text description of the image you want to generate.
   */
  prompt: string;
  /**
   * The number of diffusion steps; higher values can improve quality but take longer.
   */
  steps?: number;
}
interface Ai_Cf_Black_Forest_Labs_Flux_1_Schnell_Output {
  /**
   * The generated image in Base64 format.
   */
  image?: string;
}
declare abstract class Base_Ai_Cf_Black_Forest_Labs_Flux_1_Schnell {
  inputs: Ai_Cf_Black_Forest_Labs_Flux_1_Schnell_Input;
  postProcessedOutputs: Ai_Cf_Black_Forest_Labs_Flux_1_Schnell_Output;
}
type Ai_Cf_Meta_Llama_3_2_11B_Vision_Instruct_Input = Prompt | Messages;
interface Prompt {
  /**
   * The input text prompt for the model to generate a response.
   */
  prompt: string;
  image?: number[] | (string & NonNullable<unknown>);
  /**
   * If true, a chat template is not applied and you must adhere to the specific model's expected formatting.
   */
  raw?: boolean;
  /**
   * If true, the response will be streamed back incrementally using SSE, Server Sent Events.
   */
  stream?: boolean;
  /**
   * The maximum number of tokens to generate in the response.
   */
  max_tokens?: number;
  /**
   * Controls the randomness of the output; higher values produce more random results.
   */
  temperature?: number;
  /**
   * Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.
   */
  top_p?: number;
  /**
   * Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.
   */
  top_k?: number;
  /**
   * Random seed for reproducibility of the generation.
   */
  seed?: number;
  /**
   * Penalty for repeated tokens; higher values discourage repetition.
   */
  repetition_penalty?: number;
  /**
   * Decreases the likelihood of the model repeating the same lines verbatim.
   */
  frequency_penalty?: number;
  /**
   * Increases the likelihood of the model introducing new topics.
   */
  presence_penalty?: number;
  /**
   * Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model.
   */
  lora?: string;
}
interface Messages {
  /**
   * An array of message objects representing the conversation history.
   */
  messages: {
    /**
     * The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool').
     */
    role: string;
    /**
     * The content of the message as a string.
     */
    content: string;
  }[];
  image?: number[] | string;
  functions?: {
    name: string;
    code: string;
  }[];
  /**
   * A list of tools available for the assistant to use.
   */
  tools?: (
    | {
        /**
         * The name of the tool. More descriptive the better.
         */
        name: string;
        /**
         * A brief description of what the tool does.
         */
        description: string;
        /**
         * Schema defining the parameters accepted by the tool.
         */
        parameters: {
          /**
           * The type of the parameters object (usually 'object').
           */
          type: string;
          /**
           * List of required parameter names.
           */
          required?: string[];
          /**
           * Definitions of each parameter.
           */
          properties: {
            [k: string]: {
              /**
               * The data type of the parameter.
               */
              type: string;
              /**
               * A description of the expected parameter.
               */
              description: string;
            };
          };
        };
      }
    | {
        /**
         * Specifies the type of tool (e.g., 'function').
         */
        type: string;
        /**
         * Details of the function tool.
         */
        function: {
          /**
           * The name of the function.
           */
          name: string;
          /**
           * A brief description of what the function does.
           */
          description: string;
          /**
           * Schema defining the parameters accepted by the function.
           */
          parameters: {
            /**
             * The type of the parameters object (usually 'object').
             */
            type: string;
            /**
             * List of required parameter names.
             */
            required?: string[];
            /**
             * Definitions of each parameter.
             */
            properties: {
              [k: string]: {
                /**
                 * The data type of the parameter.
                 */
                type: string;
                /**
                 * A description of the expected parameter.
                 */
                description: string;
              };
            };
          };
        };
      }
  )[];
  /**
   * If true, the response will be streamed back incrementally.
   */
  stream?: boolean;
  /**
   * The maximum number of tokens to generate in the response.
   */
  max_tokens?: number;
  /**
   * Controls the randomness of the output; higher values produce more random results.
   */
  temperature?: number;
  /**
   * Controls the creativity of the AI's responses by adjusting how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.
   */
  top_p?: number;
  /**
   * Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.
   */
  top_k?: number;
  /**
   * Random seed for reproducibility of the generation.
   */
  seed?: number;
  /**
   * Penalty for repeated tokens; higher values discourage repetition.
   */
  repetition_penalty?: number;
  /**
   * Decreases the likelihood of the model repeating the same lines verbatim.
   */
  frequency_penalty?: number;
  /**
   * Increases the likelihood of the model introducing new topics.
   */
  presence_penalty?: number;
}
type Ai_Cf_Meta_Llama_3_2_11B_Vision_Instruct_Output =
  | {
      /**
       * The generated text response from the model
       */
      response?: string;
      /**
       * An array of tool calls requests made during the response generation
       */
      tool_calls?: {
        /**
         * The arguments passed to be passed to the tool call request
         */
        arguments?: object;
        /**
         * The name of the tool to be called
         */
        name?: string;
      }[];
    }
  | ReadableStream;
declare abstract class Base_Ai_Cf_Meta_Llama_3_2_11B_Vision_Instruct {
  inputs: Ai_Cf_Meta_Llama_3_2_11B_Vision_Instruct_Input;
  postProcessedOutputs: Ai_Cf_Meta_Llama_3_2_11B_Vision_Instruct_Output;
}
interface Ai_Cf_Meta_Llama_Guard_3_8B_Input {
  /**
   * An array of message objects representing the conversation history.
   */
  messages: {
    /**
     * The role of the message sender must alternate between 'user' and 'assistant'.
     */
    role: "user" | "assistant";
    /**
     * The content of the message as a string.
     */
    content: string;
  }[];
  /**
   * The maximum number of tokens to generate in the response.
   */
  max_tokens?: number;
  /**
   * Controls the randomness of the output; higher values produce more random results.
   */
  temperature?: number;
  /**
   * Dictate the output format of the generated response.
   */
  response_format?: {
    /**
     * Set to json_object to process and output generated text as JSON.
     */
    type?: string;
  };
}
interface Ai_Cf_Meta_Llama_Guard_3_8B_Output {
  response?:
    | string
    | {
        /**
         * Whether the conversation is safe or not.
         */
        safe?: boolean;
        /**
         * A list of what hazard categories predicted for the conversation, if the conversation is deemed unsafe.
         */
        categories?: string[];
      };
  /**
   * Usage statistics for the inference request
   */
  usage?: {
    /**
     * Total number of tokens in input
     */
    prompt_tokens?: number;
    /**
     * Total number of tokens in output
     */
    completion_tokens?: number;
    /**
     * Total number of input and output tokens
     */
    total_tokens?: number;
  };
}
declare abstract class Base_Ai_Cf_Meta_Llama_Guard_3_8B {
  inputs: Ai_Cf_Meta_Llama_Guard_3_8B_Input;
  postProcessedOutputs: Ai_Cf_Meta_Llama_Guard_3_8B_Output;
}
interface Ai_Cf_Baai_Bge_Reranker_Base_Input {
  /**
   * A query you wish to perform against the provided contexts.
   */
  /**
   * Number of returned results starting with the best score.
   */
  top_k?: number;
  /**
   * List of provided contexts. Note that the index in this array is important, as the response will refer to it.
   */
  contexts: {
    /**
     * One of the provided context content
     */
    text?: string;
  }[];
}
interface Ai_Cf_Baai_Bge_Reranker_Base_Output {
  response?: {
    /**
     * Index of the context in the request
     */
    id?: number;
    /**
     * Score of the context under the index.
     */
    score?: number;
  }[];
}
declare abstract class Base_Ai_Cf_Baai_Bge_Reranker_Base {
  inputs: Ai_Cf_Baai_Bge_Reranker_Base_Input;
  postProcessedOutputs: Ai_Cf_Baai_Bge_Reranker_Base_Output;
}
type Ai_Cf_Meta_Llama_4_Scout_17B_16E_Instruct_Input =
  | Ai_Cf_Meta_Llama_4_Prompt
  | Ai_Cf_Meta_Llama_4_Messages;
interface Ai_Cf_Meta_Llama_4_Prompt {
  /**
   * The input text prompt for the model to generate a response.
   */
  prompt: string;
  /**
   * JSON schema that should be fulfilled for the response.
   */
  guided_json?: object;
  /**
   * If true, a chat template is not applied and you must adhere to the specific model's expected formatting.
   */
  raw?: boolean;
  /**
   * If true, the response will be streamed back incrementally using SSE, Server Sent Events.
   */
  stream?: boolean;
  /**
   * The maximum number of tokens to generate in the response.
   */
  max_tokens?: number;
  /**
   * Controls the randomness of the output; higher values produce more random results.
   */
  temperature?: number;
  /**
   * Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.
   */
  top_p?: number;
  /**
   * Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.
   */
  top_k?: number;
  /**
   * Random seed for reproducibility of the generation.
   */
  seed?: number;
  /**
   * Penalty for repeated tokens; higher values discourage repetition.
   */
  repetition_penalty?: number;
  /**
   * Decreases the likelihood of the model repeating the same lines verbatim.
   */
  frequency_penalty?: number;
  /**
   * Increases the likelihood of the model introducing new topics.
   */
  presence_penalty?: number;
}
interface Ai_Cf_Meta_Llama_4_Messages {
  /**
   * An array of message objects representing the conversation history.
   */
  messages: {
    /**
     * The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool').
     */
    role?: string;
    /**
     * The tool call id. Must be supplied for tool calls for Mistral-3. If you don't know what to put here you can fall back to 000000001
     */
    tool_call_id?: string;
    content?:
      | string
      | {
          /**
           * Type of the content provided
           */
          type?: string;
          text?: string;
          image_url?: {
            /**
             * image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted
             */
            url?: string;
          };
        }[]
      | {
          /**
           * Type of the content provided
           */
          type?: string;
          text?: string;
          image_url?: {
            /**
             * image uri with data (e.g. data:image/jpeg;base64,/9j/...). HTTP URL will not be accepted
             */
            url?: string;
          };
        };
  }[];
  functions?: {
    name: string;
    code: string;
  }[];
  /**
   * A list of tools available for the assistant to use.
   */
  tools?: (
    | {
        /**
         * The name of the tool. More descriptive the better.
         */
        name: string;
        /**
         * A brief description of what the tool does.
         */
        description: string;
        /**
         * Schema defining the parameters accepted by the tool.
         */
        parameters: {
          /**
           * The type of the parameters object (usually 'object').
           */
          type: string;
          /**
           * List of required parameter names.
           */
          required?: string[];
          /**
           * Definitions of each parameter.
           */
          properties: {
            [k: string]: {
              /**
               * The data type of the parameter.
               */
              type: string;
              /**
               * A description of the expected parameter.
               */
              description: string;
            };
          };
        };
      }
    | {
        /**
         * Specifies the type of tool (e.g., 'function').
         */
        type: string;
        /**
         * Details of the function tool.
         */
        function: {
          /**
           * The name of the function.
           */
          name: string;
          /**
           * A brief description of what the function does.
           */
          description: string;
          /**
           * Schema defining the parameters accepted by the function.
           */
          parameters: {
            /**
             * The type of the parameters object (usually 'object').
             */
            type: string;
            /**
             * List of required parameter names.
             */
            required?: string[];
            /**
             * Definitions of each parameter.
             */
            properties: {
              [k: string]: {
                /**
                 * The data type of the parameter.
                 */
                type: string;
                /**
                 * A description of the expected parameter.
                 */
                description: string;
              };
            };
          };
        };
      }
  )[];
  /**
   * JSON schema that should be fufilled for the response.
   */
  guided_json?: object;
  /**
   * If true, a chat template is not applied and you must adhere to the specific model's expected formatting.
   */
  raw?: boolean;
  /**
   * If true, the response will be streamed back incrementally using SSE, Server Sent Events.
   */
  stream?: boolean;
  /**
   * The maximum number of tokens to generate in the response.
   */
  max_tokens?: number;
  /**
   * Controls the randomness of the output; higher values produce more random results.
   */
  temperature?: number;
  /**
   * Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.
   */
  top_p?: number;
  /**
   * Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.
   */
  top_k?: number;
  /**
   * Random seed for reproducibility of the generation.
   */
  seed?: number;
  /**
   * Penalty for repeated tokens; higher values discourage repetition.
   */
  repetition_penalty?: number;
  /**
   * Decreases the likelihood of the model repeating the same lines verbatim.
   */
  frequency_penalty?: number;
  /**
   * Increases the likelihood of the model introducing new topics.
   */
  presence_penalty?: number;
}
type Ai_Cf_Meta_Llama_4_Scout_17B_16E_Instruct_Output =
  | {
      /**
       * The generated text response from the model
       */
      response: string;
      /**
       * Usage statistics for the inference request
       */
      usage?: {
        /**
         * Total number of tokens in input
         */
        prompt_tokens?: number;
        /**
         * Total number of tokens in output
         */
        completion_tokens?: number;
        /**
         * Total number of input and output tokens
         */
        total_tokens?: number;
      };
      /**
       * An array of tool calls requests made during the response generation
       */
      tool_calls?: {
        /**
         * The arguments passed to be passed to the tool call request
         */
        arguments?: object;
        /**
         * The name of the tool to be called
         */
        name?: string;
      }[];
    }
  | string;
declare abstract class Base_Ai_Cf_Meta_Llama_4_Scout_17B_16E_Instruct {
  inputs: Ai_Cf_Meta_Llama_4_Scout_17B_16E_Instruct_Input;
  postProcessedOutputs: Ai_Cf_Meta_Llama_4_Scout_17B_16E_Instruct_Output;
}
interface AiModels {
  "@cf/huggingface/distilbert-sst-2-int8": BaseAiTextClassification;
  "@cf/stabilityai/stable-diffusion-xl-base-1.0": BaseAiTextToImage;
  "@cf/runwayml/stable-diffusion-v1-5-inpainting": BaseAiTextToImage;
  "@cf/runwayml/stable-diffusion-v1-5-img2img": BaseAiTextToImage;
  "@cf/lykon/dreamshaper-8-lcm": BaseAiTextToImage;
  "@cf/bytedance/stable-diffusion-xl-lightning": BaseAiTextToImage;
  "@cf/myshell-ai/melotts": BaseAiTextToSpeech;
  "@cf/baai/bge-base-en-v1.5": BaseAiTextEmbeddings;
  "@cf/baai/bge-small-en-v1.5": BaseAiTextEmbeddings;
  "@cf/baai/bge-large-en-v1.5": BaseAiTextEmbeddings;
  "@cf/microsoft/resnet-50": BaseAiImageClassification;
  "@cf/facebook/detr-resnet-50": BaseAiObjectDetection;
  "@cf/meta/llama-2-7b-chat-int8": BaseAiTextGeneration;
  "@cf/mistral/mistral-7b-instruct-v0.1": BaseAiTextGeneration;
  "@cf/meta/llama-2-7b-chat-fp16": BaseAiTextGeneration;
  "@hf/thebloke/llama-2-13b-chat-awq": BaseAiTextGeneration;
  "@hf/thebloke/mistral-7b-instruct-v0.1-awq": BaseAiTextGeneration;
  "@hf/thebloke/zephyr-7b-beta-awq": BaseAiTextGeneration;
  "@hf/thebloke/openhermes-2.5-mistral-7b-awq": BaseAiTextGeneration;
  "@hf/thebloke/neural-chat-7b-v3-1-awq": BaseAiTextGeneration;
  "@hf/thebloke/llamaguard-7b-awq": BaseAiTextGeneration;
  "@hf/thebloke/deepseek-coder-6.7b-base-awq": BaseAiTextGeneration;
  "@hf/thebloke/deepseek-coder-6.7b-instruct-awq": BaseAiTextGeneration;
  "@cf/deepseek-ai/deepseek-math-7b-instruct": BaseAiTextGeneration;
  "@cf/defog/sqlcoder-7b-2": BaseAiTextGeneration;
  "@cf/openchat/openchat-3.5-0106": BaseAiTextGeneration;
  "@cf/tiiuae/falcon-7b-instruct": BaseAiTextGeneration;
  "@cf/thebloke/discolm-german-7b-v1-awq": BaseAiTextGeneration;
  "@cf/qwen/qwen1.5-0.5b-chat": BaseAiTextGeneration;
  "@cf/qwen/qwen1.5-7b-chat-awq": BaseAiTextGeneration;
  "@cf/qwen/qwen1.5-14b-chat-awq": BaseAiTextGeneration;
  "@cf/tinyllama/tinyllama-1.1b-chat-v1.0": BaseAiTextGeneration;
  "@cf/microsoft/phi-2": BaseAiTextGeneration;
  "@cf/qwen/qwen1.5-1.8b-chat": BaseAiTextGeneration;
  "@cf/mistral/mistral-7b-instruct-v0.2-lora": BaseAiTextGeneration;
  "@hf/nousresearch/hermes-2-pro-mistral-7b": BaseAiTextGeneration;
  "@hf/nexusflow/starling-lm-7b-beta": BaseAiTextGeneration;
  "@hf/google/gemma-7b-it": BaseAiTextGeneration;
  "@cf/meta-llama/llama-2-7b-chat-hf-lora": BaseAiTextGeneration;
  "@cf/google/gemma-2b-it-lora": BaseAiTextGeneration;
  "@cf/google/gemma-7b-it-lora": BaseAiTextGeneration;
  "@hf/mistral/mistral-7b-instruct-v0.2": BaseAiTextGeneration;
  "@cf/meta/llama-3-8b-instruct": BaseAiTextGeneration;
  "@cf/fblgit/una-cybertron-7b-v2-bf16": BaseAiTextGeneration;
  "@cf/meta/llama-3-8b-instruct-awq": BaseAiTextGeneration;
  "@hf/meta-llama/meta-llama-3-8b-instruct": BaseAiTextGeneration;
  "@cf/meta/llama-3.1-8b-instruct": BaseAiTextGeneration;
  "@cf/meta/llama-3.1-8b-instruct-fp8": BaseAiTextGeneration;
  "@cf/meta/llama-3.1-8b-instruct-awq": BaseAiTextGeneration;
  "@cf/meta/llama-3.2-3b-instruct": BaseAiTextGeneration;
  "@cf/meta/llama-3.2-1b-instruct": BaseAiTextGeneration;
  "@cf/meta/llama-3.3-70b-instruct-fp8-fast": BaseAiTextGeneration;
  "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b": BaseAiTextGeneration;
  "@cf/meta/m2m100-1.2b": BaseAiTranslation;
  "@cf/facebook/bart-large-cnn": BaseAiSummarization;
  "@cf/llava-hf/llava-1.5-7b-hf": BaseAiImageToText;
  "@cf/openai/whisper": Base_Ai_Cf_Openai_Whisper;
  "@cf/unum/uform-gen2-qwen-500m": Base_Ai_Cf_Unum_Uform_Gen2_Qwen_500M;
  "@cf/openai/whisper-tiny-en": Base_Ai_Cf_Openai_Whisper_Tiny_En;
  "@cf/openai/whisper-large-v3-turbo": Base_Ai_Cf_Openai_Whisper_Large_V3_Turbo;
  "@cf/baai/bge-m3": Base_Ai_Cf_Baai_Bge_M3;
  "@cf/black-forest-labs/flux-1-schnell": Base_Ai_Cf_Black_Forest_Labs_Flux_1_Schnell;
  "@cf/meta/llama-3.2-11b-vision-instruct": Base_Ai_Cf_Meta_Llama_3_2_11B_Vision_Instruct;
  "@cf/meta/llama-guard-3-8b": Base_Ai_Cf_Meta_Llama_Guard_3_8B;
  "@cf/baai/bge-reranker-base": Base_Ai_Cf_Baai_Bge_Reranker_Base;
  "@cf/meta/llama-4-scout-17b-16e-instruct": Base_Ai_Cf_Meta_Llama_4_Scout_17B_16E_Instruct;
}
type AiOptions = {
  gateway?: GatewayOptions;
  returnRawResponse?: boolean;
  prefix?: string;
  extraHeaders?: object;
};
type ConversionResponse = {
  name: string;
  mimeType: string;
  format: "markdown";
  tokens: number;
  data: string;
};
type AiModelsSearchParams = {
  author?: string;
  hide_experimental?: boolean;
  page?: number;
  per_page?: number;
  search?: string;
  source?: number;
  task?: string;
};
type AiModelsSearchObject = {
  id: string;
  source: number;
  name: string;
  description: string;
  task: {
    id: string;
    name: string;
    description: string;
  };
  tags: string[];
  properties: {
    property_id: string;
    value: string;
  }[];
};
interface InferenceUpstreamError extends Error {}
interface AiInternalError extends Error {}
type AiModelListType = Record<string, any>;
declare abstract class Ai<AiModelList extends AiModelListType = AiModels> {
  aiGatewayLogId: string | null;
  gateway(gatewayId: string): AiGateway;
  autorag(autoragId: string): AutoRAG;
  run<Name extends keyof AiModelList, Options extends AiOptions>(
    model: Name,
    inputs: AiModelList[Name]["inputs"],
    options?: Options,
  ): Promise<
    Options extends {
      returnRawResponse: true;
    }
      ? Response
      : AiModelList[Name]["postProcessedOutputs"]
  >;
  models(params?: AiModelsSearchParams): Promise<AiModelsSearchObject[]>;
  toMarkdown(
    files: {
      name: string;
      blob: Blob;
    }[],
    options?: {
      gateway?: GatewayOptions;
      extraHeaders?: object;
    },
  ): Promise<ConversionResponse[]>;
  toMarkdown(
    files: {
      name: string;
      blob: Blob;
    },
    options?: {
      gateway?: GatewayOptions;
      extraHeaders?: object;
    },
  ): Promise<ConversionResponse>;
}
type GatewayRetries = {
  maxAttempts?: 1 | 2 | 3 | 4 | 5;
  retryDelayMs?: number;
  backoff?: "constant" | "linear" | "exponential";
};
type GatewayOptions = {
  id: string;
  cacheKey?: string;
  cacheTtl?: number;
  skipCache?: boolean;
  metadata?: Record<string, number | string | boolean | null | bigint>;
  collectLog?: boolean;
  eventId?: string;
  requestTimeoutMs?: number;
  retries?: GatewayRetries;
};
type AiGatewayPatchLog = {
  score?: number | null;
  feedback?: -1 | 1 | null;
  metadata?: Record<string, number | string | boolean | null | bigint> | null;
};
type AiGatewayLog = {
  id: string;
  provider: string;
  model: string;
  model_type?: string;
  path: string;
  duration: number;
  request_type?: string;
  request_content_type?: string;
  status_code: number;
  response_content_type?: string;
  success: boolean;
  cached: boolean;
  tokens_in?: number;
  tokens_out?: number;
  metadata?: Record<string, number | string | boolean | null | bigint>;
  step?: number;
  cost?: number;
  custom_cost?: boolean;
  request_size: number;
  request_head?: string;
  request_head_complete: boolean;
  response_size: number;
  response_head?: string;
  response_head_complete: boolean;
  created_at: Date;
};
type AIGatewayProviders =
  | "workers-ai"
  | "anthropic"
  | "aws-bedrock"
  | "azure-openai"
  | "google-vertex-ai"
  | "huggingface"
  | "openai"
  | "perplexity-ai"
  | "replicate"
  | "groq"
  | "cohere"
  | "google-ai-studio"
  | "mistral"
  | "grok"
  | "openrouter"
  | "deepseek"
  | "cerebras"
  | "cartesia"
  | "elevenlabs"
  | "adobe-firefly";
type AIGatewayHeaders = {
  "cf-aig-metadata":
    | Record<string, number | string | boolean | null | bigint>
    | string;
  "cf-aig-custom-cost":
    | {
        per_token_in?: number;
        per_token_out?: number;
      }
    | {
        total_cost?: number;
      }
    | string;
  "cf-aig-cache-ttl": number | string;
  "cf-aig-skip-cache": boolean | string;
  "cf-aig-cache-key": string;
  "cf-aig-event-id": string;
  "cf-aig-request-timeout": number | string;
  "cf-aig-max-attempts": number | string;
  "cf-aig-retry-delay": number | string;
  "cf-aig-backoff": string;
  "cf-aig-collect-log": boolean | string;
  Authorization: string;
  "Content-Type": string;
  [key: string]: string | number | boolean | object;
};
type AIGatewayUniversalRequest = {
  provider: AIGatewayProviders | string; // eslint-disable-line
  endpoint: string;
  headers: Partial<AIGatewayHeaders>;
  query: unknown;
};
interface AiGatewayInternalError extends Error {}
interface AiGatewayLogNotFound extends Error {}
declare abstract class AiGateway {
  patchLog(logId: string, data: AiGatewayPatchLog): Promise<void>;
  getLog(logId: string): Promise<AiGatewayLog>;
  run(
    data: AIGatewayUniversalRequest | AIGatewayUniversalRequest[],
    options?: {
      gateway?: GatewayOptions;
      extraHeaders?: object;
    },
  ): Promise<Response>;
  getUrl(provider?: AIGatewayProviders | string): Promise<string>; // eslint-disable-line
}
interface AutoRAGInternalError extends Error {}
interface AutoRAGNotFoundError extends Error {}
interface AutoRAGUnauthorizedError extends Error {}
type AutoRagSearchRequest = {
  query: string;
  max_num_results?: number;
  ranking_options?: {
    ranker?: string;
    score_threshold?: number;
  };
  rewrite_query?: boolean;
};
type AutoRagAiSearchRequest = AutoRagSearchRequest & {
  stream?: boolean;
};
type AutoRagAiSearchRequestStreaming = Omit<
  AutoRagAiSearchRequest,
  "stream"
> & {
  stream: true;
};
type AutoRagSearchResponse = {
  object: "vector_store.search_results.page";
  search_query: string;
  data: {
    file_id: string;
    filename: string;
    score: number;
    attributes: Record<string, string | number | boolean | null>;
    content: {
      type: "text";
      text: string;
    }[];
  }[];
  has_more: boolean;
  next_page: string | null;
};
type AutoRagAiSearchResponse = AutoRagSearchResponse & {
  response: string;
};
declare abstract class AutoRAG {
  search(params: AutoRagSearchRequest): Promise<AutoRagSearchResponse>;
  aiSearch(params: AutoRagAiSearchRequestStreaming): Promise<Response>;
  aiSearch(params: AutoRagAiSearchRequest): Promise<AutoRagAiSearchResponse>;
  aiSearch(
    params: AutoRagAiSearchRequest,
  ): Promise<AutoRagAiSearchResponse | Response>;
}
interface BasicImageTransformations {
  /**
   * Maximum width in image pixels. The value must be an integer.
   */
  width?: number;
  /**
   * Maximum height in image pixels. The value must be an integer.
   */
  height?: number;
  /**
   * Resizing mode as a string. It affects interpretation of width and height
   * options:
   *  - scale-down: Similar to contain, but the image is never enlarged. If
   *    the image is larger than given width or height, it will be resized.
   *    Otherwise its original size will be kept.
   *  - contain: Resizes to maximum size that fits within the given width and
   *    height. If only a single dimension is given (e.g. only width), the
   *    image will be shrunk or enlarged to exactly match that dimension.
   *    Aspect ratio is always preserved.
   *  - cover: Resizes (shrinks or enlarges) to fill the entire area of width
   *    and height. If the image has an aspect ratio different from the ratio
   *    of width and height, it will be cropped to fit.
   *  - crop: The image will be shrunk and cropped to fit within the area
   *    specified by width and height. The image will not be enlarged. For images
   *    smaller than the given dimensions it's the same as scale-down. For
   *    images larger than the given dimensions, it's the same as cover.
   *    See also trim.
   *  - pad: Resizes to the maximum size that fits within the given width and
   *    height, and then fills the remaining area with a background color
   *    (white by default). Use of this mode is not recommended, as the same
   *    effect can be more efficiently achieved with the contain mode and the
   *    CSS object-fit: contain property.
   *  - squeeze: Stretches and deforms to the width and height given, even if it
   *    breaks aspect ratio
   */
  fit?: "scale-down" | "contain" | "cover" | "crop" | "pad" | "squeeze";
  /**
   * When cropping with fit: "cover", this defines the side or point that should
   * be left uncropped. The value is either a string
   * "left", "right", "top", "bottom", "auto", or "center" (the default),
   * or an object {x, y} containing focal point coordinates in the original
   * image expressed as fractions ranging from 0.0 (top or left) to 1.0
   * (bottom or right), 0.5 being the center. {fit: "cover", gravity: "top"} will
   * crop bottom or left and right sides as necessary, but wont crop anything
   * from the top. {fit: "cover", gravity: {x:0.5, y:0.2}} will crop each side to
   * preserve as much as possible around a point at 20% of the height of the
   * source image.
   */
  gravity?:
    | "left"
    | "right"
    | "top"
    | "bottom"
    | "center"
    | "auto"
    | "entropy"
    | BasicImageTransformationsGravityCoordinates;
  /**
   * Background color to add underneath the image. Applies only to images with
   * transparency (such as PNG). Accepts any CSS color (#RRGGBB, rgba(),
   * hsl(), etc.)
   */
  background?: string;
  /**
   * Number of degrees (90, 180, 270) to rotate the image by. width and height
   * options refer to axes after rotation.
   */
  rotate?: 0 | 90 | 180 | 270 | 360;
}
interface BasicImageTransformationsGravityCoordinates {
  x?: number;
  y?: number;
  mode?: "remainder" | "box-center";
}
/**
 * In addition to the properties you can set in the RequestInit dict
 * that you pass as an argument to the Request constructor, you can
 * set certain properties of a `cf` object to control how Cloudflare
 * features are applied to that new Request.
 *
 * Note: Currently, these properties cannot be tested in the
 * playground.
 */
interface RequestInitCfProperties extends Record<string, unknown> {
  cacheEverything?: boolean;
  /**
   * A request's cache key is what determines if two requests are
   * "the same" for caching purposes. If a request has the same cache key
   * as some previous request, then we can serve the same cached response for
   * both. (e.g. 'some-key')
   *
   * Only available for Enterprise customers.
   */
  cacheKey?: string;
  /**
   * This allows you to append additional Cache-Tag response headers
   * to the origin response without modifications to the origin server.
   * This will allow for greater control over the Purge by Cache Tag feature
   * utilizing changes only in the Workers process.
   *
   * Only available for Enterprise customers.
   */
  cacheTags?: string[];
  /**
   * Force response to be cached for a given number of seconds. (e.g. 300)
   */
  cacheTtl?: number;
  /**
   * Force response to be cached for a given number of seconds based on the Origin status code.
   * (e.g. { '200-299': 86400, '404': 1, '500-599': 0 })
   */
  cacheTtlByStatus?: Record<string, number>;
  scrapeShield?: boolean;
  apps?: boolean;
  image?: RequestInitCfPropertiesImage;
  minify?: RequestInitCfPropertiesImageMinify;
  mirage?: boolean;
  polish?: "lossy" | "lossless" | "off";
  r2?: RequestInitCfPropertiesR2;
  /**
   * Redirects the request to an alternate origin server. You can use this,
   * for example, to implement load balancing across several origins.
   * (e.g.us-east.example.com)
   *
   * Note - For security reasons, the hostname set in resolveOverride must
   * be proxied on the same Cloudflare zone of the incoming request.
   * Otherwise, the setting is ignored. CNAME hosts are allowed, so to
   * resolve to a host under a different domain or a DNS only domain first
   * declare a CNAME record within your own zones DNS mapping to the
   * external hostname, set proxy on Cloudflare, then set resolveOverride
   * to point to that CNAME record.
   */
  resolveOverride?: string;
}
interface RequestInitCfPropertiesImageDraw extends BasicImageTransformations {
  /**
   * Absolute URL of the image file to use for the drawing. It can be any of
   * the supported file formats. For drawing of watermarks or non-rectangular
   * overlays we recommend using PNG or WebP images.
   */
  url: string;
  /**
   * Floating-point number between 0 (transparent) and 1 (opaque).
   * For example, opacity: 0.5 makes overlay semitransparent.
   */
  opacity?: number;
  /**
   * - If set to true, the overlay image will be tiled to cover the entire
   *   area. This is useful for stock-photo-like watermarks.
   * - If set to "x", the overlay image will be tiled horizontally only
   *   (form a line).
   * - If set to "y", the overlay image will be tiled vertically only
   *   (form a line).
   */
  repeat?: true | "x" | "y";
  /**
   * Position of the overlay image relative to a given edge. Each property is
   * an offset in pixels. 0 aligns exactly to the edge. For example, left: 10
   * positions left side of the overlay 10 pixels from the left edge of the
   * image it's drawn over. bottom: 0 aligns bottom of the overlay with bottom
   * of the background image.
   *
   * Setting both left & right, or both top & bottom is an error.
   *
   * If no position is specified, the image will be centered.
   */
  top?: number;
  left?: number;
  bottom?: number;
  right?: number;
}
interface RequestInitCfPropertiesImage extends BasicImageTransformations {
  /**
   * Device Pixel Ratio. Default 1. Multiplier for width/height that makes it
   * easier to specify higher-DPI sizes in <img srcset>.
   */
  dpr?: number;
  /**
   * Allows you to trim your image. Takes dpr into account and is performed before
   * resizing or rotation.
   *
   * It can be used as:
   * - left, top, right, bottom - it will specify the number of pixels to cut
   *   off each side
   * - width, height - the width/height you'd like to end up with - can be used
   *   in combination with the properties above
   * - border - this will automatically trim the surroundings of an image based on
   *   it's color. It consists of three properties:
   *    - color: rgb or hex representation of the color you wish to trim (todo: verify the rgba bit)
   *    - tolerance: difference from color to treat as color
   *    - keep: the number of pixels of border to keep
   */
  trim?:
    | "border"
    | {
        top?: number;
        bottom?: number;
        left?: number;
        right?: number;
        width?: number;
        height?: number;
        border?:
          | boolean
          | {
              color?: string;
              tolerance?: number;
              keep?: number;
            };
      };
  /**
   * Quality setting from 1-100 (useful values are in 60-90 range). Lower values
   * make images look worse, but load faster. The default is 85. It applies only
   * to JPEG and WebP images. It doesnt have any effect on PNG.
   */
  quality?: number | "low" | "medium-low" | "medium-high" | "high";
  /**
   * Output format to generate. It can be:
   *  - avif: generate images in AVIF format.
   *  - webp: generate images in Google WebP format. Set quality to 100 to get
   *    the WebP-lossless format.
   *  - json: instead of generating an image, outputs information about the
   *    image, in JSON format. The JSON object will contain image size
   *    (before and after resizing), source images MIME type, file size, etc.
   * - jpeg: generate images in JPEG format.
   * - png: generate images in PNG format.
   */
  format?:
    | "avif"
    | "webp"
    | "json"
    | "jpeg"
    | "png"
    | "baseline-jpeg"
    | "png-force"
    | "svg";
  /**
   * Whether to preserve animation frames from input files. Default is true.
   * Setting it to false reduces animations to still images. This setting is
   * recommended when enlarging images or processing arbitrary user content,
   * because large GIF animations can weigh tens or even hundreds of megabytes.
   * It is also useful to set anim:false when using format:"json" to get the
   * response quicker without the number of frames.
   */
  anim?: boolean;
  /**
   * What EXIF data should be preserved in the output image. Note that EXIF
   * rotation and embedded color profiles are always applied ("baked in" into
   * the image), and aren't affected by this option. Note that if the Polish
   * feature is enabled, all metadata may have been removed already and this
   * option may have no effect.
   *  - keep: Preserve most of EXIF metadata, including GPS location if there's
   *    any.
   *  - copyright: Only keep the copyright tag, and discard everything else.
   *    This is the default behavior for JPEG files.
   *  - none: Discard all invisible EXIF metadata. Currently WebP and PNG
   *    output formats always discard metadata.
   */
  metadata?: "keep" | "copyright" | "none";
  /**
   * Strength of sharpening filter to apply to the image. Floating-point
   * number between 0 (no sharpening, default) and 10 (maximum). 1.0 is a
   * recommended value for downscaled images.
   */
  sharpen?: number;
  /**
   * Radius of a blur filter (approximate gaussian). Maximum supported radius
   * is 250.
   */
  blur?: number;
  /**
   * Overlays are drawn in the order they appear in the array (last array
   * entry is the topmost layer).
   */
  draw?: RequestInitCfPropertiesImageDraw[];
  /**
   * Fetching image from authenticated origin. Setting this property will
   * pass authentication headers (Authorization, Cookie, etc.) through to
   * the origin.
   */
  "origin-auth"?: "share-publicly";
  /**
   * Adds a border around the image. The border is added after resizing. Border
   * width takes dpr into account, and can be specified either using a single
   * width property, or individually for each side.
   */
  border?:
    | {
        color: string;
        width: number;
      }
    | {
        color: string;
        top: number;
        right: number;
        bottom: number;
        left: number;
      };
  /**
   * Increase brightness by a factor. A value of 1.0 equals no change, a value
   * of 0.5 equals half brightness, and a value of 2.0 equals twice as bright.
   * 0 is ignored.
   */
  brightness?: number;
  /**
   * Increase contrast by a factor. A value of 1.0 equals no change, a value of
   * 0.5 equals low contrast, and a value of 2.0 equals high contrast. 0 is
   * ignored.
   */
  contrast?: number;
  /**
   * Increase exposure by a factor. A value of 1.0 equals no change, a value of
   * 0.5 darkens the image, and a value of 2.0 lightens the image. 0 is ignored.
   */
  gamma?: number;
  /**
   * Increase contrast by a factor. A value of 1.0 equals no change, a value of
   * 0.5 equals low contrast, and a value of 2.0 equals high contrast. 0 is
   * ignored.
   */
  saturation?: number;
  /**
   * Flips the images horizontally, vertically, or both. Flipping is applied before
   * rotation, so if you apply flip=h,rotate=90 then the image will be flipped
   * horizontally, then rotated by 90 degrees.
   */
  flip?: "h" | "v" | "hv";
  /**
   * Slightly reduces latency on a cache miss by selecting a
   * quickest-to-compress file format, at a cost of increased file size and
   * lower image quality. It will usually override the format option and choose
   * JPEG over WebP or AVIF. We do not recommend using this option, except in
   * unusual circumstances like resizing uncacheable dynamically-generated
   * images.
   */
  compression?: "fast";
}
interface RequestInitCfPropertiesImageMinify {
  javascript?: boolean;
  css?: boolean;
  html?: boolean;
}
interface RequestInitCfPropertiesR2 {
  /**
   * Colo id of bucket that an object is stored in
   */
  bucketColoId?: number;
}
/**
 * Request metadata provided by Cloudflare's edge.
 */
type IncomingRequestCfProperties<HostMetadata = unknown> =
  IncomingRequestCfPropertiesBase &
    IncomingRequestCfPropertiesBotManagementEnterprise &
    IncomingRequestCfPropertiesCloudflareForSaaSEnterprise<HostMetadata> &
    IncomingRequestCfPropertiesGeographicInformation &
    IncomingRequestCfPropertiesCloudflareAccessOrApiShield;
interface IncomingRequestCfPropertiesBase extends Record<string, unknown> {
  /**
   * [ASN](https://www.iana.org/assignments/as-numbers/as-numbers.xhtml) of the incoming request.
   *
   * @example 395747
   */
  asn: number;
  /**
   * The organization which owns the ASN of the incoming request.
   *
   * @example "Google Cloud"
   */
  asOrganization: string;
  /**
   * The original value of the `Accept-Encoding` header if Cloudflare modified it.
   *
   * @example "gzip, deflate, br"
   */
  clientAcceptEncoding?: string;
  /**
   * The number of milliseconds it took for the request to reach your worker.
   *
   * @example 22
   */
  clientTcpRtt?: number;
  /**
   * The three-letter [IATA](https://en.wikipedia.org/wiki/IATA_airport_code)
   * airport code of the data center that the request hit.
   *
   * @example "DFW"
   */
  colo: string;
  /**
   * Represents the upstream's response to a
   * [TCP `keepalive` message](https://tldp.org/HOWTO/TCP-Keepalive-HOWTO/overview.html)
   * from cloudflare.
   *
   * For workers with no upstream, this will always be `1`.
   *
   * @example 3
   */
  edgeRequestKeepAliveStatus: IncomingRequestCfPropertiesEdgeRequestKeepAliveStatus;
  /**
   * The HTTP Protocol the request used.
   *
   * @example "HTTP/2"
   */
  httpProtocol: string;
  /**
   * The browser-requested prioritization information in the request object.
   *
   * If no information was set, defaults to the empty string `""`
   *
   * @example "weight=192;exclusive=0;group=3;group-weight=127"
   * @default ""
   */
  requestPriority: string;
  /**
   * The TLS version of the connection to Cloudflare.
   * In requests served over plaintext (without TLS), this property is the empty string `""`.
   *
   * @example "TLSv1.3"
   */
  tlsVersion: string;
  /**
   * The cipher for the connection to Cloudflare.
   * In requests served over plaintext (without TLS), this property is the empty string `""`.
   *
   * @example "AEAD-AES128-GCM-SHA256"
   */
  tlsCipher: string;
  /**
   * Metadata containing the [`HELLO`](https://www.rfc-editor.org/rfc/rfc5246#section-7.4.1.2) and [`FINISHED`](https://www.rfc-editor.org/rfc/rfc5246#section-7.4.9) messages from this request's TLS handshake.
   *
   * If the incoming request was served over plaintext (without TLS) this field is undefined.
   */
  tlsExportedAuthenticator?: IncomingRequestCfPropertiesExportedAuthenticatorMetadata;
}
interface IncomingRequestCfPropertiesBotManagementBase {
  /**
   * Cloudflares [level of certainty](https://developers.cloudflare.com/bots/concepts/bot-score/) that a request comes from a bot,
   * represented as an integer percentage between `1` (almost certainly a bot) and `99` (almost certainly human).
   *
   * @example 54
   */
  score: number;
  /**
   * A boolean value that is true if the request comes from a good bot, like Google or Bing.
   * Most customers choose to allow this traffic. For more details, see [Traffic from known bots](https://developers.cloudflare.com/firewall/known-issues-and-faq/#how-does-firewall-rules-handle-traffic-from-known-bots).
   */
  verifiedBot: boolean;
  /**
   * A boolean value that is true if the request originates from a
   * Cloudflare-verified proxy service.
   */
  corporateProxy: boolean;
  /**
   * A boolean value that's true if the request matches [file extensions](https://developers.cloudflare.com/bots/reference/static-resources/) for many types of static resources.
   */
  staticResource: boolean;
  /**
   * List of IDs that correlate to the Bot Management heuristic detections made on a request (you can have multiple heuristic detections on the same request).
   */
  detectionIds: number[];
}
interface IncomingRequestCfPropertiesBotManagement {
  /**
   * Results of Cloudflare's Bot Management analysis
   */
  botManagement: IncomingRequestCfPropertiesBotManagementBase;
  /**
   * Duplicate of `botManagement.score`.
   *
   * @deprecated
   */
  clientTrustScore: number;
}
interface IncomingRequestCfPropertiesBotManagementEnterprise
  extends IncomingRequestCfPropertiesBotManagement {
  /**
   * Results of Cloudflare's Bot Management analysis
   */
  botManagement: IncomingRequestCfPropertiesBotManagementBase & {
    /**
     * A [JA3 Fingerprint](https://developers.cloudflare.com/bots/concepts/ja3-fingerprint/) to help profile specific SSL/TLS clients
     * across different destination IPs, Ports, and X509 certificates.
     */
    ja3Hash: string;
  };
}
interface IncomingRequestCfPropertiesCloudflareForSaaSEnterprise<HostMetadata> {
  /**
   * Custom metadata set per-host in [Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/).
   *
   * This field is only present if you have Cloudflare for SaaS enabled on your account
   * and you have followed the [required steps to enable it]((https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/domain-support/custom-metadata/)).
   */
  hostMetadata: HostMetadata;
}
interface IncomingRequestCfPropertiesCloudflareAccessOrApiShield {
  /**
   * Information about the client certificate presented to Cloudflare.
   *
   * This is populated when the incoming request is served over TLS using
   * either Cloudflare Access or API Shield (mTLS)
   * and the presented SSL certificate has a valid
   * [Certificate Serial Number](https://ldapwiki.com/wiki/Certificate%20Serial%20Number)
   * (i.e., not `null` or `""`).
   *
   * Otherwise, a set of placeholder values are used.
   *
   * The property `certPresented` will be set to `"1"` when
   * the object is populated (i.e. the above conditions were met).
   */
  tlsClientAuth:
    | IncomingRequestCfPropertiesTLSClientAuth
    | IncomingRequestCfPropertiesTLSClientAuthPlaceholder;
}
/**
 * Metadata about the request's TLS handshake
 */
interface IncomingRequestCfPropertiesExportedAuthenticatorMetadata {
  /**
   * The client's [`HELLO` message](https://www.rfc-editor.org/rfc/rfc5246#section-7.4.1.2), encoded in hexadecimal
   *
   * @example "44372ba35fa1270921d318f34c12f155dc87b682cf36a790cfaa3ba8737a1b5d"
   */
  clientHandshake: string;
  /**
   * The server's [`HELLO` message](https://www.rfc-editor.org/rfc/rfc5246#section-7.4.1.2), encoded in hexadecimal
   *
   * @example "44372ba35fa1270921d318f34c12f155dc87b682cf36a790cfaa3ba8737a1b5d"
   */
  serverHandshake: string;
  /**
   * The client's [`FINISHED` message](https://www.rfc-editor.org/rfc/rfc5246#section-7.4.9), encoded in hexadecimal
   *
   * @example "084ee802fe1348f688220e2a6040a05b2199a761f33cf753abb1b006792d3f8b"
   */
  clientFinished: string;
  /**
   * The server's [`FINISHED` message](https://www.rfc-editor.org/rfc/rfc5246#section-7.4.9), encoded in hexadecimal
   *
   * @example "084ee802fe1348f688220e2a6040a05b2199a761f33cf753abb1b006792d3f8b"
   */
  serverFinished: string;
}
/**
 * Geographic data about the request's origin.
 */
interface IncomingRequestCfPropertiesGeographicInformation {
  /**
   * The [ISO 3166-1 Alpha 2](https://www.iso.org/iso-3166-country-codes.html) country code the request originated from.
   *
   * If your worker is [configured to accept TOR connections](https://support.cloudflare.com/hc/en-us/articles/203306930-Understanding-Cloudflare-Tor-support-and-Onion-Routing), this may also be `"T1"`, indicating a request that originated over TOR.
   *
   * If Cloudflare is unable to determine where the request originated this property is omitted.
   *
   * The country code `"T1"` is used for requests originating on TOR.
   *
   * @example "GB"
   */
  country?: Iso3166Alpha2Code | "T1";
  /**
   * If present, this property indicates that the request originated in the EU
   *
   * @example "1"
   */
  isEUCountry?: "1";
  /**
   * A two-letter code indicating the continent the request originated from.
   *
   * @example "AN"
   */
  continent?: ContinentCode;
  /**
   * The city the request originated from
   *
   * @example "Austin"
   */
  city?: string;
  /**
   * Postal code of the incoming request
   *
   * @example "78701"
   */
  postalCode?: string;
  /**
   * Latitude of the incoming request
   *
   * @example "30.27130"
   */
  latitude?: string;
  /**
   * Longitude of the incoming request
   *
   * @example "-97.74260"
   */
  longitude?: string;
  /**
   * Timezone of the incoming request
   *
   * @example "America/Chicago"
   */
  timezone?: string;
  /**
   * If known, the ISO 3166-2 name for the first level region associated with
   * the IP address of the incoming request
   *
   * @example "Texas"
   */
  region?: string;
  /**
   * If known, the ISO 3166-2 code for the first-level region associated with
   * the IP address of the incoming request
   *
   * @example "TX"
   */
  regionCode?: string;
  /**
   * Metro code (DMA) of the incoming request
   *
   * @example "635"
   */
  metroCode?: string;
}
/** Data about the incoming request's TLS certificate */
interface IncomingRequestCfPropertiesTLSClientAuth {
  /** Always `"1"`, indicating that the certificate was presented */
  certPresented: "1";
  /**
   * Result of certificate verification.
   *
   * @example "FAILED:self signed certificate"
   */
  certVerified: Exclude<CertVerificationStatus, "NONE">;
  /** The presented certificate's revokation status.
   *
   * - A value of `"1"` indicates the certificate has been revoked
   * - A value of `"0"` indicates the certificate has not been revoked
   */
  certRevoked: "1" | "0";
  /**
   * The certificate issuer's [distinguished name](https://knowledge.digicert.com/generalinformation/INFO1745.html)
   *
   * @example "CN=cloudflareaccess.com, C=US, ST=Texas, L=Austin, O=Cloudflare"
   */
  certIssuerDN: string;
  /**
   * The certificate subject's [distinguished name](https://knowledge.digicert.com/generalinformation/INFO1745.html)
   *
   * @example "CN=*.cloudflareaccess.com, C=US, ST=Texas, L=Austin, O=Cloudflare"
   */
  certSubjectDN: string;
  /**
   * The certificate issuer's [distinguished name](https://knowledge.digicert.com/generalinformation/INFO1745.html) ([RFC 2253](https://www.rfc-editor.org/rfc/rfc2253.html) formatted)
   *
   * @example "CN=cloudflareaccess.com, C=US, ST=Texas, L=Austin, O=Cloudflare"
   */
  certIssuerDNRFC2253: string;
  /**
   * The certificate subject's [distinguished name](https://knowledge.digicert.com/generalinformation/INFO1745.html) ([RFC 2253](https://www.rfc-editor.org/rfc/rfc2253.html) formatted)
   *
   * @example "CN=*.cloudflareaccess.com, C=US, ST=Texas, L=Austin, O=Cloudflare"
   */
  certSubjectDNRFC2253: string;
  /** The certificate issuer's distinguished name (legacy policies) */
  certIssuerDNLegacy: string;
  /** The certificate subject's distinguished name (legacy policies) */
  certSubjectDNLegacy: string;
  /**
   * The certificate's serial number
   *
   * @example "00936EACBE07F201DF"
   */
  certSerial: string;
  /**
   * The certificate issuer's serial number
   *
   * @example "2489002934BDFEA34"
   */
  certIssuerSerial: string;
  /**
   * The certificate's Subject Key Identifier
   *
   * @example "BB:AF:7E:02:3D:FA:A6:F1:3C:84:8E:AD:EE:38:98:EC:D9:32:32:D4"
   */
  certSKI: string;
  /**
   * The certificate issuer's Subject Key Identifier
   *
   * @example "BB:AF:7E:02:3D:FA:A6:F1:3C:84:8E:AD:EE:38:98:EC:D9:32:32:D4"
   */
  certIssuerSKI: string;
  /**
   * The certificate's SHA-1 fingerprint
   *
   * @example "6b9109f323999e52259cda7373ff0b4d26bd232e"
   */
  certFingerprintSHA1: string;
  /**
   * The certificate's SHA-256 fingerprint
   *
   * @example "acf77cf37b4156a2708e34c4eb755f9b5dbbe5ebb55adfec8f11493438d19e6ad3f157f81fa3b98278453d5652b0c1fd1d71e5695ae4d709803a4d3f39de9dea"
   */
  certFingerprintSHA256: string;
  /**
   * The effective starting date of the certificate
   *
   * @example "Dec 22 19:39:00 2018 GMT"
   */
  certNotBefore: string;
  /**
   * The effective expiration date of the certificate
   *
   * @example "Dec 22 19:39:00 2018 GMT"
   */
  certNotAfter: string;
}
/** Placeholder values for TLS Client Authorization */
interface IncomingRequestCfPropertiesTLSClientAuthPlaceholder {
  certPresented: "0";
  certVerified: "NONE";
  certRevoked: "0";
  certIssuerDN: "";
  certSubjectDN: "";
  certIssuerDNRFC2253: "";
  certSubjectDNRFC2253: "";
  certIssuerDNLegacy: "";
  certSubjectDNLegacy: "";
  certSerial: "";
  certIssuerSerial: "";
  certSKI: "";
  certIssuerSKI: "";
  certFingerprintSHA1: "";
  certFingerprintSHA256: "";
  certNotBefore: "";
  certNotAfter: "";
}
/** Possible outcomes of TLS verification */
declare type CertVerificationStatus =
  /** Authentication succeeded */
  | "SUCCESS"
  /** No certificate was presented */
  | "NONE"
  /** Failed because the certificate was self-signed */
  | "FAILED:self signed certificate"
  /** Failed because the certificate failed a trust chain check */
  | "FAILED:unable to verify the first certificate"
  /** Failed because the certificate not yet valid */
  | "FAILED:certificate is not yet valid"
  /** Failed because the certificate is expired */
  | "FAILED:certificate has expired"
  /** Failed for another unspecified reason */
  | "FAILED";
/**
 * An upstream endpoint's response to a TCP `keepalive` message from Cloudflare.
 */
declare type IncomingRequestCfPropertiesEdgeRequestKeepAliveStatus =
  | 0 /** Unknown */
  | 1 /** no keepalives (not found) */
  | 2 /** no connection re-use, opening keepalive connection failed */
  | 3 /** no connection re-use, keepalive accepted and saved */
  | 4 /** connection re-use, refused by the origin server (`TCP FIN`) */
  | 5; /** connection re-use, accepted by the origin server */
/** ISO 3166-1 Alpha-2 codes */
declare type Iso3166Alpha2Code =
  | "AD"
  | "AE"
  | "AF"
  | "AG"
  | "AI"
  | "AL"
  | "AM"
  | "AO"
  | "AQ"
  | "AR"
  | "AS"
  | "AT"
  | "AU"
  | "AW"
  | "AX"
  | "AZ"
  | "BA"
  | "BB"
  | "BD"
  | "BE"
  | "BF"
  | "BG"
  | "BH"
  | "BI"
  | "BJ"
  | "BL"
  | "BM"
  | "BN"
  | "BO"
  | "BQ"
  | "BR"
  | "BS"
  | "BT"
  | "BV"
  | "BW"
  | "BY"
  | "BZ"
  | "CA"
  | "CC"
  | "CD"
  | "CF"
  | "CG"
  | "CH"
  | "CI"
  | "CK"
  | "CL"
  | "CM"
  | "CN"
  | "CO"
  | "CR"
  | "CU"
  | "CV"
  | "CW"
  | "CX"
  | "CY"
  | "CZ"
  | "DE"
  | "DJ"
  | "DK"
  | "DM"
  | "DO"
  | "DZ"
  | "EC"
  | "EE"
  | "EG"
  | "EH"
  | "ER"
  | "ES"
  | "ET"
  | "FI"
  | "FJ"
  | "FK"
  | "FM"
  | "FO"
  | "FR"
  | "GA"
  | "GB"
  | "GD"
  | "GE"
  | "GF"
  | "GG"
  | "GH"
  | "GI"
  | "GL"
  | "GM"
  | "GN"
  | "GP"
  | "GQ"
  | "GR"
  | "GS"
  | "GT"
  | "GU"
  | "GW"
  | "GY"
  | "HK"
  | "HM"
  | "HN"
  | "HR"
  | "HT"
  | "HU"
  | "ID"
  | "IE"
  | "IL"
  | "IM"
  | "IN"
  | "IO"
  | "IQ"
  | "IR"
  | "IS"
  | "IT"
  | "JE"
  | "JM"
  | "JO"
  | "JP"
  | "KE"
  | "KG"
  | "KH"
  | "KI"
  | "KM"
  | "KN"
  | "KP"
  | "KR"
  | "KW"
  | "KY"
  | "KZ"
  | "LA"
  | "LB"
  | "LC"
  | "LI"
  | "LK"
  | "LR"
  | "LS"
  | "LT"
  | "LU"
  | "LV"
  | "LY"
  | "MA"
  | "MC"
  | "MD"
  | "ME"
  | "MF"
  | "MG"
  | "MH"
  | "MK"
  | "ML"
  | "MM"
  | "MN"
  | "MO"
  | "MP"
  | "MQ"
  | "MR"
  | "MS"
  | "MT"
  | "MU"
  | "MV"
  | "MW"
  | "MX"
  | "MY"
  | "MZ"
  | "NA"
  | "NC"
  | "NE"
  | "NF"
  | "NG"
  | "NI"
  | "NL"
  | "NO"
  | "NP"
  | "NR"
  | "NU"
  | "NZ"
  | "OM"
  | "PA"
  | "PE"
  | "PF"
  | "PG"
  | "PH"
  | "PK"
  | "PL"
  | "PM"
  | "PN"
  | "PR"
  | "PS"
  | "PT"
  | "PW"
  | "PY"
  | "QA"
  | "RE"
  | "RO"
  | "RS"
  | "RU"
  | "RW"
  | "SA"
  | "SB"
  | "SC"
  | "SD"
  | "SE"
  | "SG"
  | "SH"
  | "SI"
  | "SJ"
  | "SK"
  | "SL"
  | "SM"
  | "SN"
  | "SO"
  | "SR"
  | "SS"
  | "ST"
  | "SV"
  | "SX"
  | "SY"
  | "SZ"
  | "TC"
  | "TD"
  | "TF"
  | "TG"
  | "TH"
  | "TJ"
  | "TK"
  | "TL"
  | "TM"
  | "TN"
  | "TO"
  | "TR"
  | "TT"
  | "TV"
  | "TW"
  | "TZ"
  | "UA"
  | "UG"
  | "UM"
  | "US"
  | "UY"
  | "UZ"
  | "VA"
  | "VC"
  | "VE"
  | "VG"
  | "VI"
  | "VN"
  | "VU"
  | "WF"
  | "WS"
  | "YE"
  | "YT"
  | "ZA"
  | "ZM"
  | "ZW";
/** The 2-letter continent codes Cloudflare uses */
declare type ContinentCode = "AF" | "AN" | "AS" | "EU" | "NA" | "OC" | "SA";
type CfProperties<HostMetadata = unknown> =
  | IncomingRequestCfProperties<HostMetadata>
  | RequestInitCfProperties;
interface D1Meta {
  duration: number;
  size_after: number;
  rows_read: number;
  rows_written: number;
  last_row_id: number;
  changed_db: boolean;
  changes: number;
  /**
   * The region of the database instance that executed the query.
   */
  served_by_region?: string;
  /**
   * True if-and-only-if the database instance that executed the query was the primary.
   */
  served_by_primary?: boolean;
  timings?: {
    /**
     * The duration of the SQL query execution by the database instance. It doesn't include any network time.
     */
    sql_duration_ms: number;
  };
}
interface D1Response {
  success: true;
  meta: D1Meta & Record<string, unknown>;
  error?: never;
}
type D1Result<T = unknown> = D1Response & {
  results: T[];
};
interface D1ExecResult {
  count: number;
  duration: number;
}
type D1SessionConstraint =
  // Indicates that the first query should go to the primary, and the rest queries
  // using the same D1DatabaseSession will go to any replica that is consistent with
  // the bookmark maintained by the session (returned by the first query).
  | "first-primary"
  // Indicates that the first query can go anywhere (primary or replica), and the rest queries
  // using the same D1DatabaseSession will go to any replica that is consistent with
  // the bookmark maintained by the session (returned by the first query).
  | "first-unconstrained";
type D1SessionBookmark = string;
declare abstract class D1Database {
  prepare(query: string): D1PreparedStatement;
  batch<T = unknown>(statements: D1PreparedStatement[]): Promise<D1Result<T>[]>;
  exec(query: string): Promise<D1ExecResult>;
  /**
   * Creates a new D1 Session anchored at the given constraint or the bookmark.
   * All queries executed using the created session will have sequential consistency,
   * meaning that all writes done through the session will be visible in subsequent reads.
   *
   * @param constraintOrBookmark Either the session constraint or the explicit bookmark to anchor the created session.
   */
  withSession(
    constraintOrBookmark?: D1SessionBookmark | D1SessionConstraint,
  ): D1DatabaseSession;
  /**
   * @deprecated dump() will be removed soon, only applies to deprecated alpha v1 databases.
   */
  dump(): Promise<ArrayBuffer>;
}
declare abstract class D1DatabaseSession {
  prepare(query: string): D1PreparedStatement;
  batch<T = unknown>(statements: D1PreparedStatement[]): Promise<D1Result<T>[]>;
  /**
   * @returns The latest session bookmark across all executed queries on the session.
   *          If no query has been executed yet, `null` is returned.
   */
  getBookmark(): D1SessionBookmark | null;
}
declare abstract class D1PreparedStatement {
  bind(...values: unknown[]): D1PreparedStatement;
  first<T = unknown>(colName: string): Promise<T | null>;
  first<T = Record<string, unknown>>(): Promise<T | null>;
  run<T = Record<string, unknown>>(): Promise<D1Result<T>>;
  all<T = Record<string, unknown>>(): Promise<D1Result<T>>;
  raw<T = unknown[]>(options: {
    columnNames: true;
  }): Promise<[string[], ...T[]]>;
  raw<T = unknown[]>(options?: { columnNames?: false }): Promise<T[]>;
}
// `Disposable` was added to TypeScript's standard lib types in version 5.2.
// To support older TypeScript versions, define an empty `Disposable` interface.
// Users won't be able to use `using`/`Symbol.dispose` without upgrading to 5.2,
// but this will ensure type checking on older versions still passes.
// TypeScript's interface merging will ensure our empty interface is effectively
// ignored when `Disposable` is included in the standard lib.
type Disposable = {};
/**
 * An email message that can be sent from a Worker.
 */
interface EmailMessage {
  /**
   * Envelope From attribute of the email message.
   */
  readonly from: string;
  /**
   * Envelope To attribute of the email message.
   */
  readonly to: string;
}
/**
 * An email message that is sent to a consumer Worker and can be rejected/forwarded.
 */
interface ForwardableEmailMessage extends EmailMessage {
  /**
   * Stream of the email message content.
   */
  readonly raw: ReadableStream<Uint8Array>;
  /**
   * An [Headers object](https://developer.mozilla.org/en-US/docs/Web/API/Headers).
   */
  readonly headers: Headers;
  /**
   * Size of the email message content.
   */
  readonly rawSize: number;
  /**
   * Reject this email message by returning a permanent SMTP error back to the connecting client including the given reason.
   * @param reason The reject reason.
   * @returns void
   */
  setReject(reason: string): void;
  /**
   * Forward this email message to a verified destination address of the account.
   * @param rcptTo Verified destination address.
   * @param headers A [Headers object](https://developer.mozilla.org/en-US/docs/Web/API/Headers).
   * @returns A promise that resolves when the email message is forwarded.
   */
  forward(rcptTo: string, headers?: Headers): Promise<void>;
  /**
   * Reply to the sender of this email message with a new EmailMessage object.
   * @param message The reply message.
   * @returns A promise that resolves when the email message is replied.
   */
  reply(message: EmailMessage): Promise<void>;
}
/**
 * A binding that allows a Worker to send email messages.
 */
interface SendEmail {
  send(message: EmailMessage): Promise<void>;
}
declare abstract class EmailEvent extends ExtendableEvent {
  readonly message: ForwardableEmailMessage;
}
declare type EmailExportedHandler<Env = unknown> = (
  message: ForwardableEmailMessage,
  env: Env,
  ctx: ExecutionContext,
) => void | Promise<void>;
declare module "cloudflare:email" {
  let _EmailMessage: {
    prototype: EmailMessage;
    new (from: string, to: string, raw: ReadableStream | string): EmailMessage;
  };
  export { _EmailMessage as EmailMessage };
}
interface Hyperdrive {
  /**
   * Connect directly to Hyperdrive as if it's your database, returning a TCP socket.
   *
   * Calling this method returns an idential socket to if you call
   * `connect("host:port")` using the `host` and `port` fields from this object.
   * Pick whichever approach works better with your preferred DB client library.
   *
   * Note that this socket is not yet authenticated -- it's expected that your
   * code (or preferably, the client library of your choice) will authenticate
   * using the information in this class's readonly fields.
   */
  connect(): Socket;
  /**
   * A valid DB connection string that can be passed straight into the typical
   * client library/driver/ORM. This will typically be the easiest way to use
   * Hyperdrive.
   */
  readonly connectionString: string;
  /*
   * A randomly generated hostname that is only valid within the context of the
   * currently running Worker which, when passed into `connect()` function from
   * the "cloudflare:sockets" module, will connect to the Hyperdrive instance
   * for your database.
   */
  readonly host: string;
  /*
   * The port that must be paired the the host field when connecting.
   */
  readonly port: number;
  /*
   * The username to use when authenticating to your database via Hyperdrive.
   * Unlike the host and password, this will be the same every time
   */
  readonly user: string;
  /*
   * The randomly generated password to use when authenticating to your
   * database via Hyperdrive. Like the host field, this password is only valid
   * within the context of the currently running Worker instance from which
   * it's read.
   */
  readonly password: string;
  /*
   * The name of the database to connect to.
   */
  readonly database: string;
}
// Copyright (c) 2024 Cloudflare, Inc.
// Licensed under the Apache 2.0 license found in the LICENSE file or at:
//     https://opensource.org/licenses/Apache-2.0
type ImageInfoResponse =
  | {
      format: "image/svg+xml";
    }
  | {
      format: string;
      fileSize: number;
      width: number;
      height: number;
    };
type ImageTransform = {
  width?: number;
  height?: number;
  background?: string;
  blur?: number;
  border?:
    | {
        color?: string;
        width?: number;
      }
    | {
        top?: number;
        bottom?: number;
        left?: number;
        right?: number;
      };
  brightness?: number;
  contrast?: number;
  fit?: "scale-down" | "contain" | "pad" | "squeeze" | "cover" | "crop";
  flip?: "h" | "v" | "hv";
  gamma?: number;
  gravity?:
    | "left"
    | "right"
    | "top"
    | "bottom"
    | "center"
    | "auto"
    | "entropy"
    | {
        x?: number;
        y?: number;
        mode: "remainder" | "box-center";
      };
  rotate?: 0 | 90 | 180 | 270;
  saturation?: number;
  sharpen?: number;
  trim?:
    | "border"
    | {
        top?: number;
        bottom?: number;
        left?: number;
        right?: number;
        width?: number;
        height?: number;
        border?:
          | boolean
          | {
              color?: string;
              tolerance?: number;
              keep?: number;
            };
      };
};
type ImageDrawOptions = {
  opacity?: number;
  repeat?: boolean | string;
  top?: number;
  left?: number;
  bottom?: number;
  right?: number;
};
type ImageOutputOptions = {
  format:
    | "image/jpeg"
    | "image/png"
    | "image/gif"
    | "image/webp"
    | "image/avif"
    | "rgb"
    | "rgba";
  quality?: number;
  background?: string;
};
interface ImagesBinding {
  /**
   * Get image metadata (type, width and height)
   * @throws {@link ImagesError} with code 9412 if input is not an image
   * @param stream The image bytes
   */
  info(stream: ReadableStream<Uint8Array>): Promise<ImageInfoResponse>;
  /**
   * Begin applying a series of transformations to an image
   * @param stream The image bytes
   * @returns A transform handle
   */
  input(stream: ReadableStream<Uint8Array>): ImageTransformer;
}
interface ImageTransformer {
  /**
   * Apply transform next, returning a transform handle.
   * You can then apply more transformations, draw, or retrieve the output.
   * @param transform
   */
  transform(transform: ImageTransform): ImageTransformer;
  /**
   * Draw an image on this transformer, returning a transform handle.
   * You can then apply more transformations, draw, or retrieve the output.
   * @param image The image (or transformer that will give the image) to draw
   * @param options The options configuring how to draw the image
   */
  draw(
    image: ReadableStream<Uint8Array> | ImageTransformer,
    options?: ImageDrawOptions,
  ): ImageTransformer;
  /**
   * Retrieve the image that results from applying the transforms to the
   * provided input
   * @param options Options that apply to the output e.g. output format
   */
  output(options: ImageOutputOptions): Promise<ImageTransformationResult>;
}
interface ImageTransformationResult {
  /**
   * The image as a response, ready to store in cache or return to users
   */
  response(): Response;
  /**
   * The content type of the returned image
   */
  contentType(): string;
  /**
   * The bytes of the response
   */
  image(): ReadableStream<Uint8Array>;
}
interface ImagesError extends Error {
  readonly code: number;
  readonly message: string;
  readonly stack?: string;
}
type Params<P extends string = any> = Record<P, string | string[]>;
type EventContext<Env, P extends string, Data> = {
  request: Request<unknown, IncomingRequestCfProperties<unknown>>;
  functionPath: string;
  waitUntil: (promise: Promise<any>) => void;
  passThroughOnException: () => void;
  next: (input?: Request | string, init?: RequestInit) => Promise<Response>;
  env: Env & {
    ASSETS: {
      fetch: typeof fetch;
    };
  };
  params: Params<P>;
  data: Data;
};
type PagesFunction<
  Env = unknown,
  Params extends string = any,
  Data extends Record<string, unknown> = Record<string, unknown>,
> = (context: EventContext<Env, Params, Data>) => Response | Promise<Response>;
type EventPluginContext<Env, P extends string, Data, PluginArgs> = {
  request: Request<unknown, IncomingRequestCfProperties<unknown>>;
  functionPath: string;
  waitUntil: (promise: Promise<any>) => void;
  passThroughOnException: () => void;
  next: (input?: Request | string, init?: RequestInit) => Promise<Response>;
  env: Env & {
    ASSETS: {
      fetch: typeof fetch;
    };
  };
  params: Params<P>;
  data: Data;
  pluginArgs: PluginArgs;
};
type PagesPluginFunction<
  Env = unknown,
  Params extends string = any,
  Data extends Record<string, unknown> = Record<string, unknown>,
  PluginArgs = unknown,
> = (
  context: EventPluginContext<Env, Params, Data, PluginArgs>,
) => Response | Promise<Response>;
declare module "assets:*" {
  export const onRequest: PagesFunction;
}
// Copyright (c) 2022-2023 Cloudflare, Inc.
// Licensed under the Apache 2.0 license found in the LICENSE file or at:
//     https://opensource.org/licenses/Apache-2.0
declare module "cloudflare:pipelines" {
  export abstract class PipelineTransformationEntrypoint<
    Env = unknown,
    I extends PipelineRecord = PipelineRecord,
    O extends PipelineRecord = PipelineRecord,
  > {
    protected env: Env;
    protected ctx: ExecutionContext;
    constructor(ctx: ExecutionContext, env: Env);
    /**
     * run recieves an array of PipelineRecord which can be
     * transformed and returned to the pipeline
     * @param records Incoming records from the pipeline to be transformed
     * @param metadata Information about the specific pipeline calling the transformation entrypoint
     * @returns A promise containing the transformed PipelineRecord array
     */
    public run(records: I[], metadata: PipelineBatchMetadata): Promise<O[]>;
  }
  export type PipelineRecord = Record<string, unknown>;
  export type PipelineBatchMetadata = {
    pipelineId: string;
    pipelineName: string;
  };
  export interface Pipeline<T extends PipelineRecord = PipelineRecord> {
    /**
     * The Pipeline interface represents the type of a binding to a Pipeline
     *
     * @param records The records to send to the pipeline
     */
    send(records: T[]): Promise<void>;
  }
}
// PubSubMessage represents an incoming PubSub message.
// The message includes metadata about the broker, the client, and the payload
// itself.
// https://developers.cloudflare.com/pub-sub/
interface PubSubMessage {
  // Message ID
  readonly mid: number;
  // MQTT broker FQDN in the form mqtts://BROKER.NAMESPACE.cloudflarepubsub.com:PORT
  readonly broker: string;
  // The MQTT topic the message was sent on.
  readonly topic: string;
  // The client ID of the client that published this message.
  readonly clientId: string;
  // The unique identifier (JWT ID) used by the client to authenticate, if token
  // auth was used.
  readonly jti?: string;
  // A Unix timestamp (seconds from Jan 1, 1970), set when the Pub/Sub Broker
  // received the message from the client.
  readonly receivedAt: number;
  // An (optional) string with the MIME type of the payload, if set by the
  // client.
  readonly contentType: string;
  // Set to 1 when the payload is a UTF-8 string
  // https://docs.oasis-open.org/mqtt/mqtt/v5.0/os/mqtt-v5.0-os.html#_Toc3901063
  readonly payloadFormatIndicator: number;
  // Pub/Sub (MQTT) payloads can be UTF-8 strings, or byte arrays.
  // You can use payloadFormatIndicator to inspect this before decoding.
  payload: string | Uint8Array;
}
// JsonWebKey extended by kid parameter
interface JsonWebKeyWithKid extends JsonWebKey {
  // Key Identifier of the JWK
  readonly kid: string;
}
interface RateLimitOptions {
  key: string;
}
interface RateLimitOutcome {
  success: boolean;
}
interface RateLimit {
  /**
   * Rate limit a request based on the provided options.
   * @see https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/
   * @returns A promise that resolves with the outcome of the rate limit.
   */
  limit(options: RateLimitOptions): Promise<RateLimitOutcome>;
}
// Namespace for RPC utility types. Unfortunately, we can't use a `module` here as these types need
// to referenced by `Fetcher`. This is included in the "importable" version of the types which
// strips all `module` blocks.
declare namespace Rpc {
  // Branded types for identifying `WorkerEntrypoint`/`DurableObject`/`Target`s.
  // TypeScript uses *structural* typing meaning anything with the same shape as type `T` is a `T`.
  // For the classes exported by `cloudflare:workers` we want *nominal* typing (i.e. we only want to
  // accept `WorkerEntrypoint` from `cloudflare:workers`, not any other class with the same shape)
  export const __RPC_STUB_BRAND: "__RPC_STUB_BRAND";
  export const __RPC_TARGET_BRAND: "__RPC_TARGET_BRAND";
  export const __WORKER_ENTRYPOINT_BRAND: "__WORKER_ENTRYPOINT_BRAND";
  export const __DURABLE_OBJECT_BRAND: "__DURABLE_OBJECT_BRAND";
  export const __WORKFLOW_ENTRYPOINT_BRAND: "__WORKFLOW_ENTRYPOINT_BRAND";
  export interface RpcTargetBranded {
    [__RPC_TARGET_BRAND]: never;
  }
  export interface WorkerEntrypointBranded {
    [__WORKER_ENTRYPOINT_BRAND]: never;
  }
  export interface DurableObjectBranded {
    [__DURABLE_OBJECT_BRAND]: never;
  }
  export interface WorkflowEntrypointBranded {
    [__WORKFLOW_ENTRYPOINT_BRAND]: never;
  }
  export type EntrypointBranded =
    | WorkerEntrypointBranded
    | DurableObjectBranded
    | WorkflowEntrypointBranded;
  // Types that can be used through `Stub`s
  export type Stubable = RpcTargetBranded | ((...args: any[]) => any);
  // Types that can be passed over RPC
  // The reason for using a generic type here is to build a serializable subset of structured
  //   cloneable composite types. This allows types defined with the "interface" keyword to pass the
  //   serializable check as well. Otherwise, only types defined with the "type" keyword would pass.
  type Serializable<T> =
    // Structured cloneables
    | BaseType
    // Structured cloneable composites
    | Map<
        T extends Map<infer U, unknown> ? Serializable<U> : never,
        T extends Map<unknown, infer U> ? Serializable<U> : never
      >
    | Set<T extends Set<infer U> ? Serializable<U> : never>
    | ReadonlyArray<T extends ReadonlyArray<infer U> ? Serializable<U> : never>
    | {
        [K in keyof T]: K extends number | string ? Serializable<T[K]> : never;
      }
    // Special types
    | Stub<Stubable>
    // Serialized as stubs, see `Stubify`
    | Stubable;
  // Base type for all RPC stubs, including common memory management methods.
  // `T` is used as a marker type for unwrapping `Stub`s later.
  interface StubBase<T extends Stubable> extends Disposable {
    [__RPC_STUB_BRAND]: T;
    dup(): this;
  }
  export type Stub<T extends Stubable> = Provider<T> & StubBase<T>;
  // This represents all the types that can be sent as-is over an RPC boundary
  type BaseType =
    | void
    | undefined
    | null
    | boolean
    | number
    | bigint
    | string
    | TypedArray
    | ArrayBuffer
    | DataView
    | Date
    | Error
    | RegExp
    | ReadableStream<Uint8Array>
    | WritableStream<Uint8Array>
    | Request
    | Response
    | Headers;
  // Recursively rewrite all `Stubable` types with `Stub`s
  // prettier-ignore
  type Stubify<T> = T extends Stubable
    ? Stub<T>
    : T extends Map<infer K, infer V>
      ? Map<Stubify<K>, Stubify<V>>
      : T extends Set<infer V>
        ? Set<Stubify<V>>
        : T extends Array<infer V>
          ? Array<Stubify<V>>
          : T extends ReadonlyArray<infer V>
            ? ReadonlyArray<Stubify<V>>
            : T extends BaseType
              ? T
              : T extends {
                    [key: string | number]: any;
                  }
                ? {
                    [K in keyof T]: Stubify<T[K]>;
                  }
                : T;
  // Recursively rewrite all `Stub<T>`s with the corresponding `T`s.
  // Note we use `StubBase` instead of `Stub` here to avoid circular dependencies:
  // `Stub` depends on `Provider`, which depends on `Unstubify`, which would depend on `Stub`.
  // prettier-ignore
  type Unstubify<T> = T extends StubBase<infer V>
    ? V
    : T extends Map<infer K, infer V>
      ? Map<Unstubify<K>, Unstubify<V>>
      : T extends Set<infer V>
        ? Set<Unstubify<V>>
        : T extends Array<infer V>
          ? Array<Unstubify<V>>
          : T extends ReadonlyArray<infer V>
            ? ReadonlyArray<Unstubify<V>>
            : T extends BaseType
              ? T
              : T extends {
                    [key: string | number]: unknown;
                  }
                ? {
                    [K in keyof T]: Unstubify<T[K]>;
                  }
                : T;
  type UnstubifyAll<A extends any[]> = {
    [I in keyof A]: Unstubify<A[I]>;
  };
  // Utility type for adding `Provider`/`Disposable`s to `object` types only.
  // Note `unknown & T` is equivalent to `T`.
  type MaybeProvider<T> = T extends object ? Provider<T> : unknown;
  type MaybeDisposable<T> = T extends object ? Disposable : unknown;
  // Type for method return or property on an RPC interface.
  // - Stubable types are replaced by stubs.
  // - Serializable types are passed by value, with stubable types replaced by stubs
  //   and a top-level `Disposer`.
  // Everything else can't be passed over PRC.
  // Technically, we use custom thenables here, but they quack like `Promise`s.
  // Intersecting with `(Maybe)Provider` allows pipelining.
  // prettier-ignore
  type Result<R> = R extends Stubable
    ? Promise<Stub<R>> & Provider<R>
    : R extends Serializable<R>
      ? Promise<Stubify<R> & MaybeDisposable<R>> & MaybeProvider<R>
      : never;
  // Type for method or property on an RPC interface.
  // For methods, unwrap `Stub`s in parameters, and rewrite returns to be `Result`s.
  // Unwrapping `Stub`s allows calling with `Stubable` arguments.
  // For properties, rewrite types to be `Result`s.
  // In each case, unwrap `Promise`s.
  type MethodOrProperty<V> = V extends (...args: infer P) => infer R
    ? (...args: UnstubifyAll<P>) => Result<Awaited<R>>
    : Result<Awaited<V>>;
  // Type for the callable part of an `Provider` if `T` is callable.
  // This is intersected with methods/properties.
  type MaybeCallableProvider<T> = T extends (...args: any[]) => any
    ? MethodOrProperty<T>
    : unknown;
  // Base type for all other types providing RPC-like interfaces.
  // Rewrites all methods/properties to be `MethodOrProperty`s, while preserving callable types.
  // `Reserved` names (e.g. stub method names like `dup()`) and symbols can't be accessed over RPC.
  export type Provider<
    T extends object,
    Reserved extends string = never,
  > = MaybeCallableProvider<T> & {
    [K in Exclude<
      keyof T,
      Reserved | symbol | keyof StubBase<never>
    >]: MethodOrProperty<T[K]>;
  };
}
declare namespace Cloudflare {
  type Env = {};
}
declare module "cloudflare:workers" {
  export type RpcStub<T extends Rpc.Stubable> = Rpc.Stub<T>;
  export const RpcStub: {
    new <T extends Rpc.Stubable>(value: T): Rpc.Stub<T>;
  };
  export abstract class RpcTarget implements Rpc.RpcTargetBranded {
    [Rpc.__RPC_TARGET_BRAND]: never;
  }
  // `protected` fields don't appear in `keyof`s, so can't be accessed over RPC
  export abstract class WorkerEntrypoint<Env = unknown>
    implements Rpc.WorkerEntrypointBranded
  {
    [Rpc.__WORKER_ENTRYPOINT_BRAND]: never;
    protected ctx: ExecutionContext;
    protected env: Env;
    constructor(ctx: ExecutionContext, env: Env);
    fetch?(request: Request): Response | Promise<Response>;
    tail?(events: TraceItem[]): void | Promise<void>;
    trace?(traces: TraceItem[]): void | Promise<void>;
    scheduled?(controller: ScheduledController): void | Promise<void>;
    queue?(batch: MessageBatch<unknown>): void | Promise<void>;
    test?(controller: TestController): void | Promise<void>;
  }
  export abstract class DurableObject<Env = unknown>
    implements Rpc.DurableObjectBranded
  {
    [Rpc.__DURABLE_OBJECT_BRAND]: never;
    protected ctx: DurableObjectState;
    protected env: Env;
    constructor(ctx: DurableObjectState, env: Env);
    fetch?(request: Request): Response | Promise<Response>;
    alarm?(alarmInfo?: AlarmInvocationInfo): void | Promise<void>;
    webSocketMessage?(
      ws: WebSocket,
      message: string | ArrayBuffer,
    ): void | Promise<void>;
    webSocketClose?(
      ws: WebSocket,
      code: number,
      reason: string,
      wasClean: boolean,
    ): void | Promise<void>;
    webSocketError?(ws: WebSocket, error: unknown): void | Promise<void>;
  }
  export type WorkflowDurationLabel =
    | "second"
    | "minute"
    | "hour"
    | "day"
    | "week"
    | "month"
    | "year";
  export type WorkflowSleepDuration =
    | `${number} ${WorkflowDurationLabel}${"s" | ""}`
    | number;
  export type WorkflowDelayDuration = WorkflowSleepDuration;
  export type WorkflowTimeoutDuration = WorkflowSleepDuration;
  export type WorkflowBackoff = "constant" | "linear" | "exponential";
  export type WorkflowStepConfig = {
    retries?: {
      limit: number;
      delay: WorkflowDelayDuration | number;
      backoff?: WorkflowBackoff;
    };
    timeout?: WorkflowTimeoutDuration | number;
  };
  export type WorkflowEvent<T> = {
    payload: Readonly<T>;
    timestamp: Date;
    instanceId: string;
  };
  export type WorkflowStepEvent<T> = {
    payload: Readonly<T>;
    timestamp: Date;
    type: string;
  };
  export abstract class WorkflowStep {
    do<T extends Rpc.Serializable<T>>(
      name: string,
      callback: () => Promise<T>,
    ): Promise<T>;
    do<T extends Rpc.Serializable<T>>(
      name: string,
      config: WorkflowStepConfig,
      callback: () => Promise<T>,
    ): Promise<T>;
    sleep: (name: string, duration: WorkflowSleepDuration) => Promise<void>;
    sleepUntil: (name: string, timestamp: Date | number) => Promise<void>;
    waitForEvent<T extends Rpc.Serializable<T>>(
      name: string,
      options: {
        type: string;
        timeout?: WorkflowTimeoutDuration | number;
      },
    ): Promise<WorkflowStepEvent<T>>;
  }
  export abstract class WorkflowEntrypoint<
    Env = unknown,
    T extends Rpc.Serializable<T> | unknown = unknown,
  > implements Rpc.WorkflowEntrypointBranded
  {
    [Rpc.__WORKFLOW_ENTRYPOINT_BRAND]: never;
    protected ctx: ExecutionContext;
    protected env: Env;
    constructor(ctx: ExecutionContext, env: Env);
    run(
      event: Readonly<WorkflowEvent<T>>,
      step: WorkflowStep,
    ): Promise<unknown>;
  }
  export const env: Cloudflare.Env;
}
interface SecretsStoreSecret {
  /**
   * Get a secret from the Secrets Store, returning a string of the secret value
   * if it exists, or throws an error if it does not exist
   */
  get(): Promise<string>;
}
declare module "cloudflare:sockets" {
  function _connect(
    address: string | SocketAddress,
    options?: SocketOptions,
  ): Socket;
  export { _connect as connect };
}
declare namespace TailStream {
  interface Header {
    readonly name: string;
    readonly value: string;
  }
  interface FetchEventInfo {
    readonly type: "fetch";
    readonly method: string;
    readonly url: string;
    readonly cfJson: string;
    readonly headers: Header[];
  }
  interface JsRpcEventInfo {
    readonly type: "jsrpc";
    readonly methodName: string;
  }
  interface ScheduledEventInfo {
    readonly type: "scheduled";
    readonly scheduledTime: Date;
    readonly cron: string;
  }
  interface AlarmEventInfo {
    readonly type: "alarm";
    readonly scheduledTime: Date;
  }
  interface QueueEventInfo {
    readonly type: "queue";
    readonly queueName: string;
    readonly batchSize: number;
  }
  interface EmailEventInfo {
    readonly type: "email";
    readonly mailFrom: string;
    readonly rcptTo: string;
    readonly rawSize: number;
  }
  interface TraceEventInfo {
    readonly type: "trace";
    readonly traces: (string | null)[];
  }
  interface HibernatableWebSocketEventInfoMessage {
    readonly type: "message";
  }
  interface HibernatableWebSocketEventInfoError {
    readonly type: "error";
  }
  interface HibernatableWebSocketEventInfoClose {
    readonly type: "close";
    readonly code: number;
    readonly wasClean: boolean;
  }
  interface HibernatableWebSocketEventInfo {
    readonly type: "hibernatableWebSocket";
    readonly info:
      | HibernatableWebSocketEventInfoClose
      | HibernatableWebSocketEventInfoError
      | HibernatableWebSocketEventInfoMessage;
  }
  interface Resume {
    readonly type: "resume";
    readonly attachment?: any;
  }
  interface CustomEventInfo {
    readonly type: "custom";
  }
  interface FetchResponseInfo {
    readonly type: "fetch";
    readonly statusCode: number;
  }
  type EventOutcome =
    | "ok"
    | "canceled"
    | "exception"
    | "unknown"
    | "killSwitch"
    | "daemonDown"
    | "exceededCpu"
    | "exceededMemory"
    | "loadShed"
    | "responseStreamDisconnected"
    | "scriptNotFound";
  interface ScriptVersion {
    readonly id: string;
    readonly tag?: string;
    readonly message?: string;
  }
  interface Trigger {
    readonly traceId: string;
    readonly invocationId: string;
    readonly spanId: string;
  }
  interface Onset {
    readonly type: "onset";
    readonly dispatchNamespace?: string;
    readonly entrypoint?: string;
    readonly scriptName?: string;
    readonly scriptTags?: string[];
    readonly scriptVersion?: ScriptVersion;
    readonly trigger?: Trigger;
    readonly info:
      | FetchEventInfo
      | JsRpcEventInfo
      | ScheduledEventInfo
      | AlarmEventInfo
      | QueueEventInfo
      | EmailEventInfo
      | TraceEventInfo
      | HibernatableWebSocketEventInfo
      | Resume
      | CustomEventInfo;
  }
  interface Outcome {
    readonly type: "outcome";
    readonly outcome: EventOutcome;
    readonly cpuTime: number;
    readonly wallTime: number;
  }
  interface Hibernate {
    readonly type: "hibernate";
  }
  interface SpanOpen {
    readonly type: "spanOpen";
    readonly op?: string;
    readonly info?: FetchEventInfo | JsRpcEventInfo | Attribute[];
  }
  interface SpanClose {
    readonly type: "spanClose";
    readonly outcome: EventOutcome;
  }
  interface DiagnosticChannelEvent {
    readonly type: "diagnosticChannel";
    readonly channel: string;
    readonly message: any;
  }
  interface Exception {
    readonly type: "exception";
    readonly name: string;
    readonly message: string;
    readonly stack?: string;
  }
  interface Log {
    readonly type: "log";
    readonly level: "debug" | "error" | "info" | "log" | "warn";
    readonly message: string;
  }
  interface Return {
    readonly type: "return";
    readonly info?: FetchResponseInfo | Attribute[];
  }
  interface Link {
    readonly type: "link";
    readonly label?: string;
    readonly traceId: string;
    readonly invocationId: string;
    readonly spanId: string;
  }
  interface Attribute {
    readonly type: "attribute";
    readonly name: string;
    readonly value: string | string[] | boolean | boolean[] | number | number[];
  }
  type Mark =
    | DiagnosticChannelEvent
    | Exception
    | Log
    | Return
    | Link
    | Attribute[];
  interface TailEvent {
    readonly traceId: string;
    readonly invocationId: string;
    readonly spanId: string;
    readonly timestamp: Date;
    readonly sequence: number;
    readonly event: Onset | Outcome | Hibernate | SpanOpen | SpanClose | Mark;
  }
  type TailEventHandler = (event: TailEvent) => void | Promise<void>;
  type TailEventHandlerName =
    | "onset"
    | "outcome"
    | "hibernate"
    | "spanOpen"
    | "spanClose"
    | "diagnosticChannel"
    | "exception"
    | "log"
    | "return"
    | "link"
    | "attribute";
  type TailEventHandlerObject = Record<TailEventHandlerName, TailEventHandler>;
  type TailEventHandlerType = TailEventHandler | TailEventHandlerObject;
}
// Copyright (c) 2022-2023 Cloudflare, Inc.
// Licensed under the Apache 2.0 license found in the LICENSE file or at:
//     https://opensource.org/licenses/Apache-2.0
/**
 * Data types supported for holding vector metadata.
 */
type VectorizeVectorMetadataValue = string | number | boolean | string[];
/**
 * Additional information to associate with a vector.
 */
type VectorizeVectorMetadata =
  | VectorizeVectorMetadataValue
  | Record<string, VectorizeVectorMetadataValue>;
type VectorFloatArray = Float32Array | Float64Array;
interface VectorizeError {
  code?: number;
  error: string;
}
/**
 * Comparison logic/operation to use for metadata filtering.
 *
 * This list is expected to grow as support for more operations are released.
 */
type VectorizeVectorMetadataFilterOp = "$eq" | "$ne";
/**
 * Filter criteria for vector metadata used to limit the retrieved query result set.
 */
type VectorizeVectorMetadataFilter = {
  [field: string]:
    | Exclude<VectorizeVectorMetadataValue, string[]>
    | null
    | {
        [Op in VectorizeVectorMetadataFilterOp]?: Exclude<
          VectorizeVectorMetadataValue,
          string[]
        > | null;
      };
};
/**
 * Supported distance metrics for an index.
 * Distance metrics determine how other "similar" vectors are determined.
 */
type VectorizeDistanceMetric = "euclidean" | "cosine" | "dot-product";
/**
 * Metadata return levels for a Vectorize query.
 *
 * Default to "none".
 *
 * @property all      Full metadata for the vector return set, including all fields (including those un-indexed) without truncation. This is a more expensive retrieval, as it requires additional fetching & reading of un-indexed data.
 * @property indexed  Return all metadata fields configured for indexing in the vector return set. This level of retrieval is "free" in that no additional overhead is incurred returning this data. However, note that indexed metadata is subject to truncation (especially for larger strings).
 * @property none     No indexed metadata will be returned.
 */
type VectorizeMetadataRetrievalLevel = "all" | "indexed" | "none";
interface VectorizeQueryOptions {
  topK?: number;
  namespace?: string;
  returnValues?: boolean;
  returnMetadata?: boolean | VectorizeMetadataRetrievalLevel;
  filter?: VectorizeVectorMetadataFilter;
}
/**
 * Information about the configuration of an index.
 */
type VectorizeIndexConfig =
  | {
      dimensions: number;
      metric: VectorizeDistanceMetric;
    }
  | {
      preset: string; // keep this generic, as we'll be adding more presets in the future and this is only in a read capacity
    };
/**
 * Metadata about an existing index.
 *
 * This type is exclusively for the Vectorize **beta** and will be deprecated once Vectorize RC is released.
 * See {@link VectorizeIndexInfo} for its post-beta equivalent.
 */
interface VectorizeIndexDetails {
  /** The unique ID of the index */
  readonly id: string;
  /** The name of the index. */
  name: string;
  /** (optional) A human readable description for the index. */
  description?: string;
  /** The index configuration, including the dimension size and distance metric. */
  config: VectorizeIndexConfig;
  /** The number of records containing vectors within the index. */
  vectorsCount: number;
}
/**
 * Metadata about an existing index.
 */
interface VectorizeIndexInfo {
  /** The number of records containing vectors within the index. */
  vectorCount: number;
  /** Number of dimensions the index has been configured for. */
  dimensions: number;
  /** ISO 8601 datetime of the last processed mutation on in the index. All changes before this mutation will be reflected in the index state. */
  processedUpToDatetime: number;
  /** UUIDv4 of the last mutation processed by the index. All changes before this mutation will be reflected in the index state. */
  processedUpToMutation: number;
}
/**
 * Represents a single vector value set along with its associated metadata.
 */
interface VectorizeVector {
  /** The ID for the vector. This can be user-defined, and must be unique. It should uniquely identify the object, and is best set based on the ID of what the vector represents. */
  id: string;
  /** The vector values */
  values: VectorFloatArray | number[];
  /** The namespace this vector belongs to. */
  namespace?: string;
  /** Metadata associated with the vector. Includes the values of other fields and potentially additional details. */
  metadata?: Record<string, VectorizeVectorMetadata>;
}
/**
 * Represents a matched vector for a query along with its score and (if specified) the matching vector information.
 */
type VectorizeMatch = Pick<Partial<VectorizeVector>, "values"> &
  Omit<VectorizeVector, "values"> & {
    /** The score or rank for similarity, when returned as a result */
    score: number;
  };
/**
 * A set of matching {@link VectorizeMatch} for a particular query.
 */
interface VectorizeMatches {
  matches: VectorizeMatch[];
  count: number;
}
/**
 * Results of an operation that performed a mutation on a set of vectors.
 * Here, `ids` is a list of vectors that were successfully processed.
 *
 * This type is exclusively for the Vectorize **beta** and will be deprecated once Vectorize RC is released.
 * See {@link VectorizeAsyncMutation} for its post-beta equivalent.
 */
interface VectorizeVectorMutation {
  /* List of ids of vectors that were successfully processed. */
  ids: string[];
  /* Total count of the number of processed vectors. */
  count: number;
}
/**
 * Result type indicating a mutation on the Vectorize Index.
 * Actual mutations are processed async where the `mutationId` is the unique identifier for the operation.
 */
interface VectorizeAsyncMutation {
  /** The unique identifier for the async mutation operation containing the changeset. */
  mutationId: string;
}
/**
 * A Vectorize Vector Search Index for querying vectors/embeddings.
 *
 * This type is exclusively for the Vectorize **beta** and will be deprecated once Vectorize RC is released.
 * See {@link Vectorize} for its new implementation.
 */
declare abstract class VectorizeIndex {
  /**
   * Get information about the currently bound index.
   * @returns A promise that resolves with information about the current index.
   */
  public describe(): Promise<VectorizeIndexDetails>;
  /**
   * Use the provided vector to perform a similarity search across the index.
   * @param vector Input vector that will be used to drive the similarity search.
   * @param options Configuration options to massage the returned data.
   * @returns A promise that resolves with matched and scored vectors.
   */
  public query(
    vector: VectorFloatArray | number[],
    options?: VectorizeQueryOptions,
  ): Promise<VectorizeMatches>;
  /**
   * Insert a list of vectors into the index dataset. If a provided id exists, an error will be thrown.
   * @param vectors List of vectors that will be inserted.
   * @returns A promise that resolves with the ids & count of records that were successfully processed.
   */
  public insert(vectors: VectorizeVector[]): Promise<VectorizeVectorMutation>;
  /**
   * Upsert a list of vectors into the index dataset. If a provided id exists, it will be replaced with the new values.
   * @param vectors List of vectors that will be upserted.
   * @returns A promise that resolves with the ids & count of records that were successfully processed.
   */
  public upsert(vectors: VectorizeVector[]): Promise<VectorizeVectorMutation>;
  /**
   * Delete a list of vectors with a matching id.
   * @param ids List of vector ids that should be deleted.
   * @returns A promise that resolves with the ids & count of records that were successfully processed (and thus deleted).
   */
  public deleteByIds(ids: string[]): Promise<VectorizeVectorMutation>;
  /**
   * Get a list of vectors with a matching id.
   * @param ids List of vector ids that should be returned.
   * @returns A promise that resolves with the raw unscored vectors matching the id set.
   */
  public getByIds(ids: string[]): Promise<VectorizeVector[]>;
}
/**
 * A Vectorize Vector Search Index for querying vectors/embeddings.
 *
 * Mutations in this version are async, returning a mutation id.
 */
declare abstract class Vectorize {
  /**
   * Get information about the currently bound index.
   * @returns A promise that resolves with information about the current index.
   */
  public describe(): Promise<VectorizeIndexInfo>;
  /**
   * Use the provided vector to perform a similarity search across the index.
   * @param vector Input vector that will be used to drive the similarity search.
   * @param options Configuration options to massage the returned data.
   * @returns A promise that resolves with matched and scored vectors.
   */
  public query(
    vector: VectorFloatArray | number[],
    options?: VectorizeQueryOptions,
  ): Promise<VectorizeMatches>;
  /**
   * Use the provided vector-id to perform a similarity search across the index.
   * @param vectorId Id for a vector in the index against which the index should be queried.
   * @param options Configuration options to massage the returned data.
   * @returns A promise that resolves with matched and scored vectors.
   */
  public queryById(
    vectorId: string,
    options?: VectorizeQueryOptions,
  ): Promise<VectorizeMatches>;
  /**
   * Insert a list of vectors into the index dataset. If a provided id exists, an error will be thrown.
   * @param vectors List of vectors that will be inserted.
   * @returns A promise that resolves with a unique identifier of a mutation containing the insert changeset.
   */
  public insert(vectors: VectorizeVector[]): Promise<VectorizeAsyncMutation>;
  /**
   * Upsert a list of vectors into the index dataset. If a provided id exists, it will be replaced with the new values.
   * @param vectors List of vectors that will be upserted.
   * @returns A promise that resolves with a unique identifier of a mutation containing the upsert changeset.
   */
  public upsert(vectors: VectorizeVector[]): Promise<VectorizeAsyncMutation>;
  /**
   * Delete a list of vectors with a matching id.
   * @param ids List of vector ids that should be deleted.
   * @returns A promise that resolves with a unique identifier of a mutation containing the delete changeset.
   */
  public deleteByIds(ids: string[]): Promise<VectorizeAsyncMutation>;
  /**
   * Get a list of vectors with a matching id.
   * @param ids List of vector ids that should be returned.
   * @returns A promise that resolves with the raw unscored vectors matching the id set.
   */
  public getByIds(ids: string[]): Promise<VectorizeVector[]>;
}
/**
 * The interface for "version_metadata" binding
 * providing metadata about the Worker Version using this binding.
 */
type WorkerVersionMetadata = {
  /** The ID of the Worker Version using this binding */
  id: string;
  /** The tag of the Worker Version using this binding */
  tag: string;
  /** The timestamp of when the Worker Version was uploaded */
  timestamp: string;
};
interface DynamicDispatchLimits {
  /**
   * Limit CPU time in milliseconds.
   */
  cpuMs?: number;
  /**
   * Limit number of subrequests.
   */
  subRequests?: number;
}
interface DynamicDispatchOptions {
  /**
   * Limit resources of invoked Worker script.
   */
  limits?: DynamicDispatchLimits;
  /**
   * Arguments for outbound Worker script, if configured.
   */
  outbound?: {
    [key: string]: any;
  };
}
interface DispatchNamespace {
  /**
   * @param name Name of the Worker script.
   * @param args Arguments to Worker script.
   * @param options Options for Dynamic Dispatch invocation.
   * @returns A Fetcher object that allows you to send requests to the Worker script.
   * @throws If the Worker script does not exist in this dispatch namespace, an error will be thrown.
   */
  get(
    name: string,
    args?: {
      [key: string]: any;
    },
    options?: DynamicDispatchOptions,
  ): Fetcher;
}
declare module "cloudflare:workflows" {
  /**
   * NonRetryableError allows for a user to throw a fatal error
   * that makes a Workflow instance fail immediately without triggering a retry
   */
  export class NonRetryableError extends Error {
    public constructor(message: string, name?: string);
  }
}
declare abstract class Workflow<PARAMS = unknown> {
  /**
   * Get a handle to an existing instance of the Workflow.
   * @param id Id for the instance of this Workflow
   * @returns A promise that resolves with a handle for the Instance
   */
  public get(id: string): Promise<WorkflowInstance>;
  /**
   * Create a new instance and return a handle to it. If a provided id exists, an error will be thrown.
   * @param options Options when creating an instance including id and params
   * @returns A promise that resolves with a handle for the Instance
   */
  public create(
    options?: WorkflowInstanceCreateOptions<PARAMS>,
  ): Promise<WorkflowInstance>;
  /**
   * Create a batch of instances and return handle for all of them. If a provided id exists, an error will be thrown.
   * `createBatch` is limited at 100 instances at a time or when the RPC limit for the batch (1MiB) is reached.
   * @param batch List of Options when creating an instance including name and params
   * @returns A promise that resolves with a list of handles for the created instances.
   */
  public createBatch(
    batch: WorkflowInstanceCreateOptions<PARAMS>[],
  ): Promise<WorkflowInstance[]>;
}
interface WorkflowInstanceCreateOptions<PARAMS = unknown> {
  /**
   * An id for your Workflow instance. Must be unique within the Workflow.
   */
  id?: string;
  /**
   * The event payload the Workflow instance is triggered with
   */
  params?: PARAMS;
}
type InstanceStatus = {
  status:
    | "queued" // means that instance is waiting to be started (see concurrency limits)
    | "running"
    | "paused"
    | "errored"
    | "terminated" // user terminated the instance while it was running
    | "complete"
    | "waiting" // instance is hibernating and waiting for sleep or event to finish
    | "waitingForPause" // instance is finishing the current work to pause
    | "unknown";
  error?: string;
  output?: object;
};
interface WorkflowError {
  code?: number;
  message: string;
}
declare abstract class WorkflowInstance {
  public id: string;
  /**
   * Pause the instance.
   */
  public pause(): Promise<void>;
  /**
   * Resume the instance. If it is already running, an error will be thrown.
   */
  public resume(): Promise<void>;
  /**
   * Terminate the instance. If it is errored, terminated or complete, an error will be thrown.
   */
  public terminate(): Promise<void>;
  /**
   * Restart the instance.
   */
  public restart(): Promise<void>;
  /**
   * Returns the current status of the instance.
   */
  public status(): Promise<InstanceStatus>;
  /**
   * Send an event to this instance.
   */
  public sendEvent({
    type,
    payload,
  }: {
    type: string;
    payload: unknown;
  }): Promise<void>;
}
</file>

<file path="examples/cloudflare-tanstack-start/.vscode/settings.json">
{
  "files.watcherExclude": {
    "**/routeTree.gen.ts": true
  },
  "search.exclude": {
    "**/routeTree.gen.ts": true
  },
  "files.readonlyInclude": {
    "**/routeTree.gen.ts": true
  }
}
</file>

<file path="examples/cloudflare-tanstack-start/public/site.webmanifest">
{
  "name": "",
  "short_name": "",
  "icons": [
    {
      "src": "/android-chrome-192x192.png",
      "sizes": "192x192",
      "type": "image/png"
    },
    {
      "src": "/android-chrome-512x512.png",
      "sizes": "512x512",
      "type": "image/png"
    }
  ],
  "theme_color": "#ffffff",
  "background_color": "#ffffff",
  "display": "standalone"
}
</file>

<file path="examples/cloudflare-tanstack-start/src/components/DefaultCatchBoundary.tsx">
import {
  ErrorComponent,
  Link,
  rootRouteId,
  useMatch,
  useRouter,
} from "@tanstack/react-router";
import type { ErrorComponentProps } from "@tanstack/react-router";
export function DefaultCatchBoundary({ error }: ErrorComponentProps) {
  const router = useRouter();
  const isRoot = useMatch({
    strict: false,
    select: (state) => state.id === rootRouteId,
  });
  console.error("DefaultCatchBoundary Error:", error);
  return (
    <div className="min-w-0 flex-1 p-4 flex flex-col items-center justify-center gap-6">
      <ErrorComponent error={error} />
      <div className="flex gap-2 items-center flex-wrap">
        <button
          onClick={() => {
            router.invalidate();
          }}
          className={
            "px-2 py-1 bg-gray-600 dark:bg-gray-700 rounded text-white uppercase font-extrabold"
          }
        >
          Try Again
        </button>
        {isRoot ? (
          <Link
            to="/"
            className={
              "px-2 py-1 bg-gray-600 dark:bg-gray-700 rounded text-white uppercase font-extrabold"
            }
          >
            Home
          </Link>
        ) : (
          <Link
            to="/"
            className={
              "px-2 py-1 bg-gray-600 dark:bg-gray-700 rounded text-white uppercase font-extrabold"
            }
            onClick={(e) => {
              e.preventDefault();
              window.history.back();
            }}
          >
            Go Back
          </Link>
        )}
      </div>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/components/NotFound.tsx">
import { Link } from "@tanstack/react-router";
export function NotFound({ children }: { children?: any }) {
  return (
    <div className="space-y-2 p-2">
      <div className="text-gray-600 dark:text-gray-400">
        {children || <p>The page you are looking for does not exist.</p>}
      </div>
      <p className="flex items-center gap-2 flex-wrap">
        <button
          onClick={() => window.history.back()}
          className="bg-emerald-500 text-white px-2 py-1 rounded uppercase font-black text-sm"
        >
          Go back
        </button>
        <Link
          to="/"
          className="bg-cyan-600 text-white px-2 py-1 rounded uppercase font-black text-sm"
        >
          Start Over
        </Link>
      </p>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/components/PostError.tsx">
import {
  ErrorComponent,
  type ErrorComponentProps,
} from "@tanstack/react-router";
export function PostErrorComponent({ error }: ErrorComponentProps) {
  return <ErrorComponent error={error} />;
}
</file>

<file path="examples/cloudflare-tanstack-start/src/components/UserError.tsx">
import {
  ErrorComponent,
  type ErrorComponentProps,
} from "@tanstack/react-router";
export function UserErrorComponent({ error }: ErrorComponentProps) {
  return <ErrorComponent error={error} />;
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/_pathlessLayout/_nested-layout/route-a.tsx">
import { createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/_pathlessLayout/_nested-layout/route-a")(
  {
    component: LayoutAComponent,
  },
);
function LayoutAComponent() {
  return <div>I'm A!</div>;
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/_pathlessLayout/_nested-layout/route-b.tsx">
import { createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/_pathlessLayout/_nested-layout/route-b")(
  {
    component: LayoutBComponent,
  },
);
function LayoutBComponent() {
  return <div>I'm B!</div>;
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/_pathlessLayout/_nested-layout.tsx">
import { Link, Outlet, createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/_pathlessLayout/_nested-layout")({
  component: LayoutComponent,
});
function LayoutComponent() {
  return (
    <div>
      <div>I'm a nested layout</div>
      <div className="flex gap-2 border-b">
        <Link
          to="/route-a"
          activeProps={{
            className: "font-bold",
          }}
        >
          Go to route A
        </Link>
        <Link
          to="/route-b"
          activeProps={{
            className: "font-bold",
          }}
        >
          Go to route B
        </Link>
      </div>
      <div>
        <Outlet />
      </div>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/api/users.$id.ts">
import { json } from "@tanstack/react-start";
import { createAPIFileRoute } from "@tanstack/react-start/api";
import type { User } from "../../utils/users.js";
export const APIRoute = createAPIFileRoute("/api/users/$id")({
  GET: async ({ request, params }) => {
    console.info(`Fetching users by id=${params.id}... @`, request.url);
    try {
      const res = await fetch(
        `https://jsonplaceholder.typicode.com/users/${params.id}`,
      );
      if (!res.ok) {
        throw new Error("Failed to fetch user");
      }
      const user = (await res.json()) as User;
      return json({
        id: user.id,
        name: user.name,
        email: user.email,
      });
    } catch (e) {
      console.error(e);
      return json({ error: "User not found" }, { status: 404 });
    }
  },
});
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/api/users.ts">
import { json } from "@tanstack/react-start";
import { createAPIFileRoute } from "@tanstack/react-start/api";
import type { User } from "../../utils/users.js";
export const APIRoute = createAPIFileRoute("/api/users")({
  GET: async ({ request }) => {
    console.info("Fetching users... @", request.url);
    const res = await fetch("https://jsonplaceholder.typicode.com/users");
    if (!res.ok) {
      throw new Error("Failed to fetch users");
    }
    const data = (await res.json()) as Array<User>;
    const list = data.slice(0, 10);
    return json(list.map((u) => ({ id: u.id, name: u.name, email: u.email })));
  },
});
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/__root.tsx">
import {
  HeadContent,
  Link,
  Outlet,
  Scripts,
  createRootRoute,
} from "@tanstack/react-router";
import { TanStackRouterDevtools } from "@tanstack/react-router-devtools";
import type * as React from "react";
import { DefaultCatchBoundary } from "~/components/DefaultCatchBoundary";
import { NotFound } from "~/components/NotFound";
import appCss from "~/styles/app.css?url";
import { seo } from "~/utils/seo";
export const Route = createRootRoute({
  head: () => ({
    meta: [
      {
        charSet: "utf-8",
      },
      {
        name: "viewport",
        content: "width=device-width, initial-scale=1",
      },
      ...seo({
        title:
          "TanStack Start | Type-Safe, Client-First, Full-Stack React Framework",
        description:
          "TanStack Start is a type-safe, client-first, full-stack React framework. ",
      }),
    ],
    links: [
      { rel: "stylesheet", href: appCss },
      {
        rel: "apple-touch-icon",
        sizes: "180x180",
        href: "/apple-touch-icon.png",
      },
      {
        rel: "icon",
        type: "image/png",
        sizes: "32x32",
        href: "/favicon-32x32.png",
      },
      {
        rel: "icon",
        type: "image/png",
        sizes: "16x16",
        href: "/favicon-16x16.png",
      },
      { rel: "manifest", href: "/site.webmanifest", color: "#fffff" },
      { rel: "icon", href: "/favicon.ico" },
    ],
  }),
  errorComponent: (props) => {
    return (
      <RootDocument>
        <DefaultCatchBoundary {...props} />
      </RootDocument>
    );
  },
  notFoundComponent: () => <NotFound />,
  component: RootComponent,
});
function RootComponent() {
  return (
    <RootDocument>
      <Outlet />
    </RootDocument>
  );
}
function RootDocument({ children }: { children: React.ReactNode }) {
  return (
    <html>
      <head>
        <HeadContent />
      </head>
      <body>
        <div className="p-2 flex gap-2 text-lg">
          <Link
            to="/"
            activeProps={{
              className: "font-bold",
            }}
            activeOptions={{ exact: true }}
          >
            Home
          </Link>{" "}
          <Link
            to="/posts"
            activeProps={{
              className: "font-bold",
            }}
          >
            Posts
          </Link>{" "}
          <Link
            to="/users"
            activeProps={{
              className: "font-bold",
            }}
          >
            Users
          </Link>{" "}
          <Link
            to="/route-a"
            activeProps={{
              className: "font-bold",
            }}
          >
            Pathless Layout
          </Link>{" "}
          <Link
            to="/deferred"
            activeProps={{
              className: "font-bold",
            }}
          >
            Deferred
          </Link>{" "}
          <Link
            // @ts-expect-error
            to="/this-route-does-not-exist"
            activeProps={{
              className: "font-bold",
            }}
          >
            This Route Does Not Exist
          </Link>
        </div>
        <hr />
        {children}
        <TanStackRouterDevtools position="bottom-right" />
        <Scripts />
      </body>
    </html>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/_pathlessLayout.tsx">
import { Outlet, createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/_pathlessLayout")({
  component: LayoutComponent,
});
function LayoutComponent() {
  return (
    <div className="p-2">
      <div className="border-b">I'm a layout</div>
      <div>
        <Outlet />
      </div>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/deferred.tsx">
import { Await, createFileRoute } from "@tanstack/react-router";
import { createServerFn } from "@tanstack/react-start";
import { Suspense, useState } from "react";
const personServerFn = createServerFn({ method: "GET" })
  .validator((d: string) => d)
  .handler(({ data: name }) => {
    return { name, randomNumber: Math.floor(Math.random() * 100) };
  });
const slowServerFn = createServerFn({ method: "GET" })
  .validator((d: string) => d)
  .handler(async ({ data: name }) => {
    await new Promise((r) => setTimeout(r, 1000));
    return { name, randomNumber: Math.floor(Math.random() * 100) };
  });
export const Route = createFileRoute("/deferred")({
  loader: async () => {
    return {
      deferredStuff: new Promise<string>((r) =>
        setTimeout(() => r("Hello deferred!"), 2000),
      ),
      deferredPerson: slowServerFn({ data: "Tanner Linsley" }),
      person: await personServerFn({ data: "John Doe" }),
    };
  },
  component: Deferred,
});
function Deferred() {
  const [count, setCount] = useState(0);
  const { deferredStuff, deferredPerson, person } = Route.useLoaderData();
  return (
    <div className="p-2">
      <div data-testid="regular-person">
        {person.name} - {person.randomNumber}
      </div>
      <Suspense fallback={<div>Loading person...</div>}>
        <Await
          promise={deferredPerson}
          children={(data) => (
            <div data-testid="deferred-person">
              {data.name} - {data.randomNumber}
            </div>
          )}
        />
      </Suspense>
      <Suspense fallback={<div>Loading stuff...</div>}>
        <Await
          promise={deferredStuff}
          children={(data) => <h3 data-testid="deferred-stuff">{data}</h3>}
        />
      </Suspense>
      <div>Count: {count}</div>
      <div>
        <button onClick={() => setCount(count + 1)}>Increment</button>
      </div>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/index.tsx">
import { createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/")({
  component: Home,
});
function Home() {
  return (
    <div className="p-2">
      <h3>Welcome Home!!!</h3>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/posts_.$postId.deep.tsx">
import { Link, createFileRoute } from "@tanstack/react-router";
import { fetchPost } from "../utils/posts.js";
import { PostErrorComponent } from "~/components/PostError";
export const Route = createFileRoute("/posts_/$postId/deep")({
  loader: async ({ params: { postId } }) =>
    fetchPost({
      data: postId,
    }),
  errorComponent: PostErrorComponent,
  component: PostDeepComponent,
});
function PostDeepComponent() {
  const post = Route.useLoaderData();
  return (
    <div className="p-2 space-y-2">
      <Link
        to="/posts"
        className="block py-1 text-blue-800 hover:text-blue-600"
      >
         All Posts
      </Link>
      <h4 className="text-xl font-bold underline">{post.title}</h4>
      <div className="text-sm">{post.body}</div>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/posts.$postId.tsx">
import { Link, createFileRoute } from "@tanstack/react-router";
import { fetchPost } from "../utils/posts.js";
import { NotFound } from "~/components/NotFound";
import { PostErrorComponent } from "~/components/PostError";
export const Route = createFileRoute("/posts/$postId")({
  loader: ({ params: { postId } }) => fetchPost({ data: postId }),
  errorComponent: PostErrorComponent,
  component: PostComponent,
  notFoundComponent: () => {
    return <NotFound>Post not found</NotFound>;
  },
});
function PostComponent() {
  const post = Route.useLoaderData();
  return (
    <div className="space-y-2">
      <h4 className="text-xl font-bold underline">{post.title}</h4>
      <div className="text-sm">{post.body}</div>
      <Link
        to="/posts/$postId/deep"
        params={{
          postId: post.id,
        }}
        activeProps={{ className: "text-black font-bold" }}
        className="block py-1 text-blue-800 hover:text-blue-600"
      >
        Deep View
      </Link>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/posts.index.tsx">
import { createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/posts/")({
  component: PostsIndexComponent,
});
function PostsIndexComponent() {
  return <div>Select a post.</div>;
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/posts.route.tsx">
import { Link, Outlet, createFileRoute } from "@tanstack/react-router";
import { fetchPosts } from "../utils/posts.js";
export const Route = createFileRoute("/posts")({
  loader: async () => fetchPosts(),
  component: PostsLayoutComponent,
});
function PostsLayoutComponent() {
  const posts = Route.useLoaderData();
  return (
    <div className="p-2 flex gap-2">
      <ul className="list-disc pl-4">
        {[...posts, { id: "i-do-not-exist", title: "Non-existent Post" }].map(
          (post) => {
            return (
              <li key={post.id} className="whitespace-nowrap">
                <Link
                  to="/posts/$postId"
                  params={{
                    postId: post.id,
                  }}
                  className="block py-1 text-blue-800 hover:text-blue-600"
                  activeProps={{ className: "text-black font-bold" }}
                >
                  <div>{post.title.substring(0, 20)}</div>
                </Link>
              </li>
            );
          },
        )}
      </ul>
      <hr />
      <Outlet />
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/redirect.tsx">
import { createFileRoute, redirect } from "@tanstack/react-router";
export const Route = createFileRoute("/redirect")({
  beforeLoad: async () => {
    throw redirect({
      to: "/posts",
    });
  },
});
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/users.$userId.tsx">
import { createFileRoute } from "@tanstack/react-router";
import type { User } from "~/utils/users";
import { DEPLOY_URL } from "~/utils/users";
import { NotFound } from "~/components/NotFound";
import { UserErrorComponent } from "~/components/UserError";
export const Route = createFileRoute("/users/$userId")({
  loader: async ({ params: { userId } }) => {
    try {
      const res = await fetch(`${DEPLOY_URL}/api/users/${userId}`);
      if (!res.ok) {
        throw new Error("Unexpected status code");
      }
      const data = (await res.json()) as User;
      return data;
    } catch {
      throw new Error("Failed to fetch user");
    }
  },
  errorComponent: UserErrorComponent,
  component: UserComponent,
  notFoundComponent: () => {
    return <NotFound>User not found</NotFound>;
  },
});
function UserComponent() {
  const user = Route.useLoaderData();
  return (
    <div className="space-y-2">
      <h4 className="text-xl font-bold underline">{user.name}</h4>
      <div className="text-sm">{user.email}</div>
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/users.index.tsx">
import { createFileRoute } from "@tanstack/react-router";
export const Route = createFileRoute("/users/")({
  component: UsersIndexComponent,
});
function UsersIndexComponent() {
  return <div>Select a user.</div>;
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routes/users.route.tsx">
import { Link, Outlet, createFileRoute } from "@tanstack/react-router";
import { DEPLOY_URL } from "../utils/users.js";
import type { User } from "../utils/users.js";
export const Route = createFileRoute("/users")({
  loader: async () => {
    try {
      const res = await fetch(`${DEPLOY_URL}/api/users`);
      if (!res.ok) {
        throw new Error("Unexpected status code");
      }
      const data = (await res.json()) as Array<User>;
      return data;
    } catch {
      throw new Error("Failed to fetch users");
    }
  },
  component: UsersLayoutComponent,
});
function UsersLayoutComponent() {
  const users = Route.useLoaderData();
  return (
    <div className="p-2 flex gap-2">
      <ul className="list-disc pl-4">
        {[
          ...users,
          { id: "i-do-not-exist", name: "Non-existent User", email: "" },
        ].map((user) => {
          return (
            <li key={user.id} className="whitespace-nowrap">
              <Link
                to="/users/$userId"
                params={{
                  userId: String(user.id),
                }}
                className="block py-1 text-blue-800 hover:text-blue-600"
                activeProps={{ className: "text-black font-bold" }}
              >
                <div>{user.name}</div>
              </Link>
            </li>
          );
        })}
      </ul>
      <hr />
      <Outlet />
    </div>
  );
}
</file>

<file path="examples/cloudflare-tanstack-start/src/styles/app.css">
@tailwind base;
@tailwind components;
@tailwind utilities;
@layer base {
  html {
    color-scheme: light dark;
  }
  * {
    @apply border-gray-200 dark:border-gray-800;
  }
  html,
  body {
    @apply text-gray-900 bg-gray-50 dark:bg-gray-950 dark:text-gray-200;
  }
  .using-mouse * {
    outline: none !important;
  }
}
</file>

<file path="examples/cloudflare-tanstack-start/src/utils/loggingMiddleware.tsx">
import { createMiddleware } from "@tanstack/react-start";
const preLogMiddleware = createMiddleware()
  .client(async (ctx) => {
    const clientTime = new Date();
    return ctx.next({
      context: {
        clientTime,
      },
      sendContext: {
        clientTime,
      },
    });
  })
  .server(async (ctx) => {
    const serverTime = new Date();
    return ctx.next({
      sendContext: {
        serverTime,
        durationToServer:
          serverTime.getTime() - ctx.context.clientTime.getTime(),
      },
    });
  });
export const logMiddleware = createMiddleware()
  .middleware([preLogMiddleware])
  .client(async (ctx) => {
    const res = await ctx.next();
    const now = new Date();
    console.log("Client Req/Res:", {
      duration: res.context.clientTime.getTime() - now.getTime(),
      durationToServer: res.context.durationToServer,
      durationFromServer: now.getTime() - res.context.serverTime.getTime(),
    });
    return res;
  });
</file>

<file path="examples/cloudflare-tanstack-start/src/utils/posts.tsx">
import { notFound } from "@tanstack/react-router";
import { createServerFn } from "@tanstack/react-start";
export type PostType = {
  id: string;
  title: string;
  body: string;
};
export const fetchPost = createServerFn({ method: "GET" })
  .validator((d: string) => d)
  .handler(async ({ data }) => {
    console.info(`Fetching post with id ${data}...`);
    const res = await fetch(
      `https://jsonplaceholder.typicode.com/posts/${data}`,
    );
    if (!res.ok) {
      if (res.status === 404) {
        throw notFound();
      }
      throw new Error("Failed to fetch post");
    }
    const post = (await res.json()) as PostType;
    return post;
  });
export const fetchPosts = createServerFn({ method: "GET" }).handler(
  async () => {
    console.info("Fetching posts...");
    const res = await fetch("https://jsonplaceholder.typicode.com/posts");
    if (!res.ok) {
      throw new Error("Failed to fetch posts");
    }
    const posts = (await res.json()) as Array<PostType>;
    return posts;
  },
);
</file>

<file path="examples/cloudflare-tanstack-start/src/utils/seo.ts">
export const seo = ({
  title,
  description,
  keywords,
  image,
}: {
  title: string;
  description?: string;
  image?: string;
  keywords?: string;
}) => {
  const tags = [
    { title },
    { name: "description", content: description },
    { name: "keywords", content: keywords },
    { name: "twitter:title", content: title },
    { name: "twitter:description", content: description },
    { name: "twitter:creator", content: "@tannerlinsley" },
    { name: "twitter:site", content: "@tannerlinsley" },
    { name: "og:type", content: "website" },
    { name: "og:title", content: title },
    { name: "og:description", content: description },
    ...(image
      ? [
          { name: "twitter:image", content: image },
          { name: "twitter:card", content: "summary_large_image" },
          { name: "og:image", content: image },
        ]
      : []),
  ];
  return tags;
};
</file>

<file path="examples/cloudflare-tanstack-start/src/utils/users.tsx">
export type User = {
  id: number;
  name: string;
  email: string;
};
// must check if window is not undefined since the bundler also places this code server-side
export const DEPLOY_URL =
  typeof window !== "undefined"
    ? window.location.origin
    : "http://localhost:3000";
</file>

<file path="examples/cloudflare-tanstack-start/src/api.ts">
import {
  createStartAPIHandler,
  defaultAPIFileRouteHandler,
} from "@tanstack/react-start/api";
export default createStartAPIHandler(defaultAPIFileRouteHandler);
</file>

<file path="examples/cloudflare-tanstack-start/src/client.tsx">
/// <reference types="vinxi/types/client" />
import { hydrateRoot } from "react-dom/client";
import { StartClient } from "@tanstack/react-start";
import { createRouter } from "./router.js";
const router = createRouter();
hydrateRoot(document, <StartClient router={router} />);
</file>

<file path="examples/cloudflare-tanstack-start/src/env.d.ts">
/// <reference types="./env.d.ts" />
import type { website } from "../alchemy.run.js";
export type CloudFlareEnv = typeof website.Env;
declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends CloudFlareEnv {}
  }
}
</file>

<file path="examples/cloudflare-tanstack-start/src/global-middleware.ts">
import { registerGlobalMiddleware } from "@tanstack/react-start";
import { logMiddleware } from "./utils/loggingMiddleware.js";
registerGlobalMiddleware({
  middleware: [logMiddleware],
});
</file>

<file path="examples/cloudflare-tanstack-start/src/router.tsx">
import { createRouter as createTanStackRouter } from "@tanstack/react-router";
import { routeTree } from "./routeTree.gen.js";
import { DefaultCatchBoundary } from "./components/DefaultCatchBoundary.js";
import { NotFound } from "./components/NotFound.js";
export function createRouter() {
  const router = createTanStackRouter({
    routeTree,
    defaultPreload: "intent",
    defaultErrorComponent: DefaultCatchBoundary,
    defaultNotFoundComponent: () => <NotFound />,
    scrollRestoration: true,
  });
  return router;
}
declare module "@tanstack/react-router" {
  interface Register {
    router: ReturnType<typeof createRouter>;
  }
}
</file>

<file path="examples/cloudflare-tanstack-start/src/routeTree.gen.ts">
/* eslint-disable */
// @ts-nocheck
// noinspection JSUnusedGlobalSymbols
// This file was automatically generated by TanStack Router.
// You should NOT make any changes in this file as it will be overwritten.
// Additionally, you should also exclude this file from your linter and/or formatter to prevent it from being checked or modified.
// Import Routes
import { Route as rootRoute } from "./routes/__root.js";
import { Route as RedirectImport } from "./routes/redirect.js";
import { Route as DeferredImport } from "./routes/deferred.js";
import { Route as PathlessLayoutImport } from "./routes/_pathlessLayout.js";
import { Route as UsersRouteImport } from "./routes/users.route.js";
import { Route as PostsRouteImport } from "./routes/posts.route.js";
import { Route as IndexImport } from "./routes/index/index.js";
import { Route as UsersIndexImport } from "./routes/users.index.js";
import { Route as PostsIndexImport } from "./routes/posts.index.js";
import { Route as UsersUserIdImport } from "./routes/users.$userId.js";
import { Route as PostsPostIdImport } from "./routes/posts.$postId.js";
import { Route as PathlessLayoutNestedLayoutImport } from "./routes/_pathlessLayout/_nested-layout.js";
import { Route as PostsPostIdDeepImport } from "./routes/posts_.$postId.deep.js";
import { Route as PathlessLayoutNestedLayoutRouteBImport } from "./routes/_pathlessLayout/_nested-layout/route-b.js";
import { Route as PathlessLayoutNestedLayoutRouteAImport } from "./routes/_pathlessLayout/_nested-layout/route-a.js";
// Create/Update Routes
const RedirectRoute = RedirectImport.update({
  id: "/redirect",
  path: "/redirect",
  getParentRoute: () => rootRoute,
} as any);
const DeferredRoute = DeferredImport.update({
  id: "/deferred",
  path: "/deferred",
  getParentRoute: () => rootRoute,
} as any);
const PathlessLayoutRoute = PathlessLayoutImport.update({
  id: "/_pathlessLayout",
  getParentRoute: () => rootRoute,
} as any);
const UsersRouteRoute = UsersRouteImport.update({
  id: "/users",
  path: "/users",
  getParentRoute: () => rootRoute,
} as any);
const PostsRouteRoute = PostsRouteImport.update({
  id: "/posts",
  path: "/posts",
  getParentRoute: () => rootRoute,
} as any);
const IndexRoute = IndexImport.update({
  id: "/",
  path: "/",
  getParentRoute: () => rootRoute,
} as any);
const UsersIndexRoute = UsersIndexImport.update({
  id: "/",
  path: "/",
  getParentRoute: () => UsersRouteRoute,
} as any);
const PostsIndexRoute = PostsIndexImport.update({
  id: "/",
  path: "/",
  getParentRoute: () => PostsRouteRoute,
} as any);
const UsersUserIdRoute = UsersUserIdImport.update({
  id: "/$userId",
  path: "/$userId",
  getParentRoute: () => UsersRouteRoute,
} as any);
const PostsPostIdRoute = PostsPostIdImport.update({
  id: "/$postId",
  path: "/$postId",
  getParentRoute: () => PostsRouteRoute,
} as any);
const PathlessLayoutNestedLayoutRoute = PathlessLayoutNestedLayoutImport.update(
  {
    id: "/_nested-layout",
    getParentRoute: () => PathlessLayoutRoute,
  } as any,
);
const PostsPostIdDeepRoute = PostsPostIdDeepImport.update({
  id: "/posts_/$postId/deep",
  path: "/posts/$postId/deep",
  getParentRoute: () => rootRoute,
} as any);
const PathlessLayoutNestedLayoutRouteBRoute =
  PathlessLayoutNestedLayoutRouteBImport.update({
    id: "/route-b",
    path: "/route-b",
    getParentRoute: () => PathlessLayoutNestedLayoutRoute,
  } as any);
const PathlessLayoutNestedLayoutRouteARoute =
  PathlessLayoutNestedLayoutRouteAImport.update({
    id: "/route-a",
    path: "/route-a",
    getParentRoute: () => PathlessLayoutNestedLayoutRoute,
  } as any);
// Populate the FileRoutesByPath interface
declare module "@tanstack/react-router" {
  interface FileRoutesByPath {
    "/": {
      id: "/";
      path: "/";
      fullPath: "/";
      preLoaderRoute: typeof IndexImport;
      parentRoute: typeof rootRoute;
    };
    "/posts": {
      id: "/posts";
      path: "/posts";
      fullPath: "/posts";
      preLoaderRoute: typeof PostsRouteImport;
      parentRoute: typeof rootRoute;
    };
    "/users": {
      id: "/users";
      path: "/users";
      fullPath: "/users";
      preLoaderRoute: typeof UsersRouteImport;
      parentRoute: typeof rootRoute;
    };
    "/_pathlessLayout": {
      id: "/_pathlessLayout";
      path: "";
      fullPath: "";
      preLoaderRoute: typeof PathlessLayoutImport;
      parentRoute: typeof rootRoute;
    };
    "/deferred": {
      id: "/deferred";
      path: "/deferred";
      fullPath: "/deferred";
      preLoaderRoute: typeof DeferredImport;
      parentRoute: typeof rootRoute;
    };
    "/redirect": {
      id: "/redirect";
      path: "/redirect";
      fullPath: "/redirect";
      preLoaderRoute: typeof RedirectImport;
      parentRoute: typeof rootRoute;
    };
    "/_pathlessLayout/_nested-layout": {
      id: "/_pathlessLayout/_nested-layout";
      path: "";
      fullPath: "";
      preLoaderRoute: typeof PathlessLayoutNestedLayoutImport;
      parentRoute: typeof PathlessLayoutImport;
    };
    "/posts/$postId": {
      id: "/posts/$postId";
      path: "/$postId";
      fullPath: "/posts/$postId";
      preLoaderRoute: typeof PostsPostIdImport;
      parentRoute: typeof PostsRouteImport;
    };
    "/users/$userId": {
      id: "/users/$userId";
      path: "/$userId";
      fullPath: "/users/$userId";
      preLoaderRoute: typeof UsersUserIdImport;
      parentRoute: typeof UsersRouteImport;
    };
    "/posts/": {
      id: "/posts/";
      path: "/";
      fullPath: "/posts/";
      preLoaderRoute: typeof PostsIndexImport;
      parentRoute: typeof PostsRouteImport;
    };
    "/users/": {
      id: "/users/";
      path: "/";
      fullPath: "/users/";
      preLoaderRoute: typeof UsersIndexImport;
      parentRoute: typeof UsersRouteImport;
    };
    "/_pathlessLayout/_nested-layout/route-a": {
      id: "/_pathlessLayout/_nested-layout/route-a";
      path: "/route-a";
      fullPath: "/route-a";
      preLoaderRoute: typeof PathlessLayoutNestedLayoutRouteAImport;
      parentRoute: typeof PathlessLayoutNestedLayoutImport;
    };
    "/_pathlessLayout/_nested-layout/route-b": {
      id: "/_pathlessLayout/_nested-layout/route-b";
      path: "/route-b";
      fullPath: "/route-b";
      preLoaderRoute: typeof PathlessLayoutNestedLayoutRouteBImport;
      parentRoute: typeof PathlessLayoutNestedLayoutImport;
    };
    "/posts_/$postId/deep": {
      id: "/posts_/$postId/deep";
      path: "/posts/$postId/deep";
      fullPath: "/posts/$postId/deep";
      preLoaderRoute: typeof PostsPostIdDeepImport;
      parentRoute: typeof rootRoute;
    };
  }
}
// Create and export the route tree
interface PostsRouteRouteChildren {
  PostsPostIdRoute: typeof PostsPostIdRoute;
  PostsIndexRoute: typeof PostsIndexRoute;
}
const PostsRouteRouteChildren: PostsRouteRouteChildren = {
  PostsPostIdRoute: PostsPostIdRoute,
  PostsIndexRoute: PostsIndexRoute,
};
const PostsRouteRouteWithChildren = PostsRouteRoute._addFileChildren(
  PostsRouteRouteChildren,
);
interface UsersRouteRouteChildren {
  UsersUserIdRoute: typeof UsersUserIdRoute;
  UsersIndexRoute: typeof UsersIndexRoute;
}
const UsersRouteRouteChildren: UsersRouteRouteChildren = {
  UsersUserIdRoute: UsersUserIdRoute,
  UsersIndexRoute: UsersIndexRoute,
};
const UsersRouteRouteWithChildren = UsersRouteRoute._addFileChildren(
  UsersRouteRouteChildren,
);
interface PathlessLayoutNestedLayoutRouteChildren {
  PathlessLayoutNestedLayoutRouteARoute: typeof PathlessLayoutNestedLayoutRouteARoute;
  PathlessLayoutNestedLayoutRouteBRoute: typeof PathlessLayoutNestedLayoutRouteBRoute;
}
const PathlessLayoutNestedLayoutRouteChildren: PathlessLayoutNestedLayoutRouteChildren =
  {
    PathlessLayoutNestedLayoutRouteARoute:
      PathlessLayoutNestedLayoutRouteARoute,
    PathlessLayoutNestedLayoutRouteBRoute:
      PathlessLayoutNestedLayoutRouteBRoute,
  };
const PathlessLayoutNestedLayoutRouteWithChildren =
  PathlessLayoutNestedLayoutRoute._addFileChildren(
    PathlessLayoutNestedLayoutRouteChildren,
  );
interface PathlessLayoutRouteChildren {
  PathlessLayoutNestedLayoutRoute: typeof PathlessLayoutNestedLayoutRouteWithChildren;
}
const PathlessLayoutRouteChildren: PathlessLayoutRouteChildren = {
  PathlessLayoutNestedLayoutRoute: PathlessLayoutNestedLayoutRouteWithChildren,
};
const PathlessLayoutRouteWithChildren = PathlessLayoutRoute._addFileChildren(
  PathlessLayoutRouteChildren,
);
export interface FileRoutesByFullPath {
  "/": typeof IndexRoute;
  "/posts": typeof PostsRouteRouteWithChildren;
  "/users": typeof UsersRouteRouteWithChildren;
  "": typeof PathlessLayoutNestedLayoutRouteWithChildren;
  "/deferred": typeof DeferredRoute;
  "/redirect": typeof RedirectRoute;
  "/posts/$postId": typeof PostsPostIdRoute;
  "/users/$userId": typeof UsersUserIdRoute;
  "/posts/": typeof PostsIndexRoute;
  "/users/": typeof UsersIndexRoute;
  "/route-a": typeof PathlessLayoutNestedLayoutRouteARoute;
  "/route-b": typeof PathlessLayoutNestedLayoutRouteBRoute;
  "/posts/$postId/deep": typeof PostsPostIdDeepRoute;
}
export interface FileRoutesByTo {
  "/": typeof IndexRoute;
  "": typeof PathlessLayoutNestedLayoutRouteWithChildren;
  "/deferred": typeof DeferredRoute;
  "/redirect": typeof RedirectRoute;
  "/posts/$postId": typeof PostsPostIdRoute;
  "/users/$userId": typeof UsersUserIdRoute;
  "/posts": typeof PostsIndexRoute;
  "/users": typeof UsersIndexRoute;
  "/route-a": typeof PathlessLayoutNestedLayoutRouteARoute;
  "/route-b": typeof PathlessLayoutNestedLayoutRouteBRoute;
  "/posts/$postId/deep": typeof PostsPostIdDeepRoute;
}
export interface FileRoutesById {
  __root__: typeof rootRoute;
  "/": typeof IndexRoute;
  "/posts": typeof PostsRouteRouteWithChildren;
  "/users": typeof UsersRouteRouteWithChildren;
  "/_pathlessLayout": typeof PathlessLayoutRouteWithChildren;
  "/deferred": typeof DeferredRoute;
  "/redirect": typeof RedirectRoute;
  "/_pathlessLayout/_nested-layout": typeof PathlessLayoutNestedLayoutRouteWithChildren;
  "/posts/$postId": typeof PostsPostIdRoute;
  "/users/$userId": typeof UsersUserIdRoute;
  "/posts/": typeof PostsIndexRoute;
  "/users/": typeof UsersIndexRoute;
  "/_pathlessLayout/_nested-layout/route-a": typeof PathlessLayoutNestedLayoutRouteARoute;
  "/_pathlessLayout/_nested-layout/route-b": typeof PathlessLayoutNestedLayoutRouteBRoute;
  "/posts_/$postId/deep": typeof PostsPostIdDeepRoute;
}
export interface FileRouteTypes {
  fileRoutesByFullPath: FileRoutesByFullPath;
  fullPaths:
    | "/"
    | "/posts"
    | "/users"
    | ""
    | "/deferred"
    | "/redirect"
    | "/posts/$postId"
    | "/users/$userId"
    | "/posts/"
    | "/users/"
    | "/route-a"
    | "/route-b"
    | "/posts/$postId/deep";
  fileRoutesByTo: FileRoutesByTo;
  to:
    | "/"
    | ""
    | "/deferred"
    | "/redirect"
    | "/posts/$postId"
    | "/users/$userId"
    | "/posts"
    | "/users"
    | "/route-a"
    | "/route-b"
    | "/posts/$postId/deep";
  id:
    | "__root__"
    | "/"
    | "/posts"
    | "/users"
    | "/_pathlessLayout"
    | "/deferred"
    | "/redirect"
    | "/_pathlessLayout/_nested-layout"
    | "/posts/$postId"
    | "/users/$userId"
    | "/posts/"
    | "/users/"
    | "/_pathlessLayout/_nested-layout/route-a"
    | "/_pathlessLayout/_nested-layout/route-b"
    | "/posts_/$postId/deep";
  fileRoutesById: FileRoutesById;
}
export interface RootRouteChildren {
  IndexRoute: typeof IndexRoute;
  PostsRouteRoute: typeof PostsRouteRouteWithChildren;
  UsersRouteRoute: typeof UsersRouteRouteWithChildren;
  PathlessLayoutRoute: typeof PathlessLayoutRouteWithChildren;
  DeferredRoute: typeof DeferredRoute;
  RedirectRoute: typeof RedirectRoute;
  PostsPostIdDeepRoute: typeof PostsPostIdDeepRoute;
}
const rootRouteChildren: RootRouteChildren = {
  IndexRoute: IndexRoute,
  PostsRouteRoute: PostsRouteRouteWithChildren,
  UsersRouteRoute: UsersRouteRouteWithChildren,
  PathlessLayoutRoute: PathlessLayoutRouteWithChildren,
  DeferredRoute: DeferredRoute,
  RedirectRoute: RedirectRoute,
  PostsPostIdDeepRoute: PostsPostIdDeepRoute,
};
export const routeTree = rootRoute
  ._addFileChildren(rootRouteChildren)
  ._addFileTypes<FileRouteTypes>();
/* ROUTE_MANIFEST_START
{
  "routes": {
    "__root__": {
      "filePath": "__root.tsx",
      "children": [
        "/",
        "/posts",
        "/users",
        "/_pathlessLayout",
        "/deferred",
        "/redirect",
        "/posts_/$postId/deep"
      ]
    },
    "/": {
      "filePath": "index.tsx"
    },
    "/posts": {
      "filePath": "posts.route.tsx",
      "children": [
        "/posts/$postId",
        "/posts/"
      ]
    },
    "/users": {
      "filePath": "users.route.tsx",
      "children": [
        "/users/$userId",
        "/users/"
      ]
    },
    "/_pathlessLayout": {
      "filePath": "_pathlessLayout.tsx",
      "children": [
        "/_pathlessLayout/_nested-layout"
      ]
    },
    "/deferred": {
      "filePath": "deferred.tsx"
    },
    "/redirect": {
      "filePath": "redirect.tsx"
    },
    "/_pathlessLayout/_nested-layout": {
      "filePath": "_pathlessLayout/_nested-layout.tsx",
      "parent": "/_pathlessLayout",
      "children": [
        "/_pathlessLayout/_nested-layout/route-a",
        "/_pathlessLayout/_nested-layout/route-b"
      ]
    },
    "/posts/$postId": {
      "filePath": "posts.$postId.tsx",
      "parent": "/posts"
    },
    "/users/$userId": {
      "filePath": "users.$userId.tsx",
      "parent": "/users"
    },
    "/posts/": {
      "filePath": "posts.index.tsx",
      "parent": "/posts"
    },
    "/users/": {
      "filePath": "users.index.tsx",
      "parent": "/users"
    },
    "/_pathlessLayout/_nested-layout/route-a": {
      "filePath": "_pathlessLayout/_nested-layout/route-a.tsx",
      "parent": "/_pathlessLayout/_nested-layout"
    },
    "/_pathlessLayout/_nested-layout/route-b": {
      "filePath": "_pathlessLayout/_nested-layout/route-b.tsx",
      "parent": "/_pathlessLayout/_nested-layout"
    },
    "/posts_/$postId/deep": {
      "filePath": "posts_.$postId.deep.tsx"
    }
  }
}
ROUTE_MANIFEST_END */
</file>

<file path="examples/cloudflare-tanstack-start/src/ssr.tsx">
/// <reference types="vinxi/types/server" />
import {
  createStartHandler,
  defaultStreamHandler,
} from "@tanstack/react-start/server";
import { getRouterManifest } from "@tanstack/react-start/router-manifest";
import { createRouter } from "./router.js";
export default createStartHandler({
  createRouter,
  getRouterManifest,
})(defaultStreamHandler);
</file>

<file path="examples/cloudflare-tanstack-start/.gitignore">
node_modules
package-lock.json
yarn.lock

.DS_Store
.cache
.env
.vercel
.output
.vinxi

/build/
/api/
/server/build
/public/build
.vinxi
# Sentry Config File
.env.sentry-build-plugin
/test-results/
/playwright-report/
/blob-report/
/playwright/.cache/

wrangler.jsonc
</file>

<file path="examples/cloudflare-tanstack-start/.prettierignore">
**/build
**/public
pnpm-lock.yaml
routeTree.gen.ts
</file>

<file path="examples/cloudflare-tanstack-start/alchemy.run.ts">
import "../../alchemy/src/cloudflare";
import alchemy from "../../alchemy/src";
import { R2RestStateStore, TanStackStart } from "../../alchemy/src/cloudflare";
const BRANCH_PREFIX = process.env.BRANCH_PREFIX ?? "";
const app = await alchemy("cloudflare-tanstack", {
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
});
export const website = await TanStackStart(
  `cloudflare-tanstack-website${BRANCH_PREFIX}`,
);
console.log({
  url: website.url,
});
await app.finalize();
</file>

<file path="examples/cloudflare-tanstack-start/app.config.ts">
import { defineConfig } from "@tanstack/react-start/config";
import tsConfigPaths from "vite-tsconfig-paths";
import {
  cloudflareWorkersDevEnvironmentShim,
  external,
} from "../../alchemy/src/cloudflare";
export default defineConfig({
  tsr: {
    appDirectory: "src",
  },
  server: {
    preset: "cloudflare-module",
    experimental: {
      asyncContext: true,
    },
    unenv: {
      external,
    },
  },
  vite: {
    plugins: [
      // polyfills import { env } from "cloudflare:workers" during `vite dev` (not deployed to server)
      cloudflareWorkersDevEnvironmentShim(),
      tsConfigPaths({
        projects: ["./tsconfig.json"],
      }),
    ],
    build: {
      rollupOptions: {
        external,
      },
    },
  },
});
</file>

<file path="examples/cloudflare-tanstack-start/package.json">
{
  "name": "tanstack-start-example-basic",
  "private": true,
  "sideEffects": false,
  "type": "module",
  "scripts": {
    "dev": "vinxi dev",
    "build": "vinxi build",
    "start": "vinxi start",
    "deploy": "bun run --env-file ../../.env ./alchemy.run.ts",
    "destroy": "bun run --env-file ../../.env ./alchemy.run.ts --destroy"
  },
  "dependencies": {
    "@tanstack/react-router": "^1.116.0",
    "@tanstack/react-router-devtools": "^1.116.0",
    "@tanstack/react-start": "^1.116.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "tailwind-merge": "^2.6.0",
    "vinxi": "0.5.3"
  },
  "devDependencies": {
    "@types/node": "^22.5.4",
    "@types/react-dom": "^19.0.3",
    "@types/react": "^19.0.8",
    "autoprefixer": "^10.4.20",
    "cloudflare": "^4.2.0",
    "postcss": "^8.5.1",
    "tailwindcss": "^3.4.17",
    "typescript": "^5.7.2",
    "vite-tsconfig-paths": "^5.1.4"
  }
}
</file>

<file path="examples/cloudflare-tanstack-start/postcss.config.mjs">
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
</file>

<file path="examples/cloudflare-tanstack-start/README.md">
# Welcome to TanStack.com!

This site is built with TanStack Router!

- [TanStack Router Docs](https://tanstack.com/router)

It's deployed automagically with Netlify!

- [Netlify](https://netlify.com/)

## Development

From your terminal:

```sh
pnpm install
pnpm dev
```

This starts your app in development mode, rebuilding assets on file changes.

## Editing and previewing the docs of TanStack projects locally

The documentations for all TanStack projects except for `React Charts` are hosted on [https://tanstack.com](https://tanstack.com), powered by this TanStack Router app.
In production, the markdown doc pages are fetched from the GitHub repos of the projects, but in development they are read from the local file system.

Follow these steps if you want to edit the doc pages of a project (in these steps we'll assume it's [`TanStack/form`](https://github.com/tanstack/form)) and preview them locally :

1. Create a new directory called `tanstack`.

```sh
mkdir tanstack
```

2. Enter the directory and clone this repo and the repo of the project there.

```sh
cd tanstack
git clone git@github.com:TanStack/tanstack.com.git
git clone git@github.com:TanStack/form.git
```

> [!NOTE]
> Your `tanstack` directory should look like this:
>
> ```
> tanstack/
>    |
>    +-- form/
>    |
>    +-- tanstack.com/
> ```

> [!WARNING]
> Make sure the name of the directory in your local file system matches the name of the project's repo. For example, `tanstack/form` must be cloned into `form` (this is the default) instead of `some-other-name`, because that way, the doc pages won't be found.

3. Enter the `tanstack/tanstack.com` directory, install the dependencies and run the app in dev mode:

```sh
cd tanstack.com
pnpm i
# The app will run on https://localhost:3000 by default
pnpm dev
```

4. Now you can visit http://localhost:3000/form/latest/docs/overview in the browser and see the changes you make in `tanstack/form/docs`.

> [!NOTE]
> The updated pages need to be manually reloaded in the browser.

> [!WARNING]
> You will need to update the `docs/config.json` file (in the project's repo) if you add a new doc page!
</file>

<file path="examples/cloudflare-tanstack-start/tailwind.config.mjs">
/** @type {import('tailwindcss').Config} */
export default {
  content: ['./src/**/*.{js,jsx,ts,tsx}'],
}
</file>

<file path="examples/cloudflare-tanstack-start/tsconfig.json">
{
  "include": ["**/*.ts", "**/*.tsx"],
  "references": [{ "path": "../../alchemy/tsconfig.json" }],
  "compilerOptions": {
    "strict": true,
    "esModuleInterop": true,
    "jsx": "react-jsx",
    "module": "ESNext",
    "moduleResolution": "Bundler",
    "lib": ["DOM", "DOM.Iterable", "ES2022"],
    "isolatedModules": true,
    "resolveJsonModule": true,
    "skipLibCheck": true,
    "target": "ES2022",
    "allowJs": true,
    "forceConsistentCasingInFileNames": true,
    "baseUrl": ".",
    "paths": {
      "~/*": ["./src/*"]
    },
    "noImplicitAny": false,
    "types": ["@cloudflare/workers-types"],
    "noEmit": true
  }
}
</file>

<file path="examples/cloudflare-vite/public/vite.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="31.88" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 257"><defs><linearGradient id="IconifyId1813088fe1fbc01fb466" x1="-.828%" x2="57.636%" y1="7.652%" y2="78.411%"><stop offset="0%" stop-color="#41D1FF"></stop><stop offset="100%" stop-color="#BD34FE"></stop></linearGradient><linearGradient id="IconifyId1813088fe1fbc01fb467" x1="43.376%" x2="50.316%" y1="2.242%" y2="89.03%"><stop offset="0%" stop-color="#FFEA83"></stop><stop offset="8.333%" stop-color="#FFDD35"></stop><stop offset="100%" stop-color="#FFA800"></stop></linearGradient></defs><path fill="url(#IconifyId1813088fe1fbc01fb466)" d="M255.153 37.938L134.897 252.976c-2.483 4.44-8.862 4.466-11.382.048L.875 37.958c-2.746-4.814 1.371-10.646 6.827-9.67l120.385 21.517a6.537 6.537 0 0 0 2.322-.004l117.867-21.483c5.438-.991 9.574 4.796 6.877 9.62Z"></path><path fill="url(#IconifyId1813088fe1fbc01fb467)" d="M185.432.063L96.44 17.501a3.268 3.268 0 0 0-2.634 3.014l-5.474 92.456a3.268 3.268 0 0 0 3.997 3.378l24.777-5.718c2.318-.535 4.413 1.507 3.936 3.838l-7.361 36.047c-.495 2.426 1.782 4.5 4.151 3.78l15.304-4.649c2.372-.72 4.652 1.36 4.15 3.788l-11.698 56.621c-.732 3.542 3.979 5.473 5.943 2.437l1.313-2.028l72.516-144.72c1.215-2.423-.88-5.186-3.54-4.672l-25.505 4.922c-2.396.462-4.435-1.77-3.759-4.114l16.646-57.705c.677-2.35-1.37-4.583-3.769-4.113Z"></path></svg>
</file>

<file path="examples/cloudflare-vite/src/assets/react.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="35.93" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 228"><path fill="#00D8FF" d="M210.483 73.824a171.49 171.49 0 0 0-8.24-2.597c.465-1.9.893-3.777 1.273-5.621c6.238-30.281 2.16-54.676-11.769-62.708c-13.355-7.7-35.196.329-57.254 19.526a171.23 171.23 0 0 0-6.375 5.848a155.866 155.866 0 0 0-4.241-3.917C100.759 3.829 77.587-4.822 63.673 3.233C50.33 10.957 46.379 33.89 51.995 62.588a170.974 170.974 0 0 0 1.892 8.48c-3.28.932-6.445 1.924-9.474 2.98C17.309 83.498 0 98.307 0 113.668c0 15.865 18.582 31.778 46.812 41.427a145.52 145.52 0 0 0 6.921 2.165a167.467 167.467 0 0 0-2.01 9.138c-5.354 28.2-1.173 50.591 12.134 58.266c13.744 7.926 36.812-.22 59.273-19.855a145.567 145.567 0 0 0 5.342-4.923a168.064 168.064 0 0 0 6.92 6.314c21.758 18.722 43.246 26.282 56.54 18.586c13.731-7.949 18.194-32.003 12.4-61.268a145.016 145.016 0 0 0-1.535-6.842c1.62-.48 3.21-.974 4.76-1.488c29.348-9.723 48.443-25.443 48.443-41.52c0-15.417-17.868-30.326-45.517-39.844Zm-6.365 70.984c-1.4.463-2.836.91-4.3 1.345c-3.24-10.257-7.612-21.163-12.963-32.432c5.106-11 9.31-21.767 12.459-31.957c2.619.758 5.16 1.557 7.61 2.4c23.69 8.156 38.14 20.213 38.14 29.504c0 9.896-15.606 22.743-40.946 31.14Zm-10.514 20.834c2.562 12.94 2.927 24.64 1.23 33.787c-1.524 8.219-4.59 13.698-8.382 15.893c-8.067 4.67-25.32-1.4-43.927-17.412a156.726 156.726 0 0 1-6.437-5.87c7.214-7.889 14.423-17.06 21.459-27.246c12.376-1.098 24.068-2.894 34.671-5.345a134.17 134.17 0 0 1 1.386 6.193ZM87.276 214.515c-7.882 2.783-14.16 2.863-17.955.675c-8.075-4.657-11.432-22.636-6.853-46.752a156.923 156.923 0 0 1 1.869-8.499c10.486 2.32 22.093 3.988 34.498 4.994c7.084 9.967 14.501 19.128 21.976 27.15a134.668 134.668 0 0 1-4.877 4.492c-9.933 8.682-19.886 14.842-28.658 17.94ZM50.35 144.747c-12.483-4.267-22.792-9.812-29.858-15.863c-6.35-5.437-9.555-10.836-9.555-15.216c0-9.322 13.897-21.212 37.076-29.293c2.813-.98 5.757-1.905 8.812-2.773c3.204 10.42 7.406 21.315 12.477 32.332c-5.137 11.18-9.399 22.249-12.634 32.792a134.718 134.718 0 0 1-6.318-1.979Zm12.378-84.26c-4.811-24.587-1.616-43.134 6.425-47.789c8.564-4.958 27.502 2.111 47.463 19.835a144.318 144.318 0 0 1 3.841 3.545c-7.438 7.987-14.787 17.08-21.808 26.988c-12.04 1.116-23.565 2.908-34.161 5.309a160.342 160.342 0 0 1-1.76-7.887Zm110.427 27.268a347.8 347.8 0 0 0-7.785-12.803c8.168 1.033 15.994 2.404 23.343 4.08c-2.206 7.072-4.956 14.465-8.193 22.045a381.151 381.151 0 0 0-7.365-13.322Zm-45.032-43.861c5.044 5.465 10.096 11.566 15.065 18.186a322.04 322.04 0 0 0-30.257-.006c4.974-6.559 10.069-12.652 15.192-18.18ZM82.802 87.83a323.167 323.167 0 0 0-7.227 13.238c-3.184-7.553-5.909-14.98-8.134-22.152c7.304-1.634 15.093-2.97 23.209-3.984a321.524 321.524 0 0 0-7.848 12.897Zm8.081 65.352c-8.385-.936-16.291-2.203-23.593-3.793c2.26-7.3 5.045-14.885 8.298-22.6a321.187 321.187 0 0 0 7.257 13.246c2.594 4.48 5.28 8.868 8.038 13.147Zm37.542 31.03c-5.184-5.592-10.354-11.779-15.403-18.433c4.902.192 9.899.29 14.978.29c5.218 0 10.376-.117 15.453-.343c-4.985 6.774-10.018 12.97-15.028 18.486Zm52.198-57.817c3.422 7.8 6.306 15.345 8.596 22.52c-7.422 1.694-15.436 3.058-23.88 4.071a382.417 382.417 0 0 0 7.859-13.026a347.403 347.403 0 0 0 7.425-13.565Zm-16.898 8.101a358.557 358.557 0 0 1-12.281 19.815a329.4 329.4 0 0 1-23.444.823c-7.967 0-15.716-.248-23.178-.732a310.202 310.202 0 0 1-12.513-19.846h.001a307.41 307.41 0 0 1-10.923-20.627a310.278 310.278 0 0 1 10.89-20.637l-.001.001a307.318 307.318 0 0 1 12.413-19.761c7.613-.576 15.42-.876 23.31-.876H128c7.926 0 15.743.303 23.354.883a329.357 329.357 0 0 1 12.335 19.695a358.489 358.489 0 0 1 11.036 20.54a329.472 329.472 0 0 1-11 20.722Zm22.56-122.124c8.572 4.944 11.906 24.881 6.52 51.026c-.344 1.668-.73 3.367-1.15 5.09c-10.622-2.452-22.155-4.275-34.23-5.408c-7.034-10.017-14.323-19.124-21.64-27.008a160.789 160.789 0 0 1 5.888-5.4c18.9-16.447 36.564-22.941 44.612-18.3ZM128 90.808c12.625 0 22.86 10.235 22.86 22.86s-10.235 22.86-22.86 22.86s-22.86-10.235-22.86-22.86s10.235-22.86 22.86-22.86Z"></path></svg>
</file>

<file path="examples/cloudflare-vite/src/auth/issuer.ts">
// @ts-nocheck
import { issuer as openauthIssuer } from "@openauthjs/openauth";
import { GithubProvider } from "@openauthjs/openauth/provider/github";
import { CloudflareStorage } from "@openauthjs/openauth/storage/cloudflare";
import { env } from "cloudflare:workers";
import { Subjects } from "../auth/subjects.js";
const storage = CloudflareStorage({
  namespace: env.AUTH_STORE as any, // TODO: what is openauth doing weird with types?
});
// Create the OpenAuth issuer app
export const issuer = openauthIssuer({
  // Configure providers
  ttl: {
    // see: https://github.com/toolbeam/openauth/issues/133
    reuse: 61,
  },
  providers: {
    github: GithubProvider({
      clientID: env.GITHUB_CLIENT_ID,
      clientSecret: env.GITHUB_CLIENT_SECRET,
      scopes: ["user:email", "read:user"],
    }),
  },
  // Configure Cloudflare KV for storage
  storage,
  // Define our subjects (user data structure)
  subjects: Subjects,
  // Handle successful authentication
  async success(ctx, value) {
    let id = "";
    let name = "";
    let email = "";
    let avatar = "";
    // Handle different provider responses
    if (value.provider === "github") {
      // Get user data from GitHub
      const response = await fetch("https://api.github.com/user", {
        headers: {
          Authorization: `Bearer ${value.tokenset.access}`,
          "User-Agent": "gorogue.sh",
        },
      });
      if (response.ok) {
        const data: any = await response.json();
        console.log(data);
        id = data.id.toString();
        name = data.name || data.login;
        email = data.email || "";
        avatar = data.avatar_url || "";
      } else {
        console.log("Error Getting User Data", await response.text());
      }
    } else {
      throw new Error(`Unsupported provider: ${value.provider}`);
    }
    // Create the user subject with the data
    return ctx.subject("user", {
      id,
      name,
      email,
      avatar,
    });
  },
});
</file>

<file path="examples/cloudflare-vite/src/auth/subjects.ts">
import { createSubjects } from "@openauthjs/openauth/subject";
import type { InferOutput } from "valibot";
import { object, string } from "valibot";
export type User = InferOutput<typeof User>;
export const User = object({
  id: string(),
  name: string(),
  email: string(),
  avatar: string(),
});
export interface Subjects {
  user: InferOutput<typeof User>;
}
// Define our subject structure
export const Subjects = createSubjects({
  user: User,
});
</file>

<file path="examples/cloudflare-vite/src/App.css">
#root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}
.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}
@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}
@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}
.card {
  padding: 2em;
}
.read-the-docs {
  color: #888;
}
</file>

<file path="examples/cloudflare-vite/src/App.tsx">
import { useState } from "react";
import reactLogo from "./assets/react.svg";
import viteLogo from "/vite.svg";
import "./App.css";
function App() {
  const [count, setCount] = useState(0);
  return (
    <>
      <div>
        <a href="https://vite.dev" target="_blank" rel="noopener">
          <img src={viteLogo} className="logo" alt="Vite logo" />
        </a>
        <a href="https://react.dev" target="_blank" rel="noopener">
          <img src={reactLogo} className="logo react" alt="React logo" />
        </a>
      </div>
      <h1>Vite + React</h1>
      <div className="card">
        <button onClick={() => setCount((count) => count + 1)}>
          count is {count}
        </button>
        <p>
          Edit <code>src/App.tsx</code> and save to test HMR
        </p>
      </div>
      <p className="read-the-docs">
        Click on the Vite and React logos to learn more
      </p>
    </>
  );
}
export default App;
</file>

<file path="examples/cloudflare-vite/src/env.d.ts">
/// <reference types="./env.d.ts" />
import type { website } from "../alchemy.run.js";
export type CloudFlareEnv = typeof website.Env;
declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends CloudFlareEnv {}
  }
}
</file>

<file path="examples/cloudflare-vite/src/index.css">
:root {
  font-family: system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;
  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;
  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}
body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}
h1 {
  font-size: 3.2em;
  line-height: 1.1;
}
button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}
@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
}
</file>

<file path="examples/cloudflare-vite/src/index.ts">
import { Hono } from "hono";
// TODO: looks like openauth imports node:fs ...
// import { issuer } from "./auth/issuer";
export const api = new Hono();
api.get("/hello", (c) => c.text("Hello World"));
export default {
  async fetch(request: Request): Promise<Response> {
    return api.fetch(request);
  },
};
</file>

<file path="examples/cloudflare-vite/src/main.tsx">
import { StrictMode } from "react";
import { createRoot } from "react-dom/client";
import "./index.css";
import App from "./App.tsx";
createRoot(document.getElementById("root")!).render(
  <StrictMode>
    <App />
  </StrictMode>,
);
</file>

<file path="examples/cloudflare-vite/src/vite-env.d.ts">
/// <reference types="vite/client" />
</file>

<file path="examples/cloudflare-vite/.gitignore">
/wrangler.*
/.wrangler
</file>

<file path="examples/cloudflare-vite/alchemy.run.ts">
/// <reference types="node" />
import alchemy from "../../alchemy/src/";
import {
  KVNamespace,
  R2Bucket,
  R2RestStateStore,
  Vite,
} from "../../alchemy/src/cloudflare";
const BRANCH_PREFIX = process.env.BRANCH_PREFIX ?? "";
const app = await alchemy("cloudflare-vite", {
  stage: process.env.USER ?? "dev",
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  quiet: !process.argv.includes("--verbose"),
  password: process.env.ALCHEMY_PASSWORD,
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
});
export const [authStore, storage] = await Promise.all([
  KVNamespace("AUTH_STORE", {
    title: `cloudflare-vite-auth-store${BRANCH_PREFIX}`,
  }),
  R2Bucket(`cloudflare-vite-storage${BRANCH_PREFIX}`, {
    allowPublicAccess: false,
    // so that CI is idempotent
    adopt: true,
  }),
]);
export const website = await Vite(`cloudflare-vite-website${BRANCH_PREFIX}`, {
  main: "./src/index.ts",
  command: "bun run build",
  bindings: {
    STORAGE: storage,
    AUTH_STORE: authStore,
  },
});
console.log({
  url: website.url,
});
await app.finalize();
</file>

<file path="examples/cloudflare-vite/index.html">
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React + TS</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
</file>

<file path="examples/cloudflare-vite/package.json">
{
  "name": "vite-project",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc -b && vite build",
    "deploy": "bun run --env-file ../../.env ./alchemy.run.ts",
    "destroy": "bun run --env-file ../../.env ./alchemy.run.ts --destroy",
    "lint": "eslint .",
    "preview": "vite preview"
  },
  "dependencies": {
    "@openauthjs/openauth": "^0.4.3",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "valibot": "^1.0.0"
  },
  "devDependencies": {
    "@cloudflare/vite-plugin": "^1.0.4",
    "@eslint/js": "^9.21.0",
    "@types/node": "^22.13.10",
    "@types/react": "^19.0.10",
    "@types/react-dom": "^19.0.4",
    "@vitejs/plugin-react": "^4.3.4",
    "cloudflare": "^4.2.0",
    "dotenv": "^16.4.7",
    "eslint": "^9.21.0",
    "eslint-plugin-react-hooks": "^5.1.0",
    "eslint-plugin-react-refresh": "^0.4.19",
    "globals": "^15.15.0",
    "tsx": "^4.19.3",
    "typescript": "~5.7.2",
    "typescript-eslint": "^8.24.1",
    "vite": "^6.2.0"
  }
}
</file>

<file path="examples/cloudflare-vite/tsconfig.json">
{
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "types": ["@cloudflare/workers-types"],
    "allowImportingTsExtensions": true,
    "jsx": "react-jsx"
  },
  "include": ["vite/*.ts", "src/**/*.ts", "src/**/*.tsx", "src/env.d.ts"],
  "references": [{ "path": "../../alchemy/tsconfig.json" }]
}
</file>

<file path="examples/cloudflare-vite/vite.config.ts">
import { cloudflare } from "@cloudflare/vite-plugin";
import react from "@vitejs/plugin-react";
import { defineConfig } from "vite";
// https://vite.dev/config/
export default defineConfig({
  plugins: [react(), cloudflare()],
});
</file>

<file path="examples/cloudflare-worker/src/do.ts">
/**
 * A simple Hello World Durable Object
 */
export class HelloWorldDO implements DurableObject {
  constructor(private readonly state: DurableObjectState) {}
  /**
   * Handle HTTP requests to the Durable Object
   */
  async fetch(request: Request): Promise<Response> {
    // Get the current count from storage or initialize to 0
    let count = (await this.state.storage.get("count")) || 0;
    // Store the updated count
    await this.state.storage.put("count", count);
    // Return a response with the count
    return new Response(
      JSON.stringify({
        message: "Hello World from Durable Object!",
        count: count,
        timestamp: new Date().toISOString(),
      }),
      {
        headers: {
          "Content-Type": "application/json",
        },
      },
    );
  }
}
</file>

<file path="examples/cloudflare-worker/src/env.d.ts">
/// <reference types="./env.d.ts" />
import type { worker } from "../alchemy.run.js";
export type CloudFlareEnv = typeof worker.Env;
declare module "cloudflare:workers" {
  namespace Cloudflare {
    export interface Env extends CloudFlareEnv {}
  }
}
</file>

<file path="examples/cloudflare-worker/src/worker.ts">
import type { queue, worker } from "../alchemy.run.js";
export * from "./do.js";
export * from "./workflow.js";
export default {
  async fetch(request: Request, env: typeof worker.Env) {
    await env.QUEUE.send({
      name: "John Doe",
      email: "john.doe@example.com",
    });
    return new Response("Ok");
  },
  async queue(batch: typeof queue.Batch, env: typeof worker.Env) {
    for (const message of batch.messages) {
      console.log(message);
      message.ack();
    }
    batch.ackAll();
  },
};
</file>

<file path="examples/cloudflare-worker/.gitignore">
wrangler.jsonc
</file>

<file path="examples/cloudflare-worker/alchemy.run.ts">
import alchemy from "../../alchemy/src";
import {
  DurableObjectNamespace,
  Queue,
  R2Bucket,
  R2RestStateStore,
  Worker,
  Workflow,
  WranglerJson,
} from "../../alchemy/src/cloudflare";
const BRANCH_PREFIX = process.env.BRANCH_PREFIX ?? "";
const app = await alchemy("cloudflare-worker", {
  phase: process.argv.includes("--destroy") ? "destroy" : "up",
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
});
export const queue = await Queue<{
  name: string;
  email: string;
}>(`cloudflare-worker-queue${BRANCH_PREFIX}`);
export const worker = await Worker(`cloudflare-worker-worker${BRANCH_PREFIX}`, {
  entrypoint: "./src/worker.ts",
  bindings: {
    BUCKET: await R2Bucket(`cloudflare-worker-bucket${BRANCH_PREFIX}`, {
      // so that CI is idempotent
      adopt: true,
    }),
    QUEUE: queue,
    WORKFLOW: new Workflow("OFACWorkflow", {
      className: "OFACWorkflow",
      workflowName: "ofac-workflow",
    }),
    DO: new DurableObjectNamespace("HelloWorldDO", {
      className: "HelloWorldDO",
      sqlite: true,
    }),
  },
  url: true,
  eventSources: [queue],
  bundle: {
    metafile: true,
    format: "esm",
    target: "es2020",
  },
});
await WranglerJson("wrangler.jsonc", {
  worker,
});
console.log(worker.url);
await app.finalize();
</file>

<file path="examples/cloudflare-worker/package.json">
{
  "name": "cloudflare-worker",
  "private": true,
  "type": "module",
  "scripts": {
    "deploy": "bun run --env-file ../../.env ./alchemy.run.ts",
    "destroy": "bun run --env-file ../../.env ./alchemy.run.ts --destroy"
  },
  "dependencies": {
    "braintrust": "^0.0.201",
    "chalk": "^5.4.1",
    "pluralize": "^8.0.0",
    "cli-progress": "^3.12.0"
  }
}
</file>

<file path="examples/cloudflare-worker/tsconfig.json">
{
  "include": ["src/*.ts"],
  "extends": "../../tsconfig.base.json",
  "compilerOptions": {
    "types": ["@cloudflare/workers-types", "@types/node"]
  },
  "references": [
    {
      "path": "../../alchemy/tsconfig.json"
    }
  ]
}
</file>

<file path="scripts/shell.ts">
import { exec } from "../alchemy/src/os/exec.js";
import { website } from "../stacks/website.run.js";
const command = process.argv.slice(2).join(" ");
if (!command) {
  console.error("No command provided");
  process.exit(1);
}
await exec(command, {
  env: {
    WEBSITE_URL: website.url,
  },
});
</file>

<file path="scripts/smoke.sh">
#!/bin/bash
# Exit immediately if a command exits with a non-zero status.
set -e
# Get the root directory of the script
SCRIPT_DIR=$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &> /dev/null && pwd)
ROOT_DIR=$(dirname "$SCRIPT_DIR")
EXAMPLES_DIR="$ROOT_DIR/examples"
if [ ! -d "$EXAMPLES_DIR" ]; then
  echo "Error: Directory '$EXAMPLES_DIR' does not exist."
  exit 1
fi
echo "Running smoke tests..."
# Loop through each subdirectory in the examples directory
for dir in "$EXAMPLES_DIR"/*/; do
  if [ -d "$dir" ]; then
    EXAMPLE_NAME=$(basename "$dir")
    # Skip the aws-app directory
    if [ "$EXAMPLE_NAME" = "aws-app" ]; then
      echo "--- Skipping: $EXAMPLE_NAME ---"
      echo ""
      continue
    fi
    echo "--- Processing: $EXAMPLE_NAME ---"
    # Change into the example directory and run commands
    (
      cd "$dir"
      echo "  Running deploy..."
      if [ -f "../../.env" ]; then
        bun --env-file ../../.env ./alchemy.run.ts
        bun --env-file ../../.env ./alchemy.run.ts --destroy
      # If we're using Cloudflare state store in CI, verify .alchemy/ folder doesn't exist
      if [ "$ALCHEMY_STATE_STORE" = "cloudflare" ] && [ "$CI" = "true" ]; then
        echo "  Verifying no local state files were created..."
        if [ -d ".alchemy" ]; then
          echo "  Error: .alchemy/ directory exists when using Cloudflare state store in CI"
          exit 1
        fi
      fi
      else
        bun ./alchemy.run.ts
        bun ./alchemy.run.ts --destroy
      fi
    ) # Run in a subshell to automatically return to the original directory
    echo "--- Completed: $EXAMPLE_NAME ---"
    echo ""
  fi
done
echo "All examples processed successfully."
exit 0
</file>

<file path="stacks/docs.run.ts">
import path from "node:path";
import "../alchemy/src/fs";
import "../alchemy/src/web/vitepress";
import alchemy from "../alchemy/src";
import { CopyFile } from "../alchemy/src/fs/copy-file.js";
import { Folder } from "../alchemy/src/fs/folder.js";
import { Providers } from "../alchemy/src/internal/docs/providers.js";
import { VitepressProject } from "../alchemy/src/web/vitepress";
import env from "./env.js";
const app = await alchemy("alchemy:docs", env);
const project = await VitepressProject("vitepress", {
  name: "alchemy-web",
  delete: true,
});
const docs = await Folder("docs", {
  path: path.join(project.dir, "docs"),
});
const [pub, blogs, guides, providers, conceptsDir] = await Promise.all([
  Folder("public", {
    path: path.join(project.dir, "public"),
  }),
  Folder("blogs", {
    path: path.join(project.dir, "blogs"),
  }),
  Folder("guides", {
    path: path.join(docs.path, "guides"),
  }),
  Folder("providers", {
    path: path.join(docs.path, "providers"),
  }),
  Folder("concepts", {
    path: path.join(docs.path, "concepts"),
  }),
]);
await CopyFile("docs-public-alchemist", {
  src: path.join(process.cwd(), "public", "alchemist.webp"),
  dest: path.join(pub.path, "alchemist.webp"),
});
const filterIdx = process.argv.findIndex((arg) => arg === "--filter");
await Providers({
  srcDir: path.join("alchemy", "src"),
  outDir: providers.path,
  // anthropic throttles are painful, so we'll run them serially
  parallel: false,
  filter:
    process.argv[filterIdx + 1] === "true"
      ? true
      : filterIdx > -1
        ? Number.isNaN(Number.parseInt(process.argv[filterIdx + 1]))
          ? false
          : Number.parseInt(process.argv[filterIdx + 1])
        : false,
});
await app.finalize();
</file>

<file path="stacks/env.ts">
import alchemy from "../alchemy/src";
import type { AlchemyOptions, Phase } from "../alchemy/src/alchemy.js";
import { R2RestStateStore } from "../alchemy/src/cloudflare";
export const CLOUDFLARE_EMAIL = await alchemy.env.CLOUDFLARE_EMAIL;
export const CLOUDFLARE_ACCOUNT_ID = await alchemy.env.CLOUDFLARE_ACCOUNT_ID;
export const CLOUDFLARE_API_KEY = await alchemy.secret.env.CLOUDFLARE_API_KEY;
export const STRIPE_API_KEY = await alchemy.secret.env.STRIPE_API_KEY;
export const OPENAI_API_KEY = await alchemy.secret.env.OPENAI_API_KEY;
export const NEON_API_KEY = await alchemy.secret.env.NEON_API_KEY;
export default {
  stage: "prod",
  phase:
    (process.env.ALCHEMY_PHASE as Phase) ??
    (process.argv.includes("--destroy")
      ? "destroy"
      : process.argv.includes("--read")
        ? "read"
        : "up"),
  // pass the password in (you can get it from anywhere, e.g. stdin)
  password: process.env.SECRET_PASSPHRASE,
  quiet: process.argv.includes("--quiet"),
  stateStore:
    process.env.ALCHEMY_STATE_STORE === "cloudflare"
      ? (scope) => new R2RestStateStore(scope)
      : undefined,
} satisfies AlchemyOptions;
</file>

<file path="stacks/repo.run.ts">
// ensure providers are registered (for deletion purposes)
import "../alchemy/src/aws";
import "../alchemy/src/aws/oidc";
import "../alchemy/src/cloudflare";
import "../alchemy/src/os";
import alchemy from "../alchemy/src";
import { AccountId, Role } from "../alchemy/src/aws";
import { GitHubOIDCProvider } from "../alchemy/src/aws/oidc";
import {
  AccountApiToken,
  PermissionGroups,
  R2Bucket,
} from "../alchemy/src/cloudflare";
import { GitHubSecret, RepositoryEnvironment } from "../alchemy/src/github";
import env, {
  CLOUDFLARE_ACCOUNT_ID,
  CLOUDFLARE_API_KEY,
  CLOUDFLARE_EMAIL,
  NEON_API_KEY,
  OPENAI_API_KEY,
  STRIPE_API_KEY,
} from "./env.js";
const app = await alchemy("alchemy:repo", env);
const awsAccountId = await AccountId();
const githubRole = await Role("github-oidc-role", {
  roleName: "alchemy-github-oidc-role",
  assumeRolePolicy: {
    Version: "2012-10-17",
    Statement: [
      {
        Sid: "GitHubOIDC",
        Effect: "Allow",
        Principal: {
          Federated: `arn:aws:iam::${awsAccountId}:oidc-provider/token.actions.githubusercontent.com`,
        },
        Action: "sts:AssumeRoleWithWebIdentity",
        Condition: {
          StringEquals: {
            "token.actions.githubusercontent.com:aud": "sts.amazonaws.com",
          },
          StringLike: {
            "token.actions.githubusercontent.com:sub":
              "repo:sam-goodwin/alchemy:*",
          },
        },
      },
    ],
  },
  // TODO: probably scope this down
  managedPolicyArns: ["arn:aws:iam::aws:policy/AdministratorAccess"],
});
const stateStore = await R2Bucket("state-store", {
  name: "alchemy-state-store",
});
const testEnvironment = await RepositoryEnvironment("test environment", {
  owner: "sam-goodwin",
  repository: "alchemy",
  name: "test",
  reviewers: {
    users: ["sam-goodwin"],
  },
});
const permissions = await PermissionGroups("cloudflare-permissions", {
  // TODO: remove this once we have a way to get the account ID from the API
  accountId: CLOUDFLARE_ACCOUNT_ID,
});
const accountAccessToken = await AccountApiToken("account-access-token", {
  name: "alchemy-account-access-token",
  policies: [
    {
      effect: "allow",
      permissionGroups: [{ id: permissions["Workers R2 Storage Write"].id }],
      resources: {
        [`com.cloudflare.api.account.${CLOUDFLARE_ACCOUNT_ID}`]: "*",
      },
    },
  ],
});
await Promise.all([
  GitHubOIDCProvider("github-oidc", {
    owner: "sam-goodwin",
    repository: "alchemy",
    roleArn: githubRole.arn,
  }),
  ...Object.entries({
    AWS_ROLE_ARN: githubRole.arn,
    CLOUDFLARE_ACCOUNT_ID,
    CLOUDFLARE_API_KEY,
    CLOUDFLARE_EMAIL,
    STRIPE_API_KEY,
    OPENAI_API_KEY,
    NEON_API_KEY,
    CLOUDFLARE_BUCKET_NAME: stateStore.name,
    R2_ACCESS_KEY_ID: accountAccessToken.accessKeyId,
    R2_SECRET_ACCESS_KEY: accountAccessToken.secretAccessKey,
    SECRET_PASSPHRASE: alchemy.secret(process.env.SECRET_PASSPHRASE!),
  }).flatMap(async ([name, value]) => {
    const props = {
      owner: "sam-goodwin",
      repository: "alchemy",
      name,
      value: typeof value === "string" ? alchemy.secret(value) : await value!,
    };
    return [
      GitHubSecret(`github-secret-${name}`, {
        ...props,
        environment: testEnvironment.name,
      }),
      GitHubSecret(`github-repo-secret-${name}`, props),
    ];
  }),
]);
await app.finalize();
</file>

<file path="stacks/website.run.ts">
// ensure providers are registered (for deletion purposes)
import "../alchemy/src/cloudflare";
import "../alchemy/src/dns";
import "../alchemy/src/os";
import path from "node:path";
import alchemy from "../alchemy/src";
import { Assets, CustomDomain, Worker, Zone } from "../alchemy/src/cloudflare";
import { Exec } from "../alchemy/src/os";
import options from "./env.js";
const app = await alchemy("alchemy:website", options);
const zone = await Zone("alchemy.run", {
  name: "alchemy.run",
  type: "full",
});
await Exec("build-site", {
  command: "bun run --filter alchemy-web docs:build",
});
const staticAssets = await Assets("static-assets", {
  path: path.join("alchemy-web", ".vitepress", "dist"),
});
export const website = await Worker("website", {
  name: "alchemy-website",
  url: true,
  bindings: {
    ASSETS: staticAssets,
  },
  assets: {
    html_handling: "auto-trailing-slash",
    // not_found_handling: "single-page-application",
    run_worker_first: false,
  },
  script: `
export default {
  async fetch(request, env) {
    // return env.ASSETS.fetch(request);
    return new Response("Not Found", { status: 404 });
  },
};
`,
});
await CustomDomain("alchemy-web-domain", {
  name: "alchemy.run",
  zoneId: zone.id,
  workerName: website.name,
});
await app.finalize();
</file>

<file path=".cursorrules">
Always use bun to install dependencies.

All dependencies must be peer dependencies.

Always use alchemy.secret() instead of new Secret() to create secrets.

# Running Tests with Bun

We use Bun for testing. Here's how to run tests:

```bash
# Run all tests
bun test

# Run tests in a specific file
bun test alchemy/test/stripe/price.test.ts

# Run a specific test in a specific file
bun test --test-name-pattern="create and update price" alchemy/test/stripe/price.test.ts
```

For resource tests, create a dedicated test file for each resource type following the pattern `alchemy/test/service-name/resource-name.test.ts`.

# Creating a New Service Resource

This guide provides step-by-step instructions for creating a new resource for a service (like Stripe's Price, Product, or Webhook resources).

## Step 1: Create the Resource File

Create a new file in the service directory with kebab-case naming:

```
alchemy/src/{{service-name}}/{{resource-name}}.ts
```

Example: `alchemy/src/stripe/price.ts`

## Step 2: Define Resource Interfaces

Start by importing dependencies and defining the resource interfaces:

```typescript
import type { Context } from "../context";
import { Resource } from "../resource";

/**
 * Properties for creating or updating a {{ResourceName}}
 */
export interface {{ResourceName}}Props {
  /**
   * {{Property description}}
   */
  propertyName: string;

  /**
   * {{Property description}}
   */
  anotherProperty?: number;

  // Add all required and optional properties
  // Include JSDoc comments for each property
}

/**
 * Output returned after {{ResourceName}} creation/update
 * IMPORTANT: The interface name MUST match the exported resource name
 * For example, if your resource is exported as "Product", this interface
 * should be named "Product" (not "ProductOutput")
 * 
 */
export interface {{ResourceName}} extends Resource<"{{service-name}}::{{ResourceName}}"> {{ResourceName}}Props {
  /**
   * The ID of the resource
   */
  id: string;

  /**
   * Time at which the object was created
   */
  createdAt: number;

  // Add all additional properties returned by the service
  // Include JSDoc comments for each property
}
```

## Step 3: API Client Implementation

Create a minimal API client that wraps fetch calls without excessive abstraction:

```typescript
/**
 * Options for {{ServiceName}} API requests
 */
export interface {{ServiceName}}ApiOptions {
  /**
   * API key or token to use (overrides environment variable)
   */
  apiKey?: string;

  /**
   * Account or project ID (overrides environment variable)
   */
  accountId?: string;
}

/**
 * Minimal API client using raw fetch
 */
export class {{ServiceName}}Api {
  /** Base URL for API */
  readonly baseUrl: string;

  /** API key or token */
  readonly apiKey: string;

  /** Account ID */
  readonly accountId: string;

  /**
   * Create a new API client
   *
   * @param options API options
   */
  constructor(options: {{ServiceName}}ApiOptions = {}) {
    // Initialize with environment variables or provided values
    this.baseUrl = "https://api.{{service-name}}.com/v1";
    this.apiKey = options.apiKey || process.env.{{SERVICE_API_KEY}} || '';
    this.accountId = options.accountId || process.env.{{SERVICE_ACCOUNT_ID}} || '';

    // Validate required configuration
    if (!this.apiKey) {
      throw new Error("{{SERVICE_API_KEY}} environment variable is required");
    }
  }

  /**
   * Make a request to the API
   *
   * @param path API path (without base URL)
   * @param init Fetch init options
   * @returns Raw Response object from fetch
   */
  async fetch(path: string, init: RequestInit = {}): Promise<Response> {
    // Set up authentication headers
    const headers: Record<string, string> = {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${this.apiKey}`
    };

    // Add headers from init if provided
    if (init.headers) {
      const initHeaders = init.headers as Record<string, string>;
      Object.keys(initHeaders).forEach(key => {
        headers[key] = initHeaders[key];
      });
    }

    // For FormData, remove Content-Type
    if (init.body instanceof FormData) {
      delete headers["Content-Type"];
    }

    // Make the request
    return fetch(`${this.baseUrl}${path}`, {
      ...init,
      headers
    });
  }

  /**
   * Helper for GET requests
   */
  async get(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "GET" });
  }

  /**
   * Helper for POST requests
   */
  async post(path: string, body: any, init: RequestInit = {}): Promise<Response> {
    const requestBody = body instanceof FormData ? body : JSON.stringify(body);
    return this.fetch(path, { ...init, method: "POST", body: requestBody });
  }

  /**
   * Helper for PUT requests
   */
  async put(path: string, body: any, init: RequestInit = {}): Promise<Response> {
    const requestBody = body instanceof FormData ? body : JSON.stringify(body);
    return this.fetch(path, { ...init, method: "PUT", body: requestBody });
  }

  /**
   * Helper for DELETE requests
   */
  async delete(path: string, init: RequestInit = {}): Promise<Response> {
    return this.fetch(path, { ...init, method: "DELETE" });
  }
}
```

## Step 4: Implement the Resource

Create the resource with the pseudo-class pattern using `this` with Context type. The exported const MUST match the output interface name:

```typescript
/**
 * (Resource description)
 * 
 * (followed by examples for distinct use-cases of the Resource)
 * 
 * @example
 * // Create a basic table with just a hash key for simple 
 * // key-value lookups:
 * const basicTable = await DynamoTable("users", {
 *   hashKey: {
 *     name: "userId",
 *     type: "string"
 *   }
 * });
 * 
 * @example
 * // Create a time-series table with hash and sort key 
 * // for efficient range queries:
 * const timeSeriesTable = await DynamoTable("events", {
 *   hashKey: {
 *     name: "deviceId",
 *     type: "string"
 *   },
 *   sortKey: {
 *     name: "timestamp",
 *     type: "number"
 *   }
 * });
 * 
 * @example
 * // Create a table with a global secondary index 
 * // for alternate access patterns:
 * const ordersTable = await DynamoTable("orders", {
 *   hashKey: {
 *     name: "orderId",
 *     type: "string"
 *   },
 *   globalSecondaryIndexes: [{
 *     indexName: "by-customer",
 *     hashKey: {
 *       name: "customerId",
 *       type: "string"
 *     },
 *     sortKey: {
 *       name: "orderDate",
 *       type: "string"
 *     }
 *   }]
 * });
 * 
 * @example
 * // Create a one-time fixed price for a product:
 * const oneTimePrice = await Price("basic-license", {
 *   currency: "usd",
 *   unitAmount: 2999,
 *   product: "prod_xyz"
 * });
 * 
 * @example
 * // Create a recurring subscription price with fixed 
 * // monthly billing:
 * const subscriptionPrice = await Price("pro-monthly", {
 *   currency: "usd",
 *   unitAmount: 1499,
 *   product: "prod_xyz",
 *   recurring: {
 *     interval: "month",
 *     usageType: "licensed"
 *   }
 * });
 * 
 * @example
 * // Create a metered price for usage-based billing:
 * const meteredPrice = await Price("storage", {
 *   currency: "usd",
 *   unitAmount: 25,
 *   product: "prod_xyz",
 *   recurring: {
 *     interval: "month",
 *     usageType: "metered",
 *     aggregateUsage: "sum"
 *   }
 * });
 */
export const {{ResourceName}} = Resource(
  "{{service-name}}::{{ResourceName}}",
  async function(this: Context<{{ResourceName}}>, id: string, props: {{ResourceName}}Props): Promise<{{ResourceName}}> {
    // Get API key from environment
    const apiKey = process.env.{{SERVICE_API_KEY}};
    if (!apiKey) {
      throw new Error("{{SERVICE_API_KEY}} environment variable is required");
    }

    // Initialize API client
    const api = new {{ServiceName}}Api();

    if (this.phase === "delete") {
      try {
        if (this.output?.id) {
          // Delete resource
          const deleteResponse = await api.delete(`/accounts/${api.accountId}/resources/${this.output.id}`);

          // Check response status directly instead of relying on exceptions
          if (!deleteResponse.ok && deleteResponse.status !== 404) {
            console.error("Error deleting resource:", deleteResponse.statusText);
          }
        }
      } catch (error) {
        console.error("Error deleting resource:", error);
      }

      // Return destroyed state
      return this.destroy();
    } else {
      try {
        let response;

        if (this.phase === "update" && this.output?.id) {
          // Update existing resource
          response = await api.put(
            `/accounts/${api.accountId}/resources/${this.output.id}`,
            {
              // Map props to API-expected format
              name: props.name,
              description: props.description
            }
          );
        } else {
          // Create new resource
          response = await api.post(
            `/accounts/${api.accountId}/resources`,
            {
              // Map props to API-expected format
              name: props.name,
              description: props.description
            }
          );
        }

        // Check response status directly
        if (!response.ok) {
          throw new Error(`API error: ${response.statusText}`);
        }

        // Parse response JSON
        const data = await response.json();
        const resource = data.result || data;

        // Return the resource using this() to construct output
        return this({
          id: resource.id,
          name: resource.name,
          description: resource.description,
          createdAt: resource.created_at || Date.now(),
          // Include all other required properties from the interface
          ...props // Include any additional properties from props
        });
      } catch (error) {
        console.error("Error creating/updating resource:", error);
        throw error;
      }
    }
  }
);
```

### Important Notes on Resource Implementation

1. **Pseudo-Class Pattern**: The resource is implemented as a constant that matches the interface name, creating a pseudo-class construct:

   ```typescript
   export interface Product extends ProductProps {...}
   export const Product = Resource(...);
   ```

2. **Context Type**: The implementation function uses `this: Context<T>` to provide type-safe access to the resource context.

3. **Phase Handling**:

   - Use `this.phase` to check the current operation phase ("create", "update", or "delete")
   - For deletion, return `this.destroy()`
   - For creation/update, return `this({...})` with the resource properties

4. **Output Construction**:

   - Use `this({...})` to construct the resource output
   - Include all required properties from the interface
   - Spread the props object to include any additional properties

5. **Error Handling**:
   - Check response status codes directly
   - Preserve original error details when possible
   - Log errors before rethrowing

## Step 5: Export from Service Index

Create or update the service index file to export the new resource:

```typescript
// alchemy/src/{{service-name}}/index.ts
export * from "./{{resource-name}}";
```

## Step 6: Update Package.json

Add the service to package.json exports if not already present:

```json
"exports": {
  // ... existing exports
  "./{{service-name}}": "./lib/{{service-name}}/index.js"
}
```

Add the service SDK as a peer dependency if not already present:

```json
"peerDependencies": {
  // ... existing dependencies
  "{{service-sdk}}": "^x.y.z"
}
```

## Step 7: Create Tests

Create a test file that uses direct API interaction for verification:

```typescript
// alchemy/test/{{service-name}}/{{resource-name}}.test.ts
import { describe, expect } from "bun:test";
import { alchemy } from "../../src/alchemy";
import { destroy } from "../../src/destroy";
import { {{ResourceName}} } from "../../src/{{service-name}}/{{resource-name}}";
import { {{ServiceName}}Api } from "../../src/{{service-name}}/api";
import { BRANCH_PREFIX } from "../util";
// must import this or else alchemy.test won't exist
import "../../src/test/bun";

const api = new {{ServiceName}}Api();

const test = alchemy.test(import.meta);

describe("{{ResourceName}} Resource", () => {
  // Use BRANCH_PREFIX for deterministic, non-colliding resource names
  const testId = `${BRANCH_PREFIX}-test-resource`;

  test("create, update, and delete resource", async (scope) => {
    let resource: {{ResourceName}} | undefined;
    try {
      // Create a test resource
      resource = await {{ResourceName}}(testId, {
        name: `Test Resource ${testId}`,
        description: "This is a test resource"
      });

      expect(resource.id).toBeTruthy();
      expect(resource.name).toEqual(`Test Resource ${testId}`);

      // Verify resource was created by querying the API directly
      const getResponse = await api.get(`/accounts/${api.accountId}/resources/${resource.id}`);
      expect(getResponse.status).toEqual(200);

      const responseData = await getResponse.json();
      expect(responseData.result.name).toEqual(`Test Resource ${testId}`);

      // Update the resource
      resource = await {{ResourceName}}(testId, {
        name: `Updated Resource ${testId}`,
        description: "This is an updated test resource"
      });

      expect(resource.id).toEqual(resource.id);
      expect(resource.name).toEqual(`Updated Resource ${testId}`);

      // Verify resource was updated
      const getUpdatedResponse = await api.get(`/accounts/${api.accountId}/resources/${resource.id}`);
      const updatedData = await getUpdatedResponse.json();
      expect(updatedData.result.name).toEqual(`Updated Resource ${testId}`);
    } catch(err) {
      // log the error or else it's silently swallowed by destroy errors
      console.log(err);
      throw err;
    } finally {
      // Always clean up, even if test assertions fail
      await destroy(scope);

      // Verify resource was deleted
      const getDeletedResponse = await api.get(`/accounts/${api.accountId}/resources/${resource?.id}`);
      expect(getDeletedResponse.status).toEqual(404);
    }
  });
});
```

### Important Notes on Testing

1. **Test Scope**: Use `alchemy.test(import.meta)` to create a test with proper scope management.

2. **Resource Cleanup**:

   - Use `try/finally` to ensure resources are cleaned up
   - Call `destroy(scope)` to clean up all resources created in the test
   - Verify resources are properly deleted after cleanup

3. **Direct API Verification**:

   - Use the service's API client to verify changes directly
   - Check both successful operations and cleanup
   - Verify resource state after each operation

4. **Naming Convention**:

   - Use `BRANCH_PREFIX` for unique test resource names
   - Follow the pattern: `${BRANCH_PREFIX}-test-resource-type`
   - Keep names consistent and descriptive

5. **Error Handling**:
   - Let test failures propagate for visibility
   - Catch errors only in cleanup to ensure proper resource deletion
   - Log cleanup errors but don't throw

## Resource Naming Convention

When implementing resources, follow this important naming convention:

1. The output interface must have the same name as the exported resource. For example:

   - If your resource constant is `export const Product = Resource(...)`,
   - Then your output interface must be named "Product" (not "ProductOutput")

2. The name of the interface and the exported constant create a pseudo-class construct:

   ```typescript
   // This naming pattern allows the resource to work correctly with type system
   export interface Product extends ProductProps {...}
   export const Product = Resource(...);
   ```

3. Always use this pattern for consistency across resources.

## API Design Principles

When implementing resources that interact with external APIs, follow these design principles:

1. **Minimal abstraction**: Use a thin wrapper around fetch rather than complex SDK clients.

2. **Explicit path construction**: Construct API paths explicitly at the call site instead of using helper methods:

   ```typescript
   // DO THIS:
   await api.get(`/accounts/${api.accountId}/resources/${resourceId}`);

   // NOT THIS:
   await api.get(api.accountPath(`/resources/${resourceId}`));
   ```

3. **Direct HTTP status handling**: Check response status codes directly rather than relying on exceptions:

   ```typescript
   // DO THIS:
   const response = await api.get(`/path/to/resource`);
   if (!response.ok) {
     // Handle error case
   }

   // NOT THIS:
   try {
     const data = await api.get(`/path/to/resource`);
   } catch (error) {
     // Handle error
   }
   ```

4. **Explicit JSON parsing**: Parse JSON responses explicitly where needed:

   ```typescript
   const response = await api.get(`/path/to/resource`);
   if (response.ok) {
     const data = await response.json();
     // Process data
   }
   ```

5. **Public properties over helper methods**: Expose properties like `api.accountId` publicly to construct URLs instead of creating helper methods.

6. **Minimal error transformation**: Report errors with minimal transformation to preserve original error details.

## Using Raw Fetch Calls Instead of SDKs

Always prefer using raw fetch calls instead of service SDKs unless explicitly instructed not to by the user. This approach:

- Reduces dependency bloat
- Minimizes version compatibility issues
- Gives you more control over the request/response cycle
- Often results in smaller bundle sizes

For both implementation and tests, directly interact with APIs using fetch.

## Resource Implementation Pattern

Alchemy resources follow an async/await pattern with a pseudo-class implementation. Key concepts:

1. **Async/Await Pattern**:

   - Resources are implemented as async functions
   - Direct use of async/await for all operations
   - No Input<T>/Output<T> wrappers needed

2. **Pseudo-Class Structure**:

   ```typescript
   // Define the props interface
   export interface ResourceProps {
     name: string;
     // ... other properties
   }

   // Define the resource interface extending props
   export interface Resource extends ResourceProps {
     id: string;
     createdAt: number;
     // ... other properties
   }

   // Implement the resource
   export const Resource = Resource(
     "service::Resource",
     async function (
       this: Context<Resource>,
       id: string,
       props: ResourceProps
     ): Promise<Resource> {
       // Implementation
     }
   );
   ```

3. **Context Usage**:

   - Access context through `this: Context<T>`
   - Use `this.phase` for operation type ("create", "update", "delete")
   - Use `this.output` for current resource state
   - Use `this({...})` to construct resource output
   - Use `this.destroy()` for deletion

4. **Phase Handling**:

   ```typescript
   if (this.phase === "delete") {
     // Handle deletion
     return this.destroy();
   } else if (this.phase === "update") {
     // Handle update
     return this({ ...updatedProps });
   } else {
     // Handle create
     return this({ ...newProps });
   }
   ```

5. **Resource Construction**:

   ```typescript
   // Construct resource output
   return this({
     id: resourceId,
     ...props,
     // Add computed properties
     createdAt: Date.now(),
   });
   ```

6. **Error Handling**:
   ```typescript
   try {
     // Resource operations
   } catch (error) {
     console.error("Operation failed:", error);
     throw error; // Propagate errors
   }
   ```
</file>

<file path=".gitignore">
node_modules/
dist/
lib/
.out/
.test/
.env
*.tsbuildinfo

.alchemy/
# !.alchemy/github:alchemy/
# examples/*/.alchemy
</file>

<file path="biome.json">
{
  "files": {
    "includes": [
      "./alchemy/src/**",
      "./alchemy/test/**",
      "./scripts/**",
      "./examples/*/src/**",
      "./examples/*/alchemy.run.ts",
      "!**/node_modules"
    ]
  },
  "assist": {
    "actions": {
      "source": {
        "organizeImports": "off"
      }
    }
  },
  "linter": {
    "enabled": true,
    "rules": {
      "recommended": true,
      "correctness": {
        "useImportExtensions": {
          "level": "error",
          "options": {
            "forceJsExtensions": true
          }
        },
        "noUnsafeFinally": "off",
        "noChildrenProp": "off"
      },
      "a11y": {
        "useButtonType": "off",
        "useHtmlLang": "off"
      },
      "performance": {
        "noAccumulatingSpread": "off"
      },
      "complexity": {
        "noBannedTypes": "off"
      },
      "suspicious": {
        "noExplicitAny": "off",
        "noImplicitAnyLet": "off",
        "noAssignInExpressions": "off",
        "noShadowRestrictedNames": "off"
      },
      "style": {
        "useLiteralEnumMembers": "error",
        "noCommaOperator": "error",
        "useNodejsImportProtocol": "error",
        "useAsConstAssertion": "error",
        "useNumericLiterals": "error",
        "useEnumInitializers": "error",
        "useSelfClosingElements": "error",
        "useConst": "off",
        "useSingleVarDeclarator": "error",
        "noUnusedTemplateLiteral": "error",
        "useNumberNamespace": "error",
        "noInferrableTypes": "error",
        "useExponentiationOperator": "error",
        "useTemplate": "error",
        "noParameterAssign": "off",
        "noNonNullAssertion": "off",
        "useDefaultParameterLast": "error",
        "noArguments": "error",
        "useImportType": "error",
        "useExportType": "error",
        "noUselessElse": "off",
        "useShorthandFunctionType": "error"
      }
    }
  },
  "formatter": {
    "enabled": true,
    "formatWithErrors": false,
    "indentStyle": "space",
    "indentWidth": 2,
    "lineWidth": 80,
    "lineEnding": "lf",
    "includes": ["**", "!**/node_modules/**"]
  },
  "javascript": {
    "formatter": {
      "indentWidth": 2,
      "indentStyle": "space"
    }
  },
  "json": {
    "formatter": {
      "indentWidth": 2,
      "indentStyle": "space"
    }
  }
}
</file>

<file path="LICENSE">
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
</file>

<file path="package.json">
{
  "name": "alchemy-mono",
  "version": "0.0.0",
  "private": true,
  "type": "module",
  "module": "./lib/index.js",
  "license": "Apache-2.0",
  "scripts": {
    "build": "tsc -b",
    "check": "tsc -b ./tsconfig.json && biome check",
    "fix": "biome check --write",
    "deploy:repo": "bun ./stacks/repo.run.ts",
    "deploy:website": "bun ./stacks/website.run.ts",
    "generate:docs": "bun ./stacks/docs.run.ts",
    "publish:npm": "bun run --filter alchemy publish:npm",
    "test": "bun ./alchemy/test/run.ts",
    "test:smoke": "./scripts/smoke.sh"
  },
  "workspaces": [
    "alchemy",
    "alchemy-web",
    "examples/aws-app",
    "examples/cloudflare-vite",
    "examples/cloudflare-worker",
    "examples/cloudflare-nuxt-pipeline",
    "examples/cloudflare-redwood",
    "examples/cloudflare-worker"
  ],
  "devDependencies": {
    "@biomejs/biome": "beta",
    "@types/bun": "latest",
    "@types/node": "latest",
    "aws4fetch": "^1.0.20",
    "typescript": "latest",
    "yaml": "^2.7.1",
    "braintrust": "*"
  }
}
</file>

<file path="README.md">
# Alchemy

Alchemy is an embeddable, zero-dependency, TypeScript-native Infrastructure-as-Code (IaC) library for modeling Resources that are Created, Updated and Deleted automatically.

Unlike similar tools like Pulumi, Terraform, and CloudFormation, Alchemy is implemented in pure ESM-native TypeScript code with zero dependencies.

Resources are simple memoized async functions that can run in any JavaScript runtime, including the browser, serverless functions and durable workflows.

```ts
import alchemy from "alchemy";

// initialize the app (with default state $USER)
const app = await alchemy("cloudflare-worker");

// create a Cloudflare Worker
export const worker = await Worker("worker", {
  name: "my-worker",
  entrypoint: "./src/index.ts",
  bindings: {
    COUNTER: counter,
    STORAGE: storage,
    AUTH_STORE: authStore,
    GITHUB_CLIENT_ID: alchemy.secret(process.env.GITHUB_CLIENT_ID),
    GITHUB_CLIENT_SECRET: alchemy.secret(process.env.GITHUB_CLIENT_SECRET),
  },
});

// finalize the alchemy app (triggering deletion of orphaned resources)
await app.finalize();
```

# Features

- **JS-native** - no second language, toolchains, dependencies, processes, services, etc. to lug around.
- **Async-native** - resources are just async functions - no complex abstraction to learn.
- **ESM-native** - built exclusively on ESM, with a slight preference for modern JS runtimes like Bun.
- **Embeddable** - runs in any JavaScript/TypeScript environment, including the browser!
- **Extensible** - implement your own resources with a simple function.
- **AI-first** - alchemy actively encourages you to use LLMs to create/copy/fork/modify resources to fit your needs. No more waiting around for a provider to be implemented, just do it yourself in a few minutes.
- **No dependencies** - the `alchemy` core package has 0 required dependencies.
- **No service** - state files are stored locally in your project and can be easily inspected, modified, checked into your repo, etc.
- **No strong opinions** - structure your codebase however you want, store state anywhere - we don't care!

# Examples

- CloudFlare ViteJS Website + API Backend with Durable Objects: [examples/cloudflare-vite/](./examples/cloudflare-vite/alchemy.run.ts)
- Deploy an AWS Lambda Function with a DynamoDB Table and IAM Role: [examples/aws-app/](./examples/aws-app/alchemy.run.ts)

# Getting Started

See the [Getting Started Guide](https://alchemy.run/docs/getting-started.html).
</file>

<file path="tsconfig.base.json">
{
  "exclude": ["node_modules", "dist"],
  "compilerOptions": {
    "types": ["@cloudflare/workers-types", "@types/node"],
    // Enable latest features
    "lib": ["ESNext", "DOM"],
    "target": "ESNext",
    "moduleDetection": "force",
    "jsx": "react-jsx",
    "allowJs": true,
    "esModuleInterop": true,
    "noEmit": true,

    // Bundler mode
    "module": "Preserve",
    "moduleResolution": "Bundler",
    // "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,

    // Best practices
    "strict": true,
    "skipLibCheck": true,
    "noFallthroughCasesInSwitch": true,

    // Some stricter flags (disabled by default)
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "noPropertyAccessFromIndexSignature": false,

    "noImplicitThis": true
  }
}
</file>

<file path="tsconfig.json">
{
  "files": [],
  "exclude": ["node_modules", "dist"],
  "references": [
    { "path": "./tsconfig.stacks.json" },
    { "path": "./alchemy/tsconfig.json" },
    { "path": "./examples/aws-app/tsconfig.json" },
    { "path": "./examples/cloudflare-vite/tsconfig.json" },
    { "path": "./examples/cloudflare-nuxt-pipeline/tsconfig.json" },
    { "path": "./examples/cloudflare-redwood/tsconfig.json" },
    { "path": "./examples/cloudflare-tanstack-start/tsconfig.json" },
    { "path": "./examples/cloudflare-worker/tsconfig.json" }
  ]
}
</file>

<file path="tsconfig.stacks.json">
{
  "extends": "./tsconfig.base.json",
  "include": ["./stacks/**/*.ts", "scripts/shell.ts"],
  "compilerOptions": {
    "noEmit": true
  },
  "references": [{ "path": "./alchemy/tsconfig.json" }]
}
</file>

<file path="alchemy/src/aws/function.ts">
import {
  AddPermissionCommand,
  Architecture,
  CreateFunctionCommand,
  CreateFunctionUrlConfigCommand,
  DeleteFunctionCommand,
  DeleteFunctionUrlConfigCommand,
  GetFunctionCommand,
  GetFunctionConfigurationCommand,
  GetFunctionUrlConfigCommand,
  LambdaClient,
  ResourceNotFoundException,
  Runtime,
  UpdateFunctionCodeCommand,
  UpdateFunctionConfigurationCommand,
  UpdateFunctionUrlConfigCommand,
} from "@aws-sdk/client-lambda";
import type { Context } from "../context.js";
import type { Bundle } from "../esbuild/bundle.js";
import { Resource } from "../resource.js";
import { ignore } from "../util/ignore.js";
/**
 * Properties for creating or updating a Lambda function
 */
export interface FunctionProps {
  /**
   * Name of the Lambda function
   */
  functionName: string;
  /**
   * Bundle for the function
   */
  bundle: Bundle;
  /**
   * ARN of the IAM role that Lambda assumes when executing the function
   */
  roleArn: string;
  /**
   * Function handler in the format 'file.function'
   * For Node.js this is typically 'index.handler' or similar
   */
  handler: string;
  /**
   * Lambda runtime environment for the function
   * @default nodejs20.x if not specified
   */
  runtime?: Runtime;
  /**
   * CPU architecture for the function
   * @default x86_64 if not specified
   */
  architecture?: Architecture;
  /**
   * Description of the function's purpose
   */
  description?: string;
  /**
   * Maximum execution time in seconds
   * @default 3 seconds if not specified
   */
  timeout?: number;
  /**
   * Amount of memory available to the function in MB
   * @default 128 MB if not specified
   */
  memorySize?: number;
  /**
   * Environment variables available to the function code
   */
  environment?: Record<string, string>;
  /**
   * Resource tags for the function
   */
  tags?: Record<string, string>;
  /**
   * Function URL configuration for direct HTTP(S) invocation
   */
  url?: {
    /**
     * Configure type of response for the function URL
     */
    invokeMode?: "BUFFERED" | "RESPONSE_STREAM";
    /**
     * Authentication type for the function URL
     */
    authType?: "AWS_IAM" | "NONE";
    /**
     * CORS configuration for the function URL
     */
    cors?: {
      /**
       * Whether to allow credentials in CORS requests
       */
      allowCredentials?: boolean;
      /**
       * Allowed headers in CORS requests
       */
      allowHeaders?: string[];
      /**
       * Allowed HTTP methods in CORS requests
       */
      allowMethods?: string[];
      /**
       * Allowed origins in CORS requests
       */
      allowOrigins?: string[];
      /**
       * Headers exposed to the browser
       */
      exposeHeaders?: string[];
      /**
       * CORS preflight cache time in seconds
       */
      maxAge?: number;
    };
  };
  /**
   * Lambda layers for the function. Use the layer ARN
   */
  layers?: string[];
}
/**
 * Output returned after Lambda function creation/update
 */
export interface Function extends Resource<"lambda::Function">, FunctionProps {
  /**
   * ARN of the Lambda function
   */
  arn: string;
  /**
   * Timestamp of the last function modification
   */
  lastModified: string;
  /**
   * Function version
   */
  version: string;
  /**
   * ARN with version suffix
   */
  qualifiedArn: string;
  /**
   * ARN for invoking the function through API Gateway
   */
  invokeArn: string;
  /**
   * SHA256 hash of the function code
   */
  sourceCodeHash: string;
  /**
   * Size of the function code in bytes
   */
  sourceCodeSize: number;
  /**
   * Size of ephemeral storage (/tmp) in MB
   */
  ephemeralStorageSize?: number;
  /**
   * List of supported CPU architectures
   */
  architectures: string[];
  /**
   * ARN of the master function (Lambda@Edge only)
   */
  masterArn?: string;
  /**
   * Unique identifier for the current function code/config
   */
  revisionId: string;
  /**
   * Current state of the function
   */
  state?: string;
  /**
   * Reason for the current state
   */
  stateReason?: string;
  /**
   * Code for the current state reason
   */
  stateReasonCode?: string;
  /**
   * Status of the last update operation
   */
  lastUpdateStatus?: string;
  /**
   * Reason for the last update status
   */
  lastUpdateStatusReason?: string;
  /**
   * Code for the last update status reason
   */
  lastUpdateStatusReasonCode?: string;
  /**
   * Function package type (Zip or Image)
   */
  packageType: string;
  /**
   * ARN of the signing profile version
   */
  signingProfileVersionArn?: string;
  /**
   * ARN of the signing job
   */
  signingJobArn?: string;
  /**
   * Function URL if configured
   */
  functionUrl?: string;
}
/**
 * AWS Lambda Function Resource
 *
 * Creates and manages AWS Lambda functions with support for Node.js runtimes, custom handlers,
 * environment variables, and function URLs. Handles deployment packaging, IAM role
 * stabilization, and function updates.
 *
 * @example
 * // Create a basic Lambda function with minimal configuration
 * const basicFunction = await Function("api-handler", {
 *   functionName: "api-handler",
 *   zipPath: "./dist/api.zip",
 *   roleArn: role.arn,
 *   runtime: Runtime.nodejs20x,
 *   handler: "index.handler",
 *   tags: {
 *     Environment: "production"
 *   }
 * });
 *
 * @example
 * // Create a function with environment variables and custom memory/timeout
 * const configuredFunction = await Function("worker", {
 *   functionName: "worker",
 *   zipPath: "./dist/worker.zip",
 *   roleArn: role.arn,
 *   runtime: Runtime.nodejs20x,
 *   handler: "worker.process",
 *   memorySize: 512,
 *   timeout: 30,
 *   environment: {
 *     QUEUE_URL: queue.url,
 *     LOG_LEVEL: "info"
 *   }
 * });
 *
 * @example
 * // Create a function with a public URL endpoint, CORS and optional response streaming
 * const apiFunction = await Function("public-api", {
 *   functionName: "public-api",
 *   zipPath: "./dist/api.zip",
 *   roleArn: role.arn,
 *   handler: "api.handler",
 *   url: {
 *     authType: "NONE",
 *     invokeMode: "RESPONSE_STREAM",
 *     cors: {
 *       allowOrigins: ["*"],
 *       allowMethods: ["GET", "POST"],
 *       allowHeaders: ["content-type"],
 *       maxAge: 86400
 *     }
 *   }
 * });
 */
export const Function = Resource(
  "lambda::Function",
  async function (this: Context<Function>, id: string, props: FunctionProps) {
    const client = new LambdaClient({});
    const region = await resolveRegion(client);
    const code = await zipCode(props);
    if (this.phase === "delete") {
      // Delete function URL if it exists
      if (this.output?.url) {
        try {
          await client.send(
            new DeleteFunctionUrlConfigCommand({
              FunctionName: props.functionName,
            }),
          );
        } catch (error: any) {
          if (error.name !== "ResourceNotFoundException") {
            console.warn("Failed to delete function URL:", error);
          }
        }
      }
      await ignore(ResourceNotFoundException.name, () =>
        client.send(
          new DeleteFunctionCommand({
            FunctionName: props.functionName,
          }),
        ),
      );
      return this.destroy();
    }
    let functionUrl: string | undefined;
    try {
      // Check if function exists
      await client.send(
        new GetFunctionCommand({
          FunctionName: props.functionName,
        }),
      );
      if (this.phase === "update") {
        // Wait for function to stabilize
        await waitForFunctionStabilization(client, props.functionName);
        // Update function code
        await client.send(
          new UpdateFunctionCodeCommand({
            FunctionName: props.functionName,
            ZipFile: code,
          }),
        );
        // Wait for code update to stabilize
        await waitForFunctionStabilization(client, props.functionName);
        // Update function configuration
        await client.send(
          new UpdateFunctionConfigurationCommand({
            FunctionName: props.functionName,
            Handler: props.handler,
            Runtime: props.runtime,
            Role: props.roleArn,
            Description: props.description,
            Timeout: props.timeout,
            MemorySize: props.memorySize,
            Environment: props.environment
              ? { Variables: props.environment }
              : undefined,
            Layers: props.layers,
          }),
        );
        // Wait for configuration update to stabilize
        await waitForFunctionStabilization(client, props.functionName);
        // Handle URL configuration
        if (props.url) {
          try {
            // Check if URL config exists already
            const urlConfig = await client.send(
              new GetFunctionUrlConfigCommand({
                FunctionName: props.functionName,
              }),
            );
            // Update URL configuration if it exists
            if (urlConfig) {
              const updateResult = await client.send(
                new UpdateFunctionUrlConfigCommand({
                  FunctionName: props.functionName,
                  AuthType: props.url.authType || "NONE",
                  InvokeMode: props.url.invokeMode || "BUFFERED",
                  Cors: props.url.cors
                    ? {
                        AllowCredentials: props.url.cors.allowCredentials,
                        AllowHeaders: props.url.cors.allowHeaders,
                        AllowMethods: props.url.cors.allowMethods,
                        AllowOrigins: props.url.cors.allowOrigins,
                        ExposeHeaders: props.url.cors.exposeHeaders,
                        MaxAge: props.url.cors.maxAge,
                      }
                    : undefined,
                }),
              );
              functionUrl = updateResult.FunctionUrl;
              // Add public access permission for function URL
              if (props.url.authType === "NONE") {
                try {
                  await client.send(
                    new AddPermissionCommand({
                      FunctionName: props.functionName,
                      StatementId: "FunctionURLAllowPublicAccess",
                      Action: "lambda:InvokeFunctionUrl",
                      Principal: "*",
                      FunctionUrlAuthType: "NONE",
                    }),
                  );
                } catch (permError: any) {
                  if (!permError.message?.includes("already exists")) {
                    console.warn("Error adding URL permission:", permError);
                  }
                }
              }
            } else {
              // Create URL configuration if it doesn't exist
              const createResult = await client.send(
                new CreateFunctionUrlConfigCommand({
                  FunctionName: props.functionName,
                  AuthType: props.url.authType || "NONE",
                  InvokeMode: props.url.invokeMode || "BUFFERED",
                  Cors: props.url.cors
                    ? {
                        AllowCredentials: props.url.cors.allowCredentials,
                        AllowHeaders: props.url.cors.allowHeaders,
                        AllowMethods: props.url.cors.allowMethods,
                        AllowOrigins: props.url.cors.allowOrigins,
                        ExposeHeaders: props.url.cors.exposeHeaders,
                        MaxAge: props.url.cors.maxAge,
                      }
                    : undefined,
                }),
              );
              functionUrl = createResult.FunctionUrl;
              // Add public access permission for function URL
              if (props.url.authType === "NONE") {
                try {
                  await client.send(
                    new AddPermissionCommand({
                      FunctionName: props.functionName,
                      StatementId: "FunctionURLAllowPublicAccess",
                      Action: "lambda:InvokeFunctionUrl",
                      Principal: "*",
                      FunctionUrlAuthType: "NONE",
                    }),
                  );
                } catch (permError: any) {
                  if (!permError.message?.includes("already exists")) {
                    console.warn("Error adding URL permission:", permError);
                  }
                }
              }
            }
          } catch (error: any) {
            if (error.name === "ResourceNotFoundException") {
              // Create URL configuration if it doesn't exist
              const createResult = await client.send(
                new CreateFunctionUrlConfigCommand({
                  FunctionName: props.functionName,
                  AuthType: props.url.authType || "NONE",
                  InvokeMode: props.url.invokeMode || "BUFFERED",
                  Cors: props.url.cors
                    ? {
                        AllowCredentials: props.url.cors.allowCredentials,
                        AllowHeaders: props.url.cors.allowHeaders,
                        AllowMethods: props.url.cors.allowMethods,
                        AllowOrigins: props.url.cors.allowOrigins,
                        ExposeHeaders: props.url.cors.exposeHeaders,
                        MaxAge: props.url.cors.maxAge,
                      }
                    : undefined,
                }),
              );
              functionUrl = createResult.FunctionUrl;
              // Add public access permission for function URL
              if (props.url.authType === "NONE") {
                try {
                  await client.send(
                    new AddPermissionCommand({
                      FunctionName: props.functionName,
                      StatementId: "FunctionURLAllowPublicAccess",
                      Action: "lambda:InvokeFunctionUrl",
                      Principal: "*",
                      FunctionUrlAuthType: "NONE",
                    }),
                  );
                } catch (permError: any) {
                  if (!permError.message?.includes("already exists")) {
                    console.warn("Error adding URL permission:", permError);
                  }
                }
              }
            } else {
              throw error;
            }
          }
        } else if (this.output?.url) {
          // Remove URL config if it was previously set but not in current props
          try {
            await client.send(
              new DeleteFunctionUrlConfigCommand({
                FunctionName: props.functionName,
              }),
            );
            functionUrl = undefined;
          } catch (error: any) {
            if (error.name !== "ResourceNotFoundException") {
              console.warn("Failed to delete function URL:", error);
            }
          }
        }
      }
    } catch (error: any) {
      if (error.name === "ResourceNotFoundException") {
        // Create function if it doesn't exist
        const startTime = Date.now();
        let delay = 100; // Start with 100ms delay
        while (true) {
          try {
            await client.send(
              new CreateFunctionCommand({
                FunctionName: props.functionName,
                Code: { ZipFile: code },
                Handler: props.handler || "index.handler",
                Runtime: props.runtime || Runtime.nodejs20x,
                Role: props.roleArn,
                Description: props.description,
                Timeout: props.timeout || 3,
                MemorySize: props.memorySize || 128,
                Environment: props.environment
                  ? { Variables: props.environment }
                  : undefined,
                Architectures: props.architecture
                  ? [props.architecture]
                  : [Architecture.x86_64],
                Tags: props.tags,
                Layers: props.layers,
              }),
            );
            break; // Success - exit retry loop
          } catch (createError: any) {
            if (
              createError.name !== "InvalidParameterValueException" ||
              !createError.message?.includes("cannot be assumed by Lambda")
            ) {
              throw createError; // Different error - rethrow
            }
            if (Date.now() - startTime > 10000) {
              throw new Error(
                "Timeout waiting for IAM role to be assumable by Lambda after 10s",
              );
            }
            await new Promise((resolve) => setTimeout(resolve, delay));
            delay = Math.min(delay * 2, 1000); // Exponential backoff capped at 1s
          }
        }
        // Wait for function to be active
        let isCreating = true;
        while (isCreating) {
          const config = await client.send(
            new GetFunctionConfigurationCommand({
              FunctionName: props.functionName,
            }),
          );
          isCreating = config.State === "Pending";
          if (isCreating) {
            await new Promise((resolve) => setTimeout(resolve, 1000));
          }
        }
        // Create URL configuration if needed
        if (props.url) {
          try {
            const createResult = await client.send(
              new CreateFunctionUrlConfigCommand({
                FunctionName: props.functionName,
                AuthType: props.url.authType || "NONE",
                InvokeMode: props.url.invokeMode || "BUFFERED",
                Cors: props.url.cors
                  ? {
                      AllowCredentials: props.url.cors.allowCredentials,
                      AllowHeaders: props.url.cors.allowHeaders,
                      AllowMethods: props.url.cors.allowMethods,
                      AllowOrigins: props.url.cors.allowOrigins,
                      ExposeHeaders: props.url.cors.exposeHeaders,
                      MaxAge: props.url.cors.maxAge,
                    }
                  : undefined,
              }),
            );
            functionUrl = createResult.FunctionUrl;
            // Add public access permission for function URL
            if (props.url.authType === "NONE") {
              try {
                await client.send(
                  new AddPermissionCommand({
                    FunctionName: props.functionName,
                    StatementId: "FunctionURLAllowPublicAccess",
                    Action: "lambda:InvokeFunctionUrl",
                    Principal: "*",
                    FunctionUrlAuthType: "NONE",
                  }),
                );
              } catch (permError: any) {
                if (!permError.message?.includes("already exists")) {
                  console.warn("Error adding URL permission:", permError);
                }
              }
            }
          } catch (error) {
            console.warn("Failed to create function URL:", error);
          }
        }
      } else {
        throw error;
      }
    }
    // Get complete function details
    const [func, config] = await Promise.all([
      client.send(
        new GetFunctionCommand({
          FunctionName: props.functionName,
        }),
      ),
      client.send(
        new GetFunctionConfigurationCommand({
          FunctionName: props.functionName,
        }),
      ),
    ]);
    // Try to get function URL if it wasn't already retrieved and URL is configured
    if (!functionUrl && (props.url || this.output?.url)) {
      try {
        const urlConfig = await client.send(
          new GetFunctionUrlConfigCommand({
            FunctionName: props.functionName,
          }),
        );
        functionUrl = urlConfig.FunctionUrl;
      } catch (error: any) {
        if (error.name !== "ResourceNotFoundException") {
          console.warn("Failed to get function URL:", error);
        }
      }
    }
    return this({
      ...props,
      arn: config.FunctionArn!,
      lastModified: config.LastModified!,
      version: config.Version!,
      qualifiedArn: `${config.FunctionArn}:${config.Version}`,
      invokeArn: `arn:aws:apigateway:${region}:lambda:path/2015-03-31/functions/${config.FunctionArn}/invocations`,
      sourceCodeHash: config.CodeSha256!,
      sourceCodeSize: config.CodeSize!,
      ephemeralStorageSize: config.EphemeralStorage?.Size,
      architectures: config.Architectures || [],
      masterArn: config.MasterArn,
      revisionId: config.RevisionId!,
      state: config.State,
      stateReason: config.StateReason,
      stateReasonCode: config.StateReasonCode,
      lastUpdateStatus: config.LastUpdateStatus,
      lastUpdateStatusReason: config.LastUpdateStatusReason,
      lastUpdateStatusReasonCode: config.LastUpdateStatusReasonCode,
      packageType: config.PackageType!,
      signingProfileVersionArn: config.SigningProfileVersionArn,
      signingJobArn: config.SigningJobArn,
      functionUrl: functionUrl,
    });
  },
);
// Helper to wait for function to stabilize
async function waitForFunctionStabilization(
  client: LambdaClient,
  functionName: string,
) {
  while (true) {
    const config = await client.send(
      new GetFunctionConfigurationCommand({
        FunctionName: functionName,
      }),
    );
    // Check if function is in a stable state
    if (config.State === "Active" && config.LastUpdateStatus === "Successful") {
      break;
    }
    // If there's a failure, throw an error
    if (config.State === "Failed" || config.LastUpdateStatus === "Failed") {
      throw new Error(
        `Function failed to stabilize: ${config.StateReason || config.LastUpdateStatusReason}`,
      );
    }
    await new Promise((resolve) => setTimeout(resolve, 1000));
  }
}
const handlerRegex = /^(.*)\.([A-Za-z0-9_]+)$/;
function parseFile(handler: string): string {
  const match = handler.match(handlerRegex);
  if (!match) {
    throw new Error(`Invalid handler: ${handler}`);
  }
  return match[1];
}
// Helper to zip the code
async function zipCode(props: FunctionProps): Promise<Buffer> {
  const fileContent = props.bundle.content;
  const fileName =
    parseFile(props.handler) +
    (props.bundle.format === "cjs" ? ".cjs" : ".mjs");
  // Create a zip buffer in memory
  const zip = new (await import("jszip")).default();
  zip.file(fileName, fileContent);
  return zip.generateAsync({
    type: "nodebuffer",
    compression: "DEFLATE",
    platform: "UNIX",
  });
}
async function resolveRegion(client: LambdaClient): Promise<string> {
  const region = client.config.region;
  if (typeof region === "string") return region;
  if (typeof region === "function") return region();
  throw new Error("Could not resolve AWS region");
}
</file>

<file path="alchemy/src/cloudflare/bundle/external.ts">
// https://developers.cloudflare.com/workers/runtime-apis/nodejs/#supported-nodejs-apis
const nodejs_compat = [
  "node:async_hooks",
  "node:assert",
  "node:buffer",
  "node:console",
  "node:crypto",
  "node:debug",
  "node:diagnostics_channel",
  "node:dns",
  "node:events",
  "node:inspector",
  "node:net",
  "node:path",
  "node:perf_hooks", // partially supported
  "node:process",
  "node:querystring",
  "node:stream",
  "node:string_decoder",
  "node:timers",
  "node:tls", // partially supported
  "node:url",
  "node:util",
  "node:zlib",
  // "node:*",
];
export const external = [
  ...nodejs_compat,
  ...nodejs_compat.map((p) => p.split(":")[1]),
  "cloudflare:workers",
  "cloudflare:workflows",
  "cloudflare:*",
];
export const external_als = [
  //
  "node:async_hooks",
  "async_hooks",
  "cloudflare:*",
];
</file>

<file path="alchemy/src/cloudflare/wrangler.json.ts">
import type { Context } from "../context.js";
import { StaticJsonFile } from "../fs/static-json-file.js";
import { Resource } from "../resource.js";
import { Self, type Bindings } from "./bindings.js";
import type { DurableObjectNamespace } from "./durable-object-namespace.js";
import type { EventSource } from "./event-source.js";
import { isQueueEventSource } from "./event-source.js";
import { isQueue } from "./queue.js";
import type { Worker } from "./worker.js";
/**
 * Properties for wrangler.json configuration file
 */
export interface WranglerJsonProps {
  name?: string;
  /**
   * The worker to generate the wrangler.json file for
   */
  worker: Worker;
  /**
   * Path to write the wrangler.json file to
   *
   * @default cwd/wrangler.json
   */
  path?: string;
  /**
   * The main entry point for the worker
   *
   * @default worker.entrypoint
   */
  main?: string;
}
/**
 * Output returned after WranglerJson creation/update
 */
export interface WranglerJson
  extends Resource<"cloudflare::WranglerJson">,
    WranglerJsonProps {
  /**
   * Time at which the file was created
   */
  createdAt: number;
  /**
   * Time at which the file was last updated
   */
  updatedAt: number;
  /**
   * Path to the wrangler.json file
   */
  path: string;
  /**
   * `wrangler.json` spec
   */
  spec: WranglerJsonSpec;
}
/**
 * Resource for managing wrangler.json configuration files
 */
export const WranglerJson = Resource(
  "cloudflare::WranglerJson",
  async function (
    this: Context<WranglerJson>,
    id: string,
    props: WranglerJsonProps,
  ): Promise<WranglerJson> {
    // Default path is wrangler.json in current directory
    const filePath = props.path || "wrangler.jsonc";
    if (this.phase === "delete") {
      return this.destroy();
    }
    if (props.worker.entrypoint === undefined) {
      throw new Error(
        "Worker must have an entrypoint to generate a wrangler.json",
      );
    }
    const worker = props.worker;
    const spec: WranglerJsonSpec = {
      name: worker.name,
      // Use entrypoint as main if it exists
      main: props.main ?? worker.entrypoint,
      // see: https://developers.cloudflare.com/workers/configuration/compatibility-dates/
      compatibility_date: worker.compatibilityDate,
      compatibility_flags: props.worker.compatibilityFlags,
    };
    // Process bindings if they exist
    if (worker.bindings) {
      processBindings(spec, worker.bindings, worker.eventSources, worker.name);
    }
    // Add environment variables as vars
    if (worker.env) {
      spec.vars = { ...worker.env };
    }
    await StaticJsonFile(filePath, spec);
    // Return the resource
    return this({
      ...props,
      path: filePath,
      spec,
      createdAt: Date.now(),
      updatedAt: Date.now(),
    });
  },
);
/**
 * Wrangler.json configuration specification based on Cloudflare's schema
 */
export interface WranglerJsonSpec {
  /**
   * The name of the worker
   */
  name: string;
  /**
   * Main entry point for the worker
   */
  main?: string;
  /**
   * A date in the form yyyy-mm-dd used to determine Workers runtime version
   */
  compatibility_date?: string;
  /**
   * A list of flags that enable features from upcoming Workers runtime
   */
  compatibility_flags?: string[];
  /**
   * Whether to enable a workers.dev URL for this worker
   */
  workers_dev?: boolean;
  /**
   * Routes to attach to the worker
   */
  routes?: string[];
  /**
   * AI bindings
   */
  ai?: {
    binding: string;
  };
  /**
   * Browser bindings
   */
  browser?: {
    binding: string;
  };
  /**
   * KV Namespace bindings
   */
  kv_namespaces?: {
    binding: string;
    id: string;
    /**
     * The ID of the KV namespace used during `wrangler dev`
     */
    preview_id?: string;
  }[];
  /**
   * Durable Object bindings
   */
  durable_objects?: {
    bindings: {
      name: string;
      class_name: string;
      script_name?: string;
      environment?: string;
    }[];
  };
  /**
   * R2 bucket bindings
   */
  r2_buckets?: {
    binding: string;
    bucket_name: string;
    /**
     * The preview name of this R2 bucket at the edge.
     */
    preview_bucket_name?: string;
  }[];
  /**
   * Queue bindings
   */
  queues?: {
    producers: { queue: string; binding: string }[];
    consumers: {
      queue: string;
      max_batch_size?: number;
      max_concurrency?: number;
      max_retries?: number;
      max_wait_time_ms?: number;
      retry_delay?: number;
    }[];
  };
  /**
   * Service bindings
   */
  services?: {
    binding: string;
    service: string;
    environment?: string;
  }[];
  /**
   * Workflow bindings
   */
  workflows?: {
    name: string;
    binding: string;
    class_name: string;
  }[];
  /**
   * Vectorize index bindings
   */
  vectorize_indexes?: {
    binding: string;
    index_name: string;
  }[];
  /**
   * Plain text bindings (vars)
   */
  vars?: Record<string, string>;
  /**
   * D1 database bindings
   */
  d1_databases?: {
    binding: string;
    database_id: string;
    database_name: string;
    migrations_dir?: string;
    /**
     * The ID of the D1 database used during `wrangler dev`
     */
    preview_database_id?: string;
  }[];
  /**
   * Assets bindings
   */
  assets?: {
    directory: string;
    binding: string;
  };
  /**
   * Migrations
   */
  migrations?: {
    tag: string;
    new_sqlite_classes?: string[];
    new_classes?: string[];
  }[];
  /**
   * Workflow bindings
   */
  wasm_modules?: Record<string, string>;
  /**
   * Safe mode configuration
   */
  node_compat?: boolean;
  /**
   * Whether to minify the worker script
   */
  minify?: boolean;
}
/**
 * Process worker bindings into wrangler.json format
 */
function processBindings(
  spec: WranglerJsonSpec,
  bindings: Bindings,
  eventSources: EventSource[] | undefined,
  workerName: string,
): void {
  // Arrays to collect different binding types
  const kvNamespaces: { binding: string; id: string }[] = [];
  const durableObjects: {
    name: string;
    class_name: string;
    script_name?: string;
    environment?: string;
  }[] = [];
  const r2Buckets: { binding: string; bucket_name: string }[] = [];
  const services: { binding: string; service: string; environment?: string }[] =
    [];
  const secrets: string[] = [];
  const workflows: { name: string; binding: string; class_name: string }[] = [];
  const d1Databases: {
    binding: string;
    database_id: string;
    database_name: string;
    migrations_dir?: string;
  }[] = [];
  const queues: {
    producers: { queue: string; binding: string }[];
    consumers: {
      queue: string;
      max_batch_size?: number;
      max_concurrency?: number;
      max_retries?: number;
      max_wait_time_ms?: number;
      retry_delay?: number;
    }[];
  } = {
    producers: [],
    consumers: [],
  };
  const new_sqlite_classes: string[] = [];
  const new_classes: string[] = [];
  const vectorizeIndexes: { binding: string; index_name: string }[] = [];
  for (const eventSource of eventSources ?? []) {
    if (isQueueEventSource(eventSource)) {
      queues.consumers.push({
        queue: eventSource.queue.id,
        max_batch_size: eventSource.settings?.batchSize,
        max_concurrency: eventSource.settings?.maxConcurrency,
        max_retries: eventSource.settings?.maxRetries,
        max_wait_time_ms: eventSource.settings?.maxWaitTimeMs,
        retry_delay: eventSource.settings?.retryDelay,
      });
    } else if (isQueue(eventSource)) {
      queues.consumers.push({
        queue: eventSource.id,
      });
    }
  }
  // Process each binding
  for (const [bindingName, binding] of Object.entries(bindings)) {
    if (typeof binding === "string") {
      // Plain text binding - add to vars
      if (!spec.vars) {
        spec.vars = {};
      }
      spec.vars[bindingName] = binding;
    } else if (binding === Self) {
      // Self(service) binding
      services.push({
        binding: bindingName,
        service: workerName,
      });
    } else if (binding.type === "service") {
      // Service binding
      services.push({
        binding: bindingName,
        service: binding.id,
      });
    } else if (binding.type === "kv_namespace") {
      // KV Namespace binding
      kvNamespaces.push({
        binding: bindingName,
        id: binding.namespaceId,
      });
    } else if (
      typeof binding === "object" &&
      binding.type === "durable_object_namespace"
    ) {
      // Durable Object binding
      const doBinding = binding as DurableObjectNamespace;
      durableObjects.push({
        name: bindingName,
        class_name: doBinding.className,
        script_name: doBinding.scriptName,
        environment: doBinding.environment,
      });
      if (doBinding.sqlite) {
        new_sqlite_classes.push(doBinding.className);
      } else {
        new_classes.push(doBinding.className);
      }
    } else if (binding.type === "r2_bucket") {
      r2Buckets.push({
        binding: bindingName,
        bucket_name: binding.name,
      });
    } else if (binding.type === "secret") {
      // Secret binding
      secrets.push(bindingName);
    } else if (binding.type === "assets") {
      spec.assets = {
        directory: binding.path,
        binding: bindingName,
      };
    } else if (binding.type === "workflow") {
      workflows.push({
        name: binding.workflowName,
        binding: bindingName,
        class_name: binding.className,
      });
    } else if (binding.type === "d1") {
      d1Databases.push({
        binding: bindingName,
        database_id: binding.id,
        database_name: binding.name,
        migrations_dir: binding.migrationsDir,
      });
    } else if (binding.type === "queue") {
      queues.producers.push({
        binding: bindingName,
        queue: binding.name,
      });
    } else if (binding.type === "vectorize") {
      vectorizeIndexes.push({
        binding: bindingName,
        index_name: binding.name,
      });
    } else if (binding.type === "browser") {
      if (spec.browser) {
        throw new Error(`Browser already bound to ${spec.browser.binding}`);
      }
      spec.browser = {
        binding: bindingName,
      };
    } else if (binding.type === "ai") {
      if (spec.ai) {
        throw new Error(`AI already bound to ${spec.ai.binding}`);
      }
      spec.ai = {
        binding: bindingName,
      };
    }
  }
  // Add collected bindings to the spec
  if (kvNamespaces.length > 0) {
    spec.kv_namespaces = kvNamespaces;
  }
  if (durableObjects.length > 0) {
    spec.durable_objects = {
      bindings: durableObjects,
    };
  }
  if (r2Buckets.length > 0) {
    spec.r2_buckets = r2Buckets;
  }
  if (services.length > 0) {
    spec.services = services;
  }
  if (d1Databases.length > 0) {
    spec.d1_databases = d1Databases;
  }
  if (queues.consumers.length > 0) {
    spec.queues = queues;
  }
  if (vectorizeIndexes.length > 0) {
    spec.vectorize_indexes = vectorizeIndexes;
  }
  if (new_sqlite_classes.length > 0 || new_classes.length > 0) {
    spec.migrations = [
      {
        tag: "v1",
        new_sqlite_classes,
        new_classes,
      },
    ];
  }
  if (workflows.length > 0) {
    spec.workflows = workflows;
  }
}
</file>

<file path="alchemy/src/stripe/index.ts">
export * from "./price.js";
export * from "./product.js";
export * from "./webhook.js";
export * from "./meter.js";
</file>

<file path="alchemy/src/stripe/meter.ts">
import Stripe from "stripe";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
/**
 * Properties for creating or updating a Stripe Meter.
 * Note: Nested objects like defaultAggregation, customerMapping, valueSettings
 * use camelCase for keys here (e.g., eventPayloadKey), and the resource
 * implementation will map them to snake_case for Stripe API calls.
 */
export interface MeterProps {
  displayName: string;
  eventName: string;
  status?: "active" | "inactive"; // 'active' is default on create by Stripe
  defaultAggregation: {
    formula: Stripe.Billing.MeterCreateParams.DefaultAggregation.Formula;
  };
  customerMapping: {
    eventPayloadKey: string;
    type: Stripe.Billing.MeterCreateParams.CustomerMapping["type"];
  };
  valueSettings: {
    eventPayloadKey: string;
  };
}
/**
 * Output returned after Stripe Meter creation/update.
 */
export interface Meter extends Resource<"stripe::Meter"> {
  id: string;
  object: "billing.meter";
  displayName: string;
  eventName: string;
  defaultAggregation: {
    formula: Stripe.Billing.Meter.DefaultAggregation["formula"];
  };
  customerMapping: {
    eventPayloadKey: string;
    type: Stripe.Billing.Meter.CustomerMapping["type"];
  };
  valueSettings: {
    eventPayloadKey: string;
  };
  status: "active" | "inactive";
  createdAt: number; // Unix timestamp
  updatedAt: number; // Unix timestamp
  livemode: boolean;
  statusTransitions?: {
    deactivatedAt: number | null; // Unix timestamp
  };
}
/**
 * Manages Stripe Billing Meters. Meters allow you to define how usage of a product
 * is measured and aggregated for billing purposes. You can track events and their
 * values, and Stripe will calculate the usage based on the meter's configuration.
 *
 * Stripe Meters have several properties that are immutable after creation:
 * `displayName`, `eventName`, `defaultAggregation`, `customerMapping`, and
 * `valueSettings`. Attempting to update these will result in an error.
 * The `status` of a meter (active/inactive) can be updated.
 *
 * @example
 * // Create a new active meter to track API calls, summing the 'count' field from events.
 * const apiCallMeter = await Meter("apiUsageMeter", {
 *  displayName: "API Call Usage",
 *  eventName: "api.call.recorded", // The event name Stripe will listen for
 *  defaultAggregation: {
 *    formula: "sum" // Sum up the values of events
 *  },
 *  customerMapping: {
 *    eventPayloadKey: "customer_id", // Field in the event payload that identifies the Stripe Customer
 *    type: "by_id"
 *  },
 *  valueSettings: {
 *    eventPayloadKey: "count" // Field in the event payload that represents the value to aggregate
 *  }
 *  // status defaults to 'active' if not specified
 * });
 *
 * @example
 * // Create a new meter for data storage, initially inactive.
 * // This meter will take the last reported 'gb_used' value within a billing period.
 * const dataStorageMeterInactive = await Meter("dataStorageMeter", {
 *  displayName: "Data Storage GB",
 *  eventName: "data.storage.reported",
 *  status: "inactive", // Explicitly set to inactive
 *  defaultAggregation: {
 *    formula: "last_during_period"
 *  },
 *  customerMapping: {
 *    eventPayloadKey: "user_stripe_id",
 *    type: "by_id"
 *  },
 *  valueSettings: {
 *    eventPayloadKey: "gb_used"
 *  }
 * });
 *
 * @example
 * // (Scenario: Assuming 'dataStorageMeterInactive' from the previous example was created
 * // and its ID is available, e.g., via `dataStorageMeterInactive.id`) *
 * // If dataStorageMeterInactive was previously defined and we want to activate it:
 * const activatedStorageMeter = await Meter("dataStorageMeter", { // Same logicalId
 *  displayName: "Data Storage GB", // Immutable, must match existing
 *  eventName: "data.storage.reported", // Immutable, must match existing
 *  status: "active", // Update: change status to active
 *  defaultAggregation: { // Immutable, must match existing
 *    formula: "last_during_period"
 *  },
 *  customerMapping: { // Immutable, must match existing
 *    eventPayloadKey: "user_stripe_id",
 *    type: "by_id"
 *  },
 *  valueSettings: { // Immutable, must match existing
 *    eventPayloadKey: "gb_used"
 *  }
 * });
 *
 * @example
 * // To deactivate an existing active meter (e.g. 'apiCallMeter' from first example):
 * const deactivatedApiMeter = await Meter("apiUsageMeter", { // Same logicalId
 *  displayName: "API Call Usage", // Immutable, must match existing
 *  eventName: "api.call.recorded", // Immutable, must match existing
 *  status: "inactive", // Update: change status to inactive
 *  defaultAggregation: { // Immutable, must match existing
 *    formula: "sum"
 *  },
 *  customerMapping: { // Immutable, must match existing
 *    eventPayloadKey: "customer_id",
 *    type: "by_id"
 *  },
 *  valueSettings: { // Immutable, must match existing
 *    eventPayloadKey: "count"
 *  }
 * });
 */
export const Meter = Resource(
  "stripe::Meter",
  async function (
    this: Context<Meter>,
    logicalId: string,
    props: MeterProps,
  ): Promise<Meter> {
    const apiKey = process.env.STRIPE_API_KEY;
    if (!apiKey) {
      throw new Error("STRIPE_API_KEY environment variable is required");
    }
    const stripe = new Stripe(apiKey);
    const currentOutputId = this.output?.id;
    // Helper to map MeterProps (camelCase nested) to Stripe API params (snake_case nested)
    const mapPropsToStripeParams = (
      inputProps: MeterProps,
    ): Stripe.Billing.MeterCreateParams => ({
      display_name: inputProps.displayName,
      event_name: inputProps.eventName,
      default_aggregation: {
        formula: inputProps.defaultAggregation.formula,
      },
      customer_mapping: {
        event_payload_key: inputProps.customerMapping.eventPayloadKey,
        type: inputProps.customerMapping.type,
      },
      value_settings: {
        event_payload_key: inputProps.valueSettings.eventPayloadKey,
      },
    });
    // Helper to map Stripe API response (snake_case) to Meter output interface (camelCase)
    const mapStripeObjectToMeterOutput = (
      stripeMeter: Stripe.Billing.Meter,
    ): Omit<Meter, keyof Resource<"stripe::Meter">> => ({
      id: stripeMeter.id,
      object: stripeMeter.object,
      displayName: stripeMeter.display_name,
      eventName: stripeMeter.event_name,
      defaultAggregation: {
        formula: stripeMeter.default_aggregation.formula,
      },
      customerMapping: {
        eventPayloadKey: stripeMeter.customer_mapping.event_payload_key,
        type: stripeMeter.customer_mapping.type,
      },
      valueSettings: {
        eventPayloadKey: stripeMeter.value_settings.event_payload_key,
      },
      status: stripeMeter.status as "active" | "inactive",
      createdAt: stripeMeter.created,
      updatedAt: stripeMeter.updated,
      livemode: stripeMeter.livemode,
      statusTransitions: stripeMeter.status_transitions
        ? {
            deactivatedAt: stripeMeter.status_transitions.deactivated_at,
          }
        : undefined,
    });
    if (this.phase === "delete") {
      if (currentOutputId) {
        try {
          const meter = await stripe.billing.meters.retrieve(currentOutputId);
          if (meter.status === "active") {
            await stripe.billing.meters.deactivate(currentOutputId);
          }
        } catch (error: any) {
          if (error?.code !== "resource_missing") {
            throw error;
          }
        }
      }
      return this.destroy();
    }
    // --- Create or Update Phase ---
    let stripeAPIResponse: Stripe.Billing.Meter;
    if (this.phase === "update" && currentOutputId) {
      const existingStripeMeter =
        await stripe.billing.meters.retrieve(currentOutputId);
      // Normalize existingMeter's relevant fields for immutable comparison
      const existingPropsForCompare = {
        displayName: existingStripeMeter.display_name,
        eventName: existingStripeMeter.event_name,
        defaultAggregation: {
          formula: existingStripeMeter.default_aggregation.formula,
        },
        customerMapping: {
          eventPayloadKey:
            existingStripeMeter.customer_mapping.event_payload_key,
          type: existingStripeMeter.customer_mapping.type,
        },
        valueSettings: {
          eventPayloadKey: existingStripeMeter.value_settings.event_payload_key,
        },
      };
      // Check for immutable property changes (comparing against props passed to resource)
      if (
        props.displayName !== existingPropsForCompare.displayName ||
        props.eventName !== existingPropsForCompare.eventName ||
        JSON.stringify(props.defaultAggregation) !==
          JSON.stringify(existingPropsForCompare.defaultAggregation) ||
        JSON.stringify(props.customerMapping) !==
          JSON.stringify(existingPropsForCompare.customerMapping) ||
        JSON.stringify(props.valueSettings) !==
          JSON.stringify(existingPropsForCompare.valueSettings)
      ) {
        throw new Error(
          `Attempted to update immutable properties for Stripe Meter ${currentOutputId}. ` +
            "displayName, eventName, defaultAggregation, customerMapping, and valueSettings cannot be changed.",
        );
      }
      // Handle status change
      if (props.status && props.status !== existingStripeMeter.status) {
        if (
          props.status === "inactive" &&
          existingStripeMeter.status === "active"
        ) {
          stripeAPIResponse =
            await stripe.billing.meters.deactivate(currentOutputId);
        } else if (
          props.status === "active" &&
          existingStripeMeter.status === "inactive"
        ) {
          console.log(`Reactivating Stripe Meter ${currentOutputId}.`);
          stripeAPIResponse =
            await stripe.billing.meters.reactivate(currentOutputId);
        } else {
          stripeAPIResponse = existingStripeMeter; // No change in status
        }
      } else {
        stripeAPIResponse = existingStripeMeter; // No status change requested
      }
    } else {
      // Create phase
      if (
        !props.displayName ||
        !props.eventName ||
        !props.defaultAggregation ||
        !props.customerMapping ||
        !props.valueSettings
      ) {
        throw new Error(
          "displayName, eventName, defaultAggregation, customerMapping, and valueSettings are required for creating a Stripe Meter.",
        );
      }
      const createParams = mapPropsToStripeParams(props);
      stripeAPIResponse = await stripe.billing.meters.create(createParams);
      // If status 'inactive' is requested during creation, and Stripe created it as 'active'
      if (
        props.status === "inactive" &&
        stripeAPIResponse.status === "active"
      ) {
        stripeAPIResponse = await stripe.billing.meters.deactivate(
          stripeAPIResponse.id,
        );
      } else if (props.status && props.status !== stripeAPIResponse.status) {
        console.warn(
          `Meter ${stripeAPIResponse.id} created with status ${stripeAPIResponse.status} but requested ${props.status}. Ensure this is intended.`,
        );
      }
    }
    return this(mapStripeObjectToMeterOutput(stripeAPIResponse));
  },
);
</file>

<file path="alchemy/src/stripe/price.ts">
import Stripe from "stripe";
import type { Context } from "../context.js";
import { Resource } from "../resource.js";
/**
 * Properties for price recurring configuration
 */
export interface PriceRecurring {
  /**
   * Specifies billing frequency. Either 'day', 'week', 'month' or 'year'.
   */
  interval: Stripe.PriceCreateParams.Recurring.Interval;
  /**
   * The number of intervals between subscription billings. For example, interval=month and interval_count=3 bills every 3 months.
   */
  intervalCount?: number;
  /**
   * Configures how the quantity per period should be determined, can be either 'metered' or 'licensed'.
   * 'licensed' will automatically bill the quantity set for a plan when adding it to a subscription,
   * 'metered' will aggregate the total usage based on usage records.
   */
  usageType?: Stripe.PriceCreateParams.Recurring.UsageType;
  /**
   * Specifies a usage aggregation strategy for prices of `usage_type=metered`. Allowed values are `sum` for summing up all usage during a period,
   * `last_during_period` for picking the last usage record reported within a period,
   * `last_ever` for picking the last usage record ever (across period bounds) or `max` which picks the usage record with the maximum reported usage during a period.
   */
  aggregateUsage?: Stripe.PriceCreateParams.Recurring.AggregateUsage;
}
type TaxBehavior = Stripe.PriceCreateParams.TaxBehavior;
type BillingScheme = Stripe.PriceCreateParams.BillingScheme;
/**
 * Properties for creating a Stripe price
 */
export interface PriceProps {
  /**
   * The ID of the product that this price will belong to
   */
  product: string;
  /**
   * Three-letter ISO currency code, in lowercase. Must be a supported currency.
   */
  currency: string;
  /**
   * A positive integer in cents (or local equivalent) representing how much to charge (e.g., 999 for $9.99).
   * Alternatively, use unit_amount_decimal to specify a precise amount.
   */
  unitAmount?: number;
  /**
   * Same as unit_amount, but accepts a decimal string (e.g., '9.99') with at most 12 decimal places.
   * Only one of unit_amount and unit_amount_decimal can be set.
   */
  unitAmountDecimal?: string;
  /**
   * Whether the price can be used for new purchases
   */
  active?: boolean;
  /**
   * Describes how to compute the price per period. Either `per_unit` or `tiered`.
   * `per_unit` indicates that the fixed amount (specified in `unit_amount` or `unit_amount_decimal`)
   * will be charged per unit in `quantity`.
   * `tiered` indicates that the unit pricing will be computed using a tiering strategy.
   */
  billingScheme?: BillingScheme;
  /**
   * A brief description of the price, hidden from customers.
   */
  nickname?: string;
  /**
   * The recurring components of a price such as `interval` and `interval_count`.
   */
  recurring?: PriceRecurring;
  /**
   * Set of key-value pairs that you can attach to an object.
   */
  metadata?: Record<string, string>;
  /**
   * Specifies whether the price is considered inclusive of taxes or exclusive of taxes.
   * One of inclusive, exclusive, or unspecified.
   */
  taxBehavior?: TaxBehavior;
  /**
   * A lookup key to uniquely identify this price.
   * This key can be used to retrieve the price object without needing its ID.
   * It must be unique across all prices in your Stripe account, otherwise creation will fail.
   * If you want to transfer the lookup key from another price, set `transferLookupKey` to true
   */
  lookupKey?: string;
  /**
   * If set to true, will atomically transfer the lookup key from an existing price to this price.
   */
  transferLookupKey?: boolean;
}
/**
 * Output from the Stripe price
 */
export interface Price extends Resource<"stripe::Price">, PriceProps {
  /**
   * The ID of the price
   */
  id: string;
  /**
   * Time at which the object was created
   */
  createdAt: number;
  /**
   * Has the value true if the object exists in live mode or the value false if the object exists in test mode
   */
  livemode: boolean;
  /**
   * The type of the price - either 'one_time' or 'recurring'
   */
  type: Stripe.Price.Type;
  /**
   * The lookup key (if any) used by the customer to identify this price object
   */
  lookupKey?: string;
}
/**
 * Create and manage Stripe prices for products
 *
 * @example
 * // Create a one-time fixed price for a product
 * const oneTimePrice = await Price("basic-license", {
 *   currency: "usd",
 *   unitAmount: 2999, // $29.99
 *   product: "prod_xyz"
 * });
 *
 * @example
 * // Create a recurring subscription price with fixed monthly billing
 * const subscriptionPrice = await Price("pro-monthly", {
 *   currency: "usd",
 *   unitAmount: 1499, // $14.99/month
 *   product: "prod_xyz",
 *   recurring: {
 *     interval: "month",
 *     usageType: "licensed"
 *   }
 * });
 *
 * @example
 * // Create a metered price for usage-based billing
 * const meteredPrice = await Price("storage", {
 *   currency: "usd",
 *   unitAmount: 25, // $0.25 per GB
 *   product: "prod_xyz",
 *   recurring: {
 *     interval: "month",
 *     usageType: "metered",
 *     aggregateUsage: "sum"
 *   }
 * });
 *
 * @example
 * // Create a tiered price with tax behavior
 * const tieredPrice = await Price("enterprise", {
 *   currency: "usd",
 *   unitAmount: 10000, // $100.00
 *   product: "prod_xyz",
 *   billingScheme: "tiered",
 *   taxBehavior: "exclusive",
 *   metadata: {
 *     tier: "enterprise",
 *     features: "all"
 *   }
 * });
 */
export const Price = Resource(
  "stripe::Price",
  async function (
    this: Context<Price>,
    id: string,
    props: PriceProps,
  ): Promise<Price> {
    // Get Stripe API key from context or environment
    const apiKey = process.env.STRIPE_API_KEY;
    if (!apiKey) {
      throw new Error("STRIPE_API_KEY environment variable is required");
    }
    // Initialize Stripe client
    const stripe = new Stripe(apiKey);
    if (this.phase === "delete") {
      try {
        if (this.phase === "delete" && this.output?.id) {
          // Prices can't be deleted, only deactivated
          await stripe.prices.update(this.output.id, { active: false });
        }
      } catch (error) {
        // Ignore if the price doesn't exist
        console.error("Error deactivating price:", error);
      }
      return this.destroy();
    }
    try {
      let price: Stripe.Price;
      if (this.phase === "update" && this.output?.id) {
        // Update existing price (limited properties can be updated)
        price = await stripe.prices.update(this.output.id, {
          active: props.active,
          metadata: props.metadata,
          nickname: props.nickname,
          lookup_key: props.lookupKey,
          transfer_lookup_key: props.transferLookupKey,
        });
      } else {
        // Create new price
        const createParams: Stripe.PriceCreateParams = {
          currency: props.currency,
          product: props.product,
          active: props.active,
          billing_scheme: props.billingScheme,
          nickname: props.nickname,
          metadata: props.metadata,
          tax_behavior: props.taxBehavior,
          lookup_key: props.lookupKey,
          transfer_lookup_key: props.transferLookupKey,
        };
        // Add unit amount fields
        if (props.unitAmount !== undefined) {
          createParams.unit_amount = props.unitAmount;
        } else if (props.unitAmountDecimal !== undefined) {
          createParams.unit_amount_decimal = props.unitAmountDecimal;
        }
        // Add recurring parameters if present
        if (props.recurring) {
          createParams.recurring = {
            interval: props.recurring.interval,
            interval_count: props.recurring.intervalCount,
            usage_type: props.recurring.usageType,
            aggregate_usage: props.recurring.aggregateUsage,
          };
        }
        price = await stripe.prices.create(createParams);
      }
      // Transform Stripe recurring object to our format
      const recurring = price.recurring
        ? {
            interval: price.recurring
              .interval as Stripe.PriceCreateParams.Recurring.Interval,
            intervalCount: price.recurring.interval_count,
            usageType: price.recurring
              .usage_type as Stripe.PriceCreateParams.Recurring.UsageType,
            aggregateUsage: price.recurring
              .aggregate_usage as Stripe.PriceCreateParams.Recurring.AggregateUsage,
          }
        : undefined;
      // Map Stripe API response to our output format
      return this({
        id: price.id,
        product:
          typeof price.product === "string" ? price.product : price.product.id,
        currency: price.currency,
        unitAmount: price.unit_amount || undefined,
        unitAmountDecimal: price.unit_amount_decimal || undefined,
        active: price.active,
        billingScheme: price.billing_scheme as BillingScheme,
        nickname: price.nickname || undefined,
        recurring: recurring,
        metadata: price.metadata || undefined,
        taxBehavior: price.tax_behavior as TaxBehavior,
        createdAt: price.created,
        livemode: price.livemode,
        type: price.type as Stripe.Price.Type,
        lookupKey: price.lookup_key || undefined,
      });
    } catch (error) {
      console.error("Error creating/updating price:", error);
      throw error;
    }
  },
);
</file>

<file path="alchemy/test/cloudflare/wrangler-json.test.ts">
import { describe, expect } from "bun:test";
import * as fs from "node:fs/promises";
import * as path from "node:path";
import { alchemy } from "../../src/alchemy.js";
import { Ai } from "../../src/cloudflare/ai.js";
import { DurableObjectNamespace } from "../../src/cloudflare/durable-object-namespace.js";
import { Worker } from "../../src/cloudflare/worker.js";
import { WranglerJson } from "../../src/cloudflare/wrangler.json.js";
import { destroy } from "../../src/destroy.js";
import { BRANCH_PREFIX } from "../util.js";
import { Workflow } from "../../src/cloudflare/workflow.js";
import "../../src/test/bun.js";
const test = alchemy.test(import.meta, {
  prefix: BRANCH_PREFIX,
});
const esmWorkerScript = `
  export default {
    async fetch(request, env, ctx) {
      return new Response('Hello ESM world!', { status: 200 });
    }
  };
`;
const doWorkerScript = `
  export class Counter {
    constructor(state, env) {
      this.state = state;
      this.env = env;
      this.counter = 0;
    }
    async fetch(request) {
      this.counter++;
      return new Response('Counter: ' + this.counter, { status: 200 });
    }
  }
  export class SqliteCounter {
    constructor(state, env) {
      this.state = state;
      this.env = env;
    }
    async fetch(request) {
      let value = await this.state.storage.get("counter") || 0;
      value++;
      await this.state.storage.put("counter", value);
      return new Response('SqliteCounter: ' + value, { status: 200 });
    }
  }
  export default {
    async fetch(request, env, ctx) {
      const url = new URL(request.url);
      if (url.pathname === '/counter') {
        const id = env.COUNTER.idFromName('default');
        const stub = env.COUNTER.get(id);
        return stub.fetch(request);
      }
      if (url.pathname === '/sqlite-counter') {
        const id = env.SQLITE_COUNTER.idFromName('default');
        const stub = env.SQLITE_COUNTER.get(id);
        return stub.fetch(request);
      }
      return new Response('Hello DO world!', { status: 200 });
    }
  };
`;
const wfWorkerScript = `
// Import the Workflow definition
import {
  WorkflowEntrypoint,
  type WorkflowEvent,
  type WorkflowStep,
} from "cloudflare:workers";
// just to test bundling
import { NonRetryableError } from "cloudflare:workflows";
// Create your own class that implements a Workflow
export class TestWorkflow extends WorkflowEntrypoint<any, any> {
  // Define a run() method
  async run(_event: WorkflowEvent<any>, step: WorkflowStep) {
    // Define one or more steps that optionally return state.
    await step.do("first step", async () => {
      console.log("WORKFLOW STEP 1");
    });
    await step.do("second step", async () => {
      console.log("WORKFLOW STEP 2");
    });
    return { status: "completed" };
  }
}
export default {
  async fetch(request, env, ctx) {
    return new Response('Hello Workflow world!', { status: 200 });
  }
};
`;
describe("WranglerJson Resource", () => {
  describe("with worker", () => {
    test("infers spec from worker", async (scope) => {
      const name = `${BRANCH_PREFIX}-test-worker-esm-1`;
      const tempDir = path.join(".out", "alchemy-entrypoint-test");
      const entrypoint = path.join(tempDir, "worker.ts");
      try {
        // Create a temporary directory for the entrypoint file
        await fs.rm(tempDir, { recursive: true, force: true });
        await fs.mkdir(tempDir, { recursive: true });
        await fs.writeFile(entrypoint, esmWorkerScript);
        const worker = await Worker(name, {
          format: "esm",
          entrypoint,
          compatibilityFlags: ["nodejs_compat"],
        });
        const { spec } = await WranglerJson(
          `${BRANCH_PREFIX}-test-wrangler-json-1`,
          { worker },
        );
        expect(spec.name).toEqual(name);
        expect(spec.main).toEqual(entrypoint);
        expect(spec.compatibility_date).toEqual(worker.compatibilityDate);
        expect(spec.compatibility_flags).toEqual(worker.compatibilityFlags);
      } finally {
        await fs.rm(tempDir, { recursive: true, force: true });
        await destroy(scope);
      }
    });
    test("requires entrypoint", async (scope) => {
      const name = `${BRANCH_PREFIX}-test-worker-esm-2`;
      try {
        const worker = await Worker(name, {
          format: "esm",
          script: esmWorkerScript,
        });
        const id = `${BRANCH_PREFIX}-test-wrangler-json-2`;
        await expect(async () => await WranglerJson(id, { worker })).toThrow(
          "Worker must have an entrypoint to generate a wrangler.json",
        );
      } finally {
        await destroy(scope);
      }
    });
    test("with browser binding", async (scope) => {
      const name = `${BRANCH_PREFIX}-test-worker-browser`;
      const tempDir = path.join(".out", "alchemy-browser-test");
      const entrypoint = path.join(tempDir, "worker.ts");
      try {
        // Create a temporary directory for the entrypoint file
        await fs.rm(tempDir, { recursive: true, force: true });
        await fs.mkdir(tempDir, { recursive: true });
        await fs.writeFile(entrypoint, esmWorkerScript);
        const worker = await Worker(name, {
          format: "esm",
          entrypoint,
          bindings: {
            browser: { type: "browser" },
          },
        });
        const { spec } = await WranglerJson(
          `${BRANCH_PREFIX}-test-wrangler-json-browser`,
          { worker },
        );
        expect(spec.name).toEqual(name);
        expect(spec.browser).toBeDefined();
        expect(spec.browser?.binding).toEqual("browser");
      } finally {
        await fs.rm(tempDir, { recursive: true, force: true });
        await destroy(scope);
      }
    });
    test("with AI binding", async (scope) => {
      const name = `${BRANCH_PREFIX}-test-worker-ai`;
      const tempDir = path.join(".out", "alchemy-ai-test");
      const entrypoint = path.join(tempDir, "worker.ts");
      try {
        // Create a temporary directory for the entrypoint file
        await fs.rm(tempDir, { recursive: true, force: true });
        await fs.mkdir(tempDir, { recursive: true });
        await fs.writeFile(entrypoint, esmWorkerScript);
        const worker = await Worker(name, {
          format: "esm",
          entrypoint,
          bindings: {
            AI: new Ai(),
          },
        });
        const { spec } = await WranglerJson(
          `${BRANCH_PREFIX}-test-wrangler-json-ai`,
          { worker },
        );
        expect(spec.name).toEqual(name);
        expect(spec.ai).toBeDefined();
        expect(spec.ai?.binding).toEqual("AI");
      } finally {
        await fs.rm(tempDir, { recursive: true, force: true });
        await destroy(scope);
      }
    });
    test("with durable object bindings", async (scope) => {
      const name = `${BRANCH_PREFIX}-test-worker-do`;
      const tempDir = path.join(".out", "alchemy-do-test");
      const entrypoint = path.join(tempDir, "worker.ts");
      try {
        // Create a temporary directory for the entrypoint file
        await fs.rm(tempDir, { recursive: true, force: true });
        await fs.mkdir(tempDir, { recursive: true });
        await fs.writeFile(entrypoint, doWorkerScript);
        // Create durable object namespaces
        const counterNamespace = new DurableObjectNamespace("counter", {
          className: "Counter",
          scriptName: name,
          sqlite: false,
        });
        const sqliteCounterNamespace = new DurableObjectNamespace(
          "sqlite-counter",
          {
            className: "SqliteCounter",
            scriptName: name,
            sqlite: true,
          },
        );
        const worker = await Worker(name, {
          format: "esm",
          entrypoint,
          bindings: {
            COUNTER: counterNamespace,
            SQLITE_COUNTER: sqliteCounterNamespace,
          },
        });
        const { spec } = await WranglerJson(
          `${BRANCH_PREFIX}-test-wrangler-json-do`,
          { worker },
        );
        // Verify the worker name and entrypoint
        expect(spec.name).toEqual(name);
        expect(spec.main).toEqual(entrypoint);
        // Verify the durable object bindings
        expect(spec.durable_objects).toBeDefined();
        expect(spec.durable_objects?.bindings).toHaveLength(2);
        // Find Counter binding
        const counterBinding = spec.durable_objects?.bindings.find(
          (b) => b.class_name === "Counter",
        );
        expect(counterBinding).toBeDefined();
        expect(counterBinding?.name).toEqual("COUNTER");
        expect(counterBinding?.script_name).toEqual(name);
        // Find SqliteCounter binding
        const sqliteCounterBinding = spec.durable_objects?.bindings.find(
          (b) => b.class_name === "SqliteCounter",
        );
        expect(sqliteCounterBinding).toBeDefined();
        expect(sqliteCounterBinding?.name).toEqual("SQLITE_COUNTER");
        expect(sqliteCounterBinding?.script_name).toEqual(name);
        // Verify migrations
        expect(spec.migrations).toBeDefined();
        expect(spec.migrations?.length).toEqual(1);
        expect(spec.migrations?.[0].tag).toEqual("v1");
        // Verify new_classes contains Counter
        expect(spec.migrations?.[0].new_classes).toContain("Counter");
        expect(spec.migrations?.[0].new_classes?.length).toEqual(1);
        // Verify new_sqlite_classes contains SqliteCounter
        expect(spec.migrations?.[0].new_sqlite_classes).toContain(
          "SqliteCounter",
        );
        expect(spec.migrations?.[0].new_sqlite_classes?.length).toEqual(1);
      } finally {
        await fs.rm(tempDir, { recursive: true, force: true });
        await destroy(scope);
      }
    });
    test("with workflows", async (scope) => {
      const name = `${BRANCH_PREFIX}-test-worker-wf`;
      const tempDir = path.join(".out", "alchemy-wf-test");
      const entrypoint = path.join(tempDir, "worker.ts");
      try {
        // Create a temporary directory for the entrypoint file
        await fs.rm(tempDir, { recursive: true, force: true });
        await fs.mkdir(tempDir, { recursive: true });
        await fs.writeFile(entrypoint, wfWorkerScript);
        // Create durable object namespaces
        const workflow = new Workflow("test-workflow", {
          className: "TestWorkflow",
          workflowName: "test-workflow",
        });
        const worker = await Worker(name, {
          format: "esm",
          entrypoint,
          bindings: {
            WF: workflow,
          },
        });
        const { spec } = await WranglerJson(
          `${BRANCH_PREFIX}-test-wrangler-json-wf`,
          { worker },
        );
        expect(spec.workflows).toBeDefined();
        expect(spec.workflows?.length).toEqual(1);
        expect(spec.workflows?.[0].name).toEqual("test-workflow");
        expect(spec.workflows?.[0].binding).toEqual("WF");
        expect(spec.workflows?.[0].class_name).toEqual("TestWorkflow");
      } finally {
        await fs.rm(tempDir, { recursive: true, force: true });
        await destroy(scope);
      }
    });
  });
});
</file>

<file path="alchemy-web/docs/providers/stripe/meter.md">
# Meter

The Meter resource lets you create and manage [Stripe Billing Meters](https://stripe.com/docs/billing/usage-based-billing/meters) for your Stripe account. Meters define how usage of a product is measured and aggregated for billing purposes.

## Minimal Example

Create a basic meter to track API calls:

```ts
import { Meter } from "alchemy/stripe";

const apiCallMeter = await Meter("apiUsageMeter", {
  displayName: "API Call Usage",
  eventName: "api.call.recorded",
  defaultAggregation: {
    formula: "sum"
  },
  customerMapping: {
    eventPayloadKey: "customer_id",
    type: "by_id"
  },
  valueSettings: {
    eventPayloadKey: "count"
  }
});
```

## Last-Value Meter

Create a meter that captures the last reported value during a billing period:

```ts
import { Meter } from "alchemy/stripe";

const storageMeter = await Meter("dataStorageMeter", {
  displayName: "Data Storage GB",
  eventName: "data.storage.reported",
  defaultAggregation: {
    formula: "last_during_period"
  },
  customerMapping: {
    eventPayloadKey: "user_stripe_id",
    type: "by_id"
  },
  valueSettings: {
    eventPayloadKey: "gb_used"
  }
});
```

## Inactive Meter

Create a meter that is initially inactive:

```ts
import { Meter } from "alchemy/stripe";

const inactiveFeatureMeter = await Meter("featureUsageMeter", {
  displayName: "Feature Usage",
  eventName: "feature.usage.recorded",
  status: "inactive",
  defaultAggregation: {
    formula: "sum"
  },
  customerMapping: {
    eventPayloadKey: "customer_id",
    type: "by_id"
  },
  valueSettings: {
    eventPayloadKey: "feature_count"
  }
});
```
</file>

<file path="examples/cloudflare-worker/src/workflow.ts">
// Import the Workflow definition
import {
  WorkflowEntrypoint,
  type WorkflowEvent,
  type WorkflowStep,
} from "cloudflare:workers";
// just to test bundling
import { NonRetryableError } from "cloudflare:workflows";
// Create your own class that implements a Workflow
export class OFACWorkflow extends WorkflowEntrypoint<any, Params> {
  // Define a run() method
  async run(_event: WorkflowEvent<Params>, step: WorkflowStep) {
    // Define one or more steps that optionally return state.
    await step.do("my first step", async () => {
      console.log("OFAC WORKFLOW STEP 1");
    });
    await step.do("my second step", async () => {
      console.log("OFAC WORKFLOW STEP 2");
    });
    throw new NonRetryableError("test");
  }
}
</file>

<file path="alchemy/test/stripe/meter.test.ts">
import { beforeAll, describe, expect } from "bun:test";
import Stripe from "stripe";
import { alchemy } from "../../src/alchemy.js";
import { destroy } from "../../src/destroy.js";
import {
  Meter,
  type Meter as MeterOutput,
  type MeterProps,
} from "../../src/stripe/meter.js";
import "../../src/test/bun.js";
const BRANCH_PREFIX = process.env.BRANCH_PREFIX || "local";
let stripeClient: Stripe;
const test = alchemy.test(import.meta);
describe("Stripe Meter Resource", () => {
  const testRunSuffix = Date.now();
  const baseLogicalId = `${BRANCH_PREFIX}-test-stripe-meter`;
  const generateMeterDisplayName = (suffix: string | number) =>
    `Alchemy Test Meter ${suffix}`;
  beforeAll(() => {
    const apiKey = process.env.STRIPE_API_KEY;
    if (!apiKey) {
      throw new Error(
        "STRIPE_API_KEY environment variable is required for Stripe integration tests.",
      );
    }
    stripeClient = new Stripe(apiKey);
  });
  test("create, update status, and delete meter", async (scope) => {
    const logicalId = `${baseLogicalId}-${testRunSuffix}`;
    const initialDisplayName = generateMeterDisplayName(testRunSuffix);
    let meterOutput: MeterOutput | undefined;
    const baseTestProps: Omit<MeterProps, "displayName" | "status"> = {
      eventName: `alchemy.test.event.${testRunSuffix}`,
      defaultAggregation: { formula: "sum" },
      customerMapping: { eventPayloadKey: "stripe_user_id", type: "by_id" },
      valueSettings: { eventPayloadKey: "units" },
    };
    try {
      // --- CREATE ---
      const createProps: MeterProps = {
        ...baseTestProps,
        displayName: initialDisplayName,
      };
      meterOutput = await Meter(logicalId, createProps);
      expect(meterOutput.id).toBeTruthy();
      expect(meterOutput.displayName).toEqual(initialDisplayName);
      expect(meterOutput.eventName).toEqual(createProps.eventName);
      expect(meterOutput.status).toEqual("active"); // Default creation status
      // Verify creation directly via Stripe API
      const fetchedMeterCreate = await stripeClient.billing.meters.retrieve(
        meterOutput.id,
      );
      expect(fetchedMeterCreate.id).toEqual(meterOutput.id);
      expect(fetchedMeterCreate.display_name).toEqual(initialDisplayName);
      expect(fetchedMeterCreate.status).toEqual("active");
      // --- UPDATE (Deactivate) ---
      const deactivateProps: MeterProps = {
        ...createProps, // Includes all original immutable props
        status: "inactive",
      };
      meterOutput = await Meter(logicalId, deactivateProps);
      expect(meterOutput.id).toEqual(fetchedMeterCreate.id);
      expect(meterOutput.status).toEqual("inactive");
      // Verify deactivation via Stripe API
      const fetchedMeterDeactivated =
        await stripeClient.billing.meters.retrieve(meterOutput.id);
      expect(fetchedMeterDeactivated.status).toEqual("inactive");
      // --- UPDATE (Reactivate) ---
      const reactivateProps: MeterProps = {
        ...createProps, // Includes all original immutable props
        status: "active",
      };
      meterOutput = await Meter(logicalId, reactivateProps);
      expect(meterOutput.id).toEqual(fetchedMeterCreate.id);
      expect(meterOutput.status).toEqual("active");
      // Verify reactivation via Stripe API
      const fetchedMeterReactivated =
        await stripeClient.billing.meters.retrieve(meterOutput.id);
      expect(fetchedMeterReactivated.status).toEqual("active");
    } finally {
      await destroy(scope);
      if (meterOutput?.id) {
        // Verify meter is inactive after destroy (as Meter resource deactivates)
        try {
          const finalState = await stripeClient.billing.meters.retrieve(
            meterOutput.id,
          );
          expect(finalState.status).toEqual("inactive");
        } catch (error: any) {
          // If it's resource_missing, it's unexpected for Stripe meters (they deactivate)
          if (error.code === "resource_missing")
            throw new Error(
              `Meter ${meterOutput.id} was unexpectedly missing after destroy.`,
            );
          throw error; // rethrow other errors
        }
      }
    }
  });
  test("create meter with inactive status", async (scope) => {
    const inactiveSuffix = `create-inactive-${testRunSuffix}`;
    const logicalId = `${baseLogicalId}-${inactiveSuffix}`;
    const displayName = generateMeterDisplayName(inactiveSuffix);
    let meterOutput: MeterOutput | undefined;
    const createInactiveProps: MeterProps = {
      displayName: displayName,
      eventName: `alchemy.test.inactive.${inactiveSuffix}`,
      defaultAggregation: { formula: "count" },
      customerMapping: {
        eventPayloadKey: "customer_id_inactive",
        type: "by_id",
      },
      valueSettings: { eventPayloadKey: "count_val_inactive" },
      status: "inactive",
    };
    try {
      meterOutput = await Meter(logicalId, createInactiveProps);
      expect(meterOutput.id).toBeTruthy();
      expect(meterOutput.displayName).toEqual(displayName);
      expect(meterOutput.status).toEqual("inactive");
      // Verify via Stripe API
      const fetchedMeter = await stripeClient.billing.meters.retrieve(
        meterOutput.id,
      );
      expect(fetchedMeter.status).toEqual("inactive");
    } finally {
      await destroy(scope);
      if (meterOutput?.id) {
        try {
          const finalState = await stripeClient.billing.meters.retrieve(
            meterOutput.id,
          );
          expect(finalState.status).toEqual("inactive"); // Should remain inactive
        } catch (error: any) {
          if (error.code === "resource_missing")
            throw new Error(
              `Meter ${meterOutput.id} was unexpectedly missing after destroy (create inactive).`,
            );
          throw error;
        }
      }
    }
  });
  test("should fail to update immutable properties", async (scope) => {
    const immutableSuffix = `immutable-${testRunSuffix}`;
    const logicalId = `${baseLogicalId}-${immutableSuffix}`;
    const initialDisplayName = generateMeterDisplayName(immutableSuffix);
    let meterOutput: MeterOutput | undefined;
    const initialCreateProps: MeterProps = {
      displayName: initialDisplayName,
      eventName: `alchemy.test.immutable.${immutableSuffix}`,
      defaultAggregation: { formula: "sum" },
      customerMapping: { eventPayloadKey: "cust_immutable", type: "by_id" },
      valueSettings: { eventPayloadKey: "val_immutable" },
    };
    try {
      // Create the meter first
      meterOutput = await Meter(logicalId, initialCreateProps);
      expect(meterOutput.id).toBeTruthy();
      expect(meterOutput.displayName).toEqual(initialDisplayName);
      // Attempt to update an immutable property (e.g., displayName)
      const attemptUpdateProps: MeterProps = {
        ...initialCreateProps, // Keep other props the same as original
        displayName: "New Attempted Immutable Display Name",
        status: "active", // Keep status or specify to avoid unrelated changes
      };
      expect(Meter(logicalId, attemptUpdateProps)).rejects.toThrow(
        /Attempted to update immutable properties/,
      );
    } finally {
      await destroy(scope);
      // Cleanup verification (meter should be inactive if created)
      if (meterOutput?.id) {
        try {
          const finalState = await stripeClient.billing.meters.retrieve(
            meterOutput.id,
          );
          expect(finalState.status).toEqual("inactive");
        } catch (error: any) {
          if (error.code === "resource_missing")
            throw new Error(
              `Meter ${meterOutput.id} was unexpectedly missing after destroy (immutable test).`,
            );
          throw error;
        }
      }
    }
  });
});
</file>

<file path="alchemy/package.json">
{
  "name": "alchemy",
  "version": "0.15.10",
  "type": "module",
  "module": "./lib/index.js",
  "scripts": {
    "publish:npm": "cp ../README.md . && rm -rf ./*.tsbuildinfo && rm -rf ./lib && tsc -b && npm publish && rm README.md",
    "docs:gen": "rm -rf ./docs && typedoc"
  },
  "files": [
    "lib",
    "src"
  ],
  "exports": {
    ".": "./lib/index.js",
    "./ai": "./lib/ai/index.js",
    "./aws": "./lib/aws/index.js",
    "./aws/oidc": "./lib/aws/oidc/index.js",
    "./cloudflare": "./lib/cloudflare/index.js",
    "./dns": "./lib/dns/index.js",
    "./esbuild": "./lib/esbuild/index.js",
    "./fs": "./lib/fs/index.js",
    "./github": "./lib/github/index.js",
    "./neon": "./lib/neon/index.js",
    "./os": "./lib/os/index.js",
    "./shadcn": "./lib/shadcn/index.js",
    "./stripe": "./lib/stripe/index.js",
    "./test/bun": "./lib/test/bun.js",
    "./web/astro": "./lib/web/astro/index.js",
    "./web/tailwind": "./lib/web/tailwind/index.js",
    "./web/vite": "./lib/web/vite/index.js",
    "./web/vitepress": "./lib/web/vitepress/index.js"
  },
  "dependencies": {
    "unenv": "2.0.0-rc.15"
  },
  "peerDependencies": {
    "@ai-sdk/openai": "^1.1.9",
    "@ai-sdk/openai-compatible": "^0.2.2",
    "@aws-sdk/client-dynamodb": "^3.0.0",
    "@aws-sdk/client-iam": "^3.0.0",
    "@aws-sdk/client-lambda": "^3.0.0",
    "@aws-sdk/client-s3": "^3.0.0",
    "@aws-sdk/client-sagemaker": "^3.0.0",
    "@aws-sdk/client-ses": "^3.0.0",
    "@aws-sdk/client-sesv2": "^3.0.0",
    "@aws-sdk/client-sqs": "^3.0.0",
    "@aws-sdk/client-sts": "^3.0.0",
    "@cloudflare/unenv-preset": "^2.3.1",
    "@cloudflare/workers-shared": "^0.17.5",
    "@iarna/toml": "^2.2.5",
    "@octokit/rest": "^21.1.1",
    "ai": "^4.0.0",
    "arktype": "^2.0.0",
    "aws4fetch": "^1.0.20",
    "cloudflare": "^4.0.0",
    "diff": "^7.0.0",
    "esbuild": "^0.25.1",
    "glob": "^10.0.0",
    "hono": "^4.0.0",
    "jszip": "^3.0.0",
    "libsodium-wrappers": "^0.7.15",
    "prettier": "^3.0.0",
    "stripe": "^17.0.0",
    "turndown": "^7.0.0",
    "xdg-app-paths": "^8.0.0",
    "yaml": "^2.0.0",
    "zod": "^3.0.0"
  },
  "devDependencies": {
    "@ai-sdk/anthropic": "^1.1.6",
    "@ai-sdk/openai": "^1.1.9",
    "@asteasolutions/zod-to-openapi": "^7.3.0",
    "@aws-sdk/client-s3": "3.726.1",
    "@biomejs/biome": "^1.9.4",
    "@cloudflare/puppeteer": "^1.0.2",
    "@cloudflare/workers-types": "^4.20250303.0",
    "@iarna/toml": "^2.2.5",
    "@octokit/rest": "^21.1.1",
    "@types/bun": "latest",
    "@types/diff": "^5.0.0",
    "@types/libsodium-wrappers": "^0.7.14",
    "@types/node": "latest",
    "@types/turndown": "^5.0.5",
    "ai": "^4.1.16",
    "arktype": "^2.1.16",
    "braintrust": "^0.0.201",
    "change-case": "^5.4.4",
    "cloudflare": "^4.2.0",
    "libsodium-wrappers": "^0.7.15",
    "openpgp": "^6.1.0",
    "prettier": "^3.5.3",
    "turndown": "^7.2.0",
    "typedoc": "^0.28.1",
    "typedoc-plugin-markdown": "^4.6.0",
    "typescript": "latest",
    "vite": "^6.0.7",
    "vitepress": "^1.6.3",
    "wrangler": "^3.114.0",
    "xdg-app-paths": "^8.3.0",
    "yaml": "^2.7.1"
  }
}
</file>

</files>
